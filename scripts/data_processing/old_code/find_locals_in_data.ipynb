{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find locals in data\n",
    "Let's look for locals in the mined data.\n",
    "\n",
    "We're restricted to the JSON data which actually has user bio information, which is only (?) the data from the archive. This is sparse! We may have to re-mine the historical (GetOldTweets) data for the full JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-02-18_Sep-02-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Aug-31-18_Aug-31-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-04-18_Sep-04-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-03-18_Sep-03-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-05-18_Sep-05-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-08-18_Sep-08-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-01-18_Sep-01-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-07-18_Sep-07-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-06-18_Sep-06-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Aug-30-18_Aug-30-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-09-18_Sep-09-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-10-18_Sep-10-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-11-18_Sep-11-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-12-18_Sep-12-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-13-18_Sep-13-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-14-18_Sep-14-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-15-18_Sep-15-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-16-18_Sep-16-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-17-18_Sep-17-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-18-18_Sep-18-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-19-18_Sep-19-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-20-18_Sep-20-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-21-18_Sep-21-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-22-18_Sep-22-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-23-18_Sep-23-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-24-18_Sep-24-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-25-18_Sep-25-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneFlorence,#Florence_Sep-26-18_Sep-26-18.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-19-17_Aug-19-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-27-17_Aug-27-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-31-17_Aug-31-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-17-17_Aug-17-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-20-17_Aug-20-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-18-17_Aug-18-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-24-17_Aug-24-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-28-17_Aug-28-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-22-17_Aug-22-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-01-17_Sep-01-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-12-17_Sep-12-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-13-17_Sep-13-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-10-17_Sep-10-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-08-17_Sep-08-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-14-17_Sep-14-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-09-17_Sep-09-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-29-17_Aug-29-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-25-17_Aug-25-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-05-17_Sep-05-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-26-17_Aug-26-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-07-17_Sep-07-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-02-17_Sep-02-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-06-17_Sep-06-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-30-17_Aug-30-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-11-17_Sep-11-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-03-17_Sep-03-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-23-17_Aug-23-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-21-17_Aug-21-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-04-17_Sep-04-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-19-17_Aug-19-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-27-17_Aug-27-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-31-17_Aug-31-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-17-17_Aug-17-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-20-17_Aug-20-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-18-17_Aug-18-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-24-17_Aug-24-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-28-17_Aug-28-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-22-17_Aug-22-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-01-17_Sep-01-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-12-17_Sep-12-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-13-17_Sep-13-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-10-17_Sep-10-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-08-17_Sep-08-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-14-17_Sep-14-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-09-17_Sep-09-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-29-17_Aug-29-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-25-17_Aug-25-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-05-17_Sep-05-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-26-17_Aug-26-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-07-17_Sep-07-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-02-17_Sep-02-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-06-17_Sep-06-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-30-17_Aug-30-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-11-17_Sep-11-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-03-17_Sep-03-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-23-17_Aug-23-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Aug-21-17_Aug-21-17.gz\n",
      "../../data/mined_tweets/archive_#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_Sep-04-17_Sep-04-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-05-17_Oct-05-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-23-17_Sep-23-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-24-17_Sep-24-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-29-17_Sep-29-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-04-17_Oct-04-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-02-17_Oct-02-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-22-17_Oct-22-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-07-17_Oct-07-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-21-17_Oct-21-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-12-17_Oct-12-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-01-17_Oct-01-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-06-17_Oct-06-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-11-17_Oct-11-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-25-17_Oct-25-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-18-17_Sep-18-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-09-17_Oct-09-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-15-17_Oct-15-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-18-17_Oct-18-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-10-17_Oct-10-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-23-17_Oct-23-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-03-17_Oct-03-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-25-17_Sep-25-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-13-17_Oct-13-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-30-17_Oct-30-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-30-17_Sep-30-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-27-17_Sep-27-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-26-17_Sep-26-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-28-17_Sep-28-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-29-17_Oct-29-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-14-17_Oct-14-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-20-17_Sep-20-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-19-17_Oct-19-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-22-17_Sep-22-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-27-17_Oct-27-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-24-17_Oct-24-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-28-17_Oct-28-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-20-17_Oct-20-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-19-17_Sep-19-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-17-17_Oct-17-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-08-17_Oct-08-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Sep-21-17_Sep-21-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-26-17_Oct-26-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-16-17_Oct-16-17.gz\n",
      "../../data/mined_tweets/archive_#Maria,#HurricaneMaria,#HuracanMaria,#PuertoRico_Oct-31-17_Oct-31-17.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-07-18_Oct-07-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-08-18_Oct-08-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-11-18_Oct-11-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-12-18_Oct-12-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-09-18_Oct-09-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-10-18_Oct-10-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-14-18_Oct-14-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-13-18_Oct-13-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-15-18_Oct-15-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-16-18_Oct-16-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-17-18_Oct-17-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-18-18_Oct-18-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-19-18_Oct-19-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-20-18_Oct-20-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-22-18_Oct-22-18.gz\n",
      "../../data/mined_tweets/archive_#HurricaneMichael,#Michael_Oct-23-18_Oct-23-18.gz\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "data_dir = '../../data/mined_tweets/'\n",
    "event_names = ['florence', 'harvey', 'irma', 'maria', 'michael']\n",
    "archive_files = []\n",
    "for e in event_names:\n",
    "    matcher_e = re.compile('archive_.*#%s[_,]'%(e))\n",
    "    archive_files_e = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if matcher_e.search(f.lower()) is not None]\n",
    "    archive_files += archive_files_e\n",
    "print('\\n'.join(archive_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 0 tweets\n",
      "processed 0/146 files\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 10/146 files\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 20/146 files\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 30/146 files\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 10000 tweets\n",
      "processed 11000 tweets\n",
      "processed 12000 tweets\n",
      "processed 40/146 files\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 10000 tweets\n",
      "processed 11000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 50/146 files\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 10000 tweets\n",
      "processed 11000 tweets\n",
      "processed 12000 tweets\n",
      "processed 13000 tweets\n",
      "processed 14000 tweets\n",
      "processed 15000 tweets\n",
      "processed 16000 tweets\n",
      "processed 17000 tweets\n",
      "processed 18000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 0 tweets\n",
      "processed 60/146 files\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 10000 tweets\n",
      "processed 11000 tweets\n",
      "processed 12000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 70/146 files\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 10000 tweets\n",
      "processed 11000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 80/146 files\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 4000 tweets\n",
      "processed 5000 tweets\n",
      "processed 6000 tweets\n",
      "processed 7000 tweets\n",
      "processed 8000 tweets\n",
      "processed 9000 tweets\n",
      "processed 10000 tweets\n",
      "processed 11000 tweets\n",
      "processed 12000 tweets\n",
      "processed 13000 tweets\n",
      "processed 14000 tweets\n",
      "processed 15000 tweets\n",
      "processed 16000 tweets\n",
      "processed 17000 tweets\n",
      "processed 18000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 90/146 files\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 100/146 files\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 110/146 files\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 120/146 files\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 130/146 files\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 2000 tweets\n",
      "processed 3000 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 1000 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 140/146 files\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n",
      "processed 0 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/site-packages/ipykernel_launcher.py:50: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "def load_json(x):\n",
    "    \"\"\"\n",
    "    Try to load with literal_eval first\n",
    "    then json.loads if that fails. UGH\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x_json = literal_eval(x)\n",
    "    except Exception as e:    \n",
    "        x_json = json.loads(x)\n",
    "    return x_json\n",
    "def clean_tweet(x):\n",
    "    \"\"\"\n",
    "    Clean and extract relevant data.\n",
    "    \"\"\"\n",
    "    x_data = {}\n",
    "    x_data['text'] = x['text']\n",
    "    x_data['id'] = x['id']\n",
    "    x_data['created_at'] = x['created_at']\n",
    "    x_data['favorites'] = x['favorite_count']\n",
    "    x_data['retweets'] = x['retweet_count']\n",
    "    if('retweeted_status' in x):\n",
    "        x_data['is_retweet'] = x['retweeted_status']\n",
    "    x_data['user_id'] = x['user']['id']\n",
    "    x_data['user_name'] = x['user']['screen_name']\n",
    "    x_data['user_loc'] = x['user']['location']\n",
    "    x_data['user_bio'] = x['user']['description']\n",
    "    x_data['user_followers'] = x['user']['followers_count']\n",
    "    x_data['user_followings'] = x['user']['friends_count']\n",
    "    x_data = pd.Series(x_data)\n",
    "    return x_data\n",
    "    \n",
    "import gzip\n",
    "event_hashtag_matcher = re.compile('|'.join(['(?<=#)%s|(?<=#hurricane)%s'%(x, x) for x in event_names]))\n",
    "combined_tweets = []\n",
    "for i, f in enumerate(archive_files):\n",
    "    for j, l in enumerate(gzip.open(f)):\n",
    "        l = l.decode('utf-8').strip()\n",
    "        tweet_data = load_json(l)\n",
    "        tweet_data_clean = clean_tweet(tweet_data)\n",
    "        event_hashtag_matches = event_hashtag_matcher.findall(tweet_data_clean.loc['text'].lower().replace('\\n', ''))\n",
    "        for m in event_hashtag_matches:\n",
    "            tweet_data_clean.loc[m] = True\n",
    "        combined_tweets.append(tweet_data_clean)\n",
    "        if(j % 1000 == 0):\n",
    "            print('processed %d tweets'%(j))\n",
    "    if(i % 10 == 0):\n",
    "        print('processed %d/%d files'%(i, len(archive_files)))\n",
    "combined_tweets = pd.concat(combined_tweets, axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113947/372627 deduplicated tweets\n"
     ]
    }
   ],
   "source": [
    "## remove duplicate tweets\n",
    "combined_tweets_dedup = combined_tweets.drop_duplicates('text', inplace=False)\n",
    "print('%d/%d deduplicated tweets'%(combined_tweets_dedup.shape[0], combined_tweets.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113947 tweets\n",
      "florence=11073\n",
      "harvey=33409\n",
      "irma=39030\n",
      "maria=12242\n",
      "michael=5040\n"
     ]
    }
   ],
   "source": [
    "print('%d tweets'%(combined_tweets_dedup.shape[0]))\n",
    "for e in event_names:\n",
    "    print('%s=%d'%(e, combined_tweets_dedup.loc[:, e].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              Martinique/Skypiea\n",
       "1                    Florida, USA\n",
       "2                            None\n",
       "3    Salt Lake City, Bidhan Nagar\n",
       "4                   United States\n",
       "Name: user_loc, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tweets_dedup.loc[:, 'user_loc'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out the proportion of locals for each event by determining whether they mention a relevant state in their bio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES_SHORT_FULL_LOOKUP = {\n",
    "    'FL' : 'Florida', 'NC' : 'North Carolina', 'SC' : 'South Carolina', \n",
    "    'VA' : 'Virginia', 'GA' : 'Georgia', 'PR' : 'Puerto Rico',\n",
    "    'LA' : 'Louisiana', 'TX' : 'Texas',\n",
    "}\n",
    "DATA_NAME_STATES_SHORT_LOOKUP = {\n",
    "    'florence' : ['FL', 'NC', 'SC', 'VA'],\n",
    "    'irma' : ['FL', 'GA'],\n",
    "    'harvey' : ['TX', 'LA'],\n",
    "    'maria' : ['PR', 'NC'],\n",
    "    'michael' : ['FL', 'GA', 'NC', 'SC']\n",
    "}\n",
    "\n",
    "DATA_NAME_STATES_LONG_LOOKUP = {k : [STATES_SHORT_FULL_LOOKUP[v] for v in vs] for k, vs in DATA_NAME_STATES_SHORT_LOOKUP.items()}\n",
    "DATA_NAME_STATES_LOOKUP = {k : DATA_NAME_STATES_SHORT_LOOKUP[k]+DATA_NAME_STATES_LONG_LOOKUP[k] for k in DATA_NAME_STATES_SHORT_LOOKUP.keys()}\n",
    "data_name_state_descriptor_matchers = {k : re.compile('|'.join([',\\s?%s$|,\\s?%s\\s?,'%(v,v) for v in vs])) for k,vs in DATA_NAME_STATES_LOOKUP.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_STATE_LIST = ['Alabama','Alaska','Arizona','Arkansas','California','Colorado','Connecticut','Delaware','Florida','Georgia','Hawaii','Idaho','Illinois','Indiana','Iowa','Kansas','Kentucky','Louisiana','Maine','Maryland','Massachusetts','Michigan','Minnesota','Mississippi','Missouri','Montana','Nebraska','Nevada','New Hampshire','New Jersey','New Mexico','New York','North Carolina','North Dakota','Ohio','Oklahoma','Oregon','Pennsylvania','Rhode Island','South Carolina','South Dakota','Tennessee','Texas','Utah','Vermont','Virginia','Washington','West Virginia','Wisconsin','Wyoming','District of Columbia','Puerto Rico']\n",
    "FULL_STATE_ABBREVES = ['AK','AL','AR','AZ','CA','CO','CT','DC','DE','FL','GA','GU','HI','IA','ID', 'IL','IN','KS','KY','LA','MA','MD','ME','MH','MI','MN','MO','MS','MT','NC','ND','NE','NH','NJ','NM','NV','NY', 'OH','OK','OR','PA','PR','PW','RI','SC','SD','TN','TX','UT','VA','VI','VT','WA','WI','WV','WY']\n",
    "ALL_STATES = set(FULL_STATE_LIST + FULL_STATE_ABBREVES)\n",
    "DATA_NAME_NON_STATES_LOOKUP = {k : sorted(set(ALL_STATES) - set(vs)) for k, vs in DATA_NAME_STATES_LOOKUP.items()}\n",
    "data_name_non_state_descriptor_matchers = {k : re.compile('(?<=,)\\s?%s$|(?<=,)\\s?%s\\s?(?=,)'%('|'.join(vs), '|'.join(vs))) for k,vs in DATA_NAME_NON_STATES_LOOKUP.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_non_state_descriptor_matchers['florence'].search('yes, FL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: determine local based on city AND state level\n",
    "\n",
    "for e in event_names:\n",
    "    data_name_state_descriptor_matcher = data_name_state_descriptor_matchers[e]\n",
    "    data_name_non_state_descriptor_matcher = data_name_non_state_descriptor_matchers[e]\n",
    "    combined_tweets_dedup = combined_tweets_dedup.assign(**{'user_loc_is_local_%s'%(e) : combined_tweets_dedup.loc[:, 'user_loc'].apply(lambda x: type(x) is str and data_name_state_descriptor_matcher.search(x) is not None)})\n",
    "    combined_tweets_dedup = combined_tweets_dedup.assign(**{'user_loc_is_non_local_%s'%(e) : combined_tweets_dedup.loc[:, 'user_loc'].apply(lambda x: type(x) is str and data_name_non_state_descriptor_matcher.search(x) is not None)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing florence\n",
      "1153/9337 local users\n",
      "2621/9337 non-local users\n",
      "testing harvey\n",
      "2954/29266 local users\n",
      "8720/29266 non-local users\n",
      "testing irma\n",
      "2372/33550 local users\n",
      "7754/33550 non-local users\n",
      "testing maria\n",
      "152/9707 local users\n",
      "2529/9707 non-local users\n",
      "testing michael\n",
      "584/4494 local users\n",
      "1296/4494 non-local users\n"
     ]
    }
   ],
   "source": [
    "for e in event_names:\n",
    "    print('testing %s'%(e))\n",
    "    tweets_e = combined_tweets_dedup[combined_tweets_dedup.loc[:, e]==1]\n",
    "    tweets_e_local = tweets_e[tweets_e.loc[:, 'user_loc_is_local_%s'%(e)]==1]\n",
    "    tweets_e_non_local = tweets_e[tweets_e.loc[:, 'user_loc_is_non_local_%s'%(e)]==1]\n",
    "    print('%d/%d local users'%(tweets_e_local.loc[:, 'user_id'].nunique(), tweets_e.loc[:, 'user_id'].nunique()))\n",
    "    print('%d/%d non-local users'%(tweets_e_non_local.loc[:, 'user_id'].nunique(), tweets_e.loc[:, 'user_id'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the local content qualitatively different from the non-local content?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing event florence\n",
      "sample local tweets:\n",
      "RT @StLucieClerk: And here ðŸŒ€ we go ðŸ¤¦ðŸ¼â€â™‚ï¸! \n",
      "\n",
      "#HurricaneFlorence #HurricaneSeason https://t.co/YYXpcE3aEd\n",
      "RT @katieperalta: Whoa- huge jump over 1.5 hours- now 30k without power in Mecklenburg County #florence https://t.co/VZevZZ7kx7\n",
      "RT @hurrtrackerapp: The brand new 12Z EURO ensemble models continue to show an increasing threat to the U.S. next week from #Florence. In fâ€¦\n",
      "We are supposed to find out at 2pm when classes are cancelled for #Florence and I just canâ€™t bring myself to care about class right now.\n",
      "RT @Natural_Crisis: Video: President #Trump thanks #HurricaneFlorence first responders https://t.co/4KGNU7HvrR https://t.co/xcNw56POJJ\n",
      "I've watched dedicated media, tourism and hospitality pros in NC/SC respond to #HurricaneFlorence. As I talk to theâ€¦ https://t.co/Vpi88HjDDy\n",
      "RT @wxbrad: Here's a look at the timing and impacts from #Florence. #cltwx #ncwx #scwx https://t.co/CS0ezmYUlm\n",
      "RT @WilmOnFilm: Several #OneTreeHill and #UndertheDome actors have taken time to send well wishes to Wilmington as Hurricane #Florence apprâ€¦\n",
      "RT @NWS: Hurricane #Florence is resulting in communication difficulties in some areas. Having multiple ways to receive warnings though thisâ€¦\n",
      "RT @MyNews13: On the latest track, Hurricane #Florence is projected to make landfall somewhere along the Carolina coastline late Thursday nâ€¦\n",
      "RT @austinrye_: For those freaking out about the storm like I was, read this. I really needed it. #HurricaneFlorence https://t.co/J8p1tzA1dJ\n",
      "As crews deploy toward the coast to assist with #HurricaneFlorence, communications is very important. Thanks toâ€¦ https://t.co/WqGch3jBTq\n",
      "#hurricaneflorence Virginia Beach residents need to review their evacuation zone now by entering their home addressâ€¦ https://t.co/4QfqMlggY1\n",
      "Many schools are closed due to #Florence. See a full list here: https://t.co/eDPsk9AYoA #ncwx https://t.co/7MZ4FU1fIu\n",
      "RT @borenbears: Storm Surge: AP Explains the awesome power of water. How it kills and destroys and what that means in #Florence. https://t.â€¦\n",
      "RT @NHC_Atlantic: Here are the 5 PM EDT Friday Key Messages for #Florence https://t.co/tW4KeGdBFb https://t.co/pCCt5U0Ow3\n",
      "RT @AdamOwensTV: This is what it looks like in parts of Morehead City right now as Hurricane #Florence approaches. #WRAL #ncwx @wralweatherâ€¦\n",
      "RT @NWSSERFC: Here is the Decision Support Briefing from the SERFC.  #HurricaneFlorence #vawx #ncwx #scwx\n",
      "https://t.co/vgwoyQk2n2 https://tâ€¦\n",
      "RT @stonyislandboy2: Praying for the Carolinas, VA, AND Maryland!! #HurricaneFlorence\n",
      "#Florence winds swiping the #OuterBanks https://t.co/GlHAUHJAJD\n",
      "\n",
      "sample non-local tweets:\n",
      "RT @offlede: With North Myrtle Beach about 150 miles to the west of the eye of #HurricaneFlorence, the offshore winds have sucked the waterâ€¦\n",
      "RT @ABC7: #Florence flooding kills 3.4 million poultry, 5,500 hogs, North Carolina officials say https://t.co/iXlUIJ1mVC https://t.co/yAeq6â€¦\n",
      "RT @XandraXandraBX: #Florence: The storm of a lifetime is not yet finished with the #Carolinas - @CNN \n",
      "(Please support #EndangeredEarthlingâ€¦\n",
      "RT @HumanityRoad: #NorthCarolina #Florence â€œIn case you lose access to the internet during #Florence go ahead and save these numbers into yâ€¦\n",
      "RT @arrl: From Weather Satellite NOAA-19, here is a view of #HurricaneFlorence over #W1AW today at 4:24 PM with an 88 degree pass! This imaâ€¦\n",
      "Mainstream media is desperately hoping to make #HurricaneFlorence Trump's Katrina. They will fail, miserably.\n",
      "RT @zeynep: Remnants of hurricane #Florence had a last hurrah on Chapel Hill/Carrboro this morning. Result: massive flash flooding! It wasâ€¦\n",
      "Mutual aid resources through # EMAC are already on the ground ready to respond to #hurricaneflorence - 260 ppl andâ€¦ https://t.co/Os8wPzwDzv\n",
      "RT @JosephDeMauro1: https://t.co/v9LAT0QwDG\n",
      "\n",
      "#hurricane #HurricaneFlorence2018 #HurricaneFlorence #wrightsville #NorthCarolina #NorthCaroliâ€¦\n",
      "RT @UniNoticias: AsÃ­ se ve #Florence este martes desde un satÃ©lite de la NOAA https://t.co/hp1e9YSebD https://t.co/7xGUHAiMah\n",
      "RT @RLuettich: #Florence advisory 45 landfall winds Cat 3. Surge threat still great, w/ predictions of 10-12 ft above MSL; 7-9 ft above norâ€¦\n",
      "RT @AMHQ: Devastating destruction from #Florence https://t.co/I0elw0g56O\n",
      "RT @jhomenuk: The historical tracks of storms within 200 nautical miles of #Florence are going to do your forecast no good here. Forecast mâ€¦\n",
      "The path of and rain expected from #HurricaneFlorence https://t.co/PquQfqgsRS\n",
      "Based on current models, #Florence will likely head south very slowly towards #Atlanta, weakening inside South Caroâ€¦ https://t.co/uFG1gOdPB0\n",
      "EE.UU. espera a #Florence ,huracÃ¡n potencialmente catastrÃ³fico. Detalles âž¡ï¸https://t.co/xtSWXtjSri. https://t.co/avjbIPk3gm\n",
      "RT @NWSAtlanta: 11 AM Update from NHC: #Florence is tracking west-northwest towards the U.S. East Coast. There remains a chance for east Geâ€¦\n",
      "RT @DemiCassiani: â€œThe charm of a medieval cityâ€ ...\n",
      ".\n",
      ".\n",
      ".\n",
      "#wine #florence #italy #travel #wanderlust #sunset #nature @winewankers @JMiquelâ€¦\n",
      "RT @abc13houston: Houston is thinking of you. We support you. We are with you. \n",
      "https://t.co/JthMkLAAx5 #HurricaneFlorence https://t.co/rstâ€¦\n",
      "RT @TeamRubicon: Share with friends or family in the path of incoming storms. #HurricaneSeason #HurricaneFlorence https://t.co/Ayxm6bOKkq\n",
      "\n",
      "testing event harvey\n",
      "sample local tweets:\n",
      "RT @abc13houston: Possible tornado reported in Katy during #HurricaneHarvey: https://t.co/04gCCeIowp https://t.co/c9NmFceLec\n",
      "RT @B911Nature: Satellite Imagery of #HurricaneHarvey https://t.co/rYTaCFbfcj\n",
      "RT @TAMU: Aggie @VonMiller to give $100,000 to support #HurricaneHarvey relief efforts through @bthoharvey!â€¦ \n",
      "RT @KHOU: #BREAKING: #HurricaneHarvey makes landfall as Category 4 storm\n",
      "https://t.co/AaGKg112Q3 #khou #hounews https://t.co/yrpn2357OR\n",
      "RT @viewsfromhtx: Prayers goes out to everybody that's staying put through #HurricaneHarvey ðŸ™\n",
      "We can't get out of our subdivision. Praying our house remains dry. #HurricaneHarvey #HoustonStrong\n",
      "RT @grist: A Texas-size flood threatens the Gulf Coast, and weâ€™re so not ready https://t.co/RcE1Ja122X #Harvey https://t.co/VcGB5C422o\n",
      "RT @CallerTravis: City crew going around taking down things that could cause damage during the storm. #HarveyStorm @callerdotcom https://t.â€¦\n",
      "RT @SteveWAFB: Latest model runs on #Harvey this morning. Landfall still expected Friday PM...then note the stall over/near SE Texâ€¦ \n",
      "RT @NWSSanAntonio: Here is a quick overview of the watches and warnings issued due to #Harvey. Significant flash flooding is the mainâ€¦ \n",
      "RT @ApoIIoTheK9: @jakepaul #Beaumont #Texas #Houston #HurricaneHarvey #HoustonStrong #HoustonFlood2017 #JakePaulers ðŸ¶\n",
      "#JerseyMikes #TheWoodlands is open again today normal business hours #HarveyFlood #HoustonStrong #HoustonFlood\n",
      "RT @KUT: .@MayorAdler is asking Austin to donate toys to #Harvey-affected kids in shelters: https://t.co/IEc5CuRgwx\n",
      "Some homes were added to the mandatory evacuation list while others were removed #HurricaneHarvey #barkerreservoir https://t.co/bKENpKeTVk\n",
      "@POTUS will be coming to Texas on Tuesday. #HurricaneHarvey https://t.co/03P1pSYxWO\n",
      "RT @PearlandISD: Dawson fans: Don't forget your gift cards or cash for #HarveyRelief for students/families/employeesâ€¦ \n",
      "All Texans need to be vigilant and #HoustonStrong after #HurricaneHarvey https://t.co/KGrDE5eyqk\n",
      "RT @MedStarEMSInfo: Images from MedStar crews at #Harvey staging area. https://t.co/kL7nShzApM\n",
      "RT @businessinsider: A terrifying size comparison shows how much rain #HurricaneHarvey has produced https://t.co/3ngtkbvxcg https://t.co/TNâ€¦\n",
      "RT @NickABC13: Yes, that's a Cadillac stuck in water. The driver had to be rescued. #Harvey https://t.co/c3c8lv0MQo\n",
      "\n",
      "sample non-local tweets:\n",
      "RT @AbigailCBN: Heartbreaking to see pictures of all the devastation from #HurricaneHarvey https://t.co/hBOtDb4rGD\n",
      "RT @ABC: Coyote takes cover under nearby barn as Hurricane #Harvey rips through Texas https://t.co/EH9VjumfL7 https://t.co/st9tin3Wsq\n",
      "RT @emrane: LIVE STREAM #HurricaneHarvey https://t.co/E3oiL1ZkcN\n",
      "RT @GrassrootsSpeak: #HurricaneHarvey is a reminder of the America we fight for. People are STRONG &amp; GOOD &amp; look out for each other - thâ€¦ \n",
      "@realDonaldTrump Would that wall of yours have held up to #Harvey ?\n",
      "RT @TonyMiano52806: The God you occasionally thank for good weather is the same God who created #Harvey and #Irma. He is to be worshiped noâ€¦\n",
      "RT @StandWithUs: Linda Sarsour caught fundraising for political group under guise of helping #Harvey victims.https://t.co/IDO4ysNVhN https:â€¦\n",
      "RT @BadaBigBoom: #HarveyStorm #HarveyRelief #HARVEYHELP #Houston #HoustonFloods #HarveyFlood #harvey #HarveySOS https://t.co/Cln2BQFRLt\n",
      "RT @RepDanKildee: As Americans, we come together to help those in need. Pleased that the House has passed Hurricane #Harvey aid https://t.câ€¦\n",
      "RT @HarveyRelief: 2nd Pop up location needing vols to serve hot meals + collecting/distributing #HarveyRelief: 208 Sampson St Houston Contaâ€¦\n",
      "Mayor of Galveston: We are doing \"vertical evacuations\" into hotels and high rises #HurricaneHarvey https://t.co/ZCaMMdvBEY\n",
      "#HarveyFlood again makes landfall, this time as a #TropicalStorm, near #Cameron #LA\n",
      "\n",
      "https://t.co/5HtSH2jnNB\n",
      "#HurricaneHarvey https://t.co/JRmLL47H4d\n",
      "Today &amp; tomorrow, @LiveUnitedUWTC collecting supplies around Central New York for #HurricaneHarvey victims #twithaca https://t.co/ZDSTgYxRvI\n",
      "RT @LaurenYoung: .@Reuters has more than 50 journalists covering Hurricane #Harvey. A glimpse at how we do it https://t.co/T6mFyWqvab httpsâ€¦\n",
      "Hey #TX #LA #HurricaneHarvey Watch #Periscope #JamesSarokaJr aka #TheFeetPeace Says IF YOU EXPOSE him a #HURRICANEâ€¦ https://t.co/CCy0bJ3T0s\n",
      "RT @YourNews101: VOTE and RETWEET, Did @POTUS Trump do a good job in dealing with and preparing for #Harvey and #Irma and with recovery\n",
      "RT @LeftSentThis: Keep Haiti in mind when you send money to the Red Cross to help the victims of #HurricaneHarvey.   https://t.co/7pq8vZY6yM\n",
      "RT @AmDiabetesAssn: If you have excess #diabetes supplies, you can donate them to help ppl affected by #HurricaneHarveyâ€¦ \n",
      "RT @WFTSisabel: RIGHT NOW |TF3(@TampaFireRescue, @HillsFireRescue &amp; @StPeteFR)on way 2 TX for #Harvey rescues. Wish our heroes a saâ€¦ \n",
      "\n",
      "testing event irma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample local tweets:\n",
      "Evacuating #Florida bc of #HurricaneIrma when I noticed countless people dangerously driving fast on the edge of thâ€¦ https://t.co/xvJFNgLRUz\n",
      "Hurricane #Irma impacts to #NCFla will start today. Here's the latest as of 12 am Sunday. https://t.co/h0oVv6fbiy\n",
      "Power is out! Time for the wine ðŸ’ðŸ¼ #HurricaneIrma https://t.co/SWkq8lPEkh\n",
      "RT @JSOPIO: #HurricaneIrma - Shelters will be announced soon and plan to be open on Friday.  #JAX #Irma\n",
      "WATCH: Hurricane Irma churns toward Florida as a Category 3 storm https://t.co/WjdJZst7YF #IrmaHurricane2017â€¦ https://t.co/DsCXVH9M8W\n",
      "The Gov't of Antigua has issued a Hurricane Watch for the\n",
      "islands of Antigua, Barbuda, Anguilla, Montserrat, St. Kitts, and\n",
      "Nevis. #Irma\n",
      "Follow us on Facebook for updates on #HurricaneIrma and office availability: https://t.co/GyTTb9UffV https://t.co/UBJMpM0VpR\n",
      "RT @UCFKnightNews: Breaking News: Orange County issues mandatory curfew from Sunday 7pm through Monday 6pm #IrmaUCF https://t.co/39B9sqjCgR\n",
      "RT @miss_fenech: Stunning shot of a monster #HurricaneIrma #StaySafeFlorida https://t.co/nhkTTTuOrX\n",
      "Hurricane + Storm Surge warnings have been issued for South Florida, Lake Okeechobee and Keys #Irma https://t.co/BX0YZB5KYv\n",
      "RT @Fox35Amy: #Fox35 #Irma https://t.co/t6kWXNWct8\n",
      "RT @AliGaudiosi: We are #Floridians, we can handle you #Irma. ðŸ™ðŸ»ðŸ’•ðŸŒ€ðŸ’ªðŸ¼ #HurricaneIrma #HunkerDown #SouthFlorida #Florida https://t.co/NhDOFz3â€¦\n",
      "Looking more and more like #southflorida might be brushed by #HurricaneIrma @DebsKeeler https://t.co/GFLnytS54p\n",
      "RT @SaintsDatMan: BREAKING NEWS: Hurricane Irma has destroyed the Island of Saint Martin.\n",
      "#Irma #HurricaneIrma  https://t.co/DksFEyI0Tg\n",
      "RT @CaitlinMcGehee: Not something you see everyday... Ybor City is EMPTY on a Saturday night. #Irma #TampaBay #YborCityâ€¦ \n",
      "RT @wsvn: WATCH: Gov. Scott: Google Maps will show closed roads in real-time if #Irma forces closures https://t.co/bduMksSk8E\n",
      "RT @BrevardEOC: 9/3/17: RT @NWSMelbourne: The latest information on Major Hurricane #Irma as of 11 am. https://t.co/b6vW30Q6Ux\n",
      "We continue to monitor #Irma. \n",
      "\n",
      "We are being briefed by the National Weather Service later this morning and will... https://t.co/0nr1JzNOGs\n",
      "RT @MikeFirstAlert: Hurricane Watch issued for our NE Florida coast from St. Johns county north to Fernandina Beach. #Irma https://t.co/Eg9â€¦\n",
      "If you lose power due to #HurricaneIrma, use generators safely in the days that follow.  (And wait out the storm beâ€¦ https://t.co/obsteQzmpO\n",
      "\n",
      "sample non-local tweets:\n",
      "RT @StateDept: Information for U.S. citizens affected by #HurricaneIrma at home and abroad. Stay safe and be prepared! https://t.co/7aZKKvhâ€¦\n",
      "RT @BrevardEOC: 9/7/17 | 9AM: Brevard County Announces Evacuations and Shelters for #Irma Read all here: https://t.co/I4gZgEjt1k\n",
      "RT @ace123michael: Latest track.. #HurricaneIrma Taking a more Westward route as of now. Bringing it's chances of going into the Gulfâ€¦ \n",
      "RT @AtomicElbow1: Don't be fooled by fake climate change site @iowaclimate it's a depot for deniers #IrmaHurricane2017 @co_rapunzel4â€¦ \n",
      "RT @PJStrikeForce: #GodAnswersPrayer ðŸ™ðŸ»\n",
      "@wordfaithlife ðŸ™ŒðŸ»ðŸ™ŒðŸ»\n",
      "#Irma #HurrcaneIrma \n",
      "#PraiseGod for His #Mercy\n",
      "Psalm91\n",
      "#Florida ðŸ•ŠðŸ•Š#Updateâ€¦ \n",
      "Discussing projected paths of #HurricaneIrma with a former colleague of mine, and we are calling it the potential \"â€¦ https://t.co/YGmWyJm28e\n",
      "RT @jjperezcaban: #Moca,listo para #Irma. Excelente Planificacion de alcalde @KikoAviles2016. Rogando al Creador que siga cubriendo câ€¦ \n",
      "RT @KeysEnergy: Nearly 180 lineworkers from around the country are prepositioning to assist KEYS' crews w/ restoration efforts once #Irma hâ€¦\n",
      "RT @pppapin: #Irma just made a direct hit in St.Martin. Some scary footage coming from the island. https://t.co/9fVI1Y87Jp\n",
      "Island of Barbuda â€œliterally under waterâ€ after #HurricaneIrma2017, prime minister says https://t.co/A9ZTLOlVq6 https://t.co/pSjF1lQyRo\n",
      "Praise God!! RT @glamazini: Just got word that my parents are ok THANK YOU GOD! #HurricaneIrma\n",
      "#Irma is a powerful Category 4 storm with 150 mph sustained winds! https://t.co/ELidh4IIbq\n",
      "RT @ABC: LIVE NOW: We have continuing coverage on @ABC News as Hurricane #Irma continues to batter Florida.â€¦ \n",
      "Hurricane warnings extend far north as Southern Georgia. #Irma https://t.co/x1kQY1GwsE\n",
      "RT @NWSShreveport: Hurricane Categories explained #HurricaneIrma #Cat5 #txwx #arwx #lawx #okwx #HurricanePrep https://t.co/hosCoBYfCt\n",
      "RT @RepRichHudson: Renee &amp; I continue to pray for those in #HurricaneIrma's path - may God be with you &amp; first responders, nurses, doctorsâ€¦\n",
      "RT @tmotola: #Moonlight #MiamiBeach #CalmBeforeTheStorm #HurricaneIrma https://t.co/9O8OHHcGnT\n",
      "RT @tzounakis: Extreme #HurricaneIrma closing in on #Florida, posing dire threat; west coast most at risk\n",
      "https://t.co/yZ2lMuv7nG\n",
      "Hurricane &amp; tropical storm warnings in effect for large chunk of the Southeast. #alwx #gawx #scwx #FLwx #Irma\n",
      "RT @BreakingNLive: BREAKING NEWS: Hurricane Irma begins to arrive in Puerto Rico.\n",
      "#Irma #PuertoRico https://t.co/DWyE7TsP09\n",
      "\n",
      "testing event maria\n",
      "sample local tweets:\n",
      "RT @WeatherNation: Comparing #Maria, #Irma and #Harvey tracks. Note: Harvey weakened to a remnant low for part of this track. https://t.co/â€¦\n",
      "BAD!!! #PuertoRico #SanJuan #HurricaneMaria #hurricanemaria2017 #Domains https://t.co/1la8L72uzA\n",
      "Latest track on #Maria. It heads north through the weekend. How close to NC is the biggest question. #ncwx https://t.co/tgZhXb805g\n",
      "Las Mas Que Sufren En Estos Eventos Son Las Chillas Que Se Quedan Solas!\n",
      "#Lamentable #HurricaneMaria\n",
      "RT @julito77: In today's @washingtonpost, editorial: https://t.co/YuZAFJRba0 #MariaPR #PuertoRico #Whitefish https://t.co/CSYCBRS0i8\n",
      "BajÃ³ a 160mph pero lo horriblemente fuerte que estamos sintiendo ahora mismo en San Juan son 61mph. Esto es insoportable. #HurricaneMaria\n",
      "RT @iCyclone: 4:20 pm. Still in Palmas Del Mar area of #Humacao. It could be ground zero, but it's hard to know when #MARIA's corâ€¦ \n",
      "RT @weatherchannel: Although #Maria has weakened to a Category 2 hurricane with winds of 110 mph, some strengthening is forecast duringâ€¦ \n",
      "RT @vanesmendez: This is the weather on San Juan just hours before #Maria arrives #HurricaneMaria @CNN @weatherchannel  @adamonzon https://â€¦\n",
      "RT @hurrtrackerapp: Historical storm for Dominica. Brace for impact! #Maria https://t.co/Way911gw5h\n",
      "#NoTec #NoInternet #HurricaneMariaPR #NoElectricity #NoWater #IAmAlive #ThatsAllThatMetters ðŸ’ªðŸ¼ðŸ˜ðŸ’¯ðŸ‡µðŸ‡·ðŸ™‹ðŸ¼\n",
      "RT @PRFAA: Help those affected by #HurricaneMaria and support the rebuilding of Puerto Rico. Go to https://t.co/1fG64M0Qk5. 10â€¦ \n",
      "RT @PulsoEST: #MariaPR | Estudiantes y empleados del Recinto de RÃ­o Piedras continÃºan limpiando los edificios. MaÃ±ana seguirÃ¡n aâ€¦ \n",
      "Nice waves #hurricanemaria #topsailisland https://t.co/7DF0Mtnpnd\n",
      "RT @fortalezapr: #MariaPR https://t.co/s9NLw7Z5PF\n",
      "RT @Kedmvrie: La AEE debe sentirse como cuando estas terminando de lavar el carro y llueve. #maria\n",
      "RT @Vegas040805: ðŸš¨ðŸ†˜THREAD ðŸ†˜ðŸš¨PUERTO RICO UPDATED SHELTER LISTINGâ€¼ï¸\n",
      "#PuertoRico #Shelter #Information #HurricaneMaria #MariaPR #HELPâ€¦ \n",
      "The latest USA News! https://t.co/dPyzz0MJGE #trump #maria\n",
      "Clearly #mothernature #earth #God is pissed! Praying for all those affected #HurricaneMaria #earthquake\n",
      "God bless ðŸ™ðŸ¼ #HurricaneMariapr\n",
      "\n",
      "sample non-local tweets:\n",
      "Scott Fisher Says: #Maria Update. https://t.co/yhomIK3IKI\n",
      "RT @FloridaStorms: #Maria became the season's seventh hurricane earlier today, and it appears poised for further intensification.â€¦ \n",
      "RT @PetFriendlyPR: Fotos de Isla Verde. Nadie nos tumba, orgullosa de los mÃ­os. #NoPetLeftBehind #Maria https://t.co/8Af4huN0Ir\n",
      "Prayers for all those in the path of #HurricaneMaria https://t.co/MGam5HJAaG\n",
      "RT @CBSThisMorning: WATCH: Hurricane #Maria's top winds are now at 155 mph. @DavidBegnaud is in San Juan, Puerto Rico which is directlyâ€¦ \n",
      "Aix-en-Provence by Maria Helena Vieira da Silva https://t.co/pPbRotM0BI #guggenheim #mariahelenavieiradasilva https://t.co/g0cbDjnhLj\n",
      "RT @marac00per: Mariah Careyâ€™s First Words About Her Engagement Ring Are... https://t.co/SihdN6mVhz #mariahcarey\n",
      "models with #Maria are shifting a bit closer to the Carolina coast. Still need to closely monitor this\n",
      "RT @femaregion2: Puerto Rico: REGISTER with @FEMA if you suffered property damage or loss due to #HurricaneMaria More info:â€¦ \n",
      "RT @DeptofDefense: .@USCG Investigative Service agents provide ongoing disaster relief to victims of #HurricaneMaria at #RioGrande #PRâ€¦ \n",
      "So #Maria has had a slowly falling pressure during the flight- 947 mb with 13 kt on the drop- one fix and we are doâ€¦ https://t.co/yKEkw1nkwa\n",
      "RT @RealJoAnnBush: #MariaSOS:\n",
      "\"The #AGUADILLA #hospital in #PuertoRico needs these #meds #ASAP!\"ðŸ‘‡\n",
      "\n",
      "https://t.co/ybVdXkiXGc\n",
      "\n",
      "#FEMA #ReTweetâ€¦\n",
      "RT @margaritateresa: #puertorico #HurricaneMaria #HelpPuertoRico https://t.co/MffzU81jKV\n",
      "@RyanNBC6 Which of the previous #Irma hit islands are in the path of #HurricaneMaria  ? ðŸ˜°ðŸ™ðŸ˜°ðŸ˜¬\n",
      "RT @CBSThisMorning: Two days after Hurricane #Maria slammed into Puerto Rico, people are still being rescued, @DavidBegnaud reports.â€¦ \n",
      "RT @jhomenuk: NEW: Recon has found 160mph surface winds in the NE eyewall of #Maria. Massive pressure drop as well. Likely a Category 5.\n",
      "RT @SpencerWeather: It's approx 140 miles from the eyewall of #Maria to the shore of Puerto Rico at 5:37pm Tuesday. https://t.co/WQPyK7lBNH\n",
      "RT @TheMariahReport: #picoftheday #Lambily #mariah have you gotten your tickets to the #alliwantforchristmas tour ? https://t.co/sHyehUEJP2\n",
      "RT @cromachi: If you can, please support @DARDA_ORGâ€™s efforts to help #Dominica recover from Hurricane #Maria by donating here: https://t.câ€¦\n",
      "RT @AFP: Puerto Rico is braced for potentially calamitous flash floods after being pummeled by #HurricaneMariaâ€¦ \n",
      "\n",
      "testing event michael\n",
      "sample local tweets:\n",
      "RT @WFLALeigh: Eyewall of #HURRICANE #MICHAEL moving onshore near St. Vincent Island. FYI: Official landfall is imminent, that's when the câ€¦\n",
      "El huracÃ¡n #Michael ya es categorÃ­a 4. En el correr de la tarde tocarÃ¡ tierra cerca de PanamÃ¡ City Beach con consecâ€¦ https://t.co/FnISNYCXBv\n",
      "#NOW #HurricaneMichael\n",
      "RT @weatherchannel: An important message from @DrRickKnabb on why it's critical to prepare for #Hurricane #Michael as its forecast to bringâ€¦\n",
      "RT @USFoods: Hey @chefjoseandres and @WCKitchen! We heard you're supporting communities affected by #HurricaneMichael and we have some ideaâ€¦\n",
      "RT @KatieWallsWSB: CENTER OF MICHAEL APPROACHING MIDDLE GEORGIA...As of 8 PM, the center of #Michael was just west of Albany, moving north-â€¦\n",
      "RT @LissetteCBS4: Rain bands of Cat. 4 #HurricaneMichael spreading across #florida panhandle. Forecast to make landfall early afternoon. Thâ€¦\n",
      "RT @NCEmergency: Latest #ncwx: Looks like TS #Michael will bring 3-5â€ rain this week across SE NC &amp; southern Blue Ridge &amp; 2-3â€ rain acrossâ€¦\n",
      "RT @FLSERT: This afternoon, state and federal partners held a call to coordinate housing solutions in areas impacted by #HurricaneMichael.â€¦\n",
      "RT @matt_barrentine: #Michael #PanamaCity https://t.co/dnfNVUY6uy\n",
      "sitting here waiting on the 5am Advisory for #MICHAEL... https://t.co/RW2EUFE4xj\n",
      "As #HurricaneMichael strengthens into a Category IV storm, we urge everyone in potentially affected areas to take câ€¦ https://t.co/1n80JXCLFg\n",
      "RT @MarcWeinbergWX: We just heard police announcing an 8 pm curfew in Panama City due to #HurricaneMichael.\n",
      "After Hurricane Michael, Being Number 2603 Is A Blessing #Tallahassee #HurricaneMichael https://t.co/sGUigEI4HE\n",
      "RT @EileenSharkey: Eileen Unleashed! is out! https://t.co/ErCgFV64Hw Stories via @AstonJeffrey @pulte @elzieim29 #hurricanemichael #royalweâ€¦\n",
      "RT @News13JeffAllen: EVACUATIONS: As officials in the panhandle issue MANDATORY evacuations due to #hurricanemichael - we're seeing a lot oâ€¦\n",
      "RT @ReedTimmerAccu: In-route to chase #HurricaneMichael likely to be a major hurricane, even cat 3-4 at landfall Wednesday with a catastropâ€¦\n",
      "Hopefully #HurricaneMichael will be good to us in Coastal Ga, but we wanted to remind you that we have a plan for oâ€¦ https://t.co/SvnQR49KvY\n",
      "RT @wxbrad: The last 24 hrs as #Michael went through rapid intensification. #flwx https://t.co/QbDezd723E\n",
      "To our fellow Floridians, stay safe and stay strong. \n",
      "\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "#michael #hurricane #flostrongâ€¦ https://t.co/jSxzTh1JAK\n",
      "\n",
      "sample non-local tweets:\n",
      "RT @TODAYshow: Today, President Trump and first lady Melania Trump will visit parts of Florida and Georgia ravaged by #HurricaneMichael.\n",
      "\n",
      "Câ€¦\n",
      "Louisiana update ahead of #HurricaneMichael - â¦@wdsuâ© â¦@MargaretOrrâ© with the latest at 4/5/6. â¦@WESHâ© â¦@WPBF25Newsâ© https://t.co/dyEWXwqp7b\n",
      "RT @NHC_Atlantic: NHC Director Ken Graham will provide a Facebook Live broadcast regarding Tropical Storm #Michael at 8:30 a.m. EDT https:/â€¦\n",
      "RT @DeptofDefense: #HurricaneMichael made landfall in the #Florida panhandle. In preparation, the #DOD pre-positioned active-duty and @USNaâ€¦\n",
      "RT @USSOCOM: .@USAFSpecTactics were #FirstThere the day after #HurricaneMichael devastated parts of Florida. Within an hour of landing at @â€¦\n",
      "Welcome Back from Florida, great work by Maryland Task Force 1 #HurricaneMichael deployment &amp; thanks to @HCDFRS beiâ€¦ https://t.co/3CdBXY67A5\n",
      "RT @ComcastFL: To help residents and emergency personnel stay connected in the wake of #HurricaneMichael we've opened Xfinity #Wifi hotspotâ€¦\n",
      "#Hurricane  #Michael\n",
      "RT @BrookeWINKNews: Rail cars flipped on their sides from the force of #HurricaneMichael in Panama City @winknews https://t.co/SsCbObMNQq\n",
      "RT @SBAgov: SBA offers disaster assistance to eligible counties in Florida affected by #HurricaneMichael â†’ https://t.co/8wwqu1RcB6 https://â€¦\n",
      "RT @ABC: NEW: Gov. Rick Scott requests Pres. Trump issue a Major Disaster Declaration following #HurricaneMichael's landfall. \n",
      "\n",
      "\"This willâ€¦\n",
      "FL - REGULATORY BULLETIN - Emergency Order Eases Deadlines for #HurricaneMichael Victims https://t.co/T7QajOR6FI https://t.co/USutLEJKYD\n",
      "RT @mark_tarello: #Hurricane #Michael is a category 4 storm with winds of 150 MPH. The eye of Michael is moving inland over the Florida panâ€¦\n",
      "Right after Hurricane Michael! #HurricaneMichael #PanamaCityBeach #panamacity #theweatherchannel https://t.co/WDtNTU1lZk\n",
      "RT @MJVentrice: #HurricaneMichael is becoming better organized this evening... Eyewall has closed off and a clearing in the eye. This is noâ€¦\n",
      "RT @CGTNOfficial: One killed as #HurricaneMichael batters Florida https://t.co/uzgMUojopY https://t.co/RSuVz6XHq6\n",
      "RT @severestudios: Spectacular photo from INSIDE THE EYE of Hurricane #Michael from @Basehunters Colt Forney! https://t.co/ecbQ2tmKtk\n",
      "RT @FOXNashville: We at @FOXNashville are standing strong with the communities impacted by #HurricaneMichael.\n",
      "\n",
      "Join us as we support our reâ€¦\n",
      "RT @CBSMiami: Wind gust of 128mph observed at Tyndall AFB, a few miles SSE of Panama City Beach, FL as #HurricaneMichael made landfall. #CBâ€¦\n",
      "#HurricaneMichael: Driving around in Panama City, Florida #flwx  https://t.co/BCF10tO37S\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "N_sample = 20\n",
    "for e in event_names:\n",
    "    print('testing event %s'%(e))\n",
    "    tweets_e = combined_tweets_dedup[combined_tweets_dedup.loc[:, e]==1]\n",
    "    tweets_e_local = tweets_e[tweets_e.loc[:, 'user_loc_is_local_%s'%(e)]==1]\n",
    "    tweets_e_non_local = tweets_e[tweets_e.loc[:, 'user_loc_is_non_local_%s'%(e)]==1]\n",
    "    print('sample local tweets:\\n%s\\n'%('\\n'.join(tweets_e_local.loc[np.random.choice(tweets_e_local.index, N_sample, replace=False), 'text'].values)))\n",
    "    print('sample non-local tweets:\\n%s\\n'%('\\n'.join(tweets_e_non_local.loc[np.random.choice(tweets_e_non_local.index, N_sample, replace=False), 'text'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locals:\n",
    "- **Florence**: local impact, evacuation, weather\n",
    "- **Harvey**: weather, local impact, warnings, support\n",
    "- **Irma**: weather, local impact, warnings\n",
    "- **Maria**: weather, warning, shelters\n",
    "- **Michael**: weather, support, local impact, warning\n",
    "\n",
    "Non-locals:\n",
    "- **Florence**: large-scale impact, commentary, weather, support\n",
    "- **Harvey**: weather, support, politics, large-scale impact\n",
    "- **Irma**: local impact, large-scale impact, support\n",
    "- **Maria**: commentary, weather, support, politics, large-scale impact\n",
    "- **Michael**: weather, local impact, evacuation, large-scale impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, it seems that locals post more local impact and warnings information, while non-locals post more commentary and support.\n",
    "\n",
    "TODO: manually label individual tweets??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare NE use among locals, non-locals\n",
    "Let's see if the locals and non-locals use NEs in consistently different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130862/2339173 valid loc NEs\n"
     ]
    }
   ],
   "source": [
    "import dateutil\n",
    "combined_tweets_tagged = pd.read_csv('../../data/mined_tweets/combined_tweet_NE_flat_data.gz', sep='\\t', index_col=False, compression='gzip', converters={'date':lambda x: dateutil.parser.parse(x)})\n",
    "# restrict to valid locations!!\n",
    "combined_tweets_tagged_loc = combined_tweets_tagged[combined_tweets_tagged.loc[:, 'valid_loc']]\n",
    "print('%d/%d valid loc NEs'%(combined_tweets_tagged_loc.shape[0], combined_tweets_tagged.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing event florence\n",
      "testing event harvey\n",
      "testing event irma\n",
      "testing event maria\n",
      "testing event michael\n",
      "18516/2339173 tagged local/non-local NEs\n"
     ]
    }
   ],
   "source": [
    "local_user_labels = []\n",
    "for e in event_names:\n",
    "    print('testing event %s'%(e))\n",
    "    tweets_e = combined_tweets_dedup[combined_tweets_dedup.loc[:, e]==1]\n",
    "    tweets_e_local = tweets_e[tweets_e.loc[:, 'user_loc_is_local_%s'%(e)]==1]\n",
    "    tweets_e_non_local = tweets_e[tweets_e.loc[:, 'user_loc_is_non_local_%s'%(e)]==1]\n",
    "    local_users_e = tweets_e_local.loc[:, 'user_name'].unique()\n",
    "    non_local_users_e = tweets_e_non_local.loc[:, 'user_name'].unique()\n",
    "    local_user_labels_e = pd.DataFrame(np.vstack([np.hstack([local_users_e, non_local_users_e]), \n",
    "                                                  np.hstack([np.repeat(1, len(local_users_e)), np.repeat(0, len(non_local_users_e))])]), \n",
    "                                       index=['username', 'is_user_local']).transpose()\n",
    "    local_user_labels.append(local_user_labels_e)\n",
    "local_user_labels = pd.concat(local_user_labels, axis=0)\n",
    "## join with existing data\n",
    "combined_tweets_tagged_local = combined_tweets_tagged_loc[combined_tweets_tagged_loc.loc[:, 'username'].isin(local_user_labels.loc[:, 'username'].unique())]\n",
    "combined_tweets_tagged_local = pd.merge(combined_tweets_tagged_local, local_user_labels, on='username')\n",
    "\n",
    "print('%d/%d tagged local/non-local NEs'%(combined_tweets_tagged_local.shape[0], combined_tweets_tagged.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>txt</th>\n",
       "      <th>data_name_fixed</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>NE</th>\n",
       "      <th>NE_type</th>\n",
       "      <th>NE_LOC</th>\n",
       "      <th>valid_loc</th>\n",
       "      <th>has_descriptor</th>\n",
       "      <th>NE_fixed</th>\n",
       "      <th>is_user_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>914237220202131457</td>\n",
       "      <td>RT @FtBraggNC: #Airmen from #FortBragg's 43d A...</td>\n",
       "      <td>maria</td>\n",
       "      <td>WildAngel6</td>\n",
       "      <td>2017-09-30 21:15:13+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>San_Juan</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>san_juan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>914237220202131457</td>\n",
       "      <td>RT @FtBraggNC: #Airmen from #FortBragg's 43d A...</td>\n",
       "      <td>maria</td>\n",
       "      <td>WildAngel6</td>\n",
       "      <td>2017-09-30 21:15:13+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>San_Juan</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>san_juan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>907052767524651009</td>\n",
       "      <td>RT @B911Nature: Video out of Naples, Florida s...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>WildAngel6</td>\n",
       "      <td>2017-09-11 01:26:46+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Naples</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>naples</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>907052767524651009</td>\n",
       "      <td>RT @B911Nature: Video out of Naples, Florida s...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>WildAngel6</td>\n",
       "      <td>2017-09-11 01:26:46+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Naples</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>naples</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914251094963970048</td>\n",
       "      <td>RT @operationbless: #PuertoRico reels after #H...</td>\n",
       "      <td>maria</td>\n",
       "      <td>Enigma2You4Now</td>\n",
       "      <td>2017-09-30 22:10:21+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>San_Juan</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>san_juan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                                txt  \\\n",
       "0  914237220202131457  RT @FtBraggNC: #Airmen from #FortBragg's 43d A...   \n",
       "1  914237220202131457  RT @FtBraggNC: #Airmen from #FortBragg's 43d A...   \n",
       "2  907052767524651009  RT @B911Nature: Video out of Naples, Florida s...   \n",
       "3  907052767524651009  RT @B911Nature: Video out of Naples, Florida s...   \n",
       "4  914251094963970048  RT @operationbless: #PuertoRico reels after #H...   \n",
       "\n",
       "  data_name_fixed        username                       date lang        NE  \\\n",
       "0           maria      WildAngel6  2017-09-30 21:15:13+00:00   en  San_Juan   \n",
       "1           maria      WildAngel6  2017-09-30 21:15:13+00:00   en  San_Juan   \n",
       "2          harvey      WildAngel6  2017-09-11 01:26:46+00:00   en    Naples   \n",
       "3          harvey      WildAngel6  2017-09-11 01:26:46+00:00   en    Naples   \n",
       "4           maria  Enigma2You4Now  2017-09-30 22:10:21+00:00   en  San_Juan   \n",
       "\n",
       "    NE_type  NE_LOC  valid_loc  has_descriptor  NE_fixed is_user_local  \n",
       "0  LOCATION    True       True           False  san_juan             0  \n",
       "1  LOCATION    True       True           False  san_juan             0  \n",
       "2  LOCATION    True       True           False    naples             0  \n",
       "3  LOCATION    True       True           False    naples             0  \n",
       "4  LOCATION    True       True           False  san_juan             0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tweets_tagged_local.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: rejoin data with tagged NEs, test NE use among locals, non-locals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: find non-local users based on locations that were not affected (i.e. have a `city, state` style location where `state` is not affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
