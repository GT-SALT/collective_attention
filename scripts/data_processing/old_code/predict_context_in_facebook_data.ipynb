{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict context in Facebook data\n",
    "Let's predict contextualization in Facebook data using regression on the following variables:\n",
    "\n",
    "- importance (based on total frequency)\n",
    "- commitment (based on author posts)\n",
    "- information (based on post length)\n",
    "- audience (based on group size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765/18432 NE mentions with context\n",
      "10131/18432 local NE mentions\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "group_data = pd.read_csv('../../data/facebook-maria/combined_group_data_es_tagged_valid_anchor_group_contain.tsv', sep='\\t', index_col=False, converters={'subtree' : literal_eval, 'tree' : literal_eval})\n",
    "print('%d/%d NE mentions with context'%(group_data.loc[:, 'anchor'].sum(), group_data.shape[0]))\n",
    "print('%d/%d local NE mentions'%(group_data.loc[:, 'group_contains_NE'].sum(), group_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_with_no_context(data, id_var='status_id', txt_var='status_message', subtree_var='subtree', tree_var='tree', context_var='anchor'):\n",
    "    \"\"\"\n",
    "    Replace context from text and return clean text.\n",
    "    \"\"\"\n",
    "    no_context_txt_var = '%s_no_context'%(txt_var)\n",
    "    data_no_context_txt = []\n",
    "    for id_i, data_i in data.groupby(id_var):\n",
    "        txt_i = data_i.loc[:, txt_var].iloc[0]\n",
    "        # replace context in txt_i\n",
    "        txt_i_clean = txt_i\n",
    "        for idx_j, NE_data_j in data_i.iterrows():\n",
    "            if(NE_data_j.loc[context_var]==1):\n",
    "    #             print('clean txt before: %s'%(txt_i_clean))\n",
    "                tree_txt_j = ' '.join([token[0] for token in NE_data_j.loc[tree_var]])\n",
    "                subtree_txt_j = ' '.join([token[0] for token in NE_data_j.loc[subtree_var]])\n",
    "                txt_i_clean = txt_i_clean.replace(tree_txt_j, '')\n",
    "                txt_i_clean = txt_i_clean.replace(subtree_txt_j, '')\n",
    "        data_i = data_i.assign(**{\n",
    "            no_context_txt_var : data_i.apply(lambda x: txt_i_clean if x.loc[context_var]==1 else txt_i, axis=1)\n",
    "        })\n",
    "        data_no_context_txt.append(data_i)\n",
    "    data_no_context_txt = pd.concat(data_no_context_txt, axis=0)\n",
    "    return data_no_context_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance: NE frequency\n",
    "NE_var = 'NE_fixed'\n",
    "NE_counts = group_data.groupby(NE_var).apply(lambda x: x.shape[0]).reset_index().rename(columns={0 : 'NE_count'})\n",
    "group_data = pd.merge(group_data, NE_counts, on=NE_var)\n",
    "# information: post length\n",
    "group_data = get_text_with_no_context(group_data)\n",
    "txt_var = 'status_message'\n",
    "no_context_txt_var = '%s_no_context'%(txt_var)\n",
    "group_data = group_data.assign(**{\n",
    "    'txt_len_norm' : group_data.loc[:, no_context_txt_var].apply(lambda x: np.log(len(x)+1))\n",
    "})\n",
    "# commitment: number of posts per author per group\n",
    "author_var = 'status_author_id'\n",
    "group_var = 'group_name'\n",
    "author_group_counts = group_data.groupby([author_var, group_var]).apply(lambda x: x.shape[0]).reset_index().rename(columns={0 : 'author_group_count'})\n",
    "group_data = pd.merge(group_data, author_group_counts, on=[author_var, group_var])\n",
    "# audience: group size\n",
    "group_counts = group_data.groupby(group_var).apply(lambda x: x.loc[:, author_var].nunique()).reset_index().rename(columns={0 : 'group_size'})\n",
    "group_data = pd.merge(group_data, group_counts, on=group_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression on context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict context all explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "## Z-norm scalar vars\n",
    "scaler = StandardScaler()\n",
    "group_data_reg = group_data.copy()\n",
    "# add intercept\n",
    "group_data_reg = group_data_reg.assign(**{\n",
    "    'intercept' : 1.\n",
    "})\n",
    "scalar_vars = ['NE_count', 'txt_len_norm', 'author_group_count', 'group_size']\n",
    "for v in scalar_vars:\n",
    "    group_data_reg = group_data_reg.assign(**{\n",
    "        v : scaler.fit_transform(group_data_reg.loc[:, v].values.reshape(-1,1))\n",
    "    })\n",
    "group_data_reg = group_data_reg.assign(**{\n",
    "    'group_contains_NE' : group_data_reg.loc[:, 'group_contains_NE'].astype(int)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.166446\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 anchor   No. Observations:                18432\n",
      "Model:                          Logit   Df Residuals:                    18426\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Mon, 16 Sep 2019   Pseudo R-squ.:                 0.03618\n",
      "Time:                        17:55:08   Log-Likelihood:                -3067.9\n",
      "converged:                       True   LL-Null:                       -3183.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.066e-48\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "NE_count              -0.2520      0.047     -5.337      0.000      -0.345      -0.159\n",
      "txt_len_norm           0.2421      0.041      5.893      0.000       0.162       0.323\n",
      "author_group_count    -0.6384      0.084     -7.642      0.000      -0.802      -0.475\n",
      "group_size             0.0261      0.040      0.646      0.518      -0.053       0.105\n",
      "group_contains_NE     -0.2897      0.079     -3.655      0.000      -0.445      -0.134\n",
      "intercept             -3.1892      0.062    -51.833      0.000      -3.310      -3.069\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.discrete.discrete_model import Logit\n",
    "dep_var = 'anchor'\n",
    "indep_vars = ['NE_count', 'txt_len_norm', 'author_group_count', 'group_size', 'group_contains_NE', 'intercept']\n",
    "logit_model = Logit(endog=group_data_reg.loc[:, dep_var], exog=group_data_reg.loc[:, indep_vars])\n",
    "model_results = logit_model.fit()\n",
    "print(model_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev=230, df=5, p=9.066E-48\n"
     ]
    }
   ],
   "source": [
    "print('dev=%d, df=%d, p=%.3E'%(model_results.llr, model_results.model.df_model, model_results.llr_pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! \n",
    "\n",
    "- more NE mentions => less contextualization\n",
    "- longer text => more context?? because information seeking\n",
    "- more posts in-group => less context\n",
    "- bigger group => no effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict context fixed effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if these findings still hold with fixed effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to restrict the data to frequent authors, locations, groups for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RARE                 10675\n",
       "10155297402077917      713\n",
       "10155697137579029      658\n",
       "10155718325260502      576\n",
       "10213954436236337      441\n",
       "10213949852521688      402\n",
       "10155081537013106      207\n",
       "10155617866275516      183\n",
       "10159579876365442      173\n",
       "1722102481190791       172\n",
       "Name: status_author_id_cap, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RARE            2930\n",
       "guayama         1780\n",
       "coamo           1197\n",
       "lajas            818\n",
       "yabucoa          816\n",
       "barranquitas     814\n",
       "quebradillas     798\n",
       "cidra            756\n",
       "naranjito        695\n",
       "cayey            472\n",
       "Name: NE_fixed_cap, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Guayama: Huracán María                              2973\n",
       "Barranquitas Huracan Maria                          1529\n",
       "Huracan Maria Coamo                                 1514\n",
       "Huracan Maria En Lajas                              1016\n",
       "Quebradillas#Huracan#Maria                           970\n",
       "Huracan Maria  Yabucoa                               969\n",
       "HURACAN MARIA CIDRA                                  938\n",
       "Huracán Maria Vega Alta (Unidos por Vega Alta)       837\n",
       "Huracan Maria Naranjito                              761\n",
       "Cayey se levanta ante el paso del huracán María.     704\n",
       "Name: group_name_cap, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_author_count = 20\n",
    "min_NE_count = 20\n",
    "min_group_count = 20\n",
    "author_var = 'status_author_id'\n",
    "NE_var = 'NE_fixed'\n",
    "group_var = 'group_name'\n",
    "min_counts = [min_author_count, min_NE_count, min_group_count]\n",
    "cat_vars = ['status_author_id', 'NE_fixed', 'group_name']\n",
    "for cat_var, min_count in zip(cat_vars, min_counts):\n",
    "    cat_counts = group_data_reg.loc[:, cat_var].value_counts()\n",
    "    group_data_reg = group_data_reg.assign(**{\n",
    "        '%s_cap'%(cat_var) : group_data_reg.loc[:, cat_var].apply(lambda x: 'RARE' if cat_counts.loc[x] < min_count else x)\n",
    "    })\n",
    "    display(group_data_reg.loc[:, '%s_cap'%(cat_var)].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal regularization weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do L2 regularization to discourage variable overfitting.\n",
    "\n",
    "We'll determine the best weight with log-likelihood comparisons on k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families.family import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "from math import floor, ceil\n",
    "## likelihood definitions\n",
    "## logit cdf\n",
    "def logit_cdf(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "## log likelihood\n",
    "def compute_log_likelihood(params, Y, X):\n",
    "    q = 2 * Y - 1\n",
    "    ll = np.sum(np.log(logit_cdf(q * np.dot(X, params))))\n",
    "    return ll\n",
    "np.random.seed(123)\n",
    "\n",
    "# variable definitions\n",
    "dep_var = 'anchor'\n",
    "cat_vars = ['NE_fixed', 'status_author_id', 'group_name']\n",
    "cap_cat_vars = ['%s_cap'%(cat_var) for cat_var in cat_vars]\n",
    "scalar_vars = ['NE_count', 'txt_len_norm', 'author_group_count', 'group_size', 'group_contains_NE']\n",
    "indep_formula = ' + '.join(['C(%s)'%(cap_cat_var) for cap_cat_var in cap_cat_vars] + scalar_vars)\n",
    "formula = '%s ~ %s'%(dep_var, indep_formula)\n",
    "# convert raw data to exogenous data\n",
    "# need to do this to force train/test\n",
    "# to have same features\n",
    "l2_weights = [0., 0.001, 0.01, 0.1, 1.]\n",
    "group_data_rand = group_data_reg.copy()\n",
    "np.random.shuffle(group_data_rand.values)\n",
    "model_dummy = GLM.from_formula(formula, group_data_rand, family=Binomial(link=logit()))\n",
    "exog = model_dummy.exog\n",
    "exog_names = model_dummy.exog_names\n",
    "endog = model_dummy.endog\n",
    "# generate cross validation folds\n",
    "cross_val_folds = 10\n",
    "N = group_data_rand.shape[0]\n",
    "cross_val_chunk_size = float(N) / cross_val_folds\n",
    "cross_val_fold_train_idx = [list(range(int(floor(i*cross_val_chunk_size)), int(ceil((i+1)*cross_val_chunk_size)))) for i in range(cross_val_folds)]\n",
    "cross_val_fold_test_idx = [list(range(0, int(ceil(i*cross_val_chunk_size)))) + list(range(int(floor((i+1)*cross_val_chunk_size)), N)) for i in range(cross_val_folds)]\n",
    "weight_likelihoods = []\n",
    "for l2_weight in l2_weights:\n",
    "    print('testing weight = %.3f'%(l2_weight))\n",
    "    likelihoods_l2 = []\n",
    "    for i, (train_idx_i, test_idx_i) in enumerate(zip(cross_val_fold_train_idx, cross_val_fold_test_idx)):\n",
    "        print('fold %d'%(i))\n",
    "        train_XY = group_data_rand.iloc[train_idx_i, :]\n",
    "        test_X = exog[test_idx_i, :]\n",
    "        test_Y = endog[test_idx_i]\n",
    "#         train_i = anchor_data_NE_peak_filter_rand.iloc[train_idx_i, :]\n",
    "#         test_i = anchor_data_NE_peak_filter_rand.iloc[test_idx_i, :]\n",
    "        # fit model\n",
    "        model_i = GLM.from_formula(formula, train_XY, family=Binomial(link=logit()))\n",
    "        model_res_i = model_i.fit_regularized(maxiter=max_iter, method='elastic_net', alpha=l2_weight, L1_wt=0.)\n",
    "        # add 0 params for missing coefficients\n",
    "        # to match X shape\n",
    "        model_res_i.params = model_res_i.params.loc[exog_names].fillna(0, inplace=False)\n",
    "        # score test data\n",
    "        # implement this: http://www.statsmodels.org/stable/_modules/statsmodels/discrete/discrete_model.html#Logit.loglikeobs\n",
    "        likelihood_i = compute_log_likelihood(model_res_i.params, test_Y, test_X)\n",
    "        likelihoods_l2.append(likelihood_i)\n",
    "    weight_likelihoods.append(likelihoods_l2)\n",
    "weight_likelihoods = pd.DataFrame(np.array(weight_likelihoods), index=l2_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(weight_likelihoods.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise! The same L2 weight that we found before ($\\alpha=0.01$) has the highest log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/istewart6/.local/lib/python3.6/site-packages/statsmodels/genmod/generalized_linear_model.py:1303: UserWarning: GLM ridge optimization may have failed, |grad|=0.000192\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev=539.454, df=236, p=8.382E-26\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families.family import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "import sys\n",
    "if('..' not in sys.path):\n",
    "    sys.path.append('..')\n",
    "from importlib import reload\n",
    "import models.model_helpers\n",
    "reload(models.model_helpers)\n",
    "from models.model_helpers import compute_err_data, compute_chi2_null_test\n",
    "dep_var = 'anchor'\n",
    "cat_vars = ['NE_fixed', 'status_author_id', 'group_name']\n",
    "# cat_vars = ['NE_fixed', 'status_author_id']\n",
    "cap_cat_vars = ['%s_cap'%(cat_var) for cat_var in cat_vars]\n",
    "scalar_vars = ['NE_count', 'txt_len_norm', 'author_group_count', 'group_size', 'group_contains_NE']\n",
    "indep_formula = ' + '.join(['C(%s)'%(cap_cat_var) for cap_cat_var in cap_cat_vars] + scalar_vars)\n",
    "formula = '%s ~ %s'%(dep_var, indep_formula)\n",
    "\n",
    "## non-regularized\n",
    "# logit_model = Logit.from_formula(formula, data=group_data_reg)\n",
    "# model_results = logit_model.fit()\n",
    "## L2 norm to reduce variable inflation on fixed effects\n",
    "l2_weight = 0.01\n",
    "max_iter = 100\n",
    "model_full = GLM.from_formula(formula, group_data_reg, family=Binomial(link=logit()))\n",
    "model_res_full = model_full.fit_regularized(maxiter=max_iter, method='elastic_net', alpha=l2_weight, L1_wt=0.0)\n",
    "model_err = compute_err_data(model_res_full)\n",
    "dev, model_df, p_val = compute_chi2_null_test(model_res_full, group_data_reg, dep_var, max_iter, l2_weight)\n",
    "print('dev=%.3f, df=%d, p=%.3E'%(dev, model_df, p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>SE</th>\n",
       "      <th>z_score</th>\n",
       "      <th>p_val</th>\n",
       "      <th>conf_2.5</th>\n",
       "      <th>conf_97.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Intercept</td>\n",
       "      <td>-2.029957</td>\n",
       "      <td>28.550367</td>\n",
       "      <td>-0.071101</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>-57.987648</td>\n",
       "      <td>53.927734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(NE_fixed_cap)[T.aguadilla]</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>1.046750</td>\n",
       "      <td>0.037059</td>\n",
       "      <td>0.998904</td>\n",
       "      <td>-2.012800</td>\n",
       "      <td>2.090383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(NE_fixed_cap)[T.aguas buenas]</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>2.366402</td>\n",
       "      <td>-0.011156</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>-4.664463</td>\n",
       "      <td>4.611663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(NE_fixed_cap)[T.aibonito]</td>\n",
       "      <td>-0.010801</td>\n",
       "      <td>0.854830</td>\n",
       "      <td>-0.012636</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>-1.686238</td>\n",
       "      <td>1.664636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(NE_fixed_cap)[T.alcaldia]</td>\n",
       "      <td>-0.020647</td>\n",
       "      <td>0.800099</td>\n",
       "      <td>-0.025806</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>-1.588812</td>\n",
       "      <td>1.547518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean         SE   z_score     p_val  \\\n",
       "Intercept                       -2.029957  28.550367 -0.071101  0.995966   \n",
       "C(NE_fixed_cap)[T.aguadilla]     0.038792   1.046750  0.037059  0.998904   \n",
       "C(NE_fixed_cap)[T.aguas buenas] -0.026400   2.366402 -0.011156  0.999901   \n",
       "C(NE_fixed_cap)[T.aibonito]     -0.010801   0.854830 -0.012636  0.999873   \n",
       "C(NE_fixed_cap)[T.alcaldia]     -0.020647   0.800099 -0.025806  0.999469   \n",
       "\n",
       "                                  conf_2.5  conf_97.5  \n",
       "Intercept                       -57.987648  53.927734  \n",
       "C(NE_fixed_cap)[T.aguadilla]     -2.012800   2.090383  \n",
       "C(NE_fixed_cap)[T.aguas buenas]  -4.664463   4.611663  \n",
       "C(NE_fixed_cap)[T.aibonito]      -1.686238   1.664636  \n",
       "C(NE_fixed_cap)[T.alcaldia]      -1.588812   1.547518  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>SE</th>\n",
       "      <th>z_score</th>\n",
       "      <th>p_val</th>\n",
       "      <th>conf_2.5</th>\n",
       "      <th>conf_97.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>NE_count</td>\n",
       "      <td>-0.074550</td>\n",
       "      <td>7.164435</td>\n",
       "      <td>-0.010406</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>-14.116584</td>\n",
       "      <td>13.967484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>txt_len_norm</td>\n",
       "      <td>0.036790</td>\n",
       "      <td>0.036339</td>\n",
       "      <td>1.012397</td>\n",
       "      <td>0.305388</td>\n",
       "      <td>-0.034434</td>\n",
       "      <td>0.108013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>author_group_count</td>\n",
       "      <td>-0.328241</td>\n",
       "      <td>0.522473</td>\n",
       "      <td>-0.628245</td>\n",
       "      <td>0.693070</td>\n",
       "      <td>-1.352269</td>\n",
       "      <td>0.695787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>group_size</td>\n",
       "      <td>0.121074</td>\n",
       "      <td>33.642900</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>-65.817799</td>\n",
       "      <td>66.059947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>group_contains_NE</td>\n",
       "      <td>-0.623419</td>\n",
       "      <td>0.106352</td>\n",
       "      <td>-5.861851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.831865</td>\n",
       "      <td>-0.414973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean         SE   z_score     p_val   conf_2.5  \\\n",
       "NE_count           -0.074550   7.164435 -0.010406  0.999914 -14.116584   \n",
       "txt_len_norm        0.036790   0.036339  1.012397  0.305388  -0.034434   \n",
       "author_group_count -0.328241   0.522473 -0.628245  0.693070  -1.352269   \n",
       "group_size          0.121074  33.642900  0.003599  0.999990 -65.817799   \n",
       "group_contains_NE  -0.623419   0.106352 -5.861851  0.000000  -0.831865   \n",
       "\n",
       "                    conf_97.5  \n",
       "NE_count            13.967484  \n",
       "txt_len_norm         0.108013  \n",
       "author_group_count   0.695787  \n",
       "group_size          66.059947  \n",
       "group_contains_NE   -0.414973  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_err.head())\n",
    "display(model_err.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>SE</th>\n",
       "      <th>z_score</th>\n",
       "      <th>p_val</th>\n",
       "      <th>conf_2.5</th>\n",
       "      <th>conf_97.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Intercept</td>\n",
       "      <td>-2.029957</td>\n",
       "      <td>28.550367</td>\n",
       "      <td>-0.071101</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>-57.987648</td>\n",
       "      <td>53.927734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(NE_fixed_cap)[T.aguadilla]</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>1.046750</td>\n",
       "      <td>0.037059</td>\n",
       "      <td>0.998904</td>\n",
       "      <td>-2.012800</td>\n",
       "      <td>2.090383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(NE_fixed_cap)[T.aguas buenas]</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>2.366402</td>\n",
       "      <td>-0.011156</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>-4.664463</td>\n",
       "      <td>4.611663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(NE_fixed_cap)[T.aibonito]</td>\n",
       "      <td>-0.010801</td>\n",
       "      <td>0.854830</td>\n",
       "      <td>-0.012636</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>-1.686238</td>\n",
       "      <td>1.664636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(NE_fixed_cap)[T.alcaldia]</td>\n",
       "      <td>-0.020647</td>\n",
       "      <td>0.800099</td>\n",
       "      <td>-0.025806</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>-1.588812</td>\n",
       "      <td>1.547518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean         SE   z_score     p_val  \\\n",
       "Intercept                       -2.029957  28.550367 -0.071101  0.995966   \n",
       "C(NE_fixed_cap)[T.aguadilla]     0.038792   1.046750  0.037059  0.998904   \n",
       "C(NE_fixed_cap)[T.aguas buenas] -0.026400   2.366402 -0.011156  0.999901   \n",
       "C(NE_fixed_cap)[T.aibonito]     -0.010801   0.854830 -0.012636  0.999873   \n",
       "C(NE_fixed_cap)[T.alcaldia]     -0.020647   0.800099 -0.025806  0.999469   \n",
       "\n",
       "                                  conf_2.5  conf_97.5  \n",
       "Intercept                       -57.987648  53.927734  \n",
       "C(NE_fixed_cap)[T.aguadilla]     -2.012800   2.090383  \n",
       "C(NE_fixed_cap)[T.aguas buenas]  -4.664463   4.611663  \n",
       "C(NE_fixed_cap)[T.aibonito]      -1.686238   1.664636  \n",
       "C(NE_fixed_cap)[T.alcaldia]      -1.588812   1.547518  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>SE</th>\n",
       "      <th>z_score</th>\n",
       "      <th>p_val</th>\n",
       "      <th>conf_2.5</th>\n",
       "      <th>conf_97.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>NE_count</td>\n",
       "      <td>-0.074550</td>\n",
       "      <td>7.164435</td>\n",
       "      <td>-0.010406</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>-14.116584</td>\n",
       "      <td>13.967484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>txt_len_norm</td>\n",
       "      <td>0.036790</td>\n",
       "      <td>0.036339</td>\n",
       "      <td>1.012397</td>\n",
       "      <td>0.305388</td>\n",
       "      <td>-0.034434</td>\n",
       "      <td>0.108013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>author_group_count</td>\n",
       "      <td>-0.328241</td>\n",
       "      <td>0.522473</td>\n",
       "      <td>-0.628245</td>\n",
       "      <td>0.693070</td>\n",
       "      <td>-1.352269</td>\n",
       "      <td>0.695787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>group_size</td>\n",
       "      <td>0.121074</td>\n",
       "      <td>33.642900</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>-65.817799</td>\n",
       "      <td>66.059947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>group_contains_NE</td>\n",
       "      <td>-0.623419</td>\n",
       "      <td>0.106352</td>\n",
       "      <td>-5.861851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.831865</td>\n",
       "      <td>-0.414973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean         SE   z_score     p_val   conf_2.5  \\\n",
       "NE_count           -0.074550   7.164435 -0.010406  0.999914 -14.116584   \n",
       "txt_len_norm        0.036790   0.036339  1.012397  0.305388  -0.034434   \n",
       "author_group_count -0.328241   0.522473 -0.628245  0.693070  -1.352269   \n",
       "group_size          0.121074  33.642900  0.003599  0.999990 -65.817799   \n",
       "group_contains_NE  -0.623419   0.106352 -5.861851  0.000000  -0.831865   \n",
       "\n",
       "                    conf_97.5  \n",
       "NE_count            13.967484  \n",
       "txt_len_norm         0.108013  \n",
       "author_group_count   0.695787  \n",
       "group_size          66.059947  \n",
       "group_contains_NE   -0.414973  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# old\n",
    "display(model_err.head())\n",
    "display(model_err.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure if I believe these results, given that the intercept is insignificant when it should be negative. One reason for a negative intercept is that it serves as the \"base\" category for all the fixed effects.\n",
    "\n",
    "If these results hold, then `txt_len_norm` is the only significant result which hurts our use of the other explanatory variables in later analysis.\n",
    "\n",
    "**Conclusion**: this model is severely overfitting due to dependent variable sparsity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the deviance etc. for a model with only the fixed effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev=397.227, df=231, p=6.258E-11\n"
     ]
    }
   ],
   "source": [
    "dep_var = 'anchor'\n",
    "cat_vars = ['NE_fixed', 'status_author_id', 'group_name']\n",
    "cap_cat_vars = ['%s_cap'%(cat_var) for cat_var in cat_vars]\n",
    "indep_formula = ' + '.join(['C(%s)'%(cap_cat_var) for cap_cat_var in cap_cat_vars])\n",
    "formula = '%s ~ %s'%(dep_var, indep_formula)\n",
    "\n",
    "## non-regularized\n",
    "# logit_model = Logit.from_formula(formula, data=group_data_reg)\n",
    "# model_results = logit_model.fit()\n",
    "## L2 norm to reduce variable inflation on fixed effects\n",
    "l2_weight = 0.01\n",
    "max_iter = 100\n",
    "model_full = GLM.from_formula(formula, group_data_reg, family=Binomial(link=logit()))\n",
    "model_res_full = model_full.fit_regularized(maxiter=max_iter, method='elastic_net', alpha=l2_weight, L1_wt=0.0)\n",
    "model_err = compute_err_data(model_res_full)\n",
    "dev, model_df, p_val = compute_chi2_null_test(model_res_full, group_data_reg, dep_var, max_iter, l2_weight)\n",
    "print('dev=%.3f, df=%d, p=%.3E'%(dev, model_df, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: the full model has higher deviance than the model with only fixed effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we drop the fixed effects and just fit the explanatory variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev=183.360, df=5, p=1.025E-37\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families.family import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "import sys\n",
    "if('..' not in sys.path):\n",
    "    sys.path.append('..')\n",
    "from importlib import reload\n",
    "import models.model_helpers\n",
    "reload(models.model_helpers)\n",
    "from models.model_helpers import compute_err_data, compute_chi2_null_test\n",
    "dep_var = 'anchor'\n",
    "scalar_vars = ['NE_count', 'txt_len_norm', 'author_group_count', 'group_size', 'group_contains_NE']\n",
    "indep_formula = ' + '.join(scalar_vars)\n",
    "formula = '%s ~ %s'%(dep_var, indep_formula)\n",
    "\n",
    "## L2 norm to reduce variable inflation on fixed effects\n",
    "l2_weight = 0.01\n",
    "max_iter = 100\n",
    "model_full = GLM.from_formula(formula, group_data_reg, family=Binomial(link=logit()))\n",
    "model_res_full = model_full.fit_regularized(maxiter=max_iter, method='elastic_net', alpha=l2_weight, L1_wt=0.0)\n",
    "model_err = compute_err_data(model_res_full)\n",
    "dev, model_df, p_val = compute_chi2_null_test(model_res_full, group_data_reg, dep_var, max_iter, l2_weight)\n",
    "print('dev=%.3f, df=%d, p=%.3E'%(dev, model_df, p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>SE</th>\n",
       "      <th>z_score</th>\n",
       "      <th>p_val</th>\n",
       "      <th>conf_2.5</th>\n",
       "      <th>conf_97.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Intercept</td>\n",
       "      <td>-2.372707</td>\n",
       "      <td>0.040322</td>\n",
       "      <td>-58.843649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.451737</td>\n",
       "      <td>-2.293677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NE_count</td>\n",
       "      <td>-0.074842</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>-2.123216</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.143930</td>\n",
       "      <td>-0.005755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>txt_len_norm</td>\n",
       "      <td>0.093893</td>\n",
       "      <td>0.030279</td>\n",
       "      <td>3.100962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034548</td>\n",
       "      <td>0.153237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>author_group_count</td>\n",
       "      <td>-0.224318</td>\n",
       "      <td>0.040297</td>\n",
       "      <td>-5.566633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.303299</td>\n",
       "      <td>-0.145338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>group_size</td>\n",
       "      <td>0.046145</td>\n",
       "      <td>0.031911</td>\n",
       "      <td>1.446066</td>\n",
       "      <td>0.036518</td>\n",
       "      <td>-0.016399</td>\n",
       "      <td>0.108689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>group_contains_NE</td>\n",
       "      <td>-0.680379</td>\n",
       "      <td>0.064262</td>\n",
       "      <td>-10.587623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.806330</td>\n",
       "      <td>-0.554428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean        SE    z_score     p_val  conf_2.5  \\\n",
       "Intercept          -2.372707  0.040322 -58.843649  0.000000 -2.451737   \n",
       "NE_count           -0.074842  0.035250  -2.123216  0.000007 -0.143930   \n",
       "txt_len_norm        0.093893  0.030279   3.100962  0.000000  0.034548   \n",
       "author_group_count -0.224318  0.040297  -5.566633  0.000000 -0.303299   \n",
       "group_size          0.046145  0.031911   1.446066  0.036518 -0.016399   \n",
       "group_contains_NE  -0.680379  0.064262 -10.587623  0.000000 -0.806330   \n",
       "\n",
       "                    conf_97.5  \n",
       "Intercept           -2.293677  \n",
       "NE_count            -0.005755  \n",
       "txt_len_norm         0.153237  \n",
       "author_group_count  -0.145338  \n",
       "group_size           0.108689  \n",
       "group_contains_NE   -0.554428  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict context fixed effect from containment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpler: let's do the same thing but just using `group_contains_NE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/istewart6/.local/lib/python3.6/site-packages/statsmodels/genmod/generalized_linear_model.py:1303: UserWarning: GLM ridge optimization may have failed, |grad|=0.000036\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula=anchor ~ 1\n",
      "dev=248.732, df=127, p=6.416E-10\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod.families.family import Binomial\n",
    "from statsmodels.genmod.families.links import logit\n",
    "import sys\n",
    "if('..' not in sys.path):\n",
    "    sys.path.append('..')\n",
    "from models.model_helpers import compute_err_data\n",
    "dep_var = 'anchor'\n",
    "cat_vars = ['status_author_id', 'group_name']\n",
    "cap_cat_vars = ['%s_cap'%(cat_var) for cat_var in cat_vars]\n",
    "scalar_vars = ['group_contains_NE']\n",
    "indep_formula = ' + '.join(['C(%s)'%(cap_cat_var) for cap_cat_var in cap_cat_vars] + scalar_vars)\n",
    "formula = '%s ~ %s'%(dep_var, indep_formula)\n",
    "\n",
    "## non-regularized\n",
    "# logit_model = Logit.from_formula(formula, data=group_data_reg)\n",
    "# model_results = logit_model.fit()\n",
    "## L2 norm to reduce variable inflation on fixed effects\n",
    "l2_weight = 0.01\n",
    "max_iter = 100\n",
    "model_full = GLM.from_formula(formula, group_data_reg, family=Binomial(link=logit()))\n",
    "model_res_full = model_full.fit_regularized(maxiter=max_iter, method='elastic_net', alpha=l2_weight, L1_wt=0.0)\n",
    "model_err = compute_err_data(model_res_full)\n",
    "dev, model_df, p_val = compute_chi2_null_test(model_res_full, group_data_reg, dep_var, max_iter, l2_weight)\n",
    "print('dev=%.3f, df=%d, p=%.3E'%(dev, model_df, p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>SE</th>\n",
       "      <th>z_score</th>\n",
       "      <th>p_val</th>\n",
       "      <th>conf_2.5</th>\n",
       "      <th>conf_97.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Intercept</td>\n",
       "      <td>-2.115682</td>\n",
       "      <td>0.544714</td>\n",
       "      <td>-3.884024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.183301</td>\n",
       "      <td>-1.048062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(status_author_id_cap)[T.370781346691489]</td>\n",
       "      <td>-0.007173</td>\n",
       "      <td>0.968358</td>\n",
       "      <td>-0.007407</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>-1.905120</td>\n",
       "      <td>1.890774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(status_author_id_cap)[T.377022969399263]</td>\n",
       "      <td>-0.011229</td>\n",
       "      <td>0.842238</td>\n",
       "      <td>-0.013332</td>\n",
       "      <td>0.999858</td>\n",
       "      <td>-1.661984</td>\n",
       "      <td>1.639527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(status_author_id_cap)[T.530249124001312]</td>\n",
       "      <td>-0.008098</td>\n",
       "      <td>0.945828</td>\n",
       "      <td>-0.008561</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>-1.861887</td>\n",
       "      <td>1.845692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(status_author_id_cap)[T.603616776695697]</td>\n",
       "      <td>-0.063274</td>\n",
       "      <td>0.567813</td>\n",
       "      <td>-0.111434</td>\n",
       "      <td>0.990093</td>\n",
       "      <td>-1.176167</td>\n",
       "      <td>1.049620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                mean        SE   z_score  \\\n",
       "Intercept                                  -2.115682  0.544714 -3.884024   \n",
       "C(status_author_id_cap)[T.370781346691489] -0.007173  0.968358 -0.007407   \n",
       "C(status_author_id_cap)[T.377022969399263] -0.011229  0.842238 -0.013332   \n",
       "C(status_author_id_cap)[T.530249124001312] -0.008098  0.945828 -0.008561   \n",
       "C(status_author_id_cap)[T.603616776695697] -0.063274  0.567813 -0.111434   \n",
       "\n",
       "                                               p_val  conf_2.5  conf_97.5  \n",
       "Intercept                                   0.000000 -3.183301  -1.048062  \n",
       "C(status_author_id_cap)[T.370781346691489]  0.999956 -1.905120   1.890774  \n",
       "C(status_author_id_cap)[T.377022969399263]  0.999858 -1.661984   1.639527  \n",
       "C(status_author_id_cap)[T.530249124001312]  0.999942 -1.861887   1.845692  \n",
       "C(status_author_id_cap)[T.603616776695697]  0.990093 -1.176167   1.049620  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>SE</th>\n",
       "      <th>z_score</th>\n",
       "      <th>p_val</th>\n",
       "      <th>conf_2.5</th>\n",
       "      <th>conf_97.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C(group_name_cap)[T.Quebradillas#Huracan#Maria]</td>\n",
       "      <td>-0.179122</td>\n",
       "      <td>0.351366</td>\n",
       "      <td>-0.509786</td>\n",
       "      <td>0.794955</td>\n",
       "      <td>-0.867786</td>\n",
       "      <td>0.509543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(group_name_cap)[T.RARE]</td>\n",
       "      <td>0.042371</td>\n",
       "      <td>0.442223</td>\n",
       "      <td>0.095814</td>\n",
       "      <td>0.992675</td>\n",
       "      <td>-0.824370</td>\n",
       "      <td>0.909112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(group_name_cap)[T.Se Buscan Mayaguez PR Huracan Maria]</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>0.535183</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>-1.039775</td>\n",
       "      <td>1.058103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C(group_name_cap)[T.Updates de Familia en Isabela y Huracan Maria]</td>\n",
       "      <td>-0.035516</td>\n",
       "      <td>0.514561</td>\n",
       "      <td>-0.069023</td>\n",
       "      <td>0.996199</td>\n",
       "      <td>-1.044038</td>\n",
       "      <td>0.973005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>group_contains_NE</td>\n",
       "      <td>-0.657564</td>\n",
       "      <td>0.077184</td>\n",
       "      <td>-8.519425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.808842</td>\n",
       "      <td>-0.506286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        mean        SE  \\\n",
       "C(group_name_cap)[T.Quebradillas#Huracan#Maria]    -0.179122  0.351366   \n",
       "C(group_name_cap)[T.RARE]                           0.042371  0.442223   \n",
       "C(group_name_cap)[T.Se Buscan Mayaguez PR Hurac...  0.009164  0.535183   \n",
       "C(group_name_cap)[T.Updates de Familia en Isabe... -0.035516  0.514561   \n",
       "group_contains_NE                                  -0.657564  0.077184   \n",
       "\n",
       "                                                     z_score     p_val  \\\n",
       "C(group_name_cap)[T.Quebradillas#Huracan#Maria]    -0.509786  0.794955   \n",
       "C(group_name_cap)[T.RARE]                           0.095814  0.992675   \n",
       "C(group_name_cap)[T.Se Buscan Mayaguez PR Hurac...  0.017123  0.999766   \n",
       "C(group_name_cap)[T.Updates de Familia en Isabe... -0.069023  0.996199   \n",
       "group_contains_NE                                  -8.519425  0.000000   \n",
       "\n",
       "                                                    conf_2.5  conf_97.5  \n",
       "C(group_name_cap)[T.Quebradillas#Huracan#Maria]    -0.867786   0.509543  \n",
       "C(group_name_cap)[T.RARE]                          -0.824370   0.909112  \n",
       "C(group_name_cap)[T.Se Buscan Mayaguez PR Hurac... -1.039775   1.058103  \n",
       "C(group_name_cap)[T.Updates de Familia en Isabe... -1.044038   0.973005  \n",
       "group_contains_NE                                  -0.808842  -0.506286  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_err.head())\n",
    "display(model_err.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes more sense. The local effect is still strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
