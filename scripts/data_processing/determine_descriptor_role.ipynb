{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine anchor role\n",
    "We've detected anchor use in posts, but can we determine what the role of the information is for the author/audience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = '../../data/mined_tweets/combined_tweet_tag_data_NE_flat.gz'\n",
    "# combined_data = pd.read_csv(data_file, index_col=False, sep='\\t', compression='gzip')\n",
    "# combined_data = combined_data.assign(**{'username' : combined_data.loc[:, 'username'].apply(lambda x: x.split(':')[-1])})\n",
    "# combined_data.to_csv(data_file, sep='\\t', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>txt</th>\n",
       "      <th>data_name_fixed</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>NE</th>\n",
       "      <th>NE_type</th>\n",
       "      <th>NE_LOC</th>\n",
       "      <th>valid_loc</th>\n",
       "      <th>NE_fixed</th>\n",
       "      <th>has_descriptor</th>\n",
       "      <th>NE_fixed_clean</th>\n",
       "      <th>max_population</th>\n",
       "      <th>max_alternate_name_count</th>\n",
       "      <th>max_population_anchor</th>\n",
       "      <th>max_population_diff</th>\n",
       "      <th>max_alternate_name_count_anchor</th>\n",
       "      <th>max_alternate_name_count_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>899098735367647232</td>\n",
       "      <td>Tropical Depression #Harvey is 1543 miles SSE ...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>wralweather</td>\n",
       "      <td>2017-08-19 22:40:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>raleigh</td>\n",
       "      <td>False</td>\n",
       "      <td>raleigh</td>\n",
       "      <td>451066.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>899258634223353856</td>\n",
       "      <td>#Harvey , #Illinois #firefighters ' #pension o...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>acklaw</td>\n",
       "      <td>2017-08-20 09:15:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>chicago</td>\n",
       "      <td>False</td>\n",
       "      <td>chicago</td>\n",
       "      <td>2720546.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>899272853954101249</td>\n",
       "      <td>Harvey's. 2380 Wyandotte Street West, Windsor,...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>foodpages</td>\n",
       "      <td>2017-08-20 10:12:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Windsor</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>windsor</td>\n",
       "      <td>False</td>\n",
       "      <td>windsor</td>\n",
       "      <td>28778.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>899425632215588864</td>\n",
       "      <td>NHC_Atlantic: #Harvey 's remnants are likely t...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>JasonBoyerWLOS</td>\n",
       "      <td>2017-08-20 20:19:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Bay</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>bay</td>\n",
       "      <td>False</td>\n",
       "      <td>bay</td>\n",
       "      <td>15402.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>899443698693529601</td>\n",
       "      <td>@NHC_Atlantic #Harvey 's remnants are likely t...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>BinTaxi</td>\n",
       "      <td>2017-08-20 21:31:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Bay</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>bay</td>\n",
       "      <td>False</td>\n",
       "      <td>bay</td>\n",
       "      <td>15402.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                                txt  \\\n",
       "17  899098735367647232  Tropical Depression #Harvey is 1543 miles SSE ...   \n",
       "31  899258634223353856  #Harvey , #Illinois #firefighters ' #pension o...   \n",
       "33  899272853954101249  Harvey's. 2380 Wyandotte Street West, Windsor,...   \n",
       "49  899425632215588864  NHC_Atlantic: #Harvey 's remnants are likely t...   \n",
       "55  899443698693529601  @NHC_Atlantic #Harvey 's remnants are likely t...   \n",
       "\n",
       "   data_name_fixed        username                 date lang       NE  \\\n",
       "17          harvey     wralweather  2017-08-19 22:40:00   en  Raleigh   \n",
       "31          harvey          acklaw  2017-08-20 09:15:00   en  Chicago   \n",
       "33          harvey       foodpages  2017-08-20 10:12:00   en  Windsor   \n",
       "49          harvey  JasonBoyerWLOS  2017-08-20 20:19:00   en      Bay   \n",
       "55          harvey         BinTaxi  2017-08-20 21:31:00   en      Bay   \n",
       "\n",
       "     NE_type  NE_LOC  valid_loc NE_fixed  has_descriptor NE_fixed_clean  \\\n",
       "17  LOCATION    True       True  raleigh           False        raleigh   \n",
       "31  LOCATION    True       True  chicago           False        chicago   \n",
       "33  LOCATION    True       True  windsor           False        windsor   \n",
       "49  LOCATION    True       True      bay           False            bay   \n",
       "55  LOCATION    True       True      bay           False            bay   \n",
       "\n",
       "    max_population  max_alternate_name_count  max_population_anchor  \\\n",
       "17        451066.0                      43.0                  False   \n",
       "31       2720546.0                      70.0                  False   \n",
       "33         28778.0                      16.0                  False   \n",
       "49         15402.0                      15.0                  False   \n",
       "55         15402.0                      15.0                  False   \n",
       "\n",
       "    max_population_diff  max_alternate_name_count_anchor  \\\n",
       "17                  0.0                            False   \n",
       "31                  0.0                            False   \n",
       "33                  0.0                            False   \n",
       "49                  0.0                            False   \n",
       "55                  0.0                            False   \n",
       "\n",
       "    max_alternate_name_count_diff  \n",
       "17                            0.0  \n",
       "31                            0.0  \n",
       "33                            0.0  \n",
       "49                            0.0  \n",
       "55                            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_file = '../../data/mined_tweets/combined_tweet_tag_data_NE_flat.gz'\n",
    "combined_data = pd.read_csv(data_file, index_col=False, sep='\\t', compression='gzip')\n",
    "# remove bad NEs\n",
    "data_name_NEs = ['#%s'%(x) for x in combined_data.loc[:, 'data_name_fixed'].unique()]\n",
    "combined_data = combined_data[~combined_data.loc[:, 'NE_fixed'].isin(data_name_NEs)]\n",
    "# restrict to valid\n",
    "combined_data_valid = combined_data[combined_data.loc[:, 'valid_loc']==1]\n",
    "display(combined_data_valid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wralweather'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_valid.loc[:, 'username'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate anchors\n",
    "Annotate true/false positives for anchoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing data=florence\n",
      "4477/8683\n",
      "NE to anchor = new_bern\n",
      "txt = RT @EdValleeWx: Our models specifically used for forecasting hurricanes have great agreement in #Florence making landfall near New Bern, NC…\n",
      "NE to anchor = wilmington\n",
      "txt = RT @WMO: Hurricane #Florence is likely to make landfall near Wilmington (North Carolina) . The tidal data shows a sea level rise of around…\n",
      "NE to anchor = cape_fear\n",
      "txt = RT @ABC: LATEST: Hurricane #Florence a Category 4 storm 670 miles ESE of Cape Fear, North Carolina, with maximum sustained winds of 140 mph…\n",
      "NE to anchor = fayetteville\n",
      "txt = You put your lips on them cigars more than you do on me\" GF says. #cigar #lastselfie #sotl #botl #hurricaneflorence @ Fayetteville, North Carolina <URL>\n",
      "NE to anchor = wilmington\n",
      "txt = RT @FoxNewsResearch: #HurricaneFlorence - latest •Cat 2 •170 mi ESE of Wilmington, NC •220 mi E of Myrtle Beach, SC •10M+ in its path •1.7M…\n",
      "NE to anchor = red_cross\n",
      "txt = Met Reyna and her whole family who evacuated from the coast to a Red Cross shelter in Wilson, NC. She says they left everything behind, so they are hoping to have something to go back to. #hurricaneflorence <URL>\n",
      "NE to anchor = shallotte\n",
      "txt = UPDATE: The @WaffleHouse in North Myrtle Beach remains open this morning even as #HurricaneFlorence bears down. And who do I meet? Barrett - the tenacious employee from Shallotte who refused to shut down as long as @Bojangles1977 was still slingin’ hash. <URL>\n",
      "NE to anchor = kensington\n",
      "txt = Fast move Ng low clouds and trees starting to dance! #florence @ Kensington at Regency, Cary <URL>\n",
      "NE to anchor = wilmington\n",
      "txt = #hurricaneflorence in downtown Wilmington, NC @TheNOWtv @ Downtown Wilmington By Cape Fear River <URL>\n",
      "NE to anchor = sunset_beach\n",
      "txt = #hurricaneflorence #sunsetbeachnc #oceanislebeach #northcarolina #sup #veterinary @wildearthpets lauraw1717 madisonwardd _taylor_51 @ Sunset Beach, North Carolina <URL>\n",
      "NE to anchor = morehead_city\n",
      "txt = Morehead City, NC decimated by #HurricaneFlorence with @DukeEnergy experts doing damage assessments—saying it’s the worst they’ve seen. Flooded areas will make accessing our equipment extremely difficult. Stay safe, stay informed. <URL>\n",
      "NE to anchor = murrells_inlet\n",
      "txt = Walking around the development, so far so good regarding #Florence. Just some branches & pine needles down. #southcarolina #murrellsinlet #nofilter #scwx #wx @ Murrells Inlet, South Carolina <URL>\n",
      "NE to anchor = suwanee\n",
      "txt = The edge of Hurricane Florence #hurricaneflorence moving into Georgia. @ Suwanee, Georgia <URL>\n",
      "NE to anchor = maxton\n",
      "txt = Late dinner for linemen in Maxton, NC tonight. It’s windy and rainy, but the base camp up and operational and is able to get crews a hot meal.  #HurricaneFlorence2018 <URL>\n",
      "NE to anchor = new_bern\n",
      "txt = Downtown New Bern, North Carolina #Florence #1010WINS #NewBernStrong <URL>\n",
      "NE to anchor = charlotte\n",
      "txt = #HurricaneFlorence update! @ Charlotte, North Carolina <URL>\n",
      "NE to anchor = holden_beach\n",
      "txt = @bentonblount Lincolnton NC still okay! Also, our little Holden beach home survived. Bought with the retirement money from a 36 year Cop. .. my Hubby! #HurricaneFlorence2018 #policewife\n",
      "NE to anchor = jacksonville\n",
      "txt = HerMight&Mercy...Captured in Jacksonville, NC. Large oak uprooted but small chicken coop left in exact spot! 3 hens left nestled together w additional shelter. Amazing! #HurricaneFlorenceNC #Florence #jacksonvillenc <URL>\n",
      "NE to anchor = lumberton\n",
      "txt = We didn’t think it would be this bad #hurricaneflorence @ Lumberton, North Carolina <URL>\n",
      "NE to anchor = kinston\n",
      "txt = Deputies from the Rockingham County Sheriff's Office are here in Kinston, NC helping out with issues caused by #flooding. #HurricaneFlorence #KinstonNC <URL>\n",
      "NE to anchor = wilmington\n",
      "txt = #Florence rainfall has pushed Wilmington, NC annual rainfall to record levels with 86.2\"\". There is still 3 months left!!! It's possible Wilmington could see more than 100 inches before 2018 is up! <URL>\n",
      "NE to anchor = mayfair\n",
      "txt = Homes in the Mayfair neighborhood of Lumberton, NC are underwater again, after being flooded in 2016 during Hurricane Matthew..and water levels continue to rise. #HurricaneFlorence #lumbertonnc #northcarolina #lumberriver @TheNOWtv <URL>\n",
      "NE to anchor = little_river\n",
      "txt = The Little River in Manchester, NC, near Spring Lake and upstream from #FayettevilleNC , has hit a record level, according to @NWS . River at 34.96 ft as of 3:30PM Monday. During Hurricane Matthew (previous all-time high) it reached 32.19 ft. #florence #ncwx @newsobserver <URL>\n",
      "NE to anchor = bladen_county\n",
      "txt = So people outside NC can understand the incredible amount of rain: Elizabethtown in Bladen county got over 36 inches in four days. CHICAGO gets roughly that in a YEAR. Our average in Raleigh is 46. For the YEAR. #HurricaneFlorence\n",
      "NE to anchor = indian_trail\n",
      "txt = ROAD CLOSURE: Another closure just added to the list in Union County. This is on Chesnut Lane in Indian Trail. The area was flooded yesterday. Today... This. @wsoctv #Florence <URL>\n",
      "NE to anchor = montreal\n",
      "txt = Luckily both boxes were delivered and were delayed by #hurricaneflorence but I fly out tomorrow for a weeks vacation in Canada (Montreal and Quebec) then to #nyc for a week for work and… <URL>\n",
      "NE to anchor = ithaca\n",
      "txt = The remains of #Florence spared Rochester. However, it's a different story from Ithaca to Oneonta. 3 to 4\"\" of rain has fallen from Chemung to southern Cortland counties. Flood Warnings are up for some there. <URL>\n",
      "NE to anchor = columbus\n",
      "txt = Yesterday, our crews teamed up with @insideFPL to assess damage throughout Columbus and Bladen counties in North Carolina. Crews continue to work through challenging conditions to restore power to customers impacted by #Florence . Track progress: <URL>\n",
      "NE to anchor = williamstown\n",
      "txt = @weatherchannel this is from Williamstown, MA. Our bridge is about to get wiped out! Even Mass is being affected by #Florence <URL>\n",
      "NE to anchor = brooklyn\n",
      "txt = Looks like I made it to Brooklyn not a moment too soon. The remnants of #Florence have arrived here in NYC...\n",
      "NE to anchor = pollocksville\n",
      "txt = After almost 30\"\" of rain during #Florence , Jones county is now experiencing historic flooding along the Trent River. Here r some pics from Pollocksville where rescue crews have worked tirelessly assisting residents. Special thank you to @NYPDnews , who have come a long way 2 help! <URL>\n",
      "NE to anchor = fort_bragg\n",
      "txt = Aviators of the 82nd Airborne Division Combat Aviation Brigade began returning aircraft to Fort Bragg today. They were placed out of harms way at Robins Air Force Base in Georgia. #hurricaneflorence ; #Armyhurricaneresponse #Armyhurricaneflorence #HUREVAC2018 #ArmyResponse ; #18ABC <URL>\n",
      "NE to anchor = lumberton\n",
      "txt = Houses sit in floodwater caused by #HurricaneFlorence , in this aerial picture, on the outskirts of Lumberton, North Carolina, via @Reuters photographer Jason Miczek See Reuters top photos from the last 24 hours: <URL>\n",
      "NE to anchor = new_bern\n",
      "txt = New WCK kitchen opening in New Bern! This is one of the worst hit areas in North Carolina...Tonight we served hundreds of residents & we activate a local food truck tomorrow! My brother @cheftkilcoyne showing how food relief should be done! #Florence @WCKitchen @NC_Governor <URL>\n",
      "NE to anchor = hartsville\n",
      "txt = Our teams returned to the command base in Darlington this evening with eyes still on a concerning river and dam situation in Hartsville. Here is a look at the area they staged at today. #Florence #LouisianaProud <URL>\n",
      "NE to anchor = myrtle_beach\n",
      "txt = Thanks. My wife & I were driving that road 16 days ago heading from Myrtle Beach to the NASCAR race in Darlington. The PeeDee River is halfway between Marion and Darlington. Very sad what is happening. We're thinking about everyone in the Carolinas affected by #HurricaneFlorence .\n",
      "NE to anchor = north\n",
      "txt = Argentina expresses its sincere condolences to the Government and the people of the United States over the tragic loss of several lives left by #HurricaneFlorence in various States mainly in North and South Carolina. Read the press release here: <URL>\n",
      "NE to anchor = everett\n",
      "txt = ONLY ON @WXII : A multi-state operation to check on/rescue a stranded community. The Deep River here in Chatham County has cut off Everett Dowdy Rd. Food and water are being distributed. If needed people can be boated back and transported on a NG truck. #Florence <URL>\n",
      "NE to anchor = southport\n",
      "txt = My aunt & uncle have lived in Southport, North Carolina for about 35 years. They evacuated from #HurricaneFlorence and stayed with family a couple hours away. They are still away, but I heard from my mother today that their house is structurally safe. So much flooding though. :(\n",
      "NE to anchor = anson\n",
      "txt = CHECK THIS OUT! Viewer video of Mayesville Rd in Anson County during #Florence. @NCDOT crews say it will take several months until all impacted roads are reopened. There are 44 closed roads in Anson County alone. NCDOT has 12 assessment teams checking damage in Anson and Union. <URL>\n",
      "NE to anchor = horry_county\n",
      "txt = More evacuations coming in Horry County, SC. #Florence #flooding <URL>\n",
      "NE to anchor = new_bern\n",
      "txt = New Bern, NC & Conway, SC got visits from @POTUS Trump yesterday as they recover from the devastation brought by #Florence . Coming up hear what ppl in area had to say about his visit @WBTV_News <URL>\n",
      "NE to anchor = lumberton\n",
      "txt = Thanks to the amazing generosity of people in and around the Triangle, @WRAL helped fill 5 buses, 5 trailers, 3 vans and a small truck with supplies for #Florence victims. 130,500 lbs in supplies will be delivered next week to Wilmington, Lumberton and New Bern. #wral\n",
      "NE to anchor = boiling_spring_lakes\n",
      "txt = Update: #HurricaneFlorence Brunswick County will have food and water available for distribution Friday, Sept. 21 from 11 a.m. To 5 p.m. at: Spring Lake Park (210 Pine Road in Boiling Spring Lakes) Northwest... <URL>\n",
      "NE to anchor = jacksonville\n",
      "txt = . @COJacksonville NC​ officials recommend avoiding a major intersection at the end of the Jacksonville bypass because of heavy traffic use by those heading to the southern coast. #HurricaneFlorence #FlorenceNC <URL>\n",
      "NE to anchor = cape_fear\n",
      "txt = Please pay attention to #WilmingtonNC and surrounding areas near the Cape Fear, NE Cape Fear & Black Rivers today and through the weekend. Many in Pender County were evacuated last night by National Guard, now this today. #HurricaneFlorence <URL>\n",
      "NE to anchor = spring_lakes\n",
      "txt = Boiling Spring Lakes, NC #CarolinaStrong #HurricaneFlorence #GiveBack @EdPiotrowski @wpdeabc15 @jamiearnoldWMBF @wmbfweather <URL>\n",
      "NE to anchor = georgetown_county\n",
      "txt = Georgetown County will open emergency shelters at 7 a.m. Monday at the following locations: • Georgetown High School, 2500 Anthuan Maybank Drive, Georgetown • Waccamaw Middle School, 247 Wildcat Way, Pawleys Island @SCPublicRadio #HurricaneFlorence @GCEMD\n",
      "NE to anchor = red_cross\n",
      "txt = Eat at #beachsidebistro and 10% of your purchase will be donated to the Red Cross of North Carolina to help our fellow #northcarolinians affected by #hurricaneflorence #foodforflo … <URL>\n",
      "NE to anchor = duke\n",
      "txt = Coal ash flowing like pudding in Neuse River near Duke's Goldsboro power plant <URL>\n",
      "testing data=harvey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18355/70963\n",
      "NE to anchor = corpus_christi\n",
      "txt = The first Hurricane Watches for this part of #Texas in 3,267 days (9yrs!) like Houston & Corpus Christi #TXwx #Harvey h/t @KathrynProciv <URL>\n",
      "NE to anchor = rockport\n",
      "txt = As of 10 a.m., the modeling has #Harvey making landfall north of Rockport, which would spare Corpus Christi the worst of the storm.\n",
      "NE to anchor = brownsville\n",
      "txt = The eye of #HurricaneHarvey is now showing on the Brownsville, Texas long range radar. <URL>\n",
      "NE to anchor = corpus_christi\n",
      "txt = Praying for Texas, esp my other home Corpus Christi. #HurricaneHarvey\n",
      "NE to anchor = matagorda\n",
      "txt = Heavy squall headed toward Matagorda and Brazoria County coasts. Watch for waterspouts. #txwx #harvey <URL>\n",
      "NE to anchor = galveston\n",
      "txt = #Live . @mikebettes on #Periscope : Streaming cam from Galveston, Texas as Hurricane #Harvey approaches coast. #txwx <URL>\n",
      "NE to anchor = galveston\n",
      "txt = Headed to Galveston as #Harvey pushes closer to the TX coast. Look for updates here & live reports on @KPRC2 at 10 #HurricaneHarvey #kprc2 <URL>\n",
      "NE to anchor = rockport\n",
      "txt = #Harvey up to Cat 4 now. Just hours from landfall near Rockport, TX. Winds sustained at 130 mph. <URL>\n",
      "NE to anchor = lubbock\n",
      "txt = @UnitedAirways I know you will do the right thing and refund my flight from Corpus Christi to Lubbock. #harvey . Thanks\n",
      "NE to anchor = san_jose_island\n",
      "txt = Eyewall of #Harvey moving over San Jose Island north of Port Aransas, TX. #txwx <URL>\n",
      "NE to anchor = san_jose_island\n",
      "txt = #BREAKING #HurricaneHarvey makes landfall on TX coast over the northern end of San Jose Island about 4 miles east of Rockport. #nprnewscast\n",
      "NE to anchor = san_jose_island\n",
      "txt = #HurricaneHarvey makes landfall on San Jose Island, TX near Rockport, TX as a Cat. 4 hurricane. @WCCBCharlotte <URL>\n",
      "NE to anchor = port_aransas\n",
      "txt = The eye of Hurricane #Harvey has made landfall between Port Aransas and Port O'Conner, TX. This is still only the beginning.\n",
      "NE to anchor = houston\n",
      "txt = praying for my family all around texas, especially most of my family that resides in houston. stay safe! #prayfortexas #hurricaneharvey\n",
      "NE to anchor = houston\n",
      "txt = My hometown Houston be safe people texting me i'm chill i'm in Dallas we should be gucci #HurricaneHarvey\n",
      "NE to anchor = rockport\n",
      "txt = CBS NEWS: Reports that portions of high school in Rockport, Texas, where #HurricaneHarvey made landfall, have collapsed <URL>\n",
      "NE to anchor = corpus_christi\n",
      "txt = Hurricane #Harvey Makes Landfall Near Corpus Christi, Texas but the danger is not over <URL>\n",
      "NE to anchor = san_marcos\n",
      "txt = Rain and lots wind in San Marcos,Tx. Checked in with my parentals and everyone is ok with a little damage. Thanks #HurricaneHarvey\n",
      "NE to anchor = corpus_christi\n",
      "txt = The tale of Hurricane #Harvey from two Texas cities: Corpus Christi's peak wind gust was 63 mph while Rockport's... <URL>\n",
      "NE to anchor = sienna_plantation\n",
      "txt = Tornado damage in Sienna Plantation S of Houston and Katy W of Houston #HurricaneHarvey #Harvey2017 Flooding Mayde Creek - Katy W of Houston\n",
      "NE to anchor = austin\n",
      "txt = I'm at a shelter in Austin, TX, where @govabbott is meeting with evacuated Texans. #harvey #txlege <URL>\n",
      "NE to anchor = wharton\n",
      "txt = Convoy of wildlife agents from Louisiana towing boats leave gas station in Wharton and head toward Houston #harvey <URL>\n",
      "NE to anchor = sharpstown\n",
      "txt = ALL of my District is under siege-Brays Oaks, Med Center, Meyerland, Sharpstown, Southpark, Sunnyside, 3rd Ward, & Westbury. #Harvey #Flood <URL>\n",
      "NE to anchor = san_antonio\n",
      "txt = Wolff said patients from Ben Taub in Houston might be transported to San Antonio area hospitals. Not confirmed yet. #Harvey\n",
      "NE to anchor = plano\n",
      "txt = Plano efforts w/ #HurricaneHarvey (1/2) - Plano Fire-Rescue: 2 members deployed w/ TX Task Force One & 3 (incl K-9) w/ TX Task Force Two. <URL>\n",
      "NE to anchor = yale\n",
      "txt = VIDEO: I-10 at Yale, The Heights, Houston (residential area on the north side of downtown.) ( - @euzkera ) #Harvey <URL>\n",
      "NE to anchor = dayton\n",
      "txt = The latest rainfall totals (since Thurs) compiled by @NWSWPC are INSANE! 39.2 inches (so far) in Dayton, TX. 30+ in south Houston. #harvey <URL>\n",
      "NE to anchor = houston\n",
      "txt = Prayers to all the people of Houston especially #uoflalumni at Houston and Dallas alumni chapters #HurricaneHarvey #cardinalstrong\n",
      "NE to anchor = lindale\n",
      "txt = CONTACT?!!!!!!!!!!!!! 2 KAYAKS 4 #HELP inner LOOP: LINDALE, IRVINGTON, CAVALCADE area and BEYOND! #HurricaneHarvey #Houston <URL>\n",
      "NE to anchor = chicago\n",
      "txt = 60 TX counties declared disaster areas due to #HurricaneHarvey . Meanwhile Chicago declared a disaster area for being Chicago @ChicagosMayor\n",
      "NE to anchor = houston\n",
      "txt = From New York to Houston- our thoughts are with the safety and well-being of everyone in Texas. #HoustonStong #HurricaneHarvey <URL>\n",
      "NE to anchor = houston\n",
      "txt = @realDonaldTrump You bypassed Houston? If NYC had a 1,000-year flood wd you visit Albany & Rochester, bypass NYC? #Harvey #HurricaneHarvey\n",
      "NE to anchor = round_top\n",
      "txt = Teague's Tavern in Round Top is offering 10 percent of their sales to flood relief efforts in La Grange and Houston. Check them out! #Harvey\n",
      "NE to anchor = harris_county\n",
      "txt = NOAA: rainfall total from #Harvey for Cedar Bayou in Harris County, Texas, is at 51.88”, a contiguous US record for any tropical system.\n",
      "NE to anchor = corpus_christi\n",
      "txt = President Trump and First Lady Melania at Annaville Fire Rescue | Corpus Christi, TX #HurricaneHarvey <URL>\n",
      "NE to anchor = port_arthur\n",
      "txt = 1927 Freeman Ave. 77642 Port Arthur, Tx elderly lady and her granddaughter stuck #HurricaneHarvey #portarthur\n",
      "NE to anchor = austin\n",
      "txt = Has anyone in Houston been successful driving to Austin or are roads still under? #Houston #Harvey\n",
      "NE to anchor = united\n",
      "txt = #HurricaneHarvey #MumbaiRains Houston Vs Mumbai Divided by oceans, United in Grief <URL>\n",
      "NE to anchor = bevil_oaks\n",
      "txt = Coast Guard and Port Arthur officials involved in rescues in the city, Bevil Oaks FD rescuing in that area. #SETXNews #Harvey\n",
      "NE to anchor = harris_county\n",
      "txt = Sending prayers - More than 1,700 square miles of Harris County in Texas in underwater - more than New York City & Chicago combined. #Harvey <URL>\n",
      "NE to anchor = bend\n",
      "txt = Treviño on #HurricaneHarvey : We are getting ready for refugees. Let's not forget Coastal Bend communities. It is not just Houston.\n",
      "NE to anchor = prague\n",
      "txt = So... #Harvey for (European) scale. Corpus Christi is ~Milan Houston is ~München Beumont ~Salzburg Shreveport ~Prague <URL>\n",
      "NE to anchor = galveston\n",
      "txt = Because the horror and devastation of #Harvey was in Houston and Galveston not Corpus Cristi. Go to the heart of it all not a safe area <URL>\n",
      "NE to anchor = euless\n",
      "txt = Another crew from Euless and Haltom City heading out with a N. Texas strike team headed to Southeast Texas #Harvey <URL>\n",
      "NE to anchor = san_antonio\n",
      "txt = While airports are resuming service, getting a flight to Houston is not easy; Some folks flying to San Antonio, then driving. #Harvey\n",
      "NE to anchor = corpus_christi\n",
      "txt = Our claims adjusters are in Corpus Christi, Victoria & limited areas of Houston. To contact our claims team: <URL>\n",
      "NE to anchor = sandy\n",
      "txt = Sweet! There's no age limit on kindness. We're taking donations today @KATUNews - ocated at NE 21st & Sandy in PDX. #Harvey #TexasStrong <URL>\n",
      "NE to anchor = cleveland\n",
      "txt = Better have a plan for DC, Baltimore, Philly, NYC, CLEVELAND, BUFFALO, TORONTO, OTTOWA, MONTREAL. And all between. GFS Model #harvey correct <URL>\n",
      "NE to anchor = woodsboro\n",
      "txt = We're gonna be headed to Woodsboro, TX pop. 1,512 tomorrow to drop off supplies. #Harvey Amazon Wish List - <URL>\n",
      "NE to anchor = miami\n",
      "txt = Houston: We just had worse hurricane in recorded history Miami: Hold my cafecito #AndrewSurvivor #HurricaneIrma #HurricaneHarvey\n",
      "testing data=irma\n",
      "20033/64354\n",
      "NE to anchor = morgantown\n",
      "txt = @kellycass Good morning from Morgantown,WV. Watching today's rain & that impact on Cheat River watershed before #Irma arrives.\n",
      "NE to anchor = london\n",
      "txt = @ShiriSpear do you think #IRMA will directly hit North Florida / Orlando / WDW area. Flying from London to Orlando Thursday curious to kno?\n",
      "NE to anchor = miami\n",
      "txt = #Harvey slammed Houston. Irma on its way to Miami. Both are cities of immigrants & #dreamers . Trump hits #DACA . #HurricaneTrump\n",
      "NE to anchor = miami\n",
      "txt = If #irma is still on FL track in two days, why not fill up all cruise ships in Miami, Cape canaveral etc with ppl - ship away from storm?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE to anchor = miami\n",
      "txt = @AmericanAir supposed to fly to the Dominican Republic, connection in Miami. Trying to switch to Mexico & you want to charge me? #Help #Irma\n",
      "NE to anchor = tampa\n",
      "txt = Hoping for a safe week for our friends at Hillsborough Area Regional Transit in Tampa, FL as they prepare for #HurricaneIrma .\n",
      "NE to anchor = anna_maria_island\n",
      "txt = Anna Maria Island evacuating 9/7/17 at 12:40 PM. Mileage check zero. Destination Clearwater then sweet home Alabama. #Irma please .\n",
      "NE to anchor = miami\n",
      "txt = My thoughts and prayers are with Miami and the entire State of Florida #HurricaneIrma\n",
      "NE to anchor = white_house\n",
      "txt = #HurricaneIrma please go hit Washington DC *Specifically White House* Thanks the hole world\n",
      "NE to anchor = jacksonville\n",
      "txt = JUST IN - A MANDATORY EVACUATION has been issued for Jacksonville, Florida. #CNN #Irma\n",
      "NE to anchor = fort_myers\n",
      "txt = Made it to Tulsa last night from Fort Myers escaping #hurricaneirma . Just home we have a home back in FL when we get back. @jamesaydelott\n",
      "NE to anchor = miami\n",
      "txt = Friends in Miami and Florida, good luck and be safe! #hurricaneirma #irma #miamibeach <URL>\n",
      "NE to anchor = houston\n",
      "txt = Left FL to help in Houston, now the hope is that FL will weather the storm. Let's pray for all those in the path of #hurricaneirma\n",
      "NE to anchor = miami\n",
      "txt = LATEST: Hurricane #Irma is 405 miles southeast of Miami; it's spreading westward over parts of Cuba and the... <URL>\n",
      "NE to anchor = orlando\n",
      "txt = I hope everyone staying at the theme parks, Orlando, and throughout the entire state of Florida remains as safe as possible! #Irma\n",
      "NE to anchor = madrid\n",
      "txt = No planes over Miami right now. That one you see is Air Europa 787 leaving soon for Madrid tonight. #HurricaneIrma <URL>\n",
      "NE to anchor = tampa\n",
      "txt = My family in Miami evacuated yesterday to Tampa. They aren't out of #Irma 's path completely, but I'm so grateful they were able to leave.\n",
      "NE to anchor = jacksonville\n",
      "txt = milfordonmove: Local Statement for Jacksonville, FL #disney #dcl #Irma <URL>\n",
      "NE to anchor = naples\n",
      "txt = I expect #Irma to make landfall on MO 8 AM nearby Naples. Will hit Tampa at 2PM.\n",
      "NE to anchor = naples\n",
      "txt = #Irma is forecast to make landfall somewhere between Naples & Sarasota sometime Sun night & pass very near or over Tampa early Mon am. #flwx\n",
      "NE to anchor = charleston\n",
      "txt = Friends and family in Florida facing Hurricane Irma, know you are in our thoughts and prayers in Charleston #hurricaneirma #charleston <URL>\n",
      "NE to anchor = miami\n",
      "txt = Curfews in effect during #HurricaneIrma in the cities of Miami, Miami Beach and North Miami Beach. No curfew for unincorporated Dade County. <URL>\n",
      "NE to anchor = miami\n",
      "txt = Sincerely hope everyone in Florida & Miami is safe and prepared for #Irma (as well as you can be) thoughts and prayers for those affected.\n",
      "NE to anchor = tampa\n",
      "txt = #JewishTimes #Florida #RickScott #HurricaneIrma Irma closes in with Tampa, not Miami, in the crosshairs <URL>\n",
      "NE to anchor = lancaster\n",
      "txt = High wind watch for Cleveland county and lake wind adv. for Lancaster and Chesterfield due to #Irma . #scwx #ncwx <URL>\n",
      "NE to anchor = naples\n",
      "txt = . @CityofMiami mayor tells @MLauer he reached out to mayors of Naples, Ft. Myers, Sarasota & Tampa yesterday to offer help #HurricaneIrma\n",
      "NE to anchor = greenville\n",
      "txt = Evacuation! Keep safe everyone! #hurricane #irma — traveling to Greenville, South Carolina\n",
      "NE to anchor = miami\n",
      "txt = @MSNBC Appreciate thoroughness on #Irma but at what point do you cover prep/problems NORTH of Keys/Miami? & how's Houston? Nature itself?!\n",
      "NE to anchor = miami\n",
      "txt = Heavy flooding right now on the streets of Downtown Miami in Florida #Irma\n",
      "NE to anchor = naples\n",
      "txt = Still a long way to go but it is looking like #Irma may make landfall between Naples and Fort Myers.\n",
      "NE to anchor = miami\n",
      "txt = Pray for Florida as hurricane Irma impacts Miami. #hurricaneirma <URL>\n",
      "NE to anchor = miami\n",
      "txt = cnnbrk: #HurricaneIrma ’s intense rain and wind pound JohnBerman in Miami. 75% of Miami-Dade County is now without… <URL>\n",
      "NE to anchor = marco_island\n",
      "txt = #Irma just made landfall with FL mainland on Marco Island as a Category 3!! @yohoster @GaryBrennan10 @MichaelDillman @MrJShupp @Skena3 <URL>\n",
      "NE to anchor = sunset_terrace\n",
      "txt = Indian River Dr and Sunset Terrace, Cocoa. Drivers need to use Highview Dr from the south or Forest Hill Dr from the North #Irma <URL>\n",
      "NE to anchor = miami-dade\n",
      "txt = 3.3 million in Florida w/o power, 80% of Miami-Dade w/o power #HurricaneIrma\n",
      "NE to anchor = duval\n",
      "txt = Flash Flood Warning in effect in Clay, Duval, Nassau and St. Johns Counties until 830 AM #flwx #HurricaneIrma <URL>\n",
      "NE to anchor = tallahassee\n",
      "txt = Power outages from my friends in Miami-dade, to Orlando, and now Tallahassee #HurricaneIrma\n",
      "NE to anchor = augusta\n",
      "txt = Irma has arrived in Augusta, Georgia. The power just went out. #hurricaneirma\n",
      "NE to anchor = beaufort\n",
      "txt = New tornado warning for parts of Beaufort, Colleton County #Irma #Chswx <URL>\n",
      "NE to anchor = charleston\n",
      "txt = Power outages in GA/ flooding in Charleston, SC and Jacksonville. Just a few of the reports today as #Irma moves North. #GAwx #SCwx <URL>\n",
      "NE to anchor = jacksonville\n",
      "txt = Told someone I was from Cleveland while covering #HurricaneIrma in Jacksonville, FL. First question: What number are the @indians on #19baby\n",
      "NE to anchor = ocala\n",
      "txt = #Irma Seeing pockets of heavy traffic SB I-75 from Gainesville thru Ocala as people return to their homes\n",
      "NE to anchor = miami\n",
      "txt = Volunteers from @MuslimYouthUSA working with @HFUSA in Miami, Tampa, Naples and Jacksonville doing #HurricaneIrma cleanup work <URL>\n",
      "NE to anchor = sarasota_county\n",
      "txt = Sarasota County have been very fortunate, that hurricane #Irma did not impact our area as much as it did to other counties in Florida.\n",
      "NE to anchor = naples\n",
      "txt = Day 5 no power, limited gas after #hurricaneirma came across us in Naples, FL. Hoping and praying we get power soon. We are safe\n",
      "NE to anchor = lake\n",
      "txt = @mitchellreports We have major destruction in Polk County Florida. Including Lakeland, bartow,Lake Whales. No power. #Irma\n",
      "NE to anchor = pembroke_park\n",
      "txt = Update on lifting of boil water alert for Hollywood, Pembroke park, Miramar, West Park & Dania Beach. #Irma <URL>\n",
      "NE to anchor = clearwater\n",
      "txt = @andersoncooper #HurricaneIrma Glad to have you in Tampa. I was in Clearwater riding out the storm-I wanted to race to Tampa to meet you.\n",
      "NE to anchor = houston\n",
      "txt = Emotional homecoming for our 80-person AZ TaskForce 1. First deployed for search & rescue in Houston for #Harvey then to Florida for #Irma . <URL>\n",
      "NE to anchor = naples\n",
      "txt = The Status of Our Parks - Along the Gulfshore - September 2017 - Naples, FL #HurricaneIrma <URL>\n",
      "testing data=maria\n",
      "1168/6494\n",
      "NE to anchor = vieques\n",
      "txt = A Hurricane Warning has been issued for Puerto Rico, Culebra, and Vieques. #Maria <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = first band of #maria in San Juan , Puerto Rico <URL>\n",
      "NE to anchor = culebra\n",
      "txt = #Hurricane warnings for: U.S. Virgin Islands, British Virgin Islands, Puerto Rico, Culebra, and Vieques #Maria @680NEWS @680NEWS\n",
      "NE to anchor = ponce\n",
      "txt = This is how Ponce, Puerto Rico looked about 30 mins ago. #Maria <URL>\n",
      "NE to anchor = yabucoa\n",
      "txt = RT @hurrtrackerapp: BREAKING: Hurricane #Maria makes landfall near Yabucoa, Puerto Rico as a 155 mph, category 4 storm. <URL>\n",
      "NE to anchor = yabucoa\n",
      "txt = Went to Humacao, Yabucoa and Vieques multiple times in the mid-aughts. So scary to watch Maria right now #puertorico\n",
      "NE to anchor = yabucoa\n",
      "txt = Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "NE to anchor = yabucoa\n",
      "txt = NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria — NWS San Juan (NWSS…\n",
      "NE to anchor = san_juan\n",
      "txt = Anyone having luck connecting with San Juan, Puerto Rico? Are your texts going through? #PuertoRico #SanJuan #HurricaneMaria\n",
      "NE to anchor = guayama\n",
      "txt = #Maria ... footage from Guayama, Puerto Rico #huracanmaria #hurricanemaria <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = UPDATE: Our San Juan office remains closed today as Puerto Rico is in a state of total devastation after #HurricaneMaria @NWSSanJuan\n",
      "NE to anchor = san_sebastian\n",
      "txt = My heart & prayers are w/ my family in Puerto Rico. Aguadilla, Moca, San Sebastian, San Lorenzo & Mayaguez. ! #PuertoRicoStrong #PuertoRico\n",
      "NE to anchor = san_juan\n",
      "txt = Hurricane #Maria batters San Juan, Puerto Rico, with strong winds as the powerful storm comes ashore. <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = Incredible video from earlier today of the strong winds and flooded road in San Juan, Puerto Rico. #Maria : @TheHungryCondor <URL>\n",
      "NE to anchor = yabucoa\n",
      "txt = RT @NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "NE to anchor = san_juan\n",
      "txt = Our prayers are with the staff and students of UM-related @robinson_school , located in San Juan, Puerto Rico, in the wake of #HurricaneMaria <URL>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE to anchor = guaynabo\n",
      "txt = More destruction photos from Bayamón, Guaynabo and San Juan #Maria <URL>\n",
      "NE to anchor = humacao\n",
      "txt = Si usted se dializa con Fresenius. Caguas, Rio Grande y Humacao van a estar ofreciendo servicios desde las 10am #puertorico\n",
      "NE to anchor = altagracia\n",
      "txt = #HuracanMaria Se deja sentir en Samana, Nagua, Santiago, La Altagracia, Santo Domingo Este y otras localidades. #Maria <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = @weatherchannel is there any way we can hear of other towns in Puerto Rico? There aren’t only people in San Juan! #PuertoRico\n",
      "NE to anchor = yabucoa\n",
      "txt = RT UnivisionNews: Exclusive video: The devastating path of Hurricane #Maria across #Puerto Rico, from Yabucoa to San Juan\n",
      "NE to anchor = jayuya\n",
      "txt = Seeking info on my aunt Milly Bodon & Luis in Jayuya, Puerto Rico (Cuabey). Its only accessible by helicopter.No power/phone #HurricaneMaria <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = #SanJuan #PuertoRico Drone footage shows flooded streets in San Juan, Puerto Rico, after Hurricane #Maria . <URL>\n",
      "NE to anchor = santurce\n",
      "txt = Inundación en áreas de Ocean Park y Santurce. #María #PuertoRico <URL>\n",
      "NE to anchor = san_isidro\n",
      "txt = The current photos of Loíza, San Isidro & Toa baja are heartbreaking! The rebuild needed will be massive #HurricaneMaria #PuertoRico <URL>\n",
      "NE to anchor = las_piedras\n",
      "txt = 9-22-2017 Mabu Las Piedras, Juncos, Garabo, Caguas, southern San Juan Helicopter Video #Maria <URL>\n",
      "NE to anchor = quebradillas\n",
      "txt = Flash Flood Emergency for Quebradillas and Isabela, PR <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = Retweeted ABC News ( @ABC ): Streets in San Juan, Puerto Rico remain flooded days after #Maria made landfall as a... <URL>\n",
      "NE to anchor = ponce\n",
      "txt = Woohoo, Ponce and adjacent areas, help is coming! This is an update from mi tio in Tampa, who is monitoring faith organizations. #PuertoRico <URL>\n",
      "NE to anchor = barinas\n",
      "txt = Update on #HurricaneMaria . My cousin drove to #Yauco and said Costa Sur, Barinas, Almácigo, Palomas, La Quinta are ok. Luchetti is destroyed\n",
      "NE to anchor = vega_alta\n",
      "txt = Vega Alta, a 40 min drive from San Juan, has not seen aid a week after #Maria . Hospital on verge of shutting down. <URL>\n",
      "NE to anchor = toa_alta\n",
      "txt = Toa Alta, Puerto Rico: A cyclist rides over a bridge damaged by #HurricaneMaria . Photograph: Ricardo Arduengo/AFP #ClimateChange #Capitalism <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = Puerto Rico humanitarian crisis Trump talking about Wall Street + banks San Juan Mayor Carmen Yulin Cruz #Maria <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = #PuertoRico Some towns in Puerto Rico have been able to set up hotlines to find family: San Juan 787-294-0277... <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = From the San Juan, Puerto Rico mayor. Heart wrenching. #PuertoRico <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = Trump: If the mayor of San Juan doesn't start praising me, I'll pull ALL relief efforts from Puerto Rico. @realdonaldtRump #maga #PuertoRico\n",
      "NE to anchor = san_juan\n",
      "txt = Dodges the draft, attacks John McCain. Plays golf in NJ, attacks mayor of hurricane ravaged San Juan. #puertorico #weakness #trump <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = Can we please help Puerto Rico? Mayor of San Juan is literally begging for aid! Instead of helping @realDonaldTrump is golfing! #PuertoRico\n",
      "NE to anchor = san_juan\n",
      "txt = Wow, @potus tries to help Puerto Rico and all the mayor of San Juan can say is how bad he is. Thanks for nothing I guess. #puertorico\n",
      "NE to anchor = luquillo\n",
      "txt = El SNM emite aviso de inundaciones repentinas para los municipios de Fajardo, Naguabo, Luquillo, Ceiba hasta las 5:45 p.m. #HuracanMaria E…\n",
      "NE to anchor = morovis\n",
      "txt = We are on the ground delivering Food helping our people in #PuertoRico this weekend, Toa Baja, Morovis , Orocovis. @FeedingAmerica <URL>\n",
      "NE to anchor = san_juan\n",
      "txt = President @realDonaldTrump the Mayor of San Juan does not represent the majority in Puerto Rico. Thanks for your support. #PuertoRico\n",
      "NE to anchor = vegas\n",
      "txt = Pres Trump expected to travel to Puerto Rico tom as scheduled to Survey damage from #Maria . Then heads to Vegas on Wed. #VegasShooting\n",
      "NE to anchor = san_juan\n",
      "txt = Eye of the Storm: A dispatch from San Juan, Puerto Rico by @sodapopcomics <URL>\n",
      "NE to anchor = guaynabo\n",
      "txt = Our potus is in Guaynabo -one of the wealthiest towns in Puerto Rico - does anyone know if he plans to go out of San Juan?? #hurricanemaria\n",
      "NE to anchor = san_juan\n",
      "txt = Welcome to PR, Mr. President @Old San Juan, Puerto Rico. @realDonaldTrump #PuertoRico #HuracanMaria #TrumpBully <URL>\n",
      "NE to anchor = cidra\n",
      "txt = Photos of the land in front of my family's house in Cidra, Puerto Rico. My heart continues to ache for my people @PuertoRicoPUR #Maria <URL>\n",
      "NE to anchor = utuado\n",
      "txt = Watch: A CG aircrew air drops much needed supplies to the residents of Utuado, Puerto Rico after #HurricaneMaria left them stranded <URL>\n",
      "NE to anchor = culebra\n",
      "txt = St John, St Croix, St Thomas, Water Island, Puerto Rico, Culebra, Vieques are ALL US territories & ALL need help! #hurricanemaria\n",
      "testing data=michael\n",
      "4117/8369\n",
      "NE to anchor = gadsden\n",
      "txt = The latest reliable models available (from this morning) ALL keep Hurricane force *sustained* winds out of #Tallahassee from #HurricaneMichael . However Gadsden & Liberty will still per these models get Hurricane force winds so it’s close enough to Tallahassee to worry.\n",
      "NE to anchor = tallahassee\n",
      "txt = HurriCation Self Portrait 3. Nice work on the backdrop katebackdrops #hurricanemichaelmademedoit #longexposure @ Tallahassee, Florida <URL>\n",
      "NE to anchor = panhandle\n",
      "txt = RT @weartv: Massive construction cranes loom over the skyline in Panama City Beach as #HurricaneMichael takes aim at the #Florida Panhandle…\n",
      "NE to anchor = gulf_shores\n",
      "txt = Please be safe my Florida and Gulf Shores friends!! Praying for you! #HurricaneMichael\n",
      "NE to anchor = sarasota\n",
      "txt = #hurricanemichael, Siesta Key Beach, Sarasota, Florida.Only brits 🇬🇧 left on the beach. Sending love further up the panhandle. <URL>\n",
      "NE to anchor = okaloosa_county\n",
      "txt = Our first #HurricaneMichael response teams have arrived at a staging area in Okaloosa County, FL, just across the b… <URL>\n",
      "NE to anchor = lynn_haven\n",
      "txt = Posting for a friend: “If anyone knows what conditions are like or has pics near Delaware Ave (right outside the Lynn Haven Country Club) or on Lisenby near 390, Lynn Haven, FL north of Panama City Beach, FL. Still can get ahold of my mom or grandparents.” #HurricaneMichael\n",
      "NE to anchor = bay\n",
      "txt = More than 80% of our customers in Bay, Franklin, Gulf, Jefferson & Wakulla counties lost power as #Michael roared on shore as a cat. 4 hurricane. Damage assessment & repairs to the electric system are underway in areas that crews are able to access. <URL>\n",
      "NE to anchor = gadsden_county\n",
      "txt = Sadly, we now have 6 confirmed fatalities due to #Michael , all inland. 4 in Gadsden County, FL (NW of Tallahassee), one in Seminole County in SW Georgia, and one north of Charlotte in Iredell County, NC. Most known to be due to wind knocking down trees or structures onto victims.\n",
      "NE to anchor = miami\n",
      "txt = But here I am, always watching other places have outside help in a disaster and here we live with police and fire from Jacksonville, Miami, Hillsborough, Tallahassee and other places roll up and down the roads #PanamaCity #HurricaneMichael\n",
      "NE to anchor = jacksonville\n",
      "txt = IDES is responding to #HurricaneMichael IDES staff is en route to Florida where we will be #partnering with our Anchor Church, Christ's Church of Jacksonville, @ccontheweb to connect with churches in communities affected by #Hurricane Michael. <URL>\n",
      "NE to anchor = darlington\n",
      "txt = TS #Michael knocked down some trees, left thousands without power, and blocked several roadways in Darlington, SC. <URL>\n",
      "NE to anchor = panama_city_beach\n",
      "txt = All day we've all seen the horrific landscape in Panama City Beach and Mexico Beach, Florida and other parts of the Panhandle. But every new drone or aerial shot continues to stun. #Michael was swift. In the morning things were there. In the afternoon, they weren't. <URL>\n",
      "NE to anchor = houston_county\n",
      "txt = Keep all the cities affected by #HurricaneMichael in your prayers. Jackson County Bay County Washington County Houston County and others. We all need help!\n",
      "NE to anchor = mexico_beach\n",
      "txt = All orders to Mexico Beach, FL will be refunded FOC and sent in due course! Please contact info@wave97.com for more information. #HurricaneMichael\n",
      "NE to anchor = beach\n",
      "txt = @Dove it would be the perfect time to send extra dry shampoo to Panama City and Beach. No water for maybe weeks #HurricaneMichael #PanamaCityBeach\n",
      "NE to anchor = panama_city\n",
      "txt = ICYMI: This reporter hunkered down in a Panama City, Florida parking deck as Hurricane Michael roared ashore Wednesday More #HurricaneMichael video: <URL>\n",
      "NE to anchor = bonifay\n",
      "txt = #HurricaneRelief #HurricaneMichael #MAGA #AmericaFirst #NationalGuard #FEMA @fema #KAG From Congressman Matt Gaetz, for areas having trouble getting supplies, food, water around Bonifay, Holmes County, Ponce De Leon areas. Disaster relief contact info below. @RepMattGaetz <URL>\n",
      "NE to anchor = mexico_beach\n",
      "txt = New aerial video of the massive destruction at Mexico Beach, Florida. Thanks once again to our exclusive partners at @Livestormsmedia #arwx #Michael <URL>\n",
      "NE to anchor = mexico_beach\n",
      "txt = DEVASTATING DAMAGE: This is my 2nd year living in Florida during Hurricane Season and the images don't get easier to watch. This picture shows the devastation left behind by #HurricaneMichael in Mexico Beach. Praying for the victims and their families. #PrayersforthePanhandle <URL>\n",
      "NE to anchor = panama_city_beach\n",
      "txt = Thank you, this Panama City Beach #hurricanemichael survivor appreciates what you are doing for us!! Your store in Santa Rosa Beach helped us today when we drove over from Panama City to purchase food/water/supplies for our friends and coworkers. The employees were so kind! <URL>\n",
      "NE to anchor = springfield\n",
      "txt = Rob Golding drove to Springfield, Florida to be with his 89-year-old dad during #HurricaneMichael . His home was spared, but the area suffered damage, so they started taking in neighbors, going out to rescue friends, and organizing food for the community. <URL>\n",
      "NE to anchor = dale\n",
      "txt = #BREAKING: President Trump approves Emergency Disaster Declaration for  the following Alabama counties: Dale, Geneva, Henry, and Houston #HurricaneMichael\n",
      "NE to anchor = panama_city_beach\n",
      "txt = Heard you guys are bringing prepaid phones and charging stations. Please don’t do this on Panama City Beach. They have electricity and access to Destin. Come into Panama City, Callaway, Lynn Haven @TMobile @TMobileHelp #hurricanemichael\n",
      "NE to anchor = mexico_beach\n",
      "txt = Devastation in Mexico Beach, Florida from Hurricane #Michael . <URL>\n",
      "NE to anchor = panama_city_beach\n",
      "txt = Vacasa office in Panama City Beach. Not too bad... property assessments are under way looks promising and positive so far #hurricanemichael @vacasarentals @RickyHaskins @ Panama City… <URL>\n",
      "NE to anchor = bay\n",
      "txt = #HurricaneMichael , current #SNAP households in Bay, Calhoun, Franklin, Gadsden, Gulf, Holmes, Jackson, Jefferson, Leon, Liberty, Wakulla, and Washington counties will receive replacement benefits at a 40% rate as early as 10/15/18 <URL>\n",
      "NE to anchor = mexico_beach\n",
      "txt = At least 46 people remained unaccounted for on Sunday in Mexico Beach, Florida, an area pulverized by #HurricaneMichael 289 people, including 10 children, decided to stay put, despite evacuation orders, and ride out the Category 4 storm <URL>\n",
      "NE to anchor = panhandle\n",
      "txt = President Trump in Florida to tour #HurricaneMichael damage in panhandle: <URL>\n",
      "NE to anchor = panama_city_beach\n",
      "txt = Jackie, a #HurricaneMichael survivor in Panama City Beach, FL, is desperate to contact family and friends as cell service remains down following the storm: \"\"I hope you all are all okay...We're all okay.\"\" <URL>\n",
      "NE to anchor = blountstown\n",
      "txt = I would like to give a great big thank you to @TMobile for having your emergency management truck here in Blountstown, FL and making it possible for us to have WiFi during the aftermath of #HurricaneMichael\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NE to anchor = panama_city\n",
      "txt = #HappyMonday - If you think your Monday's bad... be reminded by the pics from #HurricaneMichael that it can ALWAYS get worse. Listen, we are here in Panama City, FL at groundZero delivering supplies to those impacted... <URL>\n",
      "NE to anchor = panama_city\n",
      "txt = The people ravaged by #HurricaneMichael in Panama City, Florida and Mexico Beach, Florida need our help. Let’s do this by donating to the American Red Cross.\n",
      "NE to anchor = youngstown\n",
      "txt = Day #2 of Hurricane #Michael Damage Surveys - Unbelievable tree damage. We surveyed spots in Southport, Youngstown, & Resota Beach (north of Lynn Haven & Panama City) where all trees were snapped, uprooted, or bent/twisted. Pictures do NOT do the damage justice at all... <URL>\n",
      "NE to anchor = callaway\n",
      "txt = #HurricaneMichael | Tide Loads of Hope is washing clothes for free from 9am-5pm at Walmart Supercenter (25 N Tyndall Pkwy, Callaway, FL 32404) #PanhandleStrong #PanamaCity <URL>\n",
      "NE to anchor = calhoun\n",
      "txt = Check out Calhoun (98% out), Gulf (86%), Jackson (83%), Liberty (71%), and Bay (56%). Then donate some money or critical supplies & lend a hand. #FloridaStrong #HurricaneMichael #beagoodneighbor <URL>\n",
      "NE to anchor = bay\n",
      "txt = Beach Surveys have been completed in Bay, Escambia, Franklin, Okaloosa, Santa Rosa and Gulf counties. #HurricaneMichael\n",
      "NE to anchor = panama_city\n",
      "txt = AMR Leaders were able to visit crews today in Panama City, Florida as the crews were coming and going from missions. Crews are all pretty upbeat and so glad to be able to be in the area to help people! #HurricaneMichael <URL>\n",
      "NE to anchor = sneads\n",
      "txt = Clean Water is on the way to Sneads, Florida! Want to help us deliver more water to victims of #HurricaneMichael ? Visit our website to make a donation! USA: <URL>\n",
      "NE to anchor = mexico_beach\n",
      "txt = Neues von DailyOverview A week ago today, on October 10th, #HurricaneMichael made landfall near Mexico Beach, Florida, with sustained winds of 155 miles per hour (250 kmh). To learn more and see more imagery of Mexico Beach, visit our Instagram page here… <URL>\n",
      "NE to anchor = calhoun\n",
      "txt = One Week After #Michael County By County #FLwx Power Outage Update: Calhoun: 97% Jackson: 81% Liberty: 67% Gulf: 58% Bay/Gadsden: 52% Washington: 18% Holmes: 17%\n",
      "NE to anchor = mexico_beach\n",
      "txt = Want to see the real #AHSApocalypse ? Come down here to Mexico beach or Panama City, FL! #HurricaneMichael #hurricanemichael2018 @CNN @weatherchannel\n",
      "NE to anchor = tallahassee\n",
      "txt = Orange County Utilities’ Water Reclamation and Field Services team members are helping restore sewer systems impacted by #HurricaneMichael in Tallahassee and Panama City. We are proud to support our neighbors, just as they did, following past storms that affected Central Florida. <URL>\n",
      "NE to anchor = bay\n",
      "txt = @verizon is offering 3 free months of service to customers in Bay and Gulf counties in FL supporting people affected by #HurricaneMichael . Good stuff! Any chance you will extend that offer to those of us in the National Guard who have been here since day 1 with no cell signal?\n",
      "NE to anchor = panama_city\n",
      "txt = Reminders from #hurricanemichael . Posted orignally by \"\"The Most Excellent Way\"\" of Panama City, Fl. \"\"And we know that for those who love God all things work together for good, for those… <URL>\n",
      "NE to anchor = mexico_beach\n",
      "txt = One home in Mexico Beach, Florida, appeared largely untouched amid the incredible destruction of #HurricaneMichael . And its owners, Lebron Lackey and his uncle, Russell King, say it's no… <URL>\n",
      "NE to anchor = panama_city\n",
      "txt = Hey guys... PLEASE come to Panama City, Fl. We need some laughs after #HurricaneMichael The beach didn't get hit bad at all. There are many venues. Club La Vila is a huge one. We'd love to see ya'll. Please consider it.\n",
      "NE to anchor = franklin_county\n",
      "txt = This afternoon, state and federal partners held a call to coordinate housing solutions in areas impacted by #HurricaneMichael . Thanks to Franklin County, Liberty County and Washington County for joining us on the call. em2franklin LibertyCoFLEM <URL>\n",
      "NE to anchor = bay\n",
      "txt = Unless you live in Bay, Gulf, Jackson, Calhoun and Gadsden counties. #850Strong #FloridaStrong #HurricaneMichael\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "np.random.seed(123)\n",
    "anchor_col = 'max_population_anchor'\n",
    "combined_data_valid_anchor = combined_data_valid[combined_data_valid.loc[:, anchor_col]==1]\n",
    "group_var = 'data_name_fixed'\n",
    "id_col = 'id'\n",
    "N_sample = 50\n",
    "NE_col = 'NE_fixed'\n",
    "sample_NE_txt = []\n",
    "for data_name_i, data_i in combined_data_valid.groupby(group_var):\n",
    "    print('testing data=%s'%(data_name_i))\n",
    "    data_i_anchor = data_i[data_i.loc[:, id_col].isin(combined_data_valid_anchor.loc[:, id_col].values)]\n",
    "    data_i_anchor_ids = np.random.choice(data_i_anchor.loc[:, id_col].values, N_sample, replace=False)\n",
    "    data_i_anchor_groups = data_i_anchor[data_i_anchor.loc[:, id_col].isin(data_i_anchor_ids)]\n",
    "    print('%d/%d'%(data_i_anchor.shape[0], data_i.shape[0]))\n",
    "    for data_j_id, data_j in data_i_anchor_groups.groupby(id_col):\n",
    "        NE_to_anchor = data_j[data_j.loc[:, anchor_col]==1].loc[:, NE_col].values[0]\n",
    "        print(\"NE to anchor = %s\"%(NE_to_anchor))\n",
    "        print(\"txt = %s\"%(data_j.loc[:, 'txt'].iloc[0]))\n",
    "        ## write to file because this is getting annoying to annotate\n",
    "        sample_NE_txt.append([data_j_id, NE_to_anchor, data_j.loc[:, 'txt'].iloc[0], data_name_i])\n",
    "sample_NE_txt = pd.DataFrame(sample_NE_txt, columns=['id', 'NE', 'txt', 'data_name'])\n",
    "out_file_name = '../../data/mined_tweets/combined_tweet_tag_data_NE_flat_anchor_examples.tsv'\n",
    "if(not os.path.exists(out_file_name)):\n",
    "    sample_NE_txt.to_csv(out_file_name, sep='\\t', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_NE_txt.loc[:, 'id'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/248\n",
      "data_name\n",
      "florence    29\n",
      "harvey      17\n",
      "irma        12\n",
      "maria       19\n",
      "michael     26\n",
      "dtype: int64\n",
      "20/248\n",
      "data_name\n",
      "florence    6\n",
      "harvey      7\n",
      "irma        0\n",
      "maria       3\n",
      "michael     4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# after annotating\n",
    "sample_NE_txt = pd.read_csv('../../data/mined_tweets/combined_tweet_tag_data_NE_flat_anchor_examples.tsv', sep='\\t', index_col=False)\n",
    "# regular context\n",
    "print('%d/%d'%(sample_NE_txt.loc[:, 'context'].sum(), sample_NE_txt.shape[0]))\n",
    "print(sample_NE_txt.groupby('data_name').apply(lambda x: x.loc[:, 'context'].sum()))\n",
    "# sub-clause context\n",
    "print('%d/%d'%(sample_NE_txt.loc[:, 'context_subclause'].sum(), sample_NE_txt.shape[0]))\n",
    "print(sample_NE_txt.groupby('data_name').apply(lambda x: x.loc[:, 'context_subclause'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution is not great! Less than 50% of anchors are actually used for disambiguation, and less than 10% of anchors exist as sub-clauses (i.e. can be extracted by parses). Maybe we need a better definition of \"anchor,\" like [occur within K words of the less important NE]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover subclause context from parse\n",
    "Can we recover subclause context using dependency parses?\n",
    "\n",
    "We can try spacy to start. The heuristic will be \"does the smaller NE have a subclause that contains the anchor NE\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import parse_twitter_data\n",
    "reload(parse_twitter_data)\n",
    "from parse_twitter_data import parse_data\n",
    "## parse all the data! because we need to keep the \"invalid\" locations\n",
    "## that are used for anchoring, ex. state names\n",
    "combined_data_parsed = parse_data(combined_data.drop_duplicates('id', inplace=False))\n",
    "# np.random.seed(123)\n",
    "# test_size = 100\n",
    "# test_data = combined_data_valid.loc[np.random.choice(combined_data_valid.index, test_size, replace=False), :]\n",
    "# test_parsed = parse_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reorganize: one line per ID\n",
    "combined_data_parsed_flat = []\n",
    "for id_i, data_i in combined_data_parsed.groupby('id'):\n",
    "    data_i_flat = pd.Series([id_i, list(data_i.loc[:, 'parse'])])\n",
    "    combined_data_parsed_flat.append(data_i_flat)\n",
    "combined_data_parsed_flat = pd.concat(combined_data_parsed_flat, axis=1).transpose()\n",
    "combined_data_parsed_flat.columns = ['id', 'parse']\n",
    "## combine\n",
    "combined_data_parsed_flat = pd.merge(combined_data, combined_data_parsed_flat, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498786/498786 data\n"
     ]
    }
   ],
   "source": [
    "print('%d/%d data'%(combined_data.shape[0], combined_data_parsed_flat.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>txt</th>\n",
       "      <th>data_name_fixed</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>NE</th>\n",
       "      <th>NE_type</th>\n",
       "      <th>NE_LOC</th>\n",
       "      <th>valid_loc</th>\n",
       "      <th>NE_fixed</th>\n",
       "      <th>has_descriptor</th>\n",
       "      <th>NE_fixed_clean</th>\n",
       "      <th>max_population</th>\n",
       "      <th>max_alternate_name_count</th>\n",
       "      <th>max_population_anchor</th>\n",
       "      <th>max_population_diff</th>\n",
       "      <th>max_alternate_name_count_anchor</th>\n",
       "      <th>max_alternate_name_count_diff</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>453202</th>\n",
       "      <td>1038453206693695489</td>\n",
       "      <td>RT @BMcNoldy: Only 10 major hurricanes have ma...</td>\n",
       "      <td>florence</td>\n",
       "      <td>thebutterknife</td>\n",
       "      <td>2018-09-08 15:45:12+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>jacksonville</td>\n",
       "      <td>False</td>\n",
       "      <td>jacksonville</td>\n",
       "      <td>868031.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[RT, PROPN, 1, compound, 0], [@BMcNoldy, PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453203</th>\n",
       "      <td>1038453206693695489</td>\n",
       "      <td>RT @BMcNoldy: Only 10 major hurricanes have ma...</td>\n",
       "      <td>florence</td>\n",
       "      <td>thebutterknife</td>\n",
       "      <td>2018-09-08 15:45:12+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Cape_Hatteras</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>cape_hatteras</td>\n",
       "      <td>False</td>\n",
       "      <td>cape hatteras</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>868031.0</td>\n",
       "      <td>True</td>\n",
       "      <td>56.0</td>\n",
       "      <td>[[[RT, PROPN, 1, compound, 0], [@BMcNoldy, PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453262</th>\n",
       "      <td>1038802428655620096</td>\n",
       "      <td>RT @MelissaNordWx: New 11 AM Advisory from the...</td>\n",
       "      <td>florence</td>\n",
       "      <td>OldCrowNest</td>\n",
       "      <td>2018-09-09 14:52:53+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>True</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>115933.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "      <td>8495434.0</td>\n",
       "      <td>True</td>\n",
       "      <td>129.0</td>\n",
       "      <td>[[[RT, PROPN, 1, compound, 0], [@MelissaNordWx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453263</th>\n",
       "      <td>1038802428655620096</td>\n",
       "      <td>RT @MelissaNordWx: New 11 AM Advisory from the...</td>\n",
       "      <td>florence</td>\n",
       "      <td>OldCrowNest</td>\n",
       "      <td>2018-09-09 14:52:53+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>NC</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>nc</td>\n",
       "      <td>False</td>\n",
       "      <td>nc</td>\n",
       "      <td>8611367.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[RT, PROPN, 1, compound, 0], [@MelissaNordWx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453292</th>\n",
       "      <td>1038943919298502659</td>\n",
       "      <td>Shoutout to #HurricaneFlorence for ruining my ...</td>\n",
       "      <td>florence</td>\n",
       "      <td>Candace_RDH</td>\n",
       "      <td>2018-09-10 00:15:07+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>charleston</td>\n",
       "      <td>True</td>\n",
       "      <td>charleston</td>\n",
       "      <td>132609.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10456416.0</td>\n",
       "      <td>True</td>\n",
       "      <td>68.0</td>\n",
       "      <td>[[[Shoutout, PROPN, 9, nsubj, 0], [to, PART, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453293</th>\n",
       "      <td>1038943919298502659</td>\n",
       "      <td>Shoutout to #HurricaneFlorence for ruining my ...</td>\n",
       "      <td>florence</td>\n",
       "      <td>Candace_RDH</td>\n",
       "      <td>2018-09-10 00:15:07+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>TN</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>tn</td>\n",
       "      <td>False</td>\n",
       "      <td>tn</td>\n",
       "      <td>10589025.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[Shoutout, PROPN, 9, nsubj, 0], [to, PART, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453337</th>\n",
       "      <td>1039158004946530305</td>\n",
       "      <td>RT @NWSCharlestonSC: Hurricane #Florence was c...</td>\n",
       "      <td>florence</td>\n",
       "      <td>ChasersChs</td>\n",
       "      <td>2018-09-10 14:25:49+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>charleston</td>\n",
       "      <td>True</td>\n",
       "      <td>charleston</td>\n",
       "      <td>132609.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>True</td>\n",
       "      <td>4097233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>122.0</td>\n",
       "      <td>[[[RT, PROPN, 1, compound, 0], [@NWSCharleston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453338</th>\n",
       "      <td>1039158004946530305</td>\n",
       "      <td>RT @NWSCharlestonSC: Hurricane #Florence was c...</td>\n",
       "      <td>florence</td>\n",
       "      <td>ChasersChs</td>\n",
       "      <td>2018-09-10 14:25:49+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>SC</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>sc</td>\n",
       "      <td>False</td>\n",
       "      <td>sc</td>\n",
       "      <td>4229842.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[RT, PROPN, 1, compound, 0], [@NWSCharleston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453374</th>\n",
       "      <td>1039207250282274816</td>\n",
       "      <td>RT @EdValleeWx: Population density map overlai...</td>\n",
       "      <td>florence</td>\n",
       "      <td>kathycalm</td>\n",
       "      <td>2018-09-10 17:41:30+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>False</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>115933.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "      <td>711164.0</td>\n",
       "      <td>True</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[[[RT, PROPN, 1, compound, 0], [@EdValleeWx, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453375</th>\n",
       "      <td>1039207250282274816</td>\n",
       "      <td>RT @EdValleeWx: Population density map overlai...</td>\n",
       "      <td>florence</td>\n",
       "      <td>kathycalm</td>\n",
       "      <td>2018-09-10 17:41:30+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>charlotte</td>\n",
       "      <td>False</td>\n",
       "      <td>charlotte</td>\n",
       "      <td>827097.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[[RT, PROPN, 1, compound, 0], [@EdValleeWx, P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "453202  1038453206693695489   \n",
       "453203  1038453206693695489   \n",
       "453262  1038802428655620096   \n",
       "453263  1038802428655620096   \n",
       "453292  1038943919298502659   \n",
       "453293  1038943919298502659   \n",
       "453337  1039158004946530305   \n",
       "453338  1039158004946530305   \n",
       "453374  1039207250282274816   \n",
       "453375  1039207250282274816   \n",
       "\n",
       "                                                      txt data_name_fixed  \\\n",
       "453202  RT @BMcNoldy: Only 10 major hurricanes have ma...        florence   \n",
       "453203  RT @BMcNoldy: Only 10 major hurricanes have ma...        florence   \n",
       "453262  RT @MelissaNordWx: New 11 AM Advisory from the...        florence   \n",
       "453263  RT @MelissaNordWx: New 11 AM Advisory from the...        florence   \n",
       "453292  Shoutout to #HurricaneFlorence for ruining my ...        florence   \n",
       "453293  Shoutout to #HurricaneFlorence for ruining my ...        florence   \n",
       "453337  RT @NWSCharlestonSC: Hurricane #Florence was c...        florence   \n",
       "453338  RT @NWSCharlestonSC: Hurricane #Florence was c...        florence   \n",
       "453374  RT @EdValleeWx: Population density map overlai...        florence   \n",
       "453375  RT @EdValleeWx: Population density map overlai...        florence   \n",
       "\n",
       "              username                       date lang             NE  \\\n",
       "453202  thebutterknife  2018-09-08 15:45:12+00:00   en   Jacksonville   \n",
       "453203  thebutterknife  2018-09-08 15:45:12+00:00   en  Cape_Hatteras   \n",
       "453262     OldCrowNest  2018-09-09 14:52:53+00:00   en     Wilmington   \n",
       "453263     OldCrowNest  2018-09-09 14:52:53+00:00   en             NC   \n",
       "453292     Candace_RDH  2018-09-10 00:15:07+00:00   en     Charleston   \n",
       "453293     Candace_RDH  2018-09-10 00:15:07+00:00   en             TN   \n",
       "453337      ChasersChs  2018-09-10 14:25:49+00:00   en     Charleston   \n",
       "453338      ChasersChs  2018-09-10 14:25:49+00:00   en             SC   \n",
       "453374       kathycalm  2018-09-10 17:41:30+00:00   en     Wilmington   \n",
       "453375       kathycalm  2018-09-10 17:41:30+00:00   en      Charlotte   \n",
       "\n",
       "         NE_type  NE_LOC  valid_loc       NE_fixed  has_descriptor  \\\n",
       "453202  LOCATION    True       True   jacksonville           False   \n",
       "453203  LOCATION    True      False  cape_hatteras           False   \n",
       "453262  LOCATION    True       True     wilmington            True   \n",
       "453263  LOCATION    True      False             nc           False   \n",
       "453292  LOCATION    True       True     charleston            True   \n",
       "453293  LOCATION    True      False             tn           False   \n",
       "453337  LOCATION    True       True     charleston            True   \n",
       "453338  LOCATION    True      False             sc           False   \n",
       "453374  LOCATION    True       True     wilmington           False   \n",
       "453375  LOCATION    True       True      charlotte           False   \n",
       "\n",
       "       NE_fixed_clean  max_population  max_alternate_name_count  \\\n",
       "453202   jacksonville        868031.0                      56.0   \n",
       "453203  cape hatteras             0.0                       0.0   \n",
       "453262     wilmington        115933.0                      38.0   \n",
       "453263             nc       8611367.0                     167.0   \n",
       "453292     charleston        132609.0                      53.0   \n",
       "453293             tn      10589025.0                     121.0   \n",
       "453337     charleston        132609.0                      53.0   \n",
       "453338             sc       4229842.0                     175.0   \n",
       "453374     wilmington        115933.0                      38.0   \n",
       "453375      charlotte        827097.0                      51.0   \n",
       "\n",
       "        max_population_anchor  max_population_diff  \\\n",
       "453202                  False                  0.0   \n",
       "453203                   True             868031.0   \n",
       "453262                   True            8495434.0   \n",
       "453263                  False                  0.0   \n",
       "453292                   True           10456416.0   \n",
       "453293                  False                  0.0   \n",
       "453337                   True            4097233.0   \n",
       "453338                  False                  0.0   \n",
       "453374                   True             711164.0   \n",
       "453375                  False                  0.0   \n",
       "\n",
       "        max_alternate_name_count_anchor  max_alternate_name_count_diff  \\\n",
       "453202                            False                            0.0   \n",
       "453203                             True                           56.0   \n",
       "453262                             True                          129.0   \n",
       "453263                            False                            0.0   \n",
       "453292                             True                           68.0   \n",
       "453293                            False                            0.0   \n",
       "453337                             True                          122.0   \n",
       "453338                            False                            0.0   \n",
       "453374                             True                           13.0   \n",
       "453375                            False                            0.0   \n",
       "\n",
       "                                                    parse  \n",
       "453202  [[[RT, PROPN, 1, compound, 0], [@BMcNoldy, PRO...  \n",
       "453203  [[[RT, PROPN, 1, compound, 0], [@BMcNoldy, PRO...  \n",
       "453262  [[[RT, PROPN, 1, compound, 0], [@MelissaNordWx...  \n",
       "453263  [[[RT, PROPN, 1, compound, 0], [@MelissaNordWx...  \n",
       "453292  [[[Shoutout, PROPN, 9, nsubj, 0], [to, PART, 0...  \n",
       "453293  [[[Shoutout, PROPN, 9, nsubj, 0], [to, PART, 0...  \n",
       "453337  [[[RT, PROPN, 1, compound, 0], [@NWSCharleston...  \n",
       "453338  [[[RT, PROPN, 1, compound, 0], [@NWSCharleston...  \n",
       "453374  [[[RT, PROPN, 1, compound, 0], [@EdValleeWx, P...  \n",
       "453375  [[[RT, PROPN, 1, compound, 0], [@EdValleeWx, P...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some test data\n",
    "# need >1 NEs, at least one anchor\n",
    "anchor_var = 'max_population_anchor'\n",
    "valid_var = 'valid_loc'\n",
    "data_anchor_ids = combined_data_parsed_flat[combined_data_parsed_flat.loc[:, anchor_var]==1].loc[:, 'id'].unique()\n",
    "# at least one status in group should be valid ;_;\n",
    "anchor_data = combined_data_parsed_flat[combined_data_parsed_flat.loc[:, 'id'].isin(data_anchor_ids)]\n",
    "anchor_data = pd.concat([data_i for id_i, data_i in anchor_data.groupby('id') if data_i.loc[:, valid_var].sum(axis=0) > 0.], axis=0)\n",
    "anchor_data.sort_values(['data_name_fixed', 'id'], inplace=True)\n",
    "display(anchor_data.iloc[:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to capture: \n",
    "- NE + appositive subclause (\"Little River in Manchester, NC\", \"Harris County in Texas\")\n",
    "- NE + parent noun + appositive subclause (\"Mayfair neighborhood of Lumberton, NC\")\n",
    "- NE + child conjunction + appositive subclause (\"for Quebradillas and Isabela, PR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract subclause anchor\n",
    "import re\n",
    "import data_helpers\n",
    "reload(data_helpers)\n",
    "from data_helpers import extract_NE_subtree, extract_full_tree\n",
    "def detect_subclause_anchor(data, valid_var='valid_loc', \n",
    "                            anchor_var='max_population', NE_var='NE', \n",
    "                            allowed_child_dep_types=['acl', 'appos', 'prep', 'nummod'],\n",
    "                            allowed_parent_dep_types=['nmod', 'compound', 'pobj'],\n",
    "                            verbose=False):\n",
    "    # find children for each NE\n",
    "    data_NEs = data.loc[:, NE_var].values\n",
    "    # fix format\n",
    "    data_NEs = [x.replace('_', ' ') for x in data_NEs]\n",
    "    data_anchor_vals = data.loc[:, anchor_var].values\n",
    "    parent_subclause_anchor = []\n",
    "    subclause_anchor = []\n",
    "    trees = data.loc[:, 'parse'].iloc[0]\n",
    "    tree_graphs = [extract_full_tree(t) for t in trees]\n",
    "    tree_ctr = 0\n",
    "    tree_token_ctr = 0\n",
    "    for i, data_NE in enumerate(data_NEs):\n",
    "        if(verbose):\n",
    "            print('candidate %d=%s'%(i, data_NE))\n",
    "        anchor_val_i = data_anchor_vals[i]\n",
    "        anchor_NE_candidates = [x for x,y in zip(data_NEs, data_anchor_vals) if y > anchor_val_i]\n",
    "        if(verbose):\n",
    "            print('anchor NE candidates = %s'%(','.join(anchor_NE_candidates)))\n",
    "        parent_subclause_anchor_i = 0\n",
    "        subclause_anchor_i = 0\n",
    "        if(len(anchor_NE_candidates) > 0):\n",
    "            \n",
    "            # add whitespace to candidates to avoid matching substrings\n",
    "            anchor_NE_candidate_matcher = re.compile('|'.join([' %s'%(x) for x in anchor_NE_candidates]))\n",
    "            data_NE_tree, data_NE_subtree, tree_ctr, tree_token_ctr = extract_NE_subtree(data_NE, trees, tree_graphs, tree_ctr, tree_token_ctr)\n",
    "            # in case tree counter is incremented too far\n",
    "            tree_ctr = min(tree_ctr, len(trees)-1)\n",
    "\n",
    "            ## test 1: determine if sibling contains anchor NE\n",
    "            if(len(data_NE_tree) > 0):\n",
    "                if(verbose):\n",
    "                    print('data NE tree=%s'%(str(data_NE_tree)))\n",
    "                # find parent node for noun, preposition tests\n",
    "                # parent node => index that is not included in NE indices\n",
    "#                 highest_child_node = sorted(data_NE_tree, key=lambda x: x[2])[-1]\n",
    "                data_NE_tree_idx = [x[4] for x in data_NE_tree]\n",
    "                NE_child_nodes = [x for x in data_NE_tree if x[2] not in data_NE_tree_idx]\n",
    "                if(len(NE_child_nodes) > 0):\n",
    "                    highest_child_node = NE_child_nodes[0]\n",
    "                    parent_node_idx = highest_child_node[2]\n",
    "                    parent_node_dep = highest_child_node[3]\n",
    "                    parent_node = trees[tree_ctr][parent_node_idx]\n",
    "                    if(verbose):\n",
    "                        print('NE parse token at tree=%d, token=%d:'%(tree_ctr, tree_token_ctr))\n",
    "                        print(str(trees[tree_ctr][tree_token_ctr-1]))\n",
    "                        print('NE parent token:')\n",
    "                        print(str(parent_node))\n",
    "                    # if parent is noun, find children and look for anchor NEs\n",
    "                    if(parent_node_dep in allowed_parent_dep_types):\n",
    "        #             if(parent_node[1]=='NOUN'):\n",
    "                        parent_node_subtree_idx = get_subtree(parent_node[4], tree_graphs[tree_ctr])\n",
    "                        parent_node_subtree = [x for x in trees[tree_ctr] if x[4] in parent_node_subtree_idx]\n",
    "                        if(verbose):\n",
    "                            print('parent node subtree %s'%(str(parent_node_subtree)))\n",
    "                        # check for anchor NE\n",
    "                        parent_node_subtree_str = ' '.join([x[0] for x in parent_node_subtree])\n",
    "                        parent_subclause_anchor_i = int(anchor_NE_candidate_matcher.search(parent_node_subtree_str) is not None)\n",
    "                    # special case: if parent node string matches candidate\n",
    "                    # then we count it as anchor e.g. \"CITY, STATE\" pattern\n",
    "                    if(parent_node[0] in anchor_NE_candidates):\n",
    "                        parent_subclause_anchor_i = 1\n",
    "            ## test 2: determine if child contains anchor NE\n",
    "            if(len(data_NE_subtree) > 0):\n",
    "                if(verbose):\n",
    "                    print('NE=%s subtree=%s'%(data_NE, str(data_NE_subtree)))\n",
    "                ## filter for allowed dependency trees\n",
    "                ## find dep type for highest node (lowest parent index) in subtree\n",
    "                min_node_dep_idx = min(data_NE_subtree, key=lambda x: x[2])\n",
    "                min_node_deps = [x[3] for x in data_NE_subtree if x[2]==min_node_dep_idx[2]]\n",
    "                if(verbose):\n",
    "                    print('min node deps %s'%(str(min_node_deps)))\n",
    "                if(len(set(min_node_deps) & set(allowed_child_dep_types)) > 0):\n",
    "                    ## look for NE in phrase\n",
    "                    subtree_str = ' '.join([x[0] for x in data_NE_subtree])\n",
    "                    if(verbose):\n",
    "                        print('subtree = %s'%(subtree_str))\n",
    "                    subclause_anchor_i = int(anchor_NE_candidate_matcher.search(subtree_str) is not None)\n",
    "                    ## conjuction is a special case: anchor NE must occur \n",
    "                    ## in format NE CONJ NE, NE_anchor\n",
    "                    if('conj' in min_node_deps):\n",
    "                        anchor_NE_candidate_matcher_conj = re.compile('|'.join([',\\s?%s'%(x) for x in anchor_NE_candidates]))\n",
    "        parent_subclause_anchor.append(parent_subclause_anchor_i)\n",
    "        subclause_anchor.append(subclause_anchor_i)\n",
    "    parent_subclause_anchor = pd.Series(parent_subclause_anchor, index=data_NEs)\n",
    "    subclause_anchor = pd.Series(subclause_anchor, index=data_NEs)\n",
    "    return parent_subclause_anchor, subclause_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The', 'DET', 2, 'det', 0], ['Little', 'PROPN', 2, 'compound', 1], ['River', 'PROPN', 14, 'nsubj', 2], ['in', 'ADP', 2, 'prep', 3], ['Manchester', 'PROPN', 5, 'compound', 4], ['NC', 'PROPN', 3, 'pobj', 5], ['near', 'ADP', 2, 'prep', 6], ['Spring', 'PROPN', 8, 'compound', 7], ['Lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#FayettevilleNC', 'PROPN', 11, 'pobj', 12], ['has', 'VERB', 14, 'aux', 13], ['hit', 'VERB', 14, 'ROOT', 14], ['a', 'DET', 17, 'det', 15], ['record', 'NOUN', 17, 'compound', 16], ['level', 'NOUN', 14, 'dobj', 17], ['according', 'VERB', 14, 'prep', 18], ['to', 'ADP', 18, 'prep', 19], ['@NWS', 'X', 19, 'pobj', 20], ['.', 'PUNCT', 14, 'punct', 21]], [['River', 'NOUN', 0, 'ROOT', 0], ['at', 'ADP', 0, 'prep', 1], ['34.96', 'NUM', 3, 'nummod', 2], ['ft', 'NOUN', 1, 'pobj', 3], ['as', 'ADP', 0, 'prep', 4], ['of', 'ADP', 4, 'prep', 5], ['3:30', 'NUM', 7, 'nummod', 6], ['PM', 'NOUN', 5, 'pobj', 7], ['Monday', 'PROPN', 0, 'npadvmod', 8], ['.', 'PUNCT', 0, 'punct', 9]], [['During', 'ADP', 9, 'prep', 0], ['Hurricane', 'PROPN', 2, 'compound', 1], ['Matthew', 'PROPN', 0, 'pobj', 2], ['(', 'PUNCT', 6, 'punct', 3], ['previous', 'ADJ', 6, 'amod', 4], ['alltime', 'NOUN', 6, 'amod', 5], ['high', 'ADJ', 2, 'appos', 6], [')', 'PUNCT', 6, 'punct', 7], ['it', 'PRON', 9, 'nsubj', 8], ['reached', 'VERB', 9, 'ROOT', 9], ['32.19', 'NUM', 11, 'nummod', 10], ['ft', 'NOUN', 9, 'dobj', 11], ['.', 'PUNCT', 9, 'punct', 12], ['#florence', 'X', 14, 'compound', 13], ['#ncwx', 'PROPN', 14, 'ROOT', 14], ['@newsobserver', 'X', 14, 'punct', 15]]]\n",
      "tree=0,tree_token=0,curr_dep=['The', 'DET', 2, 'det', 0]\n",
      "tree=0,tree_token=1,curr_dep=['Little', 'PROPN', 2, 'compound', 1]\n",
      "tree=0,tree_token=2,curr_dep=['River', 'PROPN', 14, 'nsubj', 2]\n",
      "extracted NE tree=[['Little', 'PROPN', 2, 'compound', 1], ['River', 'PROPN', 14, 'nsubj', 2]]\n",
      "parent node=['River', 'PROPN', 14, 'nsubj', 2]\n",
      "parent node subtree=[['The', 'DET', 2, 'det', 0], ['Little', 'PROPN', 2, 'compound', 1], ['in', 'ADP', 2, 'prep', 3], ['Manchester', 'PROPN', 5, 'compound', 4], ['NC', 'PROPN', 3, 'pobj', 5], ['near', 'ADP', 2, 'prep', 6], ['Spring', 'PROPN', 8, 'compound', 7], ['Lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#FayettevilleNC', 'PROPN', 11, 'pobj', 12]]\n"
     ]
    }
   ],
   "source": [
    "import data_helpers\n",
    "reload(data_helpers)\n",
    "from data_helpers import extract_NE_subtree, extract_full_tree, get_subtree\n",
    "tree_ctr = 0\n",
    "tree_token_ctr = 0\n",
    "\n",
    "## test case 1: conjunction\n",
    "# test_NE = 'Mexico beach'\n",
    "# test_trees = [[['Want', 'VERB', 0, 'ROOT', 0], ['to', 'PART', 2, 'aux', 1], ['see', 'VERB', 0, 'xcomp', 2], ['the', 'DET', 5, 'det', 3], ['real', 'ADJ', 5, 'amod', 4], ['#AHSApocalypse', 'NOUN', 2, 'dobj', 5], ['?', 'PUNCT', 0, 'punct', 6]], [['Come', 'VERB', 0, 'ROOT', 0], ['down', 'PART', 0, 'prt', 1], ['here', 'ADV', 0, 'advmod', 2], ['to', 'ADP', 0, 'prep', 3], ['Mexico', 'PROPN', 5, 'compound', 4], ['beach', 'NOUN', 3, 'pobj', 5], ['or', 'CCONJ', 5, 'cc', 6], ['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['FL', 'PROPN', 5, 'conj', 9], ['!', 'PUNCT', 0, 'punct', 10]], [['#HurricaneMichael', 'PROPN', 2, 'compound', 0], ['#hurricanemichael2018', 'PUNCT', 2, 'nsubj', 1], ['@CNN', 'PROPN', 2, 'ROOT', 2], ['@weatherchannel', 'X', 2, 'punct', 3]]]\n",
    "# print(str(test_trees))\n",
    "# test_tree_graphs = [extract_full_tree(t) for t in test_trees]\n",
    "# test_NE_tree, test_NE_subtree, tree_ctr, tree_token_ctr = extract_NE_subtree(test_NE, test_trees, test_tree_graphs, tree_ctr, tree_token_ctr, verbose=True)\n",
    "\n",
    "## test case 2: parent noun\n",
    "# test_NE = 'Mayfair'\n",
    "# test_trees = [[['Homes', 'NOUN', 8, 'nsubj', 0], ['in', 'ADP', 0, 'prep', 1], ['the', 'DET', 4, 'det', 2], ['Mayfair', 'PROPN', 4, 'compound', 3], ['neighborhood', 'NOUN', 1, 'pobj', 4], ['of', 'ADP', 4, 'prep', 5], ['Lumberton', 'PROPN', 7, 'compound', 6], ['NC', 'PROPN', 5, 'pobj', 7], ['are', 'VERB', 8, 'ROOT', 8], ['underwater', 'ADJ', 8, 'acomp', 9], ['again', 'ADV', 8, 'advmod', 10], ['after', 'ADP', 8, 'prep', 11], ['being', 'VERB', 13, 'auxpass', 12], ['flooded', 'VERB', 11, 'pcomp', 13], ['in', 'ADP', 13, 'prep', 14], ['2016', 'NUM', 14, 'pobj', 15], ['during', 'ADP', 13, 'prep', 16], ['Hurricane', 'PROPN', 18, 'compound', 17], ['Matthew', 'PROPN', 16, 'pobj', 18], ['..', 'PUNCT', 8, 'punct', 19], ['and', 'CCONJ', 8, 'cc', 20], ['water', 'NOUN', 22, 'compound', 21], ['levels', 'NOUN', 23, 'nsubj', 22], ['continue', 'VERB', 8, 'conj', 23], ['to', 'PART', 25, 'aux', 24], ['rise', 'VERB', 23, 'xcomp', 25], ['.', 'PUNCT', 23, 'punct', 26]], [['#HurricaneFlorence', 'PROPN', 2, 'compound', 0], ['#lumbertonnc', 'PROPN', 2, 'compound', 1], ['#northcarolina', 'PROPN', 2, 'ROOT', 2], ['#lumberriver', 'PROPN', 2, 'appos', 3], ['@TheNOWtv', 'PROPN', 2, 'punct', 4]]]\n",
    "# test_tree_graphs = [extract_full_tree(t) for t in test_trees]\n",
    "# print(str(test_trees))\n",
    "# test_NE_tree, test_NE_subtree, tree_ctr, tree_token_ctr = extract_NE_subtree(test_NE, test_trees, test_tree_graphs, tree_ctr, tree_token_ctr, verbose=True)\n",
    "# parent_node_idx = min([x[2] for x in test_NE_tree])\n",
    "# parent_node = test_trees[tree_ctr][parent_node_idx]\n",
    "# print('parent node=%s'%(parent_node))\n",
    "# parent_node_subtree_idx = get_subtree(parent_node[4], test_tree_graphs[tree_ctr])\n",
    "# parent_node_subtree = [x for x in test_trees[tree_ctr] if x[4] in parent_node_subtree_idx]\n",
    "# print('parent node subtree=%s'%(str(parent_node_subtree)))\n",
    "\n",
    "## test case 3: parent preposition\n",
    "test_NE = 'Little River'\n",
    "test_trees = [[['The', 'DET', 2, 'det', 0], ['Little', 'PROPN', 2, 'compound', 1], ['River', 'PROPN', 14, 'nsubj', 2], ['in', 'ADP', 2, 'prep', 3], ['Manchester', 'PROPN', 5, 'compound', 4], ['NC', 'PROPN', 3, 'pobj', 5], ['near', 'ADP', 2, 'prep', 6], ['Spring', 'PROPN', 8, 'compound', 7], ['Lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#FayettevilleNC', 'PROPN', 11, 'pobj', 12], ['has', 'VERB', 14, 'aux', 13], ['hit', 'VERB', 14, 'ROOT', 14], ['a', 'DET', 17, 'det', 15], ['record', 'NOUN', 17, 'compound', 16], ['level', 'NOUN', 14, 'dobj', 17], ['according', 'VERB', 14, 'prep', 18], ['to', 'ADP', 18, 'prep', 19], ['@NWS', 'X', 19, 'pobj', 20], ['.', 'PUNCT', 14, 'punct', 21]], [['River', 'NOUN', 0, 'ROOT', 0], ['at', 'ADP', 0, 'prep', 1], ['34.96', 'NUM', 3, 'nummod', 2], ['ft', 'NOUN', 1, 'pobj', 3], ['as', 'ADP', 0, 'prep', 4], ['of', 'ADP', 4, 'prep', 5], ['3:30', 'NUM', 7, 'nummod', 6], ['PM', 'NOUN', 5, 'pobj', 7], ['Monday', 'PROPN', 0, 'npadvmod', 8], ['.', 'PUNCT', 0, 'punct', 9]], [['During', 'ADP', 9, 'prep', 0], ['Hurricane', 'PROPN', 2, 'compound', 1], ['Matthew', 'PROPN', 0, 'pobj', 2], ['(', 'PUNCT', 6, 'punct', 3], ['previous', 'ADJ', 6, 'amod', 4], ['alltime', 'NOUN', 6, 'amod', 5], ['high', 'ADJ', 2, 'appos', 6], [')', 'PUNCT', 6, 'punct', 7], ['it', 'PRON', 9, 'nsubj', 8], ['reached', 'VERB', 9, 'ROOT', 9], ['32.19', 'NUM', 11, 'nummod', 10], ['ft', 'NOUN', 9, 'dobj', 11], ['.', 'PUNCT', 9, 'punct', 12], ['#florence', 'X', 14, 'compound', 13], ['#ncwx', 'PROPN', 14, 'ROOT', 14], ['@newsobserver', 'X', 14, 'punct', 15]]]\n",
    "test_tree_graphs = [extract_full_tree(t) for t in test_trees]\n",
    "print(str(test_trees))\n",
    "test_NE_tree, test_NE_subtree, tree_ctr, tree_token_ctr = extract_NE_subtree(test_NE, test_trees, test_tree_graphs, tree_ctr, tree_token_ctr, verbose=True)\n",
    "parent_node_idx = min([x[2] for x in test_NE_tree])\n",
    "parent_node = test_trees[tree_ctr][parent_node_idx]\n",
    "print('parent node=%s'%(parent_node))\n",
    "parent_node_subtree_idx = get_subtree(parent_node[4], test_tree_graphs[tree_ctr])\n",
    "parent_node_subtree = [x for x in test_trees[tree_ctr] if x[4] in parent_node_subtree_idx]\n",
    "print('parent node subtree=%s'%(str(parent_node_subtree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test anchor extraction on annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/20 anchors detected with subclause results; recall=0.300\n",
      "15/20 anchors detected with parent subclause results; recall=0.750\n",
      "17/20 anchors detected with combined results; recall=0.850\n",
      "subclause precision=0.934\n",
      "parent subclause precision=0.616\n",
      "combined precision=0.616\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "# get test IDs from annotated data\n",
    "annotated_anchor_data = pd.read_csv('../../data/mined_tweets/combined_tweet_tag_data_NE_flat_anchor_examples.tsv', sep='\\t', index_col=False)\n",
    "annotated_anchor_NEs = annotated_anchor_data[annotated_anchor_data.loc[:, 'context_subclause']==1].loc[:, 'NE']\n",
    "annotated_anchor_txt = annotated_anchor_data[annotated_anchor_data.loc[:, 'context_subclause']==1].loc[:, 'txt']\n",
    "## hard code \n",
    "subclause_anchor = []\n",
    "subclause_parent_anchor = []\n",
    "subclause_combined_anchor = []\n",
    "for annotated_anchor_NE_i, txt_i in zip(annotated_anchor_NEs, annotated_anchor_txt.values):\n",
    "    data_i = anchor_data[anchor_data.loc[:, 'txt']==txt_i]\n",
    "    id_i = data_i.loc[:, 'id'].iloc[0]\n",
    "    NE_i = data_i.loc[:, 'NE_fixed'].values\n",
    "#     print('id=%d; NE=%s'%(id_i, ','.join(NE_i)))\n",
    "#     print('txt=%s'%(txt_i))\n",
    "    ## goal: get parse data, extract the subclause, determine if anchoring NE exists\n",
    "    parse_i = data_i.loc[:, 'parse'].iloc[0]\n",
    "#     print('parse=%s'%(str(parse_i)))\n",
    "    parent_subclause_anchor_i, subclause_anchor_i = detect_subclause_anchor(data_i, verbose=False)\n",
    "    parent_subclause_anchor_i.index = [x.replace(' ','_').lower() for x in parent_subclause_anchor_i.index]\n",
    "    subclause_anchor_i.index = [x.replace(' ','_').lower() for x in subclause_anchor_i.index]\n",
    "    anchor_final_i = pd.concat([parent_subclause_anchor_i, subclause_anchor_i], axis=1).max(axis=1)\n",
    "#     print('parent subclause anchors = \\n%s'%(str(parent_subclause_anchor_i)))\n",
    "#     print('subclause anchors = \\n%s'%(str(subclause_anchor_i)))\n",
    "    # combine parent/subclause results\n",
    "#     anchor_final_i = pd.concat([parent_subclause_anchor_i, subclause_anchor_i], axis=1).max(axis=1)\n",
    "    # fix index to match annotated format\n",
    "#     anchor_final_i.index = [x.replace(' ','_').lower() for x in anchor_final_i.index]\n",
    "    subclause_anchor.append(subclause_anchor_i.loc[annotated_anchor_NE_i])\n",
    "    subclause_parent_anchor.append(parent_subclause_anchor_i.loc[annotated_anchor_NE_i])\n",
    "    subclause_combined_anchor.append(anchor_final_i.loc[annotated_anchor_NE_i])\n",
    "\n",
    "print('%d/%d anchors detected with subclause results; recall=%.3f'%(sum(subclause_anchor), len(subclause_combined_anchor), sum(subclause_anchor) / len(subclause_combined_anchor)))\n",
    "print('%d/%d anchors detected with parent subclause results; recall=%.3f'%(sum(subclause_parent_anchor), len(subclause_combined_anchor), sum(subclause_parent_anchor) / len(subclause_combined_anchor)))\n",
    "print('%d/%d anchors detected with combined results; recall=%.3f'%(sum(subclause_combined_anchor), len(subclause_combined_anchor), sum(subclause_combined_anchor) / len(subclause_combined_anchor)))\n",
    "\n",
    "## compute precision over all annotated data\n",
    "subclause_anchor_estimate = []\n",
    "parent_subclause_anchor_estimate = []\n",
    "subclause_combined_anchor_estimate = []\n",
    "subclause_anchor_gold = []\n",
    "for idx_i, annotated_data_i in annotated_anchor_data.iterrows():\n",
    "    annotated_NE_i = annotated_data_i.loc['NE']\n",
    "#     print('NE=%s'%(annotated_NE_i))\n",
    "    txt_i = annotated_data_i.loc['txt']\n",
    "    data_i = anchor_data[anchor_data.loc[:, 'txt']==txt_i]\n",
    "    data_NE_i = data_i.loc[:, 'NE_fixed'].values\n",
    "    # restrict to data where NE only occurs once per status\n",
    "    if(len([x for x in data_NE_i if x.replace(' ', '_').lower()==annotated_NE_i]) == 1):\n",
    "        parent_subclause_anchor_i, subclause_anchor_i = detect_subclause_anchor(data_i, verbose=False)\n",
    "        parent_subclause_anchor_i.index = [x.replace(' ','_').lower() for x in parent_subclause_anchor_i.index]\n",
    "        subclause_anchor_i.index = [x.replace(' ','_').lower() for x in subclause_anchor_i.index]\n",
    "        anchor_final_i = pd.concat([parent_subclause_anchor_i, subclause_anchor_i], axis=1).max(axis=1)\n",
    "        parent_subclause_anchor_estimate.append(parent_subclause_anchor_i.loc[annotated_NE_i])\n",
    "        subclause_anchor_estimate.append(subclause_anchor_i.loc[annotated_NE_i])\n",
    "        subclause_combined_anchor_estimate.append(anchor_final_i.loc[annotated_NE_i])\n",
    "        subclause_anchor_gold.append(annotated_data_i.loc['context_subclause'])\n",
    "subclause_anchor_estimate = np.array(subclause_anchor_estimate)\n",
    "parent_subclause_anchor_estimate = np.array(parent_subclause_anchor_estimate)\n",
    "subclause_combined_anchor_estimate = np.array(subclause_combined_anchor_estimate)\n",
    "subclause_anchor_gold = np.array(subclause_anchor_gold)\n",
    "# TP = annotated_anchor_data.loc[:, 'context_subclause'].values && subclause_anchor_full\n",
    "sub_prec = 1 - abs(subclause_anchor_gold - subclause_anchor_estimate).sum() / len(subclause_anchor_gold)\n",
    "parent_prec = 1 - abs(subclause_anchor_gold - parent_subclause_anchor_estimate).sum() / len(subclause_anchor_gold)\n",
    "prec = 1 - abs(subclause_anchor_gold - subclause_combined_anchor_estimate).sum() / len(subclause_anchor_gold)\n",
    "print('subclause precision=%.3f'%(sub_prec))\n",
    "print('parent subclause precision=%.3f'%(parent_prec))\n",
    "print('combined precision=%.3f'%(prec))\n",
    "# anchor_data_i = anchor_data[anchor_data.loc[:, 'id']==id_i]\n",
    "# display(anchor_data_i.head())\n",
    "# display(anchor_data_i.loc[:, 'txt'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! We see that including parent subclauses improves recall but hurts precision. No surprises there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the false positives that the parent strategy captures and try to weed those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=RT @EdValleeWx: Our models specifically used for forecasting hurricanes have great agreement in #Florence making landfall near New Bern, NC…\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['New', 'PROPN', 20, 'compound', 18], ['Bern', 'PROPN', 20, 'compound', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Bern', 'PROPN', 20, 'compound', 19]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 17, 'pobj', 20]\n",
      "parent node subtree [['New', 'PROPN', 20, 'compound', 18], ['Bern', 'PROPN', 20, 'compound', 19]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "false positive with NE=new_bern, txt=RT @EdValleeWx: Our models specifically used for forecasting hurricanes have great agreement in #Florence making landfall near New Bern, NC…\n",
      "txt=RT @WMO: Hurricane #Florence is likely to make landfall near Wilmington (North Carolina) . The tidal data shows a sea level rise of around…\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Wilmington', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Wilmington', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['near', 'ADP', 9, 'prep', 10]\n",
      "parent node subtree [['Wilmington', 'PROPN', 10, 'pobj', 11], ['(', 'PUNCT', 11, 'punct', 12], ['North', 'PROPN', 14, 'compound', 13], ['Carolina', 'PROPN', 11, 'appos', 14], [')', 'PUNCT', 11, 'punct', 15]]\n",
      "NE=Wilmington subtree=[['(', 'PUNCT', 11, 'punct', 12], ['North', 'PROPN', 14, 'compound', 13], ['Carolina', 'PROPN', 11, 'appos', 14], [')', 'PUNCT', 11, 'punct', 15]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( North Carolina )\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=RT @ABC: LATEST: Hurricane #Florence a Category 4 storm 670 miles ESE of Cape Fear, North Carolina, with maximum sustained winds of 140 mph…\n",
      "candidate 0=Cape Fear\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Cape', 'PROPN', 16, 'compound', 15], ['Fear', 'PROPN', 18, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Fear', 'PROPN', 18, 'compound', 16]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 14, 'pobj', 18]\n",
      "parent node subtree [['Cape', 'PROPN', 16, 'compound', 15], ['Fear', 'PROPN', 18, 'compound', 16], ['North', 'PROPN', 18, 'compound', 17]]\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=You put your lips on them cigars more than you do on me\" GF says. #cigar #lastselfie #sotl #botl #hurricaneflorence @ Fayetteville, North Carolina <URL>\n",
      "candidate 0=Fayetteville\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Fayetteville', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['Fayetteville', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 8, 'ROOT', 8]\n",
      "parent node subtree [['Fayetteville', 'PROPN', 8, 'compound', 6], ['North', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=RT @FoxNewsResearch: #HurricaneFlorence - latest •Cat 2 •170 mi ESE of Wilmington, NC •220 mi E of Myrtle Beach, SC •10M+ in its path •1.7M…\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = NC,SC\n",
      "data NE tree=[['Wilmington', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Wilmington', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 12, 'pobj', 14]\n",
      "parent node subtree [['Wilmington', 'PROPN', 14, 'compound', 13]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "candidate 2=Myrtle Beach\n",
      "anchor NE candidates = Wilmington,NC,SC\n",
      "data NE tree=[['Myrtle', 'PROPN', 21, 'compound', 20], ['Beach', 'PROPN', 22, 'compound', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Beach', 'PROPN', 22, 'compound', 21]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 19, 'pobj', 22]\n",
      "parent node subtree [['Myrtle', 'PROPN', 21, 'compound', 20], ['Beach', 'PROPN', 22, 'compound', 21]]\n",
      "candidate 3=SC\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['SC', 'PROPN', 19, 'pobj', 22]]\n",
      "NE parse token at tree=0, token=23:\n",
      "['SC', 'PROPN', 19, 'pobj', 22]\n",
      "NE parent token:\n",
      "['of', 'ADP', 18, 'prep', 19]\n",
      "parent node subtree [['Myrtle', 'PROPN', 21, 'compound', 20], ['Beach', 'PROPN', 22, 'compound', 21], ['SC', 'PROPN', 19, 'pobj', 22]]\n",
      "NE=SC subtree=[['Myrtle', 'PROPN', 21, 'compound', 20], ['Beach', 'PROPN', 22, 'compound', 21]]\n",
      "min node deps ['compound']\n",
      "false positive with NE=wilmington, txt=RT @FoxNewsResearch: #HurricaneFlorence - latest •Cat 2 •170 mi ESE of Wilmington, NC •220 mi E of Myrtle Beach, SC •10M+ in its path •1.7M…\n",
      "txt=Met Reyna and her whole family who evacuated from the coast to a Red Cross shelter in Wilson, NC. She says they left everything behind, so they are hoping to have something to go back to. #hurricaneflorence <URL>\n",
      "candidate 0=Red Cross\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Red', 'PROPN', 14, 'compound', 13], ['Cross', 'PROPN', 15, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Cross', 'PROPN', 15, 'compound', 14]\n",
      "NE parent token:\n",
      "['shelter', 'NOUN', 11, 'pobj', 15]\n",
      "parent node subtree [['a', 'DET', 15, 'det', 12], ['Red', 'PROPN', 14, 'compound', 13], ['Cross', 'PROPN', 15, 'compound', 14], ['in', 'ADP', 15, 'prep', 16], ['Wilson', 'PROPN', 18, 'compound', 17], ['NC', 'PROPN', 16, 'pobj', 18]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "false positive with NE=red_cross, txt=Met Reyna and her whole family who evacuated from the coast to a Red Cross shelter in Wilson, NC. She says they left everything behind, so they are hoping to have something to go back to. #hurricaneflorence <URL>\n",
      "txt=UPDATE: The @WaffleHouse in North Myrtle Beach remains open this morning even as #HurricaneFlorence bears down. And who do I meet? Barrett - the tenacious employee from Shallotte who refused to shut down as long as @Bojangles1977 was still slingin’ hash. <URL>\n",
      "candidate 0=Myrtle Beach\n",
      "anchor NE candidates = \n",
      "candidate 1=Shallotte\n",
      "anchor NE candidates = Myrtle Beach\n",
      "data NE tree=[['Shallotte', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=2, token=6:\n",
      "['Shallotte', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['from', 'ADP', 3, 'prep', 4]\n",
      "parent node subtree [['Shallotte', 'PROPN', 4, 'pobj', 5]]\n",
      "txt=Fast move Ng low clouds and trees starting to dance! #florence @ Kensington at Regency, Cary <URL>\n",
      "candidate 0=Kensington\n",
      "anchor NE candidates = Cary\n",
      "data NE tree=[['Kensington', 'PROPN', 2, 'ROOT', 2]]\n",
      "NE=Kensington subtree=[['at', 'ADP', 2, 'prep', 3], ['Regency', 'PROPN', 5, 'compound', 4], ['Cary', 'PROPN', 3, 'pobj', 5]]\n",
      "min node deps ['prep']\n",
      "subtree = at Regency Cary\n",
      "candidate 1=Cary\n",
      "anchor NE candidates = \n",
      "txt=#hurricaneflorence in downtown Wilmington, NC @TheNOWtv @ Downtown Wilmington By Cape Fear River <URL>\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Wilmington', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Wilmington', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'compound', 4]\n",
      "parent node subtree [['downtown', 'NOUN', 4, 'compound', 2], ['Wilmington', 'PROPN', 4, 'compound', 3]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "candidate 2=Cape Fear River\n",
      "anchor NE candidates = Wilmington,NC\n",
      "data NE tree=[['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'PROPN', 12, 'compound', 11], ['River', 'PROPN', 9, 'pobj', 12]]\n",
      "NE parse token at tree=0, token=0:\n",
      "['River', 'PROPN', 9, 'pobj', 12]\n",
      "NE parent token:\n",
      "['By', 'ADP', 8, 'prep', 9]\n",
      "parent node subtree [['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'PROPN', 12, 'compound', 11], ['River', 'PROPN', 9, 'pobj', 12]]\n",
      "false positive with NE=wilmington, txt=#hurricaneflorence in downtown Wilmington, NC @TheNOWtv @ Downtown Wilmington By Cape Fear River <URL>\n",
      "txt=#hurricaneflorence #sunsetbeachnc #oceanislebeach #northcarolina #sup #veterinary @wildearthpets lauraw1717 madisonwardd _taylor_51 @ Sunset Beach, North Carolina <URL>\n",
      "candidate 0=Sunset Beach\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Sunset', 'PROPN', 13, 'compound', 12], ['Beach', 'PROPN', 15, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Beach', 'PROPN', 15, 'compound', 13]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 15, 'ROOT', 15]\n",
      "parent node subtree [['Sunset', 'PROPN', 13, 'compound', 12], ['Beach', 'PROPN', 15, 'compound', 13], ['North', 'PROPN', 15, 'compound', 14]]\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=Morehead City, NC decimated by #HurricaneFlorence with @DukeEnergy experts doing damage assessments—saying it’s the worst they’ve seen. Flooded areas will make accessing our equipment extremely difficult. Stay safe, stay informed. <URL>\n",
      "candidate 0=Morehead City\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Morehead', 'PROPN', 1, 'compound', 0], ['City', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['City', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 3, 'nsubj', 2]\n",
      "parent node subtree [['Morehead', 'PROPN', 1, 'compound', 0], ['City', 'PROPN', 2, 'compound', 1]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "false positive with NE=morehead_city, txt=Morehead City, NC decimated by #HurricaneFlorence with @DukeEnergy experts doing damage assessments—saying it’s the worst they’ve seen. Flooded areas will make accessing our equipment extremely difficult. Stay safe, stay informed. <URL>\n",
      "txt=Walking around the development, so far so good regarding #Florence. Just some branches & pine needles down. #southcarolina #murrellsinlet #nofilter #scwx #wx @ Murrells Inlet, South Carolina <URL>\n",
      "candidate 0=Murrells Inlet\n",
      "anchor NE candidates = South Carolina\n",
      "data NE tree=[['Murrells', 'PROPN', 9, 'compound', 6], ['Inlet', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=2, token=8:\n",
      "['Inlet', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 9, 'ROOT', 9]\n",
      "parent node subtree [['Murrells', 'PROPN', 9, 'compound', 6], ['Inlet', 'PROPN', 9, 'compound', 7], ['South', 'PROPN', 9, 'compound', 8]]\n",
      "candidate 1=South Carolina\n",
      "anchor NE candidates = \n",
      "txt=The edge of Hurricane Florence #hurricaneflorence moving into Georgia. @ Suwanee, Georgia <URL>\n",
      "candidate 0=Georgia\n",
      "anchor NE candidates = \n",
      "candidate 1=Suwanee\n",
      "anchor NE candidates = Georgia,Georgia\n",
      "data NE tree=[['Suwanee', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=1, token=2:\n",
      "['Suwanee', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['Georgia', 'PROPN', 0, 'pobj', 2]\n",
      "parent node subtree [['Suwanee', 'PROPN', 2, 'compound', 1]]\n",
      "candidate 2=Georgia\n",
      "anchor NE candidates = \n",
      "false positive with NE=suwanee, txt=The edge of Hurricane Florence #hurricaneflorence moving into Georgia. @ Suwanee, Georgia <URL>\n",
      "txt=Late dinner for linemen in Maxton, NC tonight. It’s windy and rainy, but the base camp up and operational and is able to get crews a hot meal.  #HurricaneFlorence2018 <URL>\n",
      "candidate 0=Maxton\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Maxton', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Maxton', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 4, 'pobj', 6]\n",
      "parent node subtree [['Maxton', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "false positive with NE=maxton, txt=Late dinner for linemen in Maxton, NC tonight. It’s windy and rainy, but the base camp up and operational and is able to get crews a hot meal.  #HurricaneFlorence2018 <URL>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Downtown New Bern, North Carolina #Florence #1010WINS #NewBernStrong <URL>\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['New', 'PROPN', 2, 'compound', 1], ['Bern', 'PROPN', 5, 'compound', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Bern', 'PROPN', 5, 'compound', 2]\n",
      "NE parent token:\n",
      "['#Florence', 'ADP', 5, 'ROOT', 5]\n",
      "parent node subtree [['Downtown', 'NOUN', 2, 'compound', 0], ['New', 'PROPN', 2, 'compound', 1], ['Bern', 'PROPN', 5, 'compound', 2], ['North', 'PROPN', 4, 'compound', 3], ['Carolina', 'PROPN', 5, 'compound', 4], ['#1010WINS', 'PROPN', 7, 'compound', 6], ['#NewBernStrong', 'X', 5, 'appos', 7]]\n",
      "NE=New Bern subtree=[['Downtown', 'NOUN', 2, 'compound', 0]]\n",
      "min node deps ['compound']\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "false positive with NE=new_bern, txt=Downtown New Bern, North Carolina #Florence #1010WINS #NewBernStrong <URL>\n",
      "txt=#HurricaneFlorence update! @ Charlotte, North Carolina <URL>\n",
      "candidate 0=Charlotte\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Charlotte', 'PROPN', 3, 'compound', 1]]\n",
      "NE parse token at tree=1, token=2:\n",
      "['Charlotte', 'PROPN', 3, 'compound', 1]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 3, 'ROOT', 3]\n",
      "parent node subtree [['Charlotte', 'PROPN', 3, 'compound', 1], ['North', 'PROPN', 3, 'compound', 2]]\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=@bentonblount Lincolnton NC still okay! Also, our little Holden beach home survived. Bought with the retirement money from a 36 year Cop. .. my Hubby! #HurricaneFlorence2018 #policewife\n",
      "candidate 0=NC\n",
      "anchor NE candidates = \n",
      "candidate 1=Holden beach\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Holden', 'PROPN', 5, 'compound', 3], ['beach', 'NOUN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['beach', 'NOUN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['home', 'NOUN', 6, 'nsubj', 5]\n",
      "parent node subtree [['our', 'ADJ', 5, 'poss', 1], ['little', 'ADJ', 5, 'amod', 2], ['Holden', 'PROPN', 5, 'compound', 3], ['beach', 'NOUN', 5, 'compound', 4]]\n",
      "txt=HerMight&Mercy...Captured in Jacksonville, NC. Large oak uprooted but small chicken coop left in exact spot! 3 hens left nestled together w additional shelter. Amazing! #HurricaneFlorenceNC #Florence #jacksonvillenc <URL>\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Jacksonville', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Jacksonville', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "false positive with NE=jacksonville, txt=HerMight&Mercy...Captured in Jacksonville, NC. Large oak uprooted but small chicken coop left in exact spot! 3 hens left nestled together w additional shelter. Amazing! #HurricaneFlorenceNC #Florence #jacksonvillenc <URL>\n",
      "txt=We didn’t think it would be this bad #hurricaneflorence @ Lumberton, North Carolina <URL>\n",
      "candidate 0=Lumberton\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Lumberton', 'PROPN', 14, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Lumberton', 'PROPN', 14, 'compound', 12]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 14, 'ROOT', 14]\n",
      "parent node subtree [['Lumberton', 'PROPN', 14, 'compound', 12], ['North', 'PROPN', 14, 'compound', 13]]\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=Deputies from the Rockingham County Sheriff's Office are here in Kinston, NC helping out with issues caused by #flooding. #HurricaneFlorence #KinstonNC <URL>\n",
      "candidate 0=Kinston\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Kinston', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Kinston', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Kinston', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "false positive with NE=kinston, txt=Deputies from the Rockingham County Sheriff's Office are here in Kinston, NC helping out with issues caused by #flooding. #HurricaneFlorence #KinstonNC <URL>\n",
      "txt=Homes in the Mayfair neighborhood of Lumberton, NC are underwater again, after being flooded in 2016 during Hurricane Matthew..and water levels continue to rise. #HurricaneFlorence #lumbertonnc #northcarolina #lumberriver @TheNOWtv <URL>\n",
      "candidate 0=Mayfair\n",
      "anchor NE candidates = Lumberton,NC\n",
      "data NE tree=[['Mayfair', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Mayfair', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['neighborhood', 'NOUN', 1, 'pobj', 4]\n",
      "parent node subtree [['the', 'DET', 4, 'det', 2], ['Mayfair', 'PROPN', 4, 'compound', 3], ['of', 'ADP', 4, 'prep', 5], ['Lumberton', 'PROPN', 7, 'compound', 6], ['NC', 'PROPN', 5, 'pobj', 7]]\n",
      "candidate 1=Lumberton\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Lumberton', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Lumberton', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['Lumberton', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 2=NC\n",
      "anchor NE candidates = \n",
      "txt=The Little River in Manchester, NC, near Spring Lake and upstream from #FayettevilleNC , has hit a record level, according to @NWS . River at 34.96 ft as of 3:30PM Monday. During Hurricane Matthew (previous all-time high) it reached 32.19 ft. #florence #ncwx @newsobserver <URL>\n",
      "candidate 0=Little River\n",
      "anchor NE candidates = Manchester,NC,Spring Lake\n",
      "data NE tree=[['Little', 'PROPN', 2, 'compound', 1], ['River', 'PROPN', 14, 'nsubj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['River', 'PROPN', 14, 'nsubj', 2]\n",
      "NE parent token:\n",
      "['hit', 'VERB', 14, 'ROOT', 14]\n",
      "NE=Little River subtree=[['The', 'DET', 2, 'det', 0], ['in', 'ADP', 2, 'prep', 3], ['Manchester', 'PROPN', 5, 'compound', 4], ['NC', 'PROPN', 3, 'pobj', 5], ['near', 'ADP', 2, 'prep', 6], ['Spring', 'PROPN', 8, 'compound', 7], ['Lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#FayettevilleNC', 'PROPN', 11, 'pobj', 12]]\n",
      "min node deps ['det', 'prep', 'prep']\n",
      "subtree = The in Manchester NC near Spring Lake and upstream from #FayettevilleNC\n",
      "candidate 1=Manchester\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Manchester', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Manchester', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Manchester', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 2=NC\n",
      "anchor NE candidates = \n",
      "candidate 3=Spring Lake\n",
      "anchor NE candidates = Manchester,NC\n",
      "data NE tree=[['Spring', 'PROPN', 8, 'compound', 7], ['Lake', 'PROPN', 6, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Lake', 'PROPN', 6, 'pobj', 8]\n",
      "NE parent token:\n",
      "['near', 'ADP', 2, 'prep', 6]\n",
      "parent node subtree [['Spring', 'PROPN', 8, 'compound', 7], ['Lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#FayettevilleNC', 'PROPN', 11, 'pobj', 12]]\n",
      "txt=So people outside NC can understand the incredible amount of rain: Elizabethtown in Bladen county got over 36 inches in four days. CHICAGO gets roughly that in a YEAR. Our average in Raleigh is 46. For the YEAR. #HurricaneFlorence\n",
      "candidate 0=Bladen county\n",
      "anchor NE candidates = CHICAGO,Raleigh\n",
      "data NE tree=[['Bladen', 'PROPN', 15, 'compound', 14], ['county', 'NOUN', 13, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['county', 'NOUN', 13, 'pobj', 15]\n",
      "NE parent token:\n",
      "['in', 'ADP', 12, 'prep', 13]\n",
      "parent node subtree [['Bladen', 'PROPN', 15, 'compound', 14], ['county', 'NOUN', 13, 'pobj', 15]]\n",
      "candidate 1=CHICAGO\n",
      "anchor NE candidates = \n",
      "candidate 2=Raleigh\n",
      "anchor NE candidates = CHICAGO\n",
      "data NE tree=[['Raleigh', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=2, token=4:\n",
      "['Raleigh', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "parent node subtree [['Raleigh', 'PROPN', 2, 'pobj', 3]]\n",
      "txt=ROAD CLOSURE: Another closure just added to the list in Union County. This is on Chesnut Lane in Indian Trail. The area was flooded yesterday. Today... This. @wsoctv #Florence <URL>\n",
      "candidate 0=Union County\n",
      "anchor NE candidates = \n",
      "candidate 1=Indian Trail\n",
      "anchor NE candidates = Union County\n",
      "data NE tree=[['Indian', 'PROPN', 7, 'compound', 6], ['Trail', 'PROPN', 5, 'pobj', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Trail', 'PROPN', 5, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 4, 'prep', 5]\n",
      "parent node subtree [['Indian', 'PROPN', 7, 'compound', 6], ['Trail', 'PROPN', 5, 'pobj', 7]]\n",
      "txt=Luckily both boxes were delivered and were delayed by #hurricaneflorence but I fly out tomorrow for a weeks vacation in Canada (Montreal and Quebec) then to #nyc for a week for work and… <URL>\n",
      "candidate 0=Montreal\n",
      "anchor NE candidates = Quebec\n",
      "data NE tree=[['Montreal', 'PROPN', 20, 'appos', 22]]\n",
      "NE parse token at tree=0, token=23:\n",
      "['Montreal', 'PROPN', 20, 'appos', 22]\n",
      "NE parent token:\n",
      "['Canada', 'PROPN', 19, 'pobj', 20]\n",
      "NE=Montreal subtree=[['and', 'CCONJ', 22, 'cc', 23], ['Quebec', 'PROPN', 22, 'conj', 24]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Quebec\n",
      "anchor NE candidates = \n",
      "txt=The remains of #Florence spared Rochester. However, it's a different story from Ithaca to Oneonta. 3 to 4\"\" of rain has fallen from Chemung to southern Cortland counties. Flood Warnings are up for some there. <URL>\n",
      "candidate 0=Rochester\n",
      "anchor NE candidates = \n",
      "candidate 1=Ithaca\n",
      "anchor NE candidates = Rochester\n",
      "data NE tree=[['Ithaca', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['Ithaca', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['from', 'ADP', 4, 'prep', 5]\n",
      "parent node subtree [['Ithaca', 'PROPN', 5, 'pobj', 6]]\n",
      "candidate 2=Cortland\n",
      "anchor NE candidates = Rochester,Ithaca\n",
      "data NE tree=[['Cortland', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=2, token=14:\n",
      "['Cortland', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 11, 'pobj', 14]\n",
      "parent node subtree [['southern', 'ADJ', 13, 'amod', 12], ['Cortland', 'PROPN', 14, 'compound', 13]]\n",
      "NE=Cortland subtree=[['southern', 'ADJ', 13, 'amod', 12]]\n",
      "min node deps ['amod']\n",
      "txt=Yesterday, our crews teamed up with @insideFPL to assess damage throughout Columbus and Bladen counties in North Carolina. Crews continue to work through challenging conditions to restore power to customers impacted by #Florence . Track progress: <URL>\n",
      "candidate 0=Columbus\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Columbus', 'PROPN', 14, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Columbus', 'PROPN', 14, 'nmod', 11]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 10, 'pobj', 14]\n",
      "parent node subtree [['Columbus', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Bladen', 'PROPN', 11, 'conj', 13], ['in', 'ADP', 14, 'prep', 15], ['North', 'PROPN', 17, 'compound', 16], ['Carolina', 'PROPN', 15, 'pobj', 17]]\n",
      "NE=Columbus subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Bladen', 'PROPN', 11, 'conj', 13]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Bladen\n",
      "anchor NE candidates = Columbus,North Carolina\n",
      "data NE tree=[['Bladen', 'PROPN', 11, 'conj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Bladen', 'PROPN', 11, 'conj', 13]\n",
      "NE parent token:\n",
      "['Columbus', 'PROPN', 14, 'nmod', 11]\n",
      "candidate 2=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=@weatherchannel this is from Williamstown, MA. Our bridge is about to get wiped out! Even Mass is being affected by #Florence <URL>\n",
      "candidate 0=Williamstown\n",
      "anchor NE candidates = MA\n",
      "data NE tree=[['Williamstown', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Williamstown', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['MA', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Williamstown', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 1=MA\n",
      "anchor NE candidates = \n",
      "candidate 2=Mass\n",
      "anchor NE candidates = Williamstown,MA\n",
      "data NE tree=[['Mass', 'PROPN', 4, 'nsubjpass', 1]]\n",
      "NE parse token at tree=2, token=2:\n",
      "['Mass', 'PROPN', 4, 'nsubjpass', 1]\n",
      "NE parent token:\n",
      "['affected', 'VERB', 4, 'ROOT', 4]\n",
      "NE=Mass subtree=[['Even', 'ADV', 1, 'advmod', 0]]\n",
      "min node deps ['advmod']\n",
      "false positive with NE=williamstown, txt=@weatherchannel this is from Williamstown, MA. Our bridge is about to get wiped out! Even Mass is being affected by #Florence <URL>\n",
      "txt=Looks like I made it to Brooklyn not a moment too soon. The remnants of #Florence have arrived here in NYC...\n",
      "candidate 0=Brooklyn\n",
      "anchor NE candidates = NYC\n",
      "data NE tree=[['Brooklyn', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Brooklyn', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['to', 'ADP', 3, 'prep', 5]\n",
      "parent node subtree [['Brooklyn', 'PROPN', 5, 'pobj', 6]]\n",
      "candidate 1=NYC\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=After almost 30\"\" of rain during #Florence , Jones county is now experiencing historic flooding along the Trent River. Here r some pics from Pollocksville where rescue crews have worked tirelessly assisting residents. Special thank you to @NYPDnews , who have come a long way 2 help! <URL>\n",
      "candidate 0=Jones county\n",
      "anchor NE candidates = \n",
      "candidate 1=Trent River\n",
      "anchor NE candidates = Jones county,Pollocksville\n",
      "data NE tree=[['Trent', 'PROPN', 19, 'compound', 18], ['River', 'PROPN', 16, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['River', 'PROPN', 16, 'pobj', 19]\n",
      "NE parent token:\n",
      "['along', 'ADP', 15, 'prep', 16]\n",
      "parent node subtree [['the', 'DET', 19, 'det', 17], ['Trent', 'PROPN', 19, 'compound', 18], ['River', 'PROPN', 16, 'pobj', 19]]\n",
      "NE=Trent River subtree=[['the', 'DET', 19, 'det', 17]]\n",
      "min node deps ['det']\n",
      "candidate 2=Pollocksville\n",
      "anchor NE candidates = Jones county\n",
      "data NE tree=[['Pollocksville', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Pollocksville', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['from', 'ADP', 3, 'prep', 4]\n",
      "parent node subtree [['Pollocksville', 'PROPN', 4, 'pobj', 5]]\n",
      "txt=Aviators of the 82nd Airborne Division Combat Aviation Brigade began returning aircraft to Fort Bragg today. They were placed out of harms way at Robins Air Force Base in Georgia. #hurricaneflorence ; #Armyhurricaneresponse #Armyhurricaneflorence #HUREVAC2018 #ArmyResponse ; #18ABC <URL>\n",
      "candidate 0=Fort Bragg\n",
      "anchor NE candidates = Georgia\n",
      "data NE tree=[['Fort', 'PROPN', 14, 'compound', 13], ['Bragg', 'PROPN', 12, 'pobj', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Bragg', 'PROPN', 12, 'pobj', 14]\n",
      "NE parent token:\n",
      "['to', 'ADP', 10, 'prep', 12]\n",
      "parent node subtree [['Fort', 'PROPN', 14, 'compound', 13], ['Bragg', 'PROPN', 12, 'pobj', 14]]\n",
      "candidate 1=Georgia\n",
      "anchor NE candidates = \n",
      "txt=Houses sit in floodwater caused by #HurricaneFlorence , in this aerial picture, on the outskirts of Lumberton, North Carolina, via @Reuters photographer Jason Miczek See Reuters top photos from the last 24 hours: <URL>\n",
      "candidate 0=Lumberton\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Lumberton', 'PROPN', 17, 'compound', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Lumberton', 'PROPN', 17, 'compound', 15]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 14, 'pobj', 17]\n",
      "parent node subtree [['Lumberton', 'PROPN', 17, 'compound', 15], ['North', 'PROPN', 17, 'compound', 16]]\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=New WCK kitchen opening in New Bern! This is one of the worst hit areas in North Carolina...Tonight we served hundreds of residents & we activate a local food truck tomorrow! My brother @cheftkilcoyne showing how food relief should be done! #Florence @WCKitchen @NC_Governor <URL>\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['New', 'PROPN', 6, 'compound', 5], ['Bern', 'PROPN', 4, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Bern', 'PROPN', 4, 'pobj', 6]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 4]\n",
      "parent node subtree [['New', 'PROPN', 6, 'compound', 5], ['Bern', 'PROPN', 4, 'pobj', 6]]\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=Our teams returned to the command base in Darlington this evening with eyes still on a concerning river and dam situation in Hartsville. Here is a look at the area they staged at today. #Florence #LouisianaProud <URL>\n",
      "candidate 0=Darlington\n",
      "anchor NE candidates = \n",
      "candidate 1=Hartsville\n",
      "anchor NE candidates = Darlington\n",
      "data NE tree=[['Hartsville', 'PROPN', 21, 'pobj', 22]]\n",
      "NE parse token at tree=0, token=23:\n",
      "['Hartsville', 'PROPN', 21, 'pobj', 22]\n",
      "NE parent token:\n",
      "['in', 'ADP', 20, 'prep', 21]\n",
      "parent node subtree [['Hartsville', 'PROPN', 21, 'pobj', 22]]\n",
      "txt=Thanks. My wife & I were driving that road 16 days ago heading from Myrtle Beach to the NASCAR race in Darlington. The PeeDee River is halfway between Marion and Darlington. Very sad what is happening. We're thinking about everyone in the Carolinas affected by #HurricaneFlorence .\n",
      "candidate 0=Myrtle Beach\n",
      "anchor NE candidates = Darlington,Marion,Darlington\n",
      "data NE tree=[['Myrtle', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 12, 'pobj', 14]]\n",
      "NE parse token at tree=1, token=15:\n",
      "['Beach', 'PROPN', 12, 'pobj', 14]\n",
      "NE parent token:\n",
      "['from', 'ADP', 11, 'prep', 12]\n",
      "parent node subtree [['Myrtle', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 12, 'pobj', 14]]\n",
      "candidate 1=Darlington\n",
      "anchor NE candidates = \n",
      "candidate 2=Marion\n",
      "anchor NE candidates = Darlington,Darlington\n",
      "data NE tree=[['Marion', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=2, token=7:\n",
      "['Marion', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['between', 'ADP', 4, 'prep', 5]\n",
      "parent node subtree [['Marion', 'PROPN', 5, 'pobj', 6], ['and', 'CCONJ', 6, 'cc', 7], ['Darlington', 'PROPN', 6, 'conj', 8]]\n",
      "NE=Marion subtree=[['and', 'CCONJ', 6, 'cc', 7], ['Darlington', 'PROPN', 6, 'conj', 8]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 3=Darlington\n",
      "anchor NE candidates = \n",
      "txt=Argentina expresses its sincere condolences to the Government and the people of the United States over the tragic loss of several lives left by #HurricaneFlorence in various States mainly in North and South Carolina. Read the press release here: <URL>\n",
      "candidate 0=Argentina\n",
      "anchor NE candidates = United States\n",
      "data NE tree=[['Argentina', 'PROPN', 1, 'nsubj', 0]]\n",
      "NE parse token at tree=0, token=1:\n",
      "['Argentina', 'PROPN', 1, 'nsubj', 0]\n",
      "NE parent token:\n",
      "['expresses', 'VERB', 1, 'ROOT', 1]\n",
      "candidate 1=United States\n",
      "anchor NE candidates = \n",
      "candidate 2=various States\n",
      "anchor NE candidates = Argentina,United States,North,South Carolina\n",
      "data NE tree=[['various', 'ADJ', 27, 'amod', 26], ['States', 'PROPN', 25, 'pobj', 27]]\n",
      "NE parse token at tree=0, token=28:\n",
      "['States', 'PROPN', 25, 'pobj', 27]\n",
      "NE parent token:\n",
      "['in', 'ADP', 22, 'prep', 25]\n",
      "parent node subtree [['various', 'ADJ', 27, 'amod', 26], ['States', 'PROPN', 25, 'pobj', 27]]\n",
      "candidate 3=North\n",
      "anchor NE candidates = Argentina,United States,South Carolina\n",
      "data NE tree=[['North', 'PROPN', 33, 'nmod', 30]]\n",
      "NE parse token at tree=0, token=31:\n",
      "['North', 'PROPN', 33, 'nmod', 30]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 29, 'pobj', 33]\n",
      "parent node subtree [['North', 'PROPN', 33, 'nmod', 30], ['and', 'CCONJ', 30, 'cc', 31], ['South', 'PROPN', 30, 'conj', 32]]\n",
      "NE=North subtree=[['and', 'CCONJ', 30, 'cc', 31], ['South', 'PROPN', 30, 'conj', 32]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 4=South Carolina\n",
      "anchor NE candidates = Argentina,United States\n",
      "data NE tree=[['South', 'PROPN', 30, 'conj', 32], ['Carolina', 'PROPN', 29, 'pobj', 33]]\n",
      "NE parse token at tree=0, token=34:\n",
      "['Carolina', 'PROPN', 29, 'pobj', 33]\n",
      "NE parent token:\n",
      "['North', 'PROPN', 33, 'nmod', 30]\n",
      "NE=South Carolina subtree=[['North', 'PROPN', 33, 'nmod', 30], ['and', 'CCONJ', 30, 'cc', 31]]\n",
      "min node deps ['cc']\n",
      "txt=ONLY ON @WXII : A multi-state operation to check on/rescue a stranded community. The Deep River here in Chatham County has cut off Everett Dowdy Rd. Food and water are being distributed. If needed people can be boated back and transported on a NG truck. #Florence <URL>\n",
      "candidate 0=Chatham County\n",
      "anchor NE candidates = \n",
      "candidate 1=Everett\n",
      "anchor NE candidates = Chatham County\n",
      "data NE tree=[['Everett', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['Everett', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['Rd', 'PROPN', 8, 'dobj', 12]\n",
      "parent node subtree [['Everett', 'PROPN', 12, 'compound', 10], ['Dowdy', 'PROPN', 12, 'compound', 11]]\n",
      "txt=My aunt & uncle have lived in Southport, North Carolina for about 35 years. They evacuated from #HurricaneFlorence and stayed with family a couple hours away. They are still away, but I heard from my mother today that their house is structurally safe. So much flooding though. :(\n",
      "candidate 0=Southport\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Southport', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Southport', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['Southport', 'PROPN', 9, 'compound', 7], ['North', 'PROPN', 9, 'compound', 8]]\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=CHECK THIS OUT! Viewer video of Mayesville Rd in Anson County during #Florence. @NCDOT crews say it will take several months until all impacted roads are reopened. There are 44 closed roads in Anson County alone. NCDOT has 12 assessment teams checking damage in Anson and Union. <URL>\n",
      "candidate 0=Anson County\n",
      "anchor NE candidates = \n",
      "candidate 1=Anson County\n",
      "anchor NE candidates = \n",
      "candidate 2=Anson\n",
      "anchor NE candidates = Anson County,Anson County,Union\n",
      "data NE tree=[['Anson', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['Anson', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['Anson', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 3=Union\n",
      "anchor NE candidates = Anson County,Anson County\n",
      "data NE tree=[['Union', 'PROPN', 8, 'conj', 10]]\n",
      "NE parse token at tree=4, token=11:\n",
      "['Union', 'PROPN', 8, 'conj', 10]\n",
      "NE parent token:\n",
      "['Anson', 'PROPN', 7, 'pobj', 8]\n",
      "txt=More evacuations coming in Horry County, SC. #Florence #flooding <URL>\n",
      "candidate 0=Horry County\n",
      "anchor NE candidates = SC\n",
      "data NE tree=[['Horry', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['County', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 3, 'pobj', 6]\n",
      "parent node subtree [['Horry', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=SC\n",
      "anchor NE candidates = \n",
      "false positive with NE=horry_county, txt=More evacuations coming in Horry County, SC. #Florence #flooding <URL>\n",
      "txt=New Bern, NC & Conway, SC got visits from @POTUS Trump yesterday as they recover from the devastation brought by #Florence . Coming up hear what ppl in area had to say about his visit @WBTV_News <URL>\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = NC,Conway,SC\n",
      "data NE tree=[['New', 'PROPN', 2, 'compound', 0], ['Bern', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Bern', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 6, 'nsubj', 2]\n",
      "parent node subtree [['New', 'PROPN', 2, 'compound', 0], ['Bern', 'PROPN', 2, 'compound', 1], ['&', 'CCONJ', 2, 'cc', 3], ['Conway', 'PROPN', 5, 'compound', 4], ['SC', 'PROPN', 2, 'conj', 5]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "candidate 2=Conway\n",
      "anchor NE candidates = NC,SC\n",
      "data NE tree=[['Conway', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Conway', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 2, 'conj', 5]\n",
      "parent node subtree [['Conway', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 3=SC\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['SC', 'PROPN', 2, 'conj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['SC', 'PROPN', 2, 'conj', 5]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 6, 'nsubj', 2]\n",
      "NE=SC subtree=[['Conway', 'PROPN', 5, 'compound', 4]]\n",
      "min node deps ['compound']\n",
      "false positive with NE=new_bern, txt=New Bern, NC & Conway, SC got visits from @POTUS Trump yesterday as they recover from the devastation brought by #Florence . Coming up hear what ppl in area had to say about his visit @WBTV_News <URL>\n",
      "txt=Thanks to the amazing generosity of people in and around the Triangle, @WRAL helped fill 5 buses, 5 trailers, 3 vans and a small truck with supplies for #Florence victims. 130,500 lbs in supplies will be delivered next week to Wilmington, Lumberton and New Bern. #wral\n",
      "candidate 0=Triangle\n",
      "anchor NE candidates = Wilmington,Lumberton,New Bern\n",
      "data NE tree=[['Triangle', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Triangle', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['@WRAL', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['the', 'DET', 12, 'det', 10], ['Triangle', 'PROPN', 12, 'compound', 11]]\n",
      "candidate 1=Wilmington\n",
      "anchor NE candidates = \n",
      "candidate 2=Lumberton\n",
      "anchor NE candidates = Wilmington,New Bern\n",
      "data NE tree=[['Lumberton', 'PROPN', 9, 'pobj', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['Lumberton', 'PROPN', 9, 'pobj', 11]\n",
      "NE parent token:\n",
      "['to', 'ADP', 6, 'prep', 9]\n",
      "parent node subtree [['Wilmington', 'PROPN', 11, 'compound', 10], ['Lumberton', 'PROPN', 9, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['New', 'PROPN', 14, 'compound', 13], ['Bern', 'PROPN', 11, 'conj', 14]]\n",
      "NE=Lumberton subtree=[['Wilmington', 'PROPN', 11, 'compound', 10], ['and', 'CCONJ', 11, 'cc', 12], ['New', 'PROPN', 14, 'compound', 13], ['Bern', 'PROPN', 11, 'conj', 14]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 3=New Bern\n",
      "anchor NE candidates = Wilmington\n",
      "data NE tree=[['New', 'PROPN', 14, 'compound', 13], ['Bern', 'PROPN', 11, 'conj', 14]]\n",
      "NE parse token at tree=1, token=15:\n",
      "['Bern', 'PROPN', 11, 'conj', 14]\n",
      "NE parent token:\n",
      "['Lumberton', 'PROPN', 9, 'pobj', 11]\n",
      "false positive with NE=lumberton, txt=Thanks to the amazing generosity of people in and around the Triangle, @WRAL helped fill 5 buses, 5 trailers, 3 vans and a small truck with supplies for #Florence victims. 130,500 lbs in supplies will be delivered next week to Wilmington, Lumberton and New Bern. #wral\n",
      "txt=Update: #HurricaneFlorence Brunswick County will have food and water available for distribution Friday, Sept. 21 from 11 a.m. To 5 p.m. at: Spring Lake Park (210 Pine Road in Boiling Spring Lakes) Northwest... <URL>\n",
      "candidate 0=Brunswick County\n",
      "anchor NE candidates = \n",
      "candidate 1=Spring Lake Park\n",
      "anchor NE candidates = Brunswick County\n",
      "data NE tree=[['Spring', 'PROPN', 33, 'compound', 31], ['Lake', 'PROPN', 33, 'compound', 32], ['Park', 'PROPN', 29, 'pobj', 33]]\n",
      "NE parse token at tree=0, token=34:\n",
      "['Park', 'PROPN', 29, 'pobj', 33]\n",
      "NE parent token:\n",
      "['at', 'ADP', 29, 'ROOT', 29]\n",
      "parent node subtree [[':', 'PUNCT', 29, 'punct', 30], ['Spring', 'PROPN', 33, 'compound', 31], ['Lake', 'PROPN', 33, 'compound', 32], ['Park', 'PROPN', 29, 'pobj', 33], ['(', 'PUNCT', 33, 'punct', 34], ['210', 'NUM', 37, 'nummod', 35], ['Pine', 'PROPN', 37, 'compound', 36], ['Road', 'PROPN', 33, 'appos', 37], ['in', 'ADP', 37, 'prep', 38], ['Boiling', 'VERB', 41, 'compound', 39], ['Spring', 'PROPN', 41, 'compound', 40], ['Lakes', 'PROPN', 38, 'pobj', 41], [')', 'PUNCT', 33, 'punct', 42]]\n",
      "NE=Spring Lake Park subtree=[['(', 'PUNCT', 33, 'punct', 34], ['210', 'NUM', 37, 'nummod', 35], ['Pine', 'PROPN', 37, 'compound', 36], ['Road', 'PROPN', 33, 'appos', 37], ['in', 'ADP', 37, 'prep', 38], ['Boiling', 'VERB', 41, 'compound', 39], ['Spring', 'PROPN', 41, 'compound', 40], ['Lakes', 'PROPN', 38, 'pobj', 41], [')', 'PUNCT', 33, 'punct', 42]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( 210 Pine Road in Boiling Spring Lakes )\n",
      "candidate 2=Boiling Spring Lakes\n",
      "anchor NE candidates = Brunswick County,Spring Lake Park\n",
      "data NE tree=[['Boiling', 'VERB', 41, 'compound', 39], ['Spring', 'PROPN', 41, 'compound', 40], ['Lakes', 'PROPN', 38, 'pobj', 41]]\n",
      "NE parse token at tree=0, token=42:\n",
      "['Lakes', 'PROPN', 38, 'pobj', 41]\n",
      "NE parent token:\n",
      "['in', 'ADP', 37, 'prep', 38]\n",
      "parent node subtree [['Boiling', 'VERB', 41, 'compound', 39], ['Spring', 'PROPN', 41, 'compound', 40], ['Lakes', 'PROPN', 38, 'pobj', 41]]\n",
      "candidate 3=Northwest\n",
      "anchor NE candidates = Brunswick County,Spring Lake Park,Boiling Spring Lakes\n",
      "data NE tree=[['Northwest', 'PROPN', 43, 'ROOT', 43]]\n",
      "NE=Northwest subtree=[['...', 'PUNCT', 43, 'punct', 44]]\n",
      "min node deps ['punct']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=. @COJacksonville NC​ officials recommend avoiding a major intersection at the end of the Jacksonville bypass because of heavy traffic use by those heading to the southern coast. #HurricaneFlorence #FlorenceNC <URL>\n",
      "candidate 0=NC\n",
      "anchor NE candidates = \n",
      "candidate 1=Jacksonville\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Jacksonville', 'PROPN', 15, 'compound', 14]]\n",
      "NE parse token at tree=1, token=15:\n",
      "['Jacksonville', 'PROPN', 15, 'compound', 14]\n",
      "NE parent token:\n",
      "['bypass', 'NOUN', 12, 'pobj', 15]\n",
      "parent node subtree [['the', 'DET', 15, 'det', 13], ['Jacksonville', 'PROPN', 15, 'compound', 14]]\n",
      "candidate 2=southern coast\n",
      "anchor NE candidates = NC,Jacksonville\n",
      "data NE tree=[['southern', 'ADJ', 27, 'amod', 26], ['coast', 'NOUN', 24, 'pobj', 27]]\n",
      "NE parse token at tree=1, token=28:\n",
      "['coast', 'NOUN', 24, 'pobj', 27]\n",
      "NE parent token:\n",
      "['to', 'ADP', 23, 'prep', 24]\n",
      "parent node subtree [['the', 'DET', 27, 'det', 25], ['southern', 'ADJ', 27, 'amod', 26], ['coast', 'NOUN', 24, 'pobj', 27]]\n",
      "NE=southern coast subtree=[['the', 'DET', 27, 'det', 25]]\n",
      "min node deps ['det']\n",
      "txt=Please pay attention to #WilmingtonNC and surrounding areas near the Cape Fear, NE Cape Fear & Black Rivers today and through the weekend. Many in Pender County were evacuated last night by National Guard, now this today. #HurricaneFlorence <URL>\n",
      "candidate 0=Cape Fear\n",
      "anchor NE candidates = Pender County\n",
      "data NE tree=[['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'NOUN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Fear', 'NOUN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['NE', 'PROPN', 14, 'compound', 12]\n",
      "parent node subtree [['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'NOUN', 12, 'compound', 11]]\n",
      "candidate 1=Pender County\n",
      "anchor NE candidates = \n",
      "txt=Boiling Spring Lakes, NC #CarolinaStrong #HurricaneFlorence #GiveBack @EdPiotrowski @wpdeabc15 @jamiearnoldWMBF @wmbfweather <URL>\n",
      "candidate 0=Spring Lakes\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Spring', 'PROPN', 2, 'compound', 1], ['Lakes', 'PROPN', 3, 'compound', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Lakes', 'PROPN', 3, 'compound', 2]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'compound', 3]\n",
      "parent node subtree [['Boiling', 'VERB', 3, 'amod', 0], ['Spring', 'PROPN', 2, 'compound', 1], ['Lakes', 'PROPN', 3, 'compound', 2]]\n",
      "candidate 1=NC\n",
      "anchor NE candidates = \n",
      "false positive with NE=spring_lakes, txt=Boiling Spring Lakes, NC #CarolinaStrong #HurricaneFlorence #GiveBack @EdPiotrowski @wpdeabc15 @jamiearnoldWMBF @wmbfweather <URL>\n",
      "txt=Georgetown County will open emergency shelters at 7 a.m. Monday at the following locations: • Georgetown High School, 2500 Anthuan Maybank Drive, Georgetown • Waccamaw Middle School, 247 Wildcat Way, Pawleys Island @SCPublicRadio #HurricaneFlorence @GCEMD\n",
      "candidate 0=Georgetown County\n",
      "anchor NE candidates = Georgetown\n",
      "data NE tree=[['Georgetown', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['County', 'PROPN', 3, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['open', 'VERB', 3, 'ROOT', 3]\n",
      "candidate 1=Georgetown\n",
      "anchor NE candidates = \n",
      "candidate 2=Pawleys Island\n",
      "anchor NE candidates = Georgetown County,Georgetown\n",
      "data NE tree=[['Pawleys', 'PROPN', 35, 'compound', 34], ['Island', 'PROPN', 35, 'ROOT', 35]]\n",
      "NE=Pawleys Island subtree=[['Waccamaw', 'PROPN', 30, 'compound', 28], ['Middle', 'PROPN', 30, 'compound', 29], ['School', 'PROPN', 35, 'compound', 30], ['247', 'NUM', 33, 'nummod', 31], ['Wildcat', 'PROPN', 33, 'compound', 32], ['Way', 'PROPN', 35, 'compound', 33], ['@SCPublicRadio', 'PROPN', 35, 'punct', 36]]\n",
      "min node deps ['compound', 'compound']\n",
      "txt=Eat at #beachsidebistro and 10% of your purchase will be donated to the Red Cross of North Carolina to help our fellow #northcarolinians affected by #hurricaneflorence #foodforflo … <URL>\n",
      "candidate 0=Red Cross\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Red', 'PROPN', 15, 'compound', 14], ['Cross', 'PROPN', 12, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Cross', 'PROPN', 12, 'pobj', 15]\n",
      "NE parent token:\n",
      "['to', 'ADP', 11, 'prep', 12]\n",
      "parent node subtree [['the', 'DET', 15, 'det', 13], ['Red', 'PROPN', 15, 'compound', 14], ['Cross', 'PROPN', 12, 'pobj', 15], ['of', 'ADP', 15, 'prep', 16], ['North', 'PROPN', 18, 'compound', 17], ['Carolina', 'PROPN', 16, 'pobj', 18]]\n",
      "NE=Red Cross subtree=[['the', 'DET', 15, 'det', 13], ['of', 'ADP', 15, 'prep', 16], ['North', 'PROPN', 18, 'compound', 17], ['Carolina', 'PROPN', 16, 'pobj', 18]]\n",
      "min node deps ['det', 'prep']\n",
      "subtree = the of North Carolina\n",
      "candidate 1=North Carolina\n",
      "anchor NE candidates = \n",
      "txt=Coal ash flowing like pudding in Neuse River near Duke's Goldsboro power plant <URL>\n",
      "candidate 0=Neuse River\n",
      "anchor NE candidates = Duke,Goldsboro\n",
      "data NE tree=[['Neuse', 'PROPN', 7, 'compound', 6], ['River', 'PROPN', 5, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['River', 'PROPN', 5, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 4, 'prep', 5]\n",
      "parent node subtree [['Neuse', 'PROPN', 7, 'compound', 6], ['River', 'PROPN', 5, 'pobj', 7]]\n",
      "candidate 1=Duke\n",
      "anchor NE candidates = Goldsboro\n",
      "candidate 2=Goldsboro\n",
      "anchor NE candidates = \n",
      "txt=The first Hurricane Watches for this part of #Texas in 3,267 days (9yrs!) like Houston & Corpus Christi #TXwx #Harvey h/t @KathrynProciv <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Corpus Christi\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Corpus', 'PROPN', 5, 'compound', 3], ['Christi', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Christi', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['#TXwx', 'PROPN', 1, 'conj', 5]\n",
      "parent node subtree [['Corpus', 'PROPN', 5, 'compound', 3], ['Christi', 'PROPN', 5, 'compound', 4]]\n",
      "txt=As of 10 a.m., the modeling has #Harvey making landfall north of Rockport, which would spare Corpus Christi the worst of the storm.\n",
      "candidate 0=Rockport\n",
      "anchor NE candidates = Corpus Christi\n",
      "data NE tree=[['Rockport', 'PROPN', 14, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Rockport', 'PROPN', 14, 'pobj', 15]\n",
      "NE parent token:\n",
      "['of', 'ADP', 13, 'prep', 14]\n",
      "parent node subtree [['Rockport', 'PROPN', 14, 'pobj', 15]]\n",
      "candidate 1=Corpus Christi\n",
      "anchor NE candidates = \n",
      "txt=The eye of #HurricaneHarvey is now showing on the Brownsville, Texas long range radar. <URL>\n",
      "candidate 0=Brownsville\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Brownsville', 'PROPN', 10, 'nmod', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Brownsville', 'PROPN', 10, 'nmod', 9]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 13, 'nmod', 10]\n",
      "parent node subtree [['Brownsville', 'PROPN', 10, 'nmod', 9]]\n",
      "candidate 1=Texas\n",
      "anchor NE candidates = \n",
      "false positive with NE=brownsville, txt=The eye of #HurricaneHarvey is now showing on the Brownsville, Texas long range radar. <URL>\n",
      "txt=Praying for Texas, esp my other home Corpus Christi. #HurricaneHarvey\n",
      "candidate 0=Texas\n",
      "anchor NE candidates = \n",
      "candidate 1=Corpus Christi\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Corpus', 'PROPN', 8, 'compound', 7], ['Christi', 'PROPN', 6, 'appos', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Christi', 'PROPN', 6, 'appos', 8]\n",
      "NE parent token:\n",
      "['home', 'NOUN', 0, 'npadvmod', 6]\n",
      "txt=Heavy squall headed toward Matagorda and Brazoria County coasts. Watch for waterspouts. #txwx #harvey <URL>\n",
      "candidate 0=Matagorda\n",
      "anchor NE candidates = Brazoria County\n",
      "data NE tree=[['Matagorda', 'PROPN', 8, 'nmod', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Matagorda', 'PROPN', 8, 'nmod', 4]\n",
      "NE parent token:\n",
      "['coasts', 'NOUN', 3, 'pobj', 8]\n",
      "parent node subtree [['Matagorda', 'PROPN', 8, 'nmod', 4], ['and', 'CCONJ', 4, 'cc', 5], ['Brazoria', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 4, 'conj', 7]]\n",
      "NE=Matagorda subtree=[['and', 'CCONJ', 4, 'cc', 5], ['Brazoria', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 4, 'conj', 7]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Brazoria County\n",
      "anchor NE candidates = \n",
      "false positive with NE=matagorda, txt=Heavy squall headed toward Matagorda and Brazoria County coasts. Watch for waterspouts. #txwx #harvey <URL>\n",
      "txt=#Live . @mikebettes on #Periscope : Streaming cam from Galveston, Texas as Hurricane #Harvey approaches coast. #txwx <URL>\n",
      "candidate 0=Galveston\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Galveston', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Galveston', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Galveston', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=Texas\n",
      "anchor NE candidates = \n",
      "false positive with NE=galveston, txt=#Live . @mikebettes on #Periscope : Streaming cam from Galveston, Texas as Hurricane #Harvey approaches coast. #txwx <URL>\n",
      "txt=Headed to Galveston as #Harvey pushes closer to the TX coast. Look for updates here & live reports on @KPRC2 at 10 #HurricaneHarvey #kprc2 <URL>\n",
      "candidate 0=Galveston\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Galveston', 'PROPN', 1, 'pobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Galveston', 'PROPN', 1, 'pobj', 2]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "parent node subtree [['Galveston', 'PROPN', 1, 'pobj', 2]]\n",
      "candidate 1=TX\n",
      "anchor NE candidates = \n",
      "txt=#Harvey up to Cat 4 now. Just hours from landfall near Rockport, TX. Winds sustained at 130 mph. <URL>\n",
      "candidate 0=Rockport\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Rockport', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Rockport', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 4, 'pobj', 6]\n",
      "parent node subtree [['Rockport', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=TX\n",
      "anchor NE candidates = \n",
      "false positive with NE=rockport, txt=#Harvey up to Cat 4 now. Just hours from landfall near Rockport, TX. Winds sustained at 130 mph. <URL>\n",
      "txt=@UnitedAirways I know you will do the right thing and refund my flight from Corpus Christi to Lubbock. #harvey . Thanks\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "candidate 1=Lubbock\n",
      "anchor NE candidates = Corpus Christi\n",
      "data NE tree=[['Lubbock', 'PROPN', 16, 'pobj', 17]]\n",
      "NE parse token at tree=0, token=18:\n",
      "['Lubbock', 'PROPN', 16, 'pobj', 17]\n",
      "NE parent token:\n",
      "['to', 'ADP', 10, 'prep', 16]\n",
      "parent node subtree [['Lubbock', 'PROPN', 16, 'pobj', 17]]\n",
      "txt=Eyewall of #Harvey moving over San Jose Island north of Port Aransas, TX. #txwx <URL>\n",
      "candidate 0=San Jose Island\n",
      "anchor NE candidates = Port Aransas,TX\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Jose', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Island', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['north', 'ADV', 3, 'advmod', 8]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Jose', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 8, 'compound', 7], ['of', 'ADP', 8, 'prep', 9], ['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11], ['TX', 'PROPN', 9, 'pobj', 12]]\n",
      "candidate 1=Port Aransas\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Aransas', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11]]\n",
      "candidate 2=TX\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=#BREAKING #HurricaneHarvey makes landfall on TX coast over the northern end of San Jose Island about 4 miles east of Rockport. #nprnewscast\n",
      "candidate 0=TX\n",
      "anchor NE candidates = \n",
      "candidate 1=San Jose Island\n",
      "anchor NE candidates = TX,Rockport\n",
      "data NE tree=[['San', 'PROPN', 13, 'compound', 12], ['Jose', 'PROPN', 14, 'compound', 13], ['Island', 'PROPN', 11, 'pobj', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Island', 'PROPN', 11, 'pobj', 14]\n",
      "NE parent token:\n",
      "['of', 'ADP', 10, 'prep', 11]\n",
      "parent node subtree [['San', 'PROPN', 13, 'compound', 12], ['Jose', 'PROPN', 14, 'compound', 13], ['Island', 'PROPN', 11, 'pobj', 14]]\n",
      "candidate 2=Rockport\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Rockport', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Rockport', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['of', 'ADP', 18, 'prep', 19]\n",
      "parent node subtree [['Rockport', 'PROPN', 19, 'pobj', 20]]\n",
      "txt=#HurricaneHarvey makes landfall on San Jose Island, TX near Rockport, TX as a Cat. 4 hurricane. @WCCBCharlotte <URL>\n",
      "candidate 0=San Jose Island\n",
      "anchor NE candidates = TX,Rockport,TX\n",
      "data NE tree=[['San', 'PROPN', 5, 'compound', 4], ['Jose', 'PROPN', 6, 'compound', 5], ['Island', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Island', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['San', 'PROPN', 5, 'compound', 4], ['Jose', 'PROPN', 6, 'compound', 5], ['Island', 'PROPN', 7, 'compound', 6], ['near', 'ADP', 7, 'prep', 8], ['Rockport', 'PROPN', 10, 'compound', 9], ['TX', 'PROPN', 8, 'pobj', 10]]\n",
      "candidate 1=TX\n",
      "anchor NE candidates = \n",
      "candidate 2=Rockport\n",
      "anchor NE candidates = TX,TX\n",
      "data NE tree=[['Rockport', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Rockport', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 8, 'pobj', 10]\n",
      "parent node subtree [['Rockport', 'PROPN', 10, 'compound', 9]]\n",
      "candidate 3=TX\n",
      "anchor NE candidates = \n",
      "false positive with NE=san_jose_island, txt=#HurricaneHarvey makes landfall on San Jose Island, TX near Rockport, TX as a Cat. 4 hurricane. @WCCBCharlotte <URL>\n",
      "txt=The eye of Hurricane #Harvey has made landfall between Port Aransas and Port O'Conner, TX. This is still only the beginning.\n",
      "candidate 0=Port Aransas\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Port', 'PROPN', 10, 'compound', 9], ['Aransas', 'PROPN', 8, 'pobj', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Aransas', 'PROPN', 8, 'pobj', 10]\n",
      "NE parent token:\n",
      "['between', 'ADP', 7, 'prep', 8]\n",
      "parent node subtree [['Port', 'PROPN', 10, 'compound', 9], ['Aransas', 'PROPN', 8, 'pobj', 10], ['and', 'CCONJ', 10, 'cc', 11], ['Port', 'PROPN', 13, 'compound', 12], [\"O'Conner\", 'PROPN', 14, 'compound', 13], ['TX', 'PROPN', 10, 'conj', 14]]\n",
      "NE=Port Aransas subtree=[['and', 'CCONJ', 10, 'cc', 11], ['Port', 'PROPN', 13, 'compound', 12], [\"O'Conner\", 'PROPN', 14, 'compound', 13], ['TX', 'PROPN', 10, 'conj', 14]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=TX\n",
      "anchor NE candidates = \n",
      "txt=praying for my family all around texas, especially most of my family that resides in houston. stay safe! #prayfortexas #hurricaneharvey\n",
      "candidate 0=texas\n",
      "anchor NE candidates = \n",
      "candidate 1=houston\n",
      "anchor NE candidates = texas\n",
      "data NE tree=[['houston', 'NOUN', 14, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['houston', 'NOUN', 14, 'pobj', 15]\n",
      "NE parent token:\n",
      "['in', 'ADP', 13, 'prep', 14]\n",
      "parent node subtree [['houston', 'NOUN', 14, 'pobj', 15]]\n",
      "txt=My hometown Houston be safe people texting me i'm chill i'm in Dallas we should be gucci #HurricaneHarvey\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Dallas\n",
      "data NE tree=[['Houston', 'PROPN', 1, 'appos', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Houston', 'PROPN', 1, 'appos', 2]\n",
      "NE parent token:\n",
      "['hometown', 'NOUN', 3, 'nsubj', 1]\n",
      "candidate 1=Dallas\n",
      "anchor NE candidates = \n",
      "txt=CBS NEWS: Reports that portions of high school in Rockport, Texas, where #HurricaneHarvey made landfall, have collapsed <URL>\n",
      "candidate 0=Rockport\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Rockport', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Rockport', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Rockport', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=Texas\n",
      "anchor NE candidates = \n",
      "false positive with NE=rockport, txt=CBS NEWS: Reports that portions of high school in Rockport, Texas, where #HurricaneHarvey made landfall, have collapsed <URL>\n",
      "txt=Hurricane #Harvey Makes Landfall Near Corpus Christi, Texas but the danger is not over <URL>\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Corpus', 'PROPN', 6, 'compound', 5], ['Christi', 'PROPN', 4, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Christi', 'PROPN', 4, 'pobj', 6]\n",
      "NE parent token:\n",
      "['Near', 'PROPN', 3, 'prep', 4]\n",
      "parent node subtree [['Corpus', 'PROPN', 6, 'compound', 5], ['Christi', 'PROPN', 4, 'pobj', 6], ['Texas', 'PROPN', 6, 'appos', 7]]\n",
      "NE=Corpus Christi subtree=[['Texas', 'PROPN', 6, 'appos', 7]]\n",
      "min node deps ['appos']\n",
      "subtree = Texas\n",
      "candidate 1=Texas\n",
      "anchor NE candidates = \n",
      "false positive with NE=corpus_christi, txt=Hurricane #Harvey Makes Landfall Near Corpus Christi, Texas but the danger is not over <URL>\n",
      "txt=Rain and lots wind in San Marcos,Tx. Checked in with my parentals and everyone is ok with a little damage. Thanks #HurricaneHarvey\n",
      "candidate 0=San Marcos\n",
      "anchor NE candidates = Tx\n",
      "candidate 1=Tx\n",
      "anchor NE candidates = \n",
      "txt=The tale of Hurricane #Harvey from two Texas cities: Corpus Christi's peak wind gust was 63 mph while Rockport's... <URL>\n",
      "candidate 0=Texas\n",
      "anchor NE candidates = \n",
      "candidate 1=Corpus Christi\n",
      "anchor NE candidates = Texas\n",
      "candidate 2=Rockport\n",
      "anchor NE candidates = Texas,Corpus Christi\n",
      "txt=Tornado damage in Sienna Plantation S of Houston and Katy W of Houston #HurricaneHarvey #Harvey2017 Flooding Mayde Creek - Katy W of Houston\n",
      "candidate 0=Sienna Plantation\n",
      "anchor NE candidates = Houston,Houston,Houston\n",
      "data NE tree=[['Sienna', 'PROPN', 4, 'compound', 3], ['Plantation', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Plantation', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['S', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Sienna', 'PROPN', 4, 'compound', 3], ['Plantation', 'PROPN', 5, 'compound', 4], ['of', 'ADP', 5, 'prep', 6], ['Houston', 'PROPN', 6, 'pobj', 7], ['and', 'CCONJ', 5, 'cc', 8], ['Katy', 'PROPN', 10, 'compound', 9], ['W', 'PROPN', 5, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Houston', 'PROPN', 13, 'compound', 12], ['#HurricaneHarvey', 'PROPN', 14, 'compound', 13], ['#Harvey2017', 'PUNCT', 11, 'pobj', 14]]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "candidate 2=Houston\n",
      "anchor NE candidates = \n",
      "candidate 3=Houston\n",
      "anchor NE candidates = \n",
      "txt=I'm at a shelter in Austin, TX, where @govabbott is meeting with evacuated Texans. #harvey #txlege <URL>\n",
      "candidate 0=Austin\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Austin', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Austin', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 4, 'pobj', 6]\n",
      "parent node subtree [['Austin', 'PROPN', 6, 'compound', 5], ['where', 'ADV', 10, 'advmod', 7], ['@govabbott', 'PROPN', 10, 'nsubj', 8], ['is', 'VERB', 10, 'aux', 9], ['meeting', 'VERB', 6, 'relcl', 10], ['with', 'ADP', 10, 'prep', 11], ['evacuated', 'VERB', 13, 'amod', 12], ['Texans', 'PROPN', 11, 'pobj', 13]]\n",
      "candidate 1=TX\n",
      "anchor NE candidates = \n",
      "false positive with NE=austin, txt=I'm at a shelter in Austin, TX, where @govabbott is meeting with evacuated Texans. #harvey #txlege <URL>\n",
      "txt=Convoy of wildlife agents from Louisiana towing boats leave gas station in Wharton and head toward Houston #harvey <URL>\n",
      "candidate 0=Louisiana\n",
      "anchor NE candidates = \n",
      "candidate 1=Wharton\n",
      "anchor NE candidates = Louisiana,Houston\n",
      "data NE tree=[['Wharton', 'PROPN', 11, 'pobj', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Wharton', 'PROPN', 11, 'pobj', 12]\n",
      "NE parent token:\n",
      "['in', 'ADP', 8, 'prep', 11]\n",
      "parent node subtree [['Wharton', 'PROPN', 11, 'pobj', 12]]\n",
      "candidate 2=Houston\n",
      "anchor NE candidates = Louisiana\n",
      "data NE tree=[['Houston', 'PROPN', 17, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Houston', 'PROPN', 17, 'compound', 16]\n",
      "NE parent token:\n",
      "['#harvey', 'PROPN', 15, 'pobj', 17]\n",
      "parent node subtree [['Houston', 'PROPN', 17, 'compound', 16]]\n",
      "txt=ALL of my District is under siege-Brays Oaks, Med Center, Meyerland, Sharpstown, Southpark, Sunnyside, 3rd Ward, & Westbury. #Harvey #Flood <URL>\n",
      "candidate 0=Sharpstown\n",
      "anchor NE candidates = Westbury\n",
      "data NE tree=[['Sharpstown', 'PROPN', 15, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Sharpstown', 'PROPN', 15, 'compound', 11]\n",
      "NE parent token:\n",
      "['Ward', 'PROPN', 5, 'pobj', 15]\n",
      "parent node subtree [['siegeBrays', 'NOUN', 9, 'compound', 6], ['Oaks', 'PROPN', 9, 'compound', 7], ['Med', 'PROPN', 9, 'compound', 8], ['Center', 'PROPN', 15, 'compound', 9], ['Meyerland', 'PROPN', 11, 'compound', 10], ['Sharpstown', 'PROPN', 15, 'compound', 11], ['Southpark', 'PROPN', 15, 'compound', 12], ['Sunnyside', 'PROPN', 15, 'compound', 13], ['3rd', 'PROPN', 15, 'compound', 14], ['&', 'CCONJ', 15, 'cc', 16], ['Westbury', 'PROPN', 15, 'conj', 17]]\n",
      "NE=Sharpstown subtree=[['Meyerland', 'PROPN', 11, 'compound', 10]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Southpark\n",
      "anchor NE candidates = Westbury\n",
      "data NE tree=[['Southpark', 'PROPN', 15, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Southpark', 'PROPN', 15, 'compound', 12]\n",
      "NE parent token:\n",
      "['Ward', 'PROPN', 5, 'pobj', 15]\n",
      "parent node subtree [['siegeBrays', 'NOUN', 9, 'compound', 6], ['Oaks', 'PROPN', 9, 'compound', 7], ['Med', 'PROPN', 9, 'compound', 8], ['Center', 'PROPN', 15, 'compound', 9], ['Meyerland', 'PROPN', 11, 'compound', 10], ['Sharpstown', 'PROPN', 15, 'compound', 11], ['Southpark', 'PROPN', 15, 'compound', 12], ['Sunnyside', 'PROPN', 15, 'compound', 13], ['3rd', 'PROPN', 15, 'compound', 14], ['&', 'CCONJ', 15, 'cc', 16], ['Westbury', 'PROPN', 15, 'conj', 17]]\n",
      "candidate 2=Westbury\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive with NE=sharpstown, txt=ALL of my District is under siege-Brays Oaks, Med Center, Meyerland, Sharpstown, Southpark, Sunnyside, 3rd Ward, & Westbury. #Harvey #Flood <URL>\n",
      "txt=Wolff said patients from Ben Taub in Houston might be transported to San Antonio area hospitals. Not confirmed yet. #Harvey\n",
      "candidate 0=Wolff\n",
      "anchor NE candidates = Houston,San Antonio\n",
      "data NE tree=[['Wolff', 'PROPN', 1, 'nsubj', 0]]\n",
      "NE parse token at tree=0, token=1:\n",
      "['Wolff', 'PROPN', 1, 'nsubj', 0]\n",
      "NE parent token:\n",
      "['said', 'VERB', 1, 'ROOT', 1]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "candidate 2=San Antonio\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['San', 'PROPN', 13, 'compound', 12], ['Antonio', 'PROPN', 15, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Antonio', 'PROPN', 15, 'compound', 13]\n",
      "NE parent token:\n",
      "['hospitals', 'NOUN', 11, 'pobj', 15]\n",
      "parent node subtree [['San', 'PROPN', 13, 'compound', 12], ['Antonio', 'PROPN', 15, 'compound', 13], ['area', 'NOUN', 15, 'compound', 14]]\n",
      "txt=Plano efforts w/ #HurricaneHarvey (1/2) - Plano Fire-Rescue: 2 members deployed w/ TX Task Force One & 3 (incl K-9) w/ TX Task Force Two. <URL>\n",
      "candidate 0=Plano\n",
      "anchor NE candidates = TX,TX\n",
      "data NE tree=[['Plano', 'PROPN', 1, 'compound', 0]]\n",
      "NE parse token at tree=0, token=1:\n",
      "['Plano', 'PROPN', 1, 'compound', 0]\n",
      "NE parent token:\n",
      "['efforts', 'NOUN', 1, 'ROOT', 1]\n",
      "parent node subtree [['Plano', 'PROPN', 1, 'compound', 0]]\n",
      "candidate 1=TX\n",
      "anchor NE candidates = \n",
      "candidate 2=TX\n",
      "anchor NE candidates = \n",
      "txt=VIDEO: I-10 at Yale, The Heights, Houston (residential area on the north side of downtown.) ( - @euzkera ) #Harvey <URL>\n",
      "candidate 0=Yale\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Yale', 'PROPN', 10, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Yale', 'PROPN', 10, 'compound', 4]\n",
      "NE parent token:\n",
      "['area', 'NOUN', 3, 'pobj', 10]\n",
      "parent node subtree [['Yale', 'PROPN', 10, 'compound', 4], ['The', 'DET', 10, 'det', 5], ['Heights', 'PROPN', 7, 'nmod', 6], ['Houston', 'PROPN', 10, 'nmod', 7], ['(', 'PUNCT', 10, 'punct', 8], ['residential', 'ADJ', 10, 'amod', 9], ['on', 'ADP', 10, 'prep', 11], ['the', 'DET', 14, 'det', 12], ['north', 'NOUN', 14, 'compound', 13], ['side', 'NOUN', 11, 'pobj', 14], ['of', 'ADP', 14, 'prep', 15], ['downtown', 'NOUN', 15, 'pobj', 16]]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "txt=The latest rainfall totals (since Thurs) compiled by @NWSWPC are INSANE! 39.2 inches (so far) in Dayton, TX. 30+ in south Houston. #harvey <URL>\n",
      "candidate 0=Dayton\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Dayton', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Dayton', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Dayton', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=TX\n",
      "anchor NE candidates = \n",
      "candidate 2=south Houston\n",
      "anchor NE candidates = Dayton,TX\n",
      "data NE tree=[['south', 'ADJ', 4, 'amod', 3], ['Houston', 'PROPN', 2, 'pobj', 4]]\n",
      "NE parse token at tree=2, token=5:\n",
      "['Houston', 'PROPN', 2, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 0, 'conj', 2]\n",
      "parent node subtree [['south', 'ADJ', 4, 'amod', 3], ['Houston', 'PROPN', 2, 'pobj', 4]]\n",
      "false positive with NE=dayton, txt=The latest rainfall totals (since Thurs) compiled by @NWSWPC are INSANE! 39.2 inches (so far) in Dayton, TX. 30+ in south Houston. #harvey <URL>\n",
      "txt=CONTACT?!!!!!!!!!!!!! 2 KAYAKS 4 #HELP inner LOOP: LINDALE, IRVINGTON, CAVALCADE area and BEYOND! #HurricaneHarvey #Houston <URL>\n",
      "candidate 0=LINDALE\n",
      "anchor NE candidates = IRVINGTON\n",
      "data NE tree=[['LINDALE', 'PROPN', 10, 'compound', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['LINDALE', 'PROPN', 10, 'compound', 7]\n",
      "NE parent token:\n",
      "['area', 'NOUN', 10, 'ROOT', 10]\n",
      "parent node subtree [['LINDALE', 'PROPN', 10, 'compound', 7], ['IRVINGTON', 'PROPN', 9, 'compound', 8], ['CAVALCADE', 'NOUN', 10, 'compound', 9], ['and', 'CCONJ', 10, 'cc', 11], ['BEYOND', 'ADV', 10, 'conj', 12], ['!', 'PUNCT', 10, 'punct', 13]]\n",
      "candidate 1=IRVINGTON\n",
      "anchor NE candidates = \n",
      "false positive with NE=lindale, txt=CONTACT?!!!!!!!!!!!!! 2 KAYAKS 4 #HELP inner LOOP: LINDALE, IRVINGTON, CAVALCADE area and BEYOND! #HurricaneHarvey #Houston <URL>\n",
      "txt=From New York to Houston- our thoughts are with the safety and well-being of everyone in Texas. #HoustonStong #HurricaneHarvey <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Houston', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Houston', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 3]\n",
      "parent node subtree [['Houston', 'PROPN', 3, 'pobj', 4]]\n",
      "candidate 1=Texas\n",
      "anchor NE candidates = \n",
      "txt=@realDonaldTrump You bypassed Houston? If NYC had a 1,000-year flood wd you visit Albany & Rochester, bypass NYC? #Harvey #HurricaneHarvey\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Albany\n",
      "data NE tree=[['Houston', 'PROPN', 2, 'dobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Houston', 'PROPN', 2, 'dobj', 3]\n",
      "NE parent token:\n",
      "['bypassed', 'VERB', 2, 'ROOT', 2]\n",
      "candidate 1=Albany\n",
      "anchor NE candidates = \n",
      "candidate 2=Rochester\n",
      "anchor NE candidates = Houston,Albany\n",
      "data NE tree=[['Rochester', 'PROPN', 9, 'conj', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['Rochester', 'PROPN', 9, 'conj', 11]\n",
      "NE parent token:\n",
      "['Albany', 'PROPN', 8, 'dobj', 9]\n",
      "txt=Teague's Tavern in Round Top is offering 10 percent of their sales to flood relief efforts in La Grange and Houston. Check them out! #Harvey\n",
      "candidate 0=Round Top\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Round', 'PROPN', 4, 'compound', 3], ['Top', 'PROPN', 2, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Top', 'PROPN', 2, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "parent node subtree [['Round', 'PROPN', 4, 'compound', 3], ['Top', 'PROPN', 2, 'pobj', 4]]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "txt=NOAA: rainfall total from #Harvey for Cedar Bayou in Harris County, Texas, is at 51.88”, a contiguous US record for any tropical system.\n",
      "candidate 0=Harris County\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Harris', 'PROPN', 11, 'compound', 10], ['County', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['County', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Harris', 'PROPN', 11, 'compound', 10], ['County', 'PROPN', 12, 'compound', 11]]\n",
      "candidate 1=Texas\n",
      "anchor NE candidates = \n",
      "false positive with NE=harris_county, txt=NOAA: rainfall total from #Harvey for Cedar Bayou in Harris County, Texas, is at 51.88”, a contiguous US record for any tropical system.\n",
      "txt=President Trump and First Lady Melania at Annaville Fire Rescue | Corpus Christi, TX #HurricaneHarvey <URL>\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Corpus', 'PROPN', 12, 'compound', 11], ['Christi', 'PROPN', 14, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Christi', 'PROPN', 14, 'compound', 12]\n",
      "NE parent token:\n",
      "['#HurricaneHarvey', 'PROPN', 9, 'appos', 14]\n",
      "parent node subtree [['|', 'PROPN', 14, 'punct', 10], ['Corpus', 'PROPN', 12, 'compound', 11], ['Christi', 'PROPN', 14, 'compound', 12], ['TX', 'PROPN', 14, 'compound', 13]]\n",
      "candidate 1=TX\n",
      "anchor NE candidates = \n",
      "false positive with NE=corpus_christi, txt=President Trump and First Lady Melania at Annaville Fire Rescue | Corpus Christi, TX #HurricaneHarvey <URL>\n",
      "txt=1927 Freeman Ave. 77642 Port Arthur, Tx elderly lady and her granddaughter stuck #HurricaneHarvey #portarthur\n",
      "candidate 0=Port Arthur\n",
      "anchor NE candidates = Tx\n",
      "data NE tree=[['Port', 'PROPN', 7, 'nmod', 5], ['Arthur', 'PROPN', 7, 'nmod', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Arthur', 'PROPN', 7, 'nmod', 6]\n",
      "NE parent token:\n",
      "['Tx', 'PROPN', 9, 'nmod', 7]\n",
      "parent node subtree [['Port', 'PROPN', 7, 'nmod', 5], ['Arthur', 'PROPN', 7, 'nmod', 6]]\n",
      "candidate 1=Tx\n",
      "anchor NE candidates = \n",
      "false positive with NE=port_arthur, txt=1927 Freeman Ave. 77642 Port Arthur, Tx elderly lady and her granddaughter stuck #HurricaneHarvey #portarthur\n",
      "txt=Has anyone in Houston been successful driving to Austin or are roads still under? #Houston #Harvey\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Austin\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Austin', 'PROPN', 7, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Austin', 'PROPN', 7, 'pobj', 8]\n",
      "NE parent token:\n",
      "['to', 'ADP', 6, 'prep', 7]\n",
      "parent node subtree [['Austin', 'PROPN', 7, 'pobj', 8]]\n",
      "txt=#HurricaneHarvey #MumbaiRains Houston Vs Mumbai Divided by oceans, United in Grief <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Mumbai\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Mumbai', 'PROPN', 4, 'ROOT', 4]]\n",
      "NE=Mumbai subtree=[['#HurricaneHarvey', 'PROPN', 4, 'compound', 0], ['#MumbaiRains', 'PROPN', 4, 'compound', 1], ['Houston', 'PROPN', 4, 'compound', 2], ['Vs', 'PROPN', 4, 'compound', 3], ['Divided', 'VERB', 4, 'acl', 5], ['by', 'ADP', 5, 'agent', 6], ['oceans', 'NOUN', 6, 'pobj', 7], ['United', 'PROPN', 7, 'appos', 8], ['in', 'ADP', 7, 'prep', 9], ['Grief', 'PROPN', 9, 'pobj', 10]]\n",
      "min node deps ['compound', 'compound', 'compound', 'compound', 'acl']\n",
      "subtree = #HurricaneHarvey #MumbaiRains Houston Vs Divided by oceans United in Grief\n",
      "candidate 2=United\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['United', 'PROPN', 7, 'appos', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['United', 'PROPN', 7, 'appos', 8]\n",
      "NE parent token:\n",
      "['oceans', 'NOUN', 6, 'pobj', 7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Coast Guard and Port Arthur officials involved in rescues in the city, Bevil Oaks FD rescuing in that area. #SETXNews #Harvey\n",
      "candidate 0=Port Arthur\n",
      "anchor NE candidates = \n",
      "candidate 1=Bevil Oaks\n",
      "anchor NE candidates = Port Arthur\n",
      "data NE tree=[['Bevil', 'PROPN', 14, 'compound', 12], ['Oaks', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Oaks', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['FD', 'PROPN', 15, 'nsubj', 14]\n",
      "parent node subtree [['Bevil', 'PROPN', 14, 'compound', 12], ['Oaks', 'PROPN', 14, 'compound', 13]]\n",
      "txt=Sending prayers - More than 1,700 square miles of Harris County in Texas in underwater - more than New York City & Chicago combined. #Harvey <URL>\n",
      "candidate 0=Harris County\n",
      "anchor NE candidates = Texas,New York City\n",
      "data NE tree=[['Harris', 'PROPN', 9, 'compound', 8], ['County', 'PROPN', 7, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['County', 'PROPN', 7, 'pobj', 9]\n",
      "NE parent token:\n",
      "['of', 'ADP', 6, 'prep', 7]\n",
      "parent node subtree [['Harris', 'PROPN', 9, 'compound', 8], ['County', 'PROPN', 7, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Texas', 'PROPN', 10, 'pobj', 11]]\n",
      "NE=Harris County subtree=[['in', 'ADP', 9, 'prep', 10], ['Texas', 'PROPN', 10, 'pobj', 11]]\n",
      "min node deps ['prep']\n",
      "subtree = in Texas\n",
      "candidate 1=Texas\n",
      "anchor NE candidates = \n",
      "candidate 2=New York City\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['New', 'PROPN', 17, 'compound', 16], ['York', 'PROPN', 18, 'compound', 17], ['City', 'PROPN', 21, 'nsubj', 18]]\n",
      "NE parse token at tree=0, token=19:\n",
      "['City', 'PROPN', 21, 'nsubj', 18]\n",
      "NE parent token:\n",
      "['combined', 'VERB', 1, 'relcl', 21]\n",
      "NE=New York City subtree=[['&', 'CCONJ', 18, 'cc', 19], ['Chicago', 'PROPN', 18, 'conj', 20]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 3=Chicago\n",
      "anchor NE candidates = Harris County,Texas,New York City\n",
      "data NE tree=[['Chicago', 'PROPN', 18, 'conj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Chicago', 'PROPN', 18, 'conj', 20]\n",
      "NE parent token:\n",
      "['City', 'PROPN', 21, 'nsubj', 18]\n",
      "txt=Treviño on #HurricaneHarvey : We are getting ready for refugees. Let's not forget Coastal Bend communities. It is not just Houston.\n",
      "candidate 0=Bend\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Bend', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Bend', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['communities', 'NOUN', 2, 'dobj', 5]\n",
      "parent node subtree [['Coastal', 'PROPN', 4, 'compound', 3], ['Bend', 'PROPN', 5, 'compound', 4]]\n",
      "NE=Bend subtree=[['Coastal', 'PROPN', 4, 'compound', 3]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "txt=So... #Harvey for (European) scale. Corpus Christi is ~Milan Houston is ~München Beumont ~Salzburg Shreveport ~Prague <URL>\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "candidate 1=München Beumont\n",
      "anchor NE candidates = Corpus Christi,Prague\n",
      "data NE tree=[['München', 'PROPN', 9, 'compound', 8], ['Beumont', 'PROPN', 6, 'attr', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Beumont', 'PROPN', 6, 'attr', 9]\n",
      "NE parent token:\n",
      "['is', 'VERB', 2, 'ccomp', 6]\n",
      "NE=München Beumont subtree=[['~', 'PUNCT', 9, 'punct', 10], ['Salzburg', 'PROPN', 12, 'compound', 11], ['Shreveport', 'PROPN', 9, 'appos', 12], ['~', 'SYM', 12, 'punct', 13], ['Prague', 'PROPN', 12, 'appos', 14]]\n",
      "min node deps ['punct', 'appos']\n",
      "subtree = ~ Salzburg Shreveport ~ Prague\n",
      "candidate 2=Prague\n",
      "anchor NE candidates = Corpus Christi\n",
      "data NE tree=[['Prague', 'PROPN', 12, 'appos', 14]]\n",
      "NE parse token at tree=1, token=0:\n",
      "['Prague', 'PROPN', 12, 'appos', 14]\n",
      "NE parent token:\n",
      "['Shreveport', 'PROPN', 9, 'appos', 12]\n",
      "txt=Because the horror and devastation of #Harvey was in Houston and Galveston not Corpus Cristi. Go to the heart of it all not a safe area <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Galveston\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Galveston', 'PROPN', 9, 'conj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Galveston', 'PROPN', 9, 'conj', 11]\n",
      "NE parent token:\n",
      "['Houston', 'PROPN', 8, 'pobj', 9]\n",
      "false positive with NE=galveston, txt=Because the horror and devastation of #Harvey was in Houston and Galveston not Corpus Cristi. Go to the heart of it all not a safe area <URL>\n",
      "txt=Another crew from Euless and Haltom City heading out with a N. Texas strike team headed to Southeast Texas #Harvey <URL>\n",
      "candidate 0=Euless\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Euless', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Euless', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['from', 'ADP', 1, 'prep', 2]\n",
      "parent node subtree [['Euless', 'PROPN', 2, 'pobj', 3], ['and', 'CCONJ', 3, 'cc', 4], ['Haltom', 'PROPN', 6, 'compound', 5], ['City', 'PROPN', 3, 'conj', 6]]\n",
      "NE=Euless subtree=[['and', 'CCONJ', 3, 'cc', 4], ['Haltom', 'PROPN', 6, 'compound', 5], ['City', 'PROPN', 3, 'conj', 6]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Haltom City\n",
      "anchor NE candidates = Euless,Texas\n",
      "data NE tree=[['Haltom', 'PROPN', 6, 'compound', 5], ['City', 'PROPN', 3, 'conj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['City', 'PROPN', 3, 'conj', 6]\n",
      "NE parent token:\n",
      "['Euless', 'PROPN', 2, 'pobj', 3]\n",
      "candidate 2=Texas\n",
      "anchor NE candidates = \n",
      "candidate 3=Southeast Texas\n",
      "anchor NE candidates = Euless,Haltom City,Texas\n",
      "data NE tree=[['Southeast', 'PROPN', 20, 'compound', 18], ['Texas', 'PROPN', 20, 'compound', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Texas', 'PROPN', 20, 'compound', 19]\n",
      "NE parent token:\n",
      "['#Harvey', 'PROPN', 17, 'pobj', 20]\n",
      "parent node subtree [['Southeast', 'PROPN', 20, 'compound', 18], ['Texas', 'PROPN', 20, 'compound', 19]]\n",
      "txt=While airports are resuming service, getting a flight to Houston is not easy; Some folks flying to San Antonio, then driving. #Harvey\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=San Antonio\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['San', 'PROPN', 19, 'compound', 18], ['Antonio', 'PROPN', 17, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Antonio', 'PROPN', 17, 'pobj', 19]\n",
      "NE parent token:\n",
      "['to', 'ADP', 16, 'prep', 17]\n",
      "parent node subtree [['San', 'PROPN', 19, 'compound', 18], ['Antonio', 'PROPN', 17, 'pobj', 19]]\n",
      "txt=Our claims adjusters are in Corpus Christi, Victoria & limited areas of Houston. To contact our claims team: <URL>\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Corpus', 'PROPN', 7, 'compound', 5], ['Christi', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Christi', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['Victoria', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['Corpus', 'PROPN', 7, 'compound', 5], ['Christi', 'PROPN', 7, 'compound', 6], ['&', 'CCONJ', 7, 'cc', 8], ['limited', 'ADJ', 10, 'amod', 9], ['areas', 'NOUN', 7, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Houston', 'PROPN', 11, 'pobj', 12]]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "false positive with NE=corpus_christi, txt=Our claims adjusters are in Corpus Christi, Victoria & limited areas of Houston. To contact our claims team: <URL>\n",
      "txt=Sweet! There's no age limit on kindness. We're taking donations today @KATUNews - ocated at NE 21st & Sandy in PDX. #Harvey #TexasStrong <URL>\n",
      "candidate 0=NE\n",
      "anchor NE candidates = \n",
      "candidate 1=Sandy\n",
      "anchor NE candidates = NE,PDX\n",
      "data NE tree=[['Sandy', 'PROPN', 8, 'conj', 10]]\n",
      "NE parse token at tree=2, token=11:\n",
      "['Sandy', 'PROPN', 8, 'conj', 10]\n",
      "NE parent token:\n",
      "['21st', 'PROPN', 6, 'pobj', 8]\n",
      "candidate 2=PDX\n",
      "anchor NE candidates = NE\n",
      "data NE tree=[['PDX', 'PROPN', 11, 'pobj', 12]]\n",
      "NE parse token at tree=2, token=13:\n",
      "['PDX', 'PROPN', 11, 'pobj', 12]\n",
      "NE parent token:\n",
      "['in', 'ADP', 8, 'prep', 11]\n",
      "parent node subtree [['PDX', 'PROPN', 11, 'pobj', 12]]\n",
      "txt=Better have a plan for DC, Baltimore, Philly, NYC, CLEVELAND, BUFFALO, TORONTO, OTTOWA, MONTREAL. And all between. GFS Model #harvey correct <URL>\n",
      "candidate 0=Baltimore\n",
      "anchor NE candidates = Philly,NYC\n",
      "data NE tree=[['Baltimore', 'PROPN', 9, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Baltimore', 'PROPN', 9, 'compound', 6]\n",
      "NE parent token:\n",
      "['CLEVELAND', 'PROPN', 13, 'compound', 9]\n",
      "parent node subtree [['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8]]\n",
      "candidate 1=Philly\n",
      "anchor NE candidates = NYC\n",
      "data NE tree=[['Philly', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Philly', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['CLEVELAND', 'PROPN', 13, 'compound', 9]\n",
      "parent node subtree [['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8]]\n",
      "candidate 2=NYC\n",
      "anchor NE candidates = \n",
      "candidate 3=CLEVELAND\n",
      "anchor NE candidates = Baltimore,Philly,NYC\n",
      "data NE tree=[['CLEVELAND', 'PROPN', 13, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['CLEVELAND', 'PROPN', 13, 'compound', 9]\n",
      "NE parent token:\n",
      "['MONTREAL', 'PROPN', 4, 'pobj', 13]\n",
      "parent node subtree [['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8], ['CLEVELAND', 'PROPN', 13, 'compound', 9], ['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11], ['OTTOWA', 'PROPN', 13, 'compound', 12]]\n",
      "NE=CLEVELAND subtree=[['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound', 'compound', 'compound', 'compound']\n",
      "candidate 4=BUFFALO\n",
      "anchor NE candidates = Baltimore,Philly,NYC,CLEVELAND\n",
      "data NE tree=[['BUFFALO', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['BUFFALO', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['TORONTO', 'PROPN', 13, 'compound', 11]\n",
      "parent node subtree [['BUFFALO', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 5=TORONTO\n",
      "anchor NE candidates = Baltimore,Philly,NYC,CLEVELAND,BUFFALO\n",
      "data NE tree=[['TORONTO', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['TORONTO', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['MONTREAL', 'PROPN', 4, 'pobj', 13]\n",
      "parent node subtree [['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8], ['CLEVELAND', 'PROPN', 13, 'compound', 9], ['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11], ['OTTOWA', 'PROPN', 13, 'compound', 12]]\n",
      "NE=TORONTO subtree=[['BUFFALO', 'PROPN', 11, 'compound', 10]]\n",
      "min node deps ['compound']\n",
      "candidate 6=MONTREAL\n",
      "anchor NE candidates = Baltimore,Philly,NYC,CLEVELAND,BUFFALO,TORONTO\n",
      "data NE tree=[['MONTREAL', 'PROPN', 4, 'pobj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['MONTREAL', 'PROPN', 4, 'pobj', 13]\n",
      "NE parent token:\n",
      "['for', 'ADP', 3, 'prep', 4]\n",
      "parent node subtree [['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8], ['CLEVELAND', 'PROPN', 13, 'compound', 9], ['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11], ['OTTOWA', 'PROPN', 13, 'compound', 12], ['MONTREAL', 'PROPN', 4, 'pobj', 13]]\n",
      "NE=MONTREAL subtree=[['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8], ['CLEVELAND', 'PROPN', 13, 'compound', 9], ['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11], ['OTTOWA', 'PROPN', 13, 'compound', 12]]\n",
      "min node deps ['compound', 'compound', 'compound', 'compound']\n",
      "false positive with NE=cleveland, txt=Better have a plan for DC, Baltimore, Philly, NYC, CLEVELAND, BUFFALO, TORONTO, OTTOWA, MONTREAL. And all between. GFS Model #harvey correct <URL>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=We're gonna be headed to Woodsboro, TX pop. 1,512 tomorrow to drop off supplies. #Harvey Amazon Wish List - <URL>\n",
      "candidate 0=Woodsboro\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Woodsboro', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Woodsboro', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 7, 'compound', 6]\n",
      "parent node subtree [['Woodsboro', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=TX\n",
      "anchor NE candidates = \n",
      "false positive with NE=woodsboro, txt=We're gonna be headed to Woodsboro, TX pop. 1,512 tomorrow to drop off supplies. #Harvey Amazon Wish List - <URL>\n",
      "txt=@kellycass Good morning from Morgantown,WV. Watching today's rain & that impact on Cheat River watershed before #Irma arrives.\n",
      "candidate 0=Morgantown\n",
      "anchor NE candidates = WV\n",
      "candidate 1=WV\n",
      "anchor NE candidates = \n",
      "candidate 2=Cheat River\n",
      "anchor NE candidates = Morgantown,WV\n",
      "data NE tree=[['Cheat', 'PROPN', 8, 'compound', 7], ['River', 'PROPN', 6, 'pobj', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['River', 'PROPN', 6, 'pobj', 8]\n",
      "NE parent token:\n",
      "['on', 'ADP', 5, 'prep', 6]\n",
      "parent node subtree [['Cheat', 'PROPN', 8, 'compound', 7], ['River', 'PROPN', 6, 'pobj', 8]]\n",
      "txt=@ShiriSpear do you think #IRMA will directly hit North Florida / Orlando / WDW area. Flying from London to Orlando Thursday curious to kno?\n",
      "candidate 0=North Florida\n",
      "anchor NE candidates = Orlando,London,Orlando\n",
      "data NE tree=[['North', 'PROPN', 9, 'compound', 8], ['Florida', 'PROPN', 14, 'nmod', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Florida', 'PROPN', 14, 'nmod', 9]\n",
      "NE parent token:\n",
      "['area', 'NOUN', 7, 'dobj', 14]\n",
      "parent node subtree [['North', 'PROPN', 9, 'compound', 8], ['Florida', 'PROPN', 14, 'nmod', 9], ['/', 'SYM', 13, 'punct', 10], ['Orlando', 'PROPN', 13, 'nmod', 11], ['/', 'SYM', 13, 'punct', 12], ['WDW', 'PROPN', 14, 'compound', 13]]\n",
      "candidate 1=Orlando\n",
      "anchor NE candidates = \n",
      "candidate 2=London\n",
      "anchor NE candidates = Orlando,Orlando\n",
      "data NE tree=[['London', 'PROPN', 1, 'pobj', 2]]\n",
      "NE parse token at tree=1, token=3:\n",
      "['London', 'PROPN', 1, 'pobj', 2]\n",
      "NE parent token:\n",
      "['from', 'ADP', 0, 'prep', 1]\n",
      "parent node subtree [['London', 'PROPN', 1, 'pobj', 2]]\n",
      "candidate 3=Orlando\n",
      "anchor NE candidates = \n",
      "txt=If #irma is still on FL track in two days, why not fill up all cruise ships in Miami, Cape canaveral etc with ppl - ship away from storm?\n",
      "candidate 0=FL\n",
      "anchor NE candidates = \n",
      "candidate 1=Miami\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Miami', 'PROPN', 19, 'compound', 18]]\n",
      "NE parse token at tree=0, token=19:\n",
      "['Miami', 'PROPN', 19, 'compound', 18]\n",
      "NE parent token:\n",
      "['Cape', 'PROPN', 21, 'compound', 19]\n",
      "parent node subtree [['Miami', 'PROPN', 19, 'compound', 18]]\n",
      "candidate 2=Cape canaveral\n",
      "anchor NE candidates = FL,Miami\n",
      "data NE tree=[['Cape', 'PROPN', 21, 'compound', 19], ['canaveral', 'ADJ', 21, 'compound', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['canaveral', 'ADJ', 21, 'compound', 20]\n",
      "NE parent token:\n",
      "['etc', 'X', 17, 'pobj', 21]\n",
      "parent node subtree [['Miami', 'PROPN', 19, 'compound', 18], ['Cape', 'PROPN', 21, 'compound', 19], ['canaveral', 'ADJ', 21, 'compound', 20]]\n",
      "NE=Cape canaveral subtree=[['Miami', 'PROPN', 19, 'compound', 18]]\n",
      "min node deps ['compound']\n",
      "txt=@AmericanAir supposed to fly to the Dominican Republic, connection in Miami. Trying to switch to Mexico & you want to charge me? #Help #Irma\n",
      "candidate 0=Dominican Republic\n",
      "anchor NE candidates = Mexico\n",
      "data NE tree=[['Dominican', 'PROPN', 7, 'compound', 6], ['Republic', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Republic', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['connection', 'NOUN', 4, 'pobj', 8]\n",
      "parent node subtree [['the', 'DET', 8, 'det', 5], ['Dominican', 'PROPN', 7, 'compound', 6], ['Republic', 'PROPN', 8, 'compound', 7], ['in', 'ADP', 8, 'prep', 9], ['Miami', 'PROPN', 9, 'pobj', 10]]\n",
      "candidate 1=Miami\n",
      "anchor NE candidates = Dominican Republic,Mexico\n",
      "data NE tree=[['Miami', 'PROPN', 9, 'pobj', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Miami', 'PROPN', 9, 'pobj', 10]\n",
      "NE parent token:\n",
      "['in', 'ADP', 8, 'prep', 9]\n",
      "parent node subtree [['Miami', 'PROPN', 9, 'pobj', 10]]\n",
      "candidate 2=Mexico\n",
      "anchor NE candidates = \n",
      "txt=Hoping for a safe week for our friends at Hillsborough Area Regional Transit in Tampa, FL as they prepare for #HurricaneIrma .\n",
      "candidate 0=Tampa\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Tampa', 'PROPN', 15, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Tampa', 'PROPN', 15, 'compound', 14]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 13, 'pobj', 15]\n",
      "parent node subtree [['Tampa', 'PROPN', 15, 'compound', 14]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=tampa, txt=Hoping for a safe week for our friends at Hillsborough Area Regional Transit in Tampa, FL as they prepare for #HurricaneIrma .\n",
      "txt=Anna Maria Island evacuating 9/7/17 at 12:40 PM. Mileage check zero. Destination Clearwater then sweet home Alabama. #Irma please .\n",
      "candidate 0=Anna Maria Island\n",
      "anchor NE candidates = Alabama\n",
      "data NE tree=[['Anna', 'PROPN', 2, 'compound', 0], ['Maria', 'PROPN', 2, 'compound', 1], ['Island', 'PROPN', 3, 'nsubj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Island', 'PROPN', 3, 'nsubj', 2]\n",
      "NE parent token:\n",
      "['evacuating', 'VERB', 3, 'ROOT', 3]\n",
      "candidate 1=Alabama\n",
      "anchor NE candidates = \n",
      "txt=My thoughts and prayers are with Miami and the entire State of Florida #HurricaneIrma\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Miami', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['with', 'ADP', 4, 'prep', 5]\n",
      "parent node subtree [['Miami', 'PROPN', 5, 'pobj', 6], ['and', 'CCONJ', 6, 'cc', 7], ['the', 'DET', 10, 'det', 8], ['entire', 'ADJ', 10, 'amod', 9], ['State', 'NOUN', 6, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Florida', 'PROPN', 11, 'pobj', 12]]\n",
      "NE=Miami subtree=[['and', 'CCONJ', 6, 'cc', 7], ['the', 'DET', 10, 'det', 8], ['entire', 'ADJ', 10, 'amod', 9], ['State', 'NOUN', 6, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Florida', 'PROPN', 11, 'pobj', 12]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=miami, txt=My thoughts and prayers are with Miami and the entire State of Florida #HurricaneIrma\n",
      "txt=#HurricaneIrma please go hit Washington DC *Specifically White House* Thanks the hole world\n",
      "candidate 0=Washington DC\n",
      "anchor NE candidates = \n",
      "candidate 1=White House\n",
      "anchor NE candidates = Washington DC\n",
      "data NE tree=[['White', 'PROPN', 9, 'compound', 8], ['House', 'PROPN', 9, 'ROOT', 9]]\n",
      "NE=White House subtree=[['*', 'PUNCT', 9, 'punct', 6], ['Specifically', 'ADV', 9, 'advmod', 7], ['*', 'PUNCT', 9, 'punct', 10]]\n",
      "min node deps ['punct', 'advmod', 'punct']\n",
      "txt=JUST IN - A MANDATORY EVACUATION has been issued for Jacksonville, Florida. #CNN #Irma\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Jacksonville', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Jacksonville', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 8, 'pobj', 10]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 10, 'compound', 9]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=jacksonville, txt=JUST IN - A MANDATORY EVACUATION has been issued for Jacksonville, Florida. #CNN #Irma\n",
      "txt=Made it to Tulsa last night from Fort Myers escaping #hurricaneirma . Just home we have a home back in FL when we get back. @jamesaydelott\n",
      "candidate 0=Tulsa\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Tulsa', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Tulsa', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 2]\n",
      "parent node subtree [['Tulsa', 'PROPN', 2, 'pobj', 3]]\n",
      "candidate 1=Fort Myers\n",
      "anchor NE candidates = Tulsa,FL\n",
      "data NE tree=[['Fort', 'PROPN', 8, 'compound', 7], ['Myers', 'PROPN', 6, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Myers', 'PROPN', 6, 'pobj', 8]\n",
      "NE parent token:\n",
      "['from', 'ADP', 0, 'prep', 6]\n",
      "parent node subtree [['Fort', 'PROPN', 8, 'compound', 7], ['Myers', 'PROPN', 6, 'pobj', 8], ['escaping', 'VERB', 10, 'compound', 9], ['#hurricaneirma', 'PROPN', 8, 'appos', 10]]\n",
      "NE=Fort Myers subtree=[['escaping', 'VERB', 10, 'compound', 9], ['#hurricaneirma', 'PROPN', 8, 'appos', 10]]\n",
      "min node deps ['appos']\n",
      "subtree = escaping #hurricaneirma\n",
      "candidate 2=FL\n",
      "anchor NE candidates = \n",
      "txt=Friends in Miami and Florida, good luck and be safe! #hurricaneirma #irma #miamibeach <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 1, 'pobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Miami', 'PROPN', 1, 'pobj', 2]\n",
      "NE parent token:\n",
      "['in', 'ADP', 0, 'prep', 1]\n",
      "parent node subtree [['Miami', 'PROPN', 1, 'pobj', 2], ['and', 'CCONJ', 2, 'cc', 3], ['Florida', 'PROPN', 2, 'conj', 4]]\n",
      "NE=Miami subtree=[['and', 'CCONJ', 2, 'cc', 3], ['Florida', 'PROPN', 2, 'conj', 4]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive with NE=miami, txt=Friends in Miami and Florida, good luck and be safe! #hurricaneirma #irma #miamibeach <URL>\n",
      "txt=Left FL to help in Houston, now the hope is that FL will weather the storm. Let's pray for all those in the path of #hurricaneirma\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Houston', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Houston', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 4]\n",
      "parent node subtree [['Houston', 'PROPN', 4, 'pobj', 5]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "txt=LATEST: Hurricane #Irma is 405 miles southeast of Miami; it's spreading westward over parts of Cuba and the... <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Cuba\n",
      "data NE tree=[['Miami', 'PROPN', 8, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Miami', 'PROPN', 8, 'pobj', 9]\n",
      "NE parent token:\n",
      "['of', 'ADP', 7, 'prep', 8]\n",
      "parent node subtree [['Miami', 'PROPN', 8, 'pobj', 9]]\n",
      "candidate 1=Cuba\n",
      "anchor NE candidates = \n",
      "txt=I hope everyone staying at the theme parks, Orlando, and throughout the entire state of Florida remains as safe as possible! #Irma\n",
      "candidate 0=Orlando\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Orlando', 'PROPN', 7, 'appos', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Orlando', 'PROPN', 7, 'appos', 8]\n",
      "NE parent token:\n",
      "['parks', 'NOUN', 4, 'pobj', 7]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "txt=No planes over Miami right now. That one you see is Air Europa 787 leaving soon for Madrid tonight. #HurricaneIrma <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "candidate 1=Madrid\n",
      "anchor NE candidates = Miami\n",
      "data NE tree=[['Madrid', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['Madrid', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['for', 'ADP', 8, 'prep', 10]\n",
      "parent node subtree [['Madrid', 'PROPN', 10, 'pobj', 11]]\n",
      "txt=My family in Miami evacuated yesterday to Tampa. They aren't out of #Irma 's path completely, but I'm so grateful they were able to leave.\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = Miami\n",
      "data NE tree=[['Tampa', 'PROPN', 6, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Tampa', 'PROPN', 6, 'pobj', 7]\n",
      "NE parent token:\n",
      "['to', 'ADP', 4, 'prep', 6]\n",
      "parent node subtree [['Tampa', 'PROPN', 6, 'pobj', 7]]\n",
      "txt=milfordonmove: Local Statement for Jacksonville, FL #disney #dcl #Irma <URL>\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Jacksonville', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Jacksonville', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 9, 'compound', 6]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=jacksonville, txt=milfordonmove: Local Statement for Jacksonville, FL #disney #dcl #Irma <URL>\n",
      "txt=I expect #Irma to make landfall on MO 8 AM nearby Naples. Will hit Tampa at 2PM.\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Tampa\n",
      "data NE tree=[['Naples', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Naples', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['nearby', 'ADP', 4, 'advmod', 10]\n",
      "parent node subtree [['8', 'NUM', 9, 'nummod', 8], ['AM', 'PROPN', 10, 'npadvmod', 9], ['Naples', 'PROPN', 10, 'pobj', 11]]\n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = \n",
      "txt=#Irma is forecast to make landfall somewhere between Naples & Sarasota sometime Sun night & pass very near or over Tampa early Mon am. #flwx\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Sarasota,Tampa\n",
      "data NE tree=[['Naples', 'PROPN', 7, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Naples', 'PROPN', 7, 'pobj', 8]\n",
      "NE parent token:\n",
      "['between', 'ADP', 6, 'prep', 7]\n",
      "parent node subtree [['Naples', 'PROPN', 7, 'pobj', 8], ['&', 'CCONJ', 8, 'cc', 9], ['Sarasota', 'PROPN', 8, 'conj', 10]]\n",
      "NE=Naples subtree=[['&', 'CCONJ', 8, 'cc', 9], ['Sarasota', 'PROPN', 8, 'conj', 10]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Sarasota\n",
      "anchor NE candidates = \n",
      "candidate 2=Tampa\n",
      "anchor NE candidates = Sarasota\n",
      "data NE tree=[['Tampa', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Tampa', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['over', 'ADP', 17, 'conj', 19]\n",
      "parent node subtree [['Tampa', 'PROPN', 19, 'pobj', 20], ['early', 'ADJ', 22, 'amod', 21], ['Mon', 'PROPN', 20, 'appos', 22]]\n",
      "NE=Tampa subtree=[['early', 'ADJ', 22, 'amod', 21], ['Mon', 'PROPN', 20, 'appos', 22]]\n",
      "min node deps ['appos']\n",
      "subtree = early Mon\n",
      "false positive with NE=naples, txt=#Irma is forecast to make landfall somewhere between Naples & Sarasota sometime Sun night & pass very near or over Tampa early Mon am. #flwx\n",
      "txt=Friends and family in Florida facing Hurricane Irma, know you are in our thoughts and prayers in Charleston #hurricaneirma #charleston <URL>\n",
      "candidate 0=Florida\n",
      "anchor NE candidates = \n",
      "candidate 1=Charleston\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Charleston', 'PROPN', 18, 'compound', 17]]\n",
      "NE parse token at tree=0, token=18:\n",
      "['Charleston', 'PROPN', 18, 'compound', 17]\n",
      "NE parent token:\n",
      "['#hurricaneirma', 'PROPN', 16, 'pobj', 18]\n",
      "parent node subtree [['Charleston', 'PROPN', 18, 'compound', 17]]\n",
      "txt=Curfews in effect during #HurricaneIrma in the cities of Miami, Miami Beach and North Miami Beach. No curfew for unincorporated Dade County. <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Dade County\n",
      "data NE tree=[['Miami', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Miami', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "parent node subtree [['Miami', 'PROPN', 11, 'compound', 9], ['Miami', 'PROPN', 11, 'compound', 10], ['and', 'CCONJ', 11, 'cc', 12], ['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "candidate 1=Miami Beach\n",
      "anchor NE candidates = Miami,Dade County\n",
      "data NE tree=[['Miami', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 8, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "NE parent token:\n",
      "['of', 'ADP', 7, 'prep', 8]\n",
      "parent node subtree [['Miami', 'PROPN', 11, 'compound', 9], ['Miami', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 8, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "NE=Miami Beach subtree=[['Miami', 'PROPN', 11, 'compound', 9], ['and', 'CCONJ', 11, 'cc', 12], ['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 2=North Miami Beach\n",
      "anchor NE candidates = Miami,Miami Beach,Dade County\n",
      "data NE tree=[['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Beach', 'PROPN', 11, 'conj', 15]\n",
      "NE parent token:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "candidate 3=Dade County\n",
      "anchor NE candidates = \n",
      "txt=Sincerely hope everyone in Florida & Miami is safe and prepared for #Irma (as well as you can be) thoughts and prayers for those affected.\n",
      "candidate 0=Florida\n",
      "anchor NE candidates = \n",
      "candidate 1=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 4, 'conj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Miami', 'PROPN', 4, 'conj', 6]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 3, 'pobj', 4]\n",
      "false positive with NE=miami, txt=Sincerely hope everyone in Florida & Miami is safe and prepared for #Irma (as well as you can be) thoughts and prayers for those affected.\n",
      "txt=#JewishTimes #Florida #RickScott #HurricaneIrma Irma closes in with Tampa, not Miami, in the crosshairs <URL>\n",
      "candidate 0=Tampa\n",
      "anchor NE candidates = Miami\n",
      "data NE tree=[['Tampa', 'PROPN', 10, 'nmod', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Tampa', 'PROPN', 10, 'nmod', 8]\n",
      "NE parent token:\n",
      "['Miami', 'PROPN', 7, 'pobj', 10]\n",
      "parent node subtree [['Tampa', 'PROPN', 10, 'nmod', 8], ['not', 'ADV', 10, 'neg', 9], ['in', 'ADP', 10, 'prep', 11], ['the', 'DET', 13, 'det', 12], ['crosshairs', 'NOUN', 11, 'pobj', 13]]\n",
      "candidate 1=Miami\n",
      "anchor NE candidates = \n",
      "false positive with NE=tampa, txt=#JewishTimes #Florida #RickScott #HurricaneIrma Irma closes in with Tampa, not Miami, in the crosshairs <URL>\n",
      "txt=High wind watch for Cleveland county and lake wind adv. for Lancaster and Chesterfield due to #Irma . #scwx #ncwx <URL>\n",
      "candidate 0=Cleveland county\n",
      "anchor NE candidates = \n",
      "candidate 1=Lancaster\n",
      "anchor NE candidates = Cleveland county\n",
      "data NE tree=[['Lancaster', 'PROPN', 0, 'pobj', 1]]\n",
      "NE parse token at tree=1, token=2:\n",
      "['Lancaster', 'PROPN', 0, 'pobj', 1]\n",
      "NE parent token:\n",
      "['for', 'ADP', 0, 'ROOT', 0]\n",
      "parent node subtree [['Lancaster', 'PROPN', 0, 'pobj', 1], ['and', 'CCONJ', 1, 'cc', 2], ['Chesterfield', 'PROPN', 1, 'conj', 3], ['due', 'ADP', 1, 'amod', 4], ['to', 'ADP', 4, 'prep', 5], ['#Irma', 'PROPN', 5, 'pobj', 6], ['.', 'PUNCT', 0, 'punct', 7]]\n",
      "NE=Lancaster subtree=[['and', 'CCONJ', 1, 'cc', 2], ['Chesterfield', 'PROPN', 1, 'conj', 3], ['due', 'ADP', 1, 'amod', 4], ['to', 'ADP', 4, 'prep', 5], ['#Irma', 'PROPN', 5, 'pobj', 6]]\n",
      "min node deps ['cc', 'conj', 'amod']\n",
      "candidate 2=Chesterfield\n",
      "anchor NE candidates = Cleveland county,Lancaster\n",
      "data NE tree=[['Chesterfield', 'PROPN', 1, 'conj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Chesterfield', 'PROPN', 1, 'conj', 3]\n",
      "NE parent token:\n",
      "['Lancaster', 'PROPN', 0, 'pobj', 1]\n",
      "txt=. @CityofMiami mayor tells @MLauer he reached out to mayors of Naples, Ft. Myers, Sarasota & Tampa yesterday to offer help #HurricaneIrma\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Myers,Sarasota,Tampa\n",
      "data NE tree=[['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['Naples', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Ft', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=Myers\n",
      "anchor NE candidates = Sarasota,Tampa\n",
      "data NE tree=[['Myers', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['Myers', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['Sarasota', 'PROPN', 14, 'ROOT', 14]\n",
      "parent node subtree [['Myers', 'PROPN', 14, 'compound', 13], ['&', 'CCONJ', 14, 'cc', 15], ['Tampa', 'PROPN', 14, 'conj', 16], ['yesterday', 'NOUN', 14, 'npadvmod', 17], ['to', 'PART', 19, 'aux', 18], ['offer', 'VERB', 14, 'relcl', 19], ['help', 'NOUN', 19, 'dobj', 20], ['#HurricaneIrma', 'PUNCT', 14, 'punct', 21]]\n",
      "candidate 2=Sarasota\n",
      "anchor NE candidates = \n",
      "candidate 3=Tampa\n",
      "anchor NE candidates = Sarasota\n",
      "data NE tree=[['Tampa', 'PROPN', 14, 'conj', 16]]\n",
      "NE parse token at tree=1, token=17:\n",
      "['Tampa', 'PROPN', 14, 'conj', 16]\n",
      "NE parent token:\n",
      "['Sarasota', 'PROPN', 14, 'ROOT', 14]\n",
      "txt=Evacuation! Keep safe everyone! #hurricane #irma — traveling to Greenville, South Carolina\n",
      "candidate 0=Greenville\n",
      "anchor NE candidates = South Carolina\n",
      "data NE tree=[['Greenville', 'PROPN', 7, 'compound', 5]]\n",
      "NE parse token at tree=2, token=6:\n",
      "['Greenville', 'PROPN', 7, 'compound', 5]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['Greenville', 'PROPN', 7, 'compound', 5], ['South', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 1=South Carolina\n",
      "anchor NE candidates = \n",
      "txt=@MSNBC Appreciate thoroughness on #Irma but at what point do you cover prep/problems NORTH of Keys/Miami? & how's Houston? Nature itself?!\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Miami', 'PROPN', 16, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Miami', 'PROPN', 16, 'pobj', 19]\n",
      "NE parent token:\n",
      "['of', 'ADP', 15, 'prep', 16]\n",
      "parent node subtree [['Keys', 'PROPN', 19, 'nmod', 17], ['/', 'SYM', 19, 'punct', 18], ['Miami', 'PROPN', 16, 'pobj', 19]]\n",
      "NE=Miami subtree=[['Keys', 'PROPN', 19, 'nmod', 17], ['/', 'SYM', 19, 'punct', 18]]\n",
      "min node deps ['nmod', 'punct']\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "txt=Heavy flooding right now on the streets of Downtown Miami in Florida #Irma\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 7, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Miami', 'PROPN', 7, 'pobj', 9]\n",
      "NE parent token:\n",
      "['of', 'ADP', 6, 'prep', 7]\n",
      "parent node subtree [['Downtown', 'PROPN', 9, 'compound', 8], ['Miami', 'PROPN', 7, 'pobj', 9]]\n",
      "NE=Miami subtree=[['Downtown', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "txt=Still a long way to go but it is looking like #Irma may make landfall between Naples and Fort Myers.\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Fort Myers\n",
      "data NE tree=[['Naples', 'PROPN', 15, 'pobj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Naples', 'PROPN', 15, 'pobj', 16]\n",
      "NE parent token:\n",
      "['between', 'ADP', 14, 'prep', 15]\n",
      "parent node subtree [['Naples', 'PROPN', 15, 'pobj', 16], ['and', 'CCONJ', 16, 'cc', 17], ['Fort', 'PROPN', 19, 'compound', 18], ['Myers', 'PROPN', 16, 'conj', 19]]\n",
      "NE=Naples subtree=[['and', 'CCONJ', 16, 'cc', 17], ['Fort', 'PROPN', 19, 'compound', 18], ['Myers', 'PROPN', 16, 'conj', 19]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Fort Myers\n",
      "anchor NE candidates = \n",
      "false positive with NE=naples, txt=Still a long way to go but it is looking like #Irma may make landfall between Naples and Fort Myers.\n",
      "txt=Pray for Florida as hurricane Irma impacts Miami. #hurricaneirma <URL>\n",
      "candidate 0=Florida\n",
      "anchor NE candidates = \n",
      "candidate 1=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 6, 'dobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Miami', 'PROPN', 6, 'dobj', 7]\n",
      "NE parent token:\n",
      "['impacts', 'VERB', 0, 'advcl', 6]\n",
      "txt=cnnbrk: #HurricaneIrma ’s intense rain and wind pound JohnBerman in Miami. 75% of Miami-Dade County is now without… <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Miami-Dade County\n",
      "data NE tree=[['Miami', 'PROPN', 11, 'pobj', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Miami', 'PROPN', 11, 'pobj', 12]\n",
      "NE parent token:\n",
      "['in', 'ADP', 10, 'prep', 11]\n",
      "parent node subtree [['Miami', 'PROPN', 11, 'pobj', 12]]\n",
      "candidate 1=Miami-Dade County\n",
      "anchor NE candidates = \n",
      "txt=#Irma just made landfall with FL mainland on Marco Island as a Category 3!! @yohoster @GaryBrennan10 @MichaelDillman @MrJShupp @Skena3 <URL>\n",
      "candidate 0=FL\n",
      "anchor NE candidates = \n",
      "candidate 1=Marco Island\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Marco', 'PROPN', 9, 'compound', 8], ['Island', 'PROPN', 7, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Island', 'PROPN', 7, 'pobj', 9]\n",
      "NE parent token:\n",
      "['on', 'ADP', 6, 'prep', 7]\n",
      "parent node subtree [['Marco', 'PROPN', 9, 'compound', 8], ['Island', 'PROPN', 7, 'pobj', 9]]\n",
      "txt=Indian River Dr and Sunset Terrace, Cocoa. Drivers need to use Highview Dr from the south or Forest Hill Dr from the North #Irma <URL>\n",
      "candidate 0=Indian River\n",
      "anchor NE candidates = Cocoa,Forest Hill\n",
      "data NE tree=[['Indian', 'PROPN', 2, 'compound', 0], ['River', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['River', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['Dr', 'PROPN', 2, 'ROOT', 2]\n",
      "parent node subtree [['Indian', 'PROPN', 2, 'compound', 0], ['River', 'PROPN', 2, 'compound', 1], ['and', 'CCONJ', 2, 'cc', 3], ['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5], ['Cocoa', 'PROPN', 2, 'conj', 6], ['.', 'PUNCT', 2, 'punct', 7]]\n",
      "candidate 1=Sunset Terrace\n",
      "anchor NE candidates = Indian River,Cocoa,Forest Hill\n",
      "data NE tree=[['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Terrace', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['Cocoa', 'PROPN', 2, 'conj', 6]\n",
      "parent node subtree [['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 2=Cocoa\n",
      "anchor NE candidates = Forest Hill\n",
      "data NE tree=[['Cocoa', 'PROPN', 2, 'conj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Cocoa', 'PROPN', 2, 'conj', 6]\n",
      "NE parent token:\n",
      "['Dr', 'PROPN', 2, 'ROOT', 2]\n",
      "NE=Cocoa subtree=[['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5]]\n",
      "min node deps ['compound', 'compound']\n",
      "candidate 3=Forest Hill\n",
      "anchor NE candidates = \n",
      "false positive with NE=sunset_terrace, txt=Indian River Dr and Sunset Terrace, Cocoa. Drivers need to use Highview Dr from the south or Forest Hill Dr from the North #Irma <URL>\n",
      "txt=3.3 million in Florida w/o power, 80% of Miami-Dade w/o power #HurricaneIrma\n",
      "candidate 0=Florida\n",
      "anchor NE candidates = \n",
      "candidate 1=Miami-Dade\n",
      "anchor NE candidates = Florida\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Flash Flood Warning in effect in Clay, Duval, Nassau and St. Johns Counties until 830 AM #flwx #HurricaneIrma <URL>\n",
      "candidate 0=Duval\n",
      "anchor NE candidates = Nassau\n",
      "data NE tree=[['Duval', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Duval', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Nassau', 'PROPN', 5, 'pobj', 8]\n",
      "parent node subtree [['Clay', 'PROPN', 8, 'compound', 6], ['Duval', 'PROPN', 8, 'compound', 7], ['and', 'CCONJ', 8, 'cc', 9], ['St', 'PROPN', 8, 'conj', 10]]\n",
      "candidate 1=Nassau\n",
      "anchor NE candidates = \n",
      "false positive with NE=duval, txt=Flash Flood Warning in effect in Clay, Duval, Nassau and St. Johns Counties until 830 AM #flwx #HurricaneIrma <URL>\n",
      "txt=Power outages from my friends in Miami-dade, to Orlando, and now Tallahassee #HurricaneIrma\n",
      "candidate 0=Orlando\n",
      "anchor NE candidates = \n",
      "candidate 1=Tallahassee\n",
      "anchor NE candidates = Orlando\n",
      "data NE tree=[['Tallahassee', 'PROPN', 8, 'conj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Tallahassee', 'PROPN', 8, 'conj', 11]\n",
      "NE parent token:\n",
      "['Orlando', 'PROPN', 7, 'pobj', 8]\n",
      "NE=Tallahassee subtree=[['now', 'ADV', 11, 'advmod', 10]]\n",
      "min node deps ['advmod']\n",
      "false positive with NE=tallahassee, txt=Power outages from my friends in Miami-dade, to Orlando, and now Tallahassee #HurricaneIrma\n",
      "txt=Irma has arrived in Augusta, Georgia. The power just went out. #hurricaneirma\n",
      "candidate 0=Augusta\n",
      "anchor NE candidates = Georgia\n",
      "data NE tree=[['Augusta', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Augusta', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Georgia', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Augusta', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 1=Georgia\n",
      "anchor NE candidates = \n",
      "false positive with NE=augusta, txt=Irma has arrived in Augusta, Georgia. The power just went out. #hurricaneirma\n",
      "txt=New tornado warning for parts of Beaufort, Colleton County #Irma #Chswx <URL>\n",
      "candidate 0=Beaufort\n",
      "anchor NE candidates = Colleton County\n",
      "data NE tree=[['Beaufort', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Beaufort', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 10, 'compound', 8]\n",
      "parent node subtree [['Beaufort', 'PROPN', 8, 'compound', 6], ['Colleton', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=Colleton County\n",
      "anchor NE candidates = \n",
      "txt=Power outages in GA/ flooding in Charleston, SC and Jacksonville. Just a few of the reports today as #Irma moves North. #GAwx #SCwx <URL>\n",
      "candidate 0=GA\n",
      "anchor NE candidates = \n",
      "candidate 1=Charleston\n",
      "anchor NE candidates = GA,SC,Jacksonville\n",
      "data NE tree=[['Charleston', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Charleston', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Charleston', 'PROPN', 8, 'compound', 7], ['and', 'CCONJ', 8, 'cc', 9], ['Jacksonville', 'PROPN', 8, 'conj', 10]]\n",
      "candidate 2=SC\n",
      "anchor NE candidates = GA\n",
      "data NE tree=[['SC', 'PROPN', 6, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['SC', 'PROPN', 6, 'pobj', 8]\n",
      "NE parent token:\n",
      "['in', 'ADP', 5, 'prep', 6]\n",
      "parent node subtree [['Charleston', 'PROPN', 8, 'compound', 7], ['SC', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['Jacksonville', 'PROPN', 8, 'conj', 10]]\n",
      "NE=SC subtree=[['Charleston', 'PROPN', 8, 'compound', 7], ['and', 'CCONJ', 8, 'cc', 9], ['Jacksonville', 'PROPN', 8, 'conj', 10]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 3=Jacksonville\n",
      "anchor NE candidates = GA,SC\n",
      "data NE tree=[['Jacksonville', 'PROPN', 8, 'conj', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Jacksonville', 'PROPN', 8, 'conj', 10]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 6, 'pobj', 8]\n",
      "false positive with NE=charleston, txt=Power outages in GA/ flooding in Charleston, SC and Jacksonville. Just a few of the reports today as #Irma moves North. #GAwx #SCwx <URL>\n",
      "txt=Told someone I was from Cleveland while covering #HurricaneIrma in Jacksonville, FL. First question: What number are the @indians on #19baby\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Jacksonville', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Jacksonville', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=jacksonville, txt=Told someone I was from Cleveland while covering #HurricaneIrma in Jacksonville, FL. First question: What number are the @indians on #19baby\n",
      "txt=#Irma Seeing pockets of heavy traffic SB I-75 from Gainesville thru Ocala as people return to their homes\n",
      "candidate 0=Gainesville\n",
      "anchor NE candidates = \n",
      "candidate 1=Ocala\n",
      "anchor NE candidates = Gainesville\n",
      "data NE tree=[['Ocala', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Ocala', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['thru', 'ADP', 5, 'prep', 10]\n",
      "parent node subtree [['Ocala', 'PROPN', 10, 'pobj', 11]]\n",
      "txt=Volunteers from @MuslimYouthUSA working with @HFUSA in Miami, Tampa, Naples and Jacksonville doing #HurricaneIrma cleanup work <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Jacksonville\n",
      "data NE tree=[['Miami', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Miami', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Naples', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = Miami,Jacksonville\n",
      "data NE tree=[['Tampa', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Tampa', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['Naples', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "candidate 2=Naples\n",
      "anchor NE candidates = Miami,Tampa,Jacksonville\n",
      "data NE tree=[['Naples', 'PROPN', 6, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Naples', 'PROPN', 6, 'pobj', 9]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 6]\n",
      "parent node subtree [['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['Naples', 'PROPN', 6, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "NE=Naples subtree=[['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "min node deps ['compound', 'compound', 'cc', 'conj']\n",
      "candidate 3=Jacksonville\n",
      "anchor NE candidates = \n",
      "false positive with NE=miami, txt=Volunteers from @MuslimYouthUSA working with @HFUSA in Miami, Tampa, Naples and Jacksonville doing #HurricaneIrma cleanup work <URL>\n",
      "txt=Sarasota County have been very fortunate, that hurricane #Irma did not impact our area as much as it did to other counties in Florida.\n",
      "candidate 0=Sarasota County\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Sarasota', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['County', 'PROPN', 3, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['been', 'VERB', 3, 'ROOT', 3]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "txt=Day 5 no power, limited gas after #hurricaneirma came across us in Naples, FL. Hoping and praying we get power soon. We are safe\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Naples', 'PROPN', 13, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Naples', 'PROPN', 13, 'compound', 12]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 11, 'pobj', 13]\n",
      "parent node subtree [['Naples', 'PROPN', 13, 'compound', 12]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=naples, txt=Day 5 no power, limited gas after #hurricaneirma came across us in Naples, FL. Hoping and praying we get power soon. We are safe\n",
      "txt=@mitchellreports We have major destruction in Polk County Florida. Including Lakeland, bartow,Lake Whales. No power. #Irma\n",
      "candidate 0=Lakeland\n",
      "anchor NE candidates = \n",
      "candidate 1=Lake\n",
      "anchor NE candidates = Lakeland\n",
      "txt=Update on lifting of boil water alert for Hollywood, Pembroke park, Miramar, West Park & Dania Beach. #Irma <URL>\n",
      "candidate 0=Hollywood\n",
      "anchor NE candidates = \n",
      "candidate 1=Pembroke park\n",
      "anchor NE candidates = Hollywood,Miramar,West Park,Dania Beach\n",
      "data NE tree=[['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['park', 'NOUN', 13, 'compound', 10]\n",
      "NE parent token:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "parent node subtree [['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['West', 'PROPN', 13, 'compound', 12], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "NE=Pembroke park subtree=[['Hollywood', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Miramar\n",
      "anchor NE candidates = Hollywood\n",
      "data NE tree=[['Miramar', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Miramar', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "parent node subtree [['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['West', 'PROPN', 13, 'compound', 12], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "candidate 3=West Park\n",
      "anchor NE candidates = Hollywood,Miramar,Dania Beach\n",
      "data NE tree=[['West', 'PROPN', 13, 'compound', 12], ['Park', 'PROPN', 7, 'pobj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "NE parent token:\n",
      "['for', 'ADP', 2, 'prep', 7]\n",
      "parent node subtree [['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['West', 'PROPN', 13, 'compound', 12], ['Park', 'PROPN', 7, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "NE=West Park subtree=[['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "min node deps ['compound']\n",
      "candidate 4=Dania Beach\n",
      "anchor NE candidates = Hollywood,Miramar\n",
      "data NE tree=[['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Beach', 'PROPN', 13, 'conj', 16]\n",
      "NE parent token:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "false positive with NE=pembroke_park, txt=Update on lifting of boil water alert for Hollywood, Pembroke park, Miramar, West Park & Dania Beach. #Irma <URL>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=@andersoncooper #HurricaneIrma Glad to have you in Tampa. I was in Clearwater riding out the storm-I wanted to race to Tampa to meet you.\n",
      "candidate 0=Tampa\n",
      "anchor NE candidates = \n",
      "candidate 1=Clearwater\n",
      "anchor NE candidates = Tampa,Tampa\n",
      "data NE tree=[['Clearwater', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Clearwater', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "parent node subtree [['Clearwater', 'PROPN', 2, 'pobj', 3], ['riding', 'VERB', 3, 'acl', 4], ['out', 'PART', 4, 'prt', 5], ['the', 'DET', 7, 'det', 6], ['stormI', 'NOUN', 4, 'dobj', 7]]\n",
      "NE=Clearwater subtree=[['riding', 'VERB', 3, 'acl', 4], ['out', 'PART', 4, 'prt', 5], ['the', 'DET', 7, 'det', 6], ['stormI', 'NOUN', 4, 'dobj', 7]]\n",
      "min node deps ['acl']\n",
      "subtree = riding out the stormI\n",
      "candidate 2=Tampa\n",
      "anchor NE candidates = \n",
      "txt=Emotional homecoming for our 80-person AZ TaskForce 1. First deployed for search & rescue in Houston for #Harvey then to Florida for #Irma . <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Houston', 'PROPN', 6, 'pobj', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Houston', 'PROPN', 6, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 6]\n",
      "parent node subtree [['Houston', 'PROPN', 6, 'pobj', 7]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "txt=The Status of Our Parks - Along the Gulfshore - September 2017 - Naples, FL #HurricaneIrma <URL>\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Naples', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 12, 'compound', 11]\n",
      "parent node subtree [['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=naples, txt=The Status of Our Parks - Along the Gulfshore - September 2017 - Naples, FL #HurricaneIrma <URL>\n",
      "txt=A Hurricane Warning has been issued for Puerto Rico, Culebra, and Vieques. #Maria <URL>\n",
      "candidate 0=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 1=Vieques\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Vieques', 'PROPN', 9, 'conj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Vieques', 'PROPN', 9, 'conj', 11]\n",
      "NE parent token:\n",
      "['Culebra', 'PROPN', 6, 'pobj', 9]\n",
      "txt=first band of #maria in San Juan , Puerto Rico <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Juan', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 4, 'pobj', 8]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6], ['Puerto', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=#Hurricane warnings for: U.S. Virgin Islands, British Virgin Islands, Puerto Rico, Culebra, and Vieques #Maria @680NEWS @680NEWS\n",
      "candidate 0=Virgin Islands\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Virgin', 'PROPN', 9, 'compound', 8], ['Islands', 'PROPN', 12, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Islands', 'PROPN', 12, 'compound', 9]\n",
      "NE parent token:\n",
      "['Islands', 'PROPN', 15, 'compound', 12]\n",
      "parent node subtree [['Virgin', 'PROPN', 9, 'compound', 8], ['Islands', 'PROPN', 12, 'compound', 9], ['British', 'ADJ', 12, 'amod', 10], ['Virgin', 'PROPN', 12, 'compound', 11]]\n",
      "candidate 1=British Virgin Islands\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['British', 'ADJ', 12, 'amod', 10], ['Virgin', 'PROPN', 12, 'compound', 11], ['Islands', 'PROPN', 15, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Islands', 'PROPN', 15, 'compound', 12]\n",
      "NE parent token:\n",
      "['Culebra', 'PROPN', 15, 'ROOT', 15]\n",
      "parent node subtree [['Virgin', 'PROPN', 9, 'compound', 8], ['Islands', 'PROPN', 12, 'compound', 9], ['British', 'ADJ', 12, 'amod', 10], ['Virgin', 'PROPN', 12, 'compound', 11], ['Islands', 'PROPN', 15, 'compound', 12], ['Puerto', 'PROPN', 15, 'compound', 13], ['Rico', 'PROPN', 15, 'compound', 14], ['and', 'CCONJ', 15, 'cc', 16], ['Vieques', 'PROPN', 18, 'compound', 17], ['#Maria', 'X', 15, 'conj', 18]]\n",
      "NE=British Virgin Islands subtree=[['Virgin', 'PROPN', 9, 'compound', 8], ['Islands', 'PROPN', 12, 'compound', 9]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 3=Culebra\n",
      "anchor NE candidates = Puerto Rico,Vieques\n",
      "data NE tree=[['Culebra', 'PROPN', 15, 'ROOT', 15]]\n",
      "NE=Culebra subtree=[['Virgin', 'PROPN', 9, 'compound', 8], ['Islands', 'PROPN', 12, 'compound', 9], ['British', 'ADJ', 12, 'amod', 10], ['Virgin', 'PROPN', 12, 'compound', 11], ['Islands', 'PROPN', 15, 'compound', 12], ['Puerto', 'PROPN', 15, 'compound', 13], ['Rico', 'PROPN', 15, 'compound', 14], ['and', 'CCONJ', 15, 'cc', 16], ['Vieques', 'PROPN', 18, 'compound', 17], ['#Maria', 'X', 15, 'conj', 18]]\n",
      "min node deps ['compound']\n",
      "candidate 4=Vieques\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Vieques', 'PROPN', 18, 'compound', 17]]\n",
      "NE parse token at tree=0, token=18:\n",
      "['Vieques', 'PROPN', 18, 'compound', 17]\n",
      "NE parent token:\n",
      "['#Maria', 'X', 15, 'conj', 18]\n",
      "parent node subtree [['Vieques', 'PROPN', 18, 'compound', 17]]\n",
      "txt=This is how Ponce, Puerto Rico looked about 30 mins ago. #Maria <URL>\n",
      "candidate 0=Ponce\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Ponce', 'PROPN', 5, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Ponce', 'PROPN', 5, 'compound', 3]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 6, 'nsubj', 5]\n",
      "parent node subtree [['Ponce', 'PROPN', 5, 'compound', 3], ['Puerto', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=RT @hurrtrackerapp: BREAKING: Hurricane #Maria makes landfall near Yabucoa, Puerto Rico as a 155 mph, category 4 storm. <URL>\n",
      "candidate 0=Yabucoa\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Yabucoa', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Yabucoa', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Yabucoa', 'PROPN', 12, 'compound', 10], ['Puerto', 'PROPN', 12, 'compound', 11]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=Went to Humacao, Yabucoa and Vieques multiple times in the mid-aughts. So scary to watch Maria right now #puertorico\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 1, 'pobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Yabucoa', 'PROPN', 1, 'pobj', 3]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "parent node subtree [['Humacao', 'PROPN', 3, 'compound', 2], ['Yabucoa', 'PROPN', 1, 'pobj', 3], ['and', 'CCONJ', 3, 'cc', 4], ['Vieques', 'PROPN', 3, 'conj', 5]]\n",
      "NE=Yabucoa subtree=[['Humacao', 'PROPN', 3, 'compound', 2], ['and', 'CCONJ', 3, 'cc', 4], ['Vieques', 'PROPN', 3, 'conj', 5]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 2=Vieques\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Vieques', 'PROPN', 3, 'conj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Vieques', 'PROPN', 3, 'conj', 5]\n",
      "NE parent token:\n",
      "['Yabucoa', 'PROPN', 1, 'pobj', 3]\n",
      "txt=Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 6, 'flat', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Yabucoa', 'PROPN', 6, 'flat', 8]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 4, 'obl', 6]\n",
      "candidate 2=Maunabo\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Maunabo', 'PROPN', 6, 'flat', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Maunabo', 'PROPN', 6, 'flat', 9]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 4, 'obl', 6]\n",
      "false positive with NE=yabucoa, txt=Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "txt=NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria — NWS San Juan (NWSS…\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 8, 'flat', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Yabucoa', 'PROPN', 8, 'flat', 10]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 6, 'obl', 8]\n",
      "candidate 2=Maunabo\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Maunabo', 'PROPN', 8, 'flat', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Maunabo', 'PROPN', 8, 'flat', 11]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 6, 'obl', 8]\n",
      "false positive with NE=yabucoa, txt=NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria — NWS San Juan (NWSS…\n",
      "txt=Anyone having luck connecting with San Juan, Puerto Rico? Are your texts going through? #PuertoRico #SanJuan #HurricaneMaria\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Juan', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 4, 'pobj', 8]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6], ['Puerto', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=#Maria ... footage from Guayama, Puerto Rico #huracanmaria #hurricanemaria <URL>\n",
      "candidate 0=Guayama\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Guayama', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Guayama', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 3, 'pobj', 6]\n",
      "parent node subtree [['Guayama', 'PROPN', 6, 'compound', 4], ['Puerto', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=UPDATE: Our San Juan office remains closed today as Puerto Rico is in a state of total devastation after #HurricaneMaria @NWSSanJuan\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Juan', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['office', 'NOUN', 6, 'nsubj', 5]\n",
      "parent node subtree [['Our', 'ADJ', 5, 'poss', 2], ['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=My heart & prayers are w/ my family in Puerto Rico. Aguadilla, Moca, San Sebastian, San Lorenzo & Mayaguez. ! #PuertoRicoStrong #PuertoRico\n",
      "candidate 0=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 1=San Sebastian\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 3, 'compound', 2], ['Sebastian', 'PROPN', 5, 'compound', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Sebastian', 'PROPN', 5, 'compound', 3]\n",
      "NE parent token:\n",
      "['Lorenzo', 'PROPN', 5, 'ROOT', 5]\n",
      "parent node subtree [['Aguadilla', 'PROPN', 1, 'compound', 0], ['Moca', 'PROPN', 5, 'compound', 1], ['San', 'PROPN', 3, 'compound', 2], ['Sebastian', 'PROPN', 5, 'compound', 3], ['San', 'PROPN', 5, 'compound', 4], ['&', 'CCONJ', 5, 'cc', 6], ['Mayaguez', 'PROPN', 5, 'conj', 7], ['.', 'PUNCT', 5, 'punct', 8]]\n",
      "candidate 2=San Lorenzo\n",
      "anchor NE candidates = Puerto Rico,San Sebastian\n",
      "data NE tree=[['San', 'PROPN', 5, 'compound', 4], ['Lorenzo', 'PROPN', 5, 'ROOT', 5]]\n",
      "NE=San Lorenzo subtree=[['Aguadilla', 'PROPN', 1, 'compound', 0], ['Moca', 'PROPN', 5, 'compound', 1], ['San', 'PROPN', 3, 'compound', 2], ['Sebastian', 'PROPN', 5, 'compound', 3], ['&', 'CCONJ', 5, 'cc', 6], ['Mayaguez', 'PROPN', 5, 'conj', 7], ['.', 'PUNCT', 5, 'punct', 8]]\n",
      "min node deps ['compound']\n",
      "txt=Hurricane #Maria batters San Juan, Puerto Rico, with strong winds as the powerful storm comes ashore. <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Juan', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 2, 'dobj', 6]\n",
      "parent node subtree [['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 6, 'compound', 4], ['Puerto', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=Incredible video from earlier today of the strong winds and flooded road in San Juan, Puerto Rico. #Maria : @TheHungryCondor <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Juan', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 12, 'pobj', 16]\n",
      "parent node subtree [['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=RT @NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 9, 'flat', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Yabucoa', 'PROPN', 9, 'flat', 11]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 7, 'obl', 9]\n",
      "candidate 2=Maunabo\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Maunabo', 'PROPN', 9, 'flat', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Maunabo', 'PROPN', 9, 'flat', 12]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 7, 'obl', 9]\n",
      "false positive with NE=yabucoa, txt=RT @NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "txt=Our prayers are with the staff and students of UM-related @robinson_school , located in San Juan, Puerto Rico, in the wake of #HurricaneMaria <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Juan', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 12, 'pobj', 16]\n",
      "parent node subtree [['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=More destruction photos from Bayamón, Guaynabo and San Juan #Maria <URL>\n",
      "candidate 0=More\n",
      "anchor NE candidates = Bayamón,Guaynabo\n",
      "data NE tree=[['More', 'DET', 3, 'nsubj', 0]]\n",
      "NE parse token at tree=0, token=1:\n",
      "['More', 'DET', 3, 'nsubj', 0]\n",
      "NE parent token:\n",
      "['from', 'NOUN', 3, 'ROOT', 3]\n",
      "NE=More subtree=[['destruction', 'NOUN', 2, 'amod', 1], ['photos', 'ADJ', 0, 'obj', 2]]\n",
      "min node deps ['obj']\n",
      "candidate 1=Bayamón\n",
      "anchor NE candidates = \n",
      "candidate 2=Guaynabo\n",
      "anchor NE candidates = Bayamón\n",
      "data NE tree=[['Guaynabo', 'PROPN', 4, 'flat', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Guaynabo', 'PROPN', 4, 'flat', 5]\n",
      "NE parent token:\n",
      "['Bayamón', 'PROPN', 3, 'obj', 4]\n",
      "false positive with NE=guaynabo, txt=More destruction photos from Bayamón, Guaynabo and San Juan #Maria <URL>\n",
      "txt=Si usted se dializa con Fresenius. Caguas, Rio Grande y Humacao van a estar ofreciendo servicios desde las 10am #puertorico\n",
      "candidate 0=Caguas\n",
      "anchor NE candidates = \n",
      "candidate 1=Humacao\n",
      "anchor NE candidates = Caguas\n",
      "data NE tree=[['Humacao', 'PROPN', 0, 'conj', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Humacao', 'PROPN', 0, 'conj', 4]\n",
      "NE parent token:\n",
      "['Caguas', 'PROPN', 8, 'nsubj', 0]\n",
      "NE=Humacao subtree=[['y', 'CONJ', 4, 'cc', 3]]\n",
      "min node deps ['cc']\n",
      "false positive with NE=humacao, txt=Si usted se dializa con Fresenius. Caguas, Rio Grande y Humacao van a estar ofreciendo servicios desde las 10am #puertorico\n",
      "txt=#HuracanMaria Se deja sentir en Samana, Nagua, Santiago, La Altagracia, Santo Domingo Este y otras localidades. #Maria <URL>\n",
      "candidate 0=Santiago\n",
      "anchor NE candidates = \n",
      "candidate 1=Altagracia\n",
      "anchor NE candidates = Santiago\n",
      "data NE tree=[['Altagracia', 'PROPN', 5, 'flat', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Altagracia', 'PROPN', 5, 'flat', 9]\n",
      "NE parent token:\n",
      "['Samana', 'PROPN', 3, 'obl', 5]\n",
      "NE=Altagracia subtree=[['La', 'DET', 9, 'det', 8], ['Santo', 'PROPN', 9, 'flat', 10], ['Domingo', 'PROPN', 9, 'flat', 11], ['Este', 'PROPN', 9, 'flat', 12]]\n",
      "min node deps ['det', 'flat', 'flat', 'flat']\n",
      "txt=@weatherchannel is there any way we can hear of other towns in Puerto Rico? There aren’t only people in San Juan! #PuertoRico\n",
      "candidate 0=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 6, 'pobj', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['Juan', 'PROPN', 6, 'pobj', 8]\n",
      "NE parent token:\n",
      "['in', 'ADP', 5, 'prep', 6]\n",
      "parent node subtree [['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 6, 'pobj', 8]]\n",
      "txt=RT UnivisionNews: Exclusive video: The devastating path of Hurricane #Maria across #Puerto Rico, from Yabucoa to San Juan\n",
      "candidate 0=#Puerto Rico\n",
      "anchor NE candidates = Yabucoa,San Juan\n",
      "data NE tree=[['#Puerto', 'PROPN', 14, 'compound', 13], ['Rico', 'PROPN', 12, 'pobj', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Rico', 'PROPN', 12, 'pobj', 14]\n",
      "NE parent token:\n",
      "['across', 'ADP', 8, 'prep', 12]\n",
      "parent node subtree [['#Puerto', 'PROPN', 14, 'compound', 13], ['Rico', 'PROPN', 12, 'pobj', 14]]\n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = San Juan\n",
      "data NE tree=[['Yabucoa', 'PROPN', 15, 'pobj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Yabucoa', 'PROPN', 15, 'pobj', 16]\n",
      "NE parent token:\n",
      "['from', 'ADP', 8, 'prep', 15]\n",
      "parent node subtree [['Yabucoa', 'PROPN', 15, 'pobj', 16]]\n",
      "candidate 2=San Juan\n",
      "anchor NE candidates = \n",
      "txt=Seeking info on my aunt Milly Bodon & Luis in Jayuya, Puerto Rico (Cuabey). Its only accessible by helicopter.No power/phone #HurricaneMaria <URL>\n",
      "candidate 0=Jayuya\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Jayuya', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Jayuya', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Jayuya', 'PROPN', 12, 'compound', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['(', 'PUNCT', 12, 'punct', 13], ['Cuabey', 'PROPN', 12, 'appos', 14], [')', 'PUNCT', 12, 'punct', 15]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=#SanJuan #PuertoRico Drone footage shows flooded streets in San Juan, Puerto Rico, after Hurricane #Maria . <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Juan', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 7, 'pobj', 11]\n",
      "parent node subtree [['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=Inundación en áreas de Ocean Park y Santurce. #María #PuertoRico <URL>\n",
      "candidate 0=Ocean Park\n",
      "anchor NE candidates = \n",
      "candidate 1=Santurce\n",
      "anchor NE candidates = Ocean Park\n",
      "data NE tree=[['Santurce', 'PROPN', 4, 'conj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Santurce', 'PROPN', 4, 'conj', 7]\n",
      "NE parent token:\n",
      "['Ocean', 'PROPN', 2, 'nmod', 4]\n",
      "NE=Santurce subtree=[['y', 'CONJ', 7, 'cc', 6]]\n",
      "min node deps ['cc']\n",
      "txt=The current photos of Loíza, San Isidro & Toa baja are heartbreaking! The rebuild needed will be massive #HurricaneMaria #PuertoRico <URL>\n",
      "candidate 0=San Isidro\n",
      "anchor NE candidates = Toa baja\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Isidro', 'PROPN', 3, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Isidro', 'PROPN', 3, 'pobj', 6]\n",
      "NE parent token:\n",
      "['of', 'ADP', 2, 'prep', 3]\n",
      "parent node subtree [['Loíza', 'PROPN', 6, 'compound', 4], ['San', 'PROPN', 6, 'compound', 5], ['Isidro', 'PROPN', 3, 'pobj', 6], ['&', 'CCONJ', 6, 'cc', 7], ['Toa', 'PROPN', 6, 'conj', 8], ['baja', 'NOUN', 3, 'pobj', 9]]\n",
      "NE=San Isidro subtree=[['Loíza', 'PROPN', 6, 'compound', 4], ['&', 'CCONJ', 6, 'cc', 7], ['Toa', 'PROPN', 6, 'conj', 8]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 1=Toa baja\n",
      "anchor NE candidates = \n",
      "false positive with NE=san_isidro, txt=The current photos of Loíza, San Isidro & Toa baja are heartbreaking! The rebuild needed will be massive #HurricaneMaria #PuertoRico <URL>\n",
      "txt=9-22-2017 Mabu Las Piedras, Juncos, Garabo, Caguas, southern San Juan Helicopter Video #Maria <URL>\n",
      "candidate 0=Las Piedras\n",
      "anchor NE candidates = Caguas,San Juan\n",
      "data NE tree=[['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Piedras', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['Juncos', 'PROPN', 6, 'nmod', 4]\n",
      "parent node subtree [['Mabu', 'PROPN', 3, 'compound', 1], ['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3]]\n",
      "NE=Las Piedras subtree=[['Mabu', 'PROPN', 3, 'compound', 1]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Caguas\n",
      "anchor NE candidates = San Juan\n",
      "data NE tree=[['Caguas', 'PROPN', 6, 'ROOT', 6]]\n",
      "NE=Caguas subtree=[['Mabu', 'PROPN', 3, 'compound', 1], ['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3], ['Juncos', 'PROPN', 6, 'nmod', 4], ['Garabo', 'PROPN', 6, 'nmod', 5], ['southern', 'ADJ', 12, 'amod', 7], ['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 12, 'compound', 9], ['Helicopter', 'PROPN', 12, 'compound', 10], ['Video', 'PROPN', 12, 'compound', 11], ['#Maria', 'PUNCT', 6, 'appos', 12]]\n",
      "min node deps ['compound', 'compound']\n",
      "candidate 2=San Juan\n",
      "anchor NE candidates = \n",
      "txt=Flash Flood Emergency for Quebradillas and Isabela, PR <URL>\n",
      "candidate 0=Quebradillas\n",
      "anchor NE candidates = Isabela\n",
      "data NE tree=[['Quebradillas', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Quebradillas', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['for', 'ADP', 2, 'prep', 3]\n",
      "parent node subtree [['Quebradillas', 'PROPN', 3, 'pobj', 4], ['and', 'CCONJ', 4, 'cc', 5], ['Isabela', 'PROPN', 7, 'compound', 6], ['PR', 'PROPN', 4, 'conj', 7]]\n",
      "NE=Quebradillas subtree=[['and', 'CCONJ', 4, 'cc', 5], ['Isabela', 'PROPN', 7, 'compound', 6], ['PR', 'PROPN', 4, 'conj', 7]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Isabela\n",
      "anchor NE candidates = \n",
      "txt=Retweeted ABC News ( @ABC ): Streets in San Juan, Puerto Rico remain flooded days after #Maria made landfall as a... <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Juan', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 7, 'pobj', 11]\n",
      "parent node subtree [['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=Woohoo, Ponce and adjacent areas, help is coming! This is an update from mi tio in Tampa, who is monitoring faith organizations. #PuertoRico <URL>\n",
      "candidate 0=Ponce\n",
      "anchor NE candidates = Tampa\n",
      "data NE tree=[['Ponce', 'PROPN', 5, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Ponce', 'PROPN', 5, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['help', 'VERB', 7, 'nsubj', 5]\n",
      "NE=Ponce subtree=[['Woohoo', 'PROPN', 1, 'compound', 0], ['and', 'CCONJ', 1, 'cc', 2], ['adjacent', 'ADJ', 4, 'amod', 3], ['areas', 'NOUN', 1, 'conj', 4]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = \n",
      "txt=Update on #HurricaneMaria . My cousin drove to #Yauco and said Costa Sur, Barinas, Almácigo, Palomas, La Quinta are ok. Luchetti is destroyed\n",
      "candidate 0=Barinas\n",
      "anchor NE candidates = Palomas,La Quinta\n",
      "data NE tree=[['Barinas', 'PROPN', 13, 'compound', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Barinas', 'PROPN', 13, 'compound', 9]\n",
      "NE parent token:\n",
      "['Quinta', 'PROPN', 14, 'nsubj', 13]\n",
      "parent node subtree [['Costa', 'PROPN', 13, 'compound', 7], ['Sur', 'PROPN', 13, 'compound', 8], ['Barinas', 'PROPN', 13, 'compound', 9], ['Almácigo', 'PROPN', 13, 'compound', 10], ['Palomas', 'PROPN', 13, 'compound', 11], ['La', 'PROPN', 13, 'compound', 12]]\n",
      "candidate 1=Palomas\n",
      "anchor NE candidates = La Quinta\n",
      "data NE tree=[['Palomas', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['Palomas', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['Quinta', 'PROPN', 14, 'nsubj', 13]\n",
      "parent node subtree [['Costa', 'PROPN', 13, 'compound', 7], ['Sur', 'PROPN', 13, 'compound', 8], ['Barinas', 'PROPN', 13, 'compound', 9], ['Almácigo', 'PROPN', 13, 'compound', 10], ['Palomas', 'PROPN', 13, 'compound', 11], ['La', 'PROPN', 13, 'compound', 12]]\n",
      "candidate 2=La Quinta\n",
      "anchor NE candidates = \n",
      "false positive with NE=barinas, txt=Update on #HurricaneMaria . My cousin drove to #Yauco and said Costa Sur, Barinas, Almácigo, Palomas, La Quinta are ok. Luchetti is destroyed\n",
      "txt=Vega Alta, a 40 min drive from San Juan, has not seen aid a week after #Maria . Hospital on verge of shutting down. <URL>\n",
      "candidate 0=Vega Alta\n",
      "anchor NE candidates = San Juan\n",
      "data NE tree=[['Vega', 'PROPN', 1, 'compound', 0], ['Alta', 'PROPN', 11, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Alta', 'PROPN', 11, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['seen', 'VERB', 11, 'ROOT', 11]\n",
      "NE=Vega Alta subtree=[['a', 'DET', 5, 'det', 2], ['40', 'NUM', 4, 'nummod', 3], ['min', 'NOUN', 5, 'compound', 4], ['drive', 'NOUN', 1, 'appos', 5], ['from', 'ADP', 5, 'prep', 6], ['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 6, 'pobj', 8]]\n",
      "min node deps ['appos']\n",
      "subtree = a 40 min drive from San Juan\n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = \n",
      "txt=Toa Alta, Puerto Rico: A cyclist rides over a bridge damaged by #HurricaneMaria . Photograph: Ricardo Arduengo/AFP #ClimateChange #Capitalism <URL>\n",
      "candidate 0=Toa Alta\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Toa', 'PROPN', 3, 'compound', 0], ['Alta', 'PROPN', 3, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Alta', 'PROPN', 3, 'compound', 1]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 3, 'ROOT', 3]\n",
      "parent node subtree [['Toa', 'PROPN', 3, 'compound', 0], ['Alta', 'PROPN', 3, 'compound', 1], ['Puerto', 'PROPN', 3, 'compound', 2], [':', 'PUNCT', 3, 'punct', 4]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Puerto Rico humanitarian crisis Trump talking about Wall Street + banks San Juan Mayor Carmen Yulin Cruz #Maria <URL>\n",
      "candidate 0=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 12, 'compound', 11], ['Juan', 'PROPN', 13, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Juan', 'PROPN', 13, 'compound', 12]\n",
      "NE parent token:\n",
      "['Mayor', 'PROPN', 13, 'ROOT', 13]\n",
      "parent node subtree [['San', 'PROPN', 12, 'compound', 11], ['Juan', 'PROPN', 13, 'compound', 12]]\n",
      "txt=#PuertoRico Some towns in Puerto Rico have been able to set up hotlines to find family: San Juan 787-294-0277... <URL>\n",
      "candidate 0=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 18, 'compound', 17], ['Juan', 'PROPN', 18, 'ROOT', 18]]\n",
      "NE=San Juan subtree=[['7872940277', 'NUM', 18, 'nummod', 19], ['...', 'PUNCT', 18, 'punct', 20]]\n",
      "min node deps ['nummod', 'punct']\n",
      "subtree = 7872940277 ...\n",
      "txt=From the San Juan, Puerto Rico mayor. Heart wrenching. #PuertoRico <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 6, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Juan', 'PROPN', 6, 'compound', 3]\n",
      "NE parent token:\n",
      "['mayor', 'NOUN', 0, 'pobj', 6]\n",
      "parent node subtree [['the', 'DET', 6, 'det', 1], ['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 6, 'compound', 3], ['Puerto', 'PROPN', 5, 'compound', 4], ['Rico', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "false positive with NE=san_juan, txt=From the San Juan, Puerto Rico mayor. Heart wrenching. #PuertoRico <URL>\n",
      "txt=Trump: If the mayor of San Juan doesn't start praising me, I'll pull ALL relief efforts from Puerto Rico. @realdonaldtRump #maga #PuertoRico\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 7, 'compound', 6], ['Juan', 'PROPN', 5, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Juan', 'PROPN', 5, 'pobj', 7]\n",
      "NE parent token:\n",
      "['of', 'ADP', 4, 'prep', 5]\n",
      "parent node subtree [['San', 'PROPN', 7, 'compound', 6], ['Juan', 'PROPN', 5, 'pobj', 7]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=Dodges the draft, attacks John McCain. Plays golf in NJ, attacks mayor of hurricane ravaged San Juan. #puertorico #weakness #trump <URL>\n",
      "candidate 0=NJ\n",
      "anchor NE candidates = \n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = NJ\n",
      "data NE tree=[['San', 'PROPN', 10, 'compound', 9], ['Juan', 'PROPN', 8, 'dobj', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['Juan', 'PROPN', 8, 'dobj', 10]\n",
      "NE parent token:\n",
      "['ravaged', 'VERB', 8, 'ROOT', 8]\n",
      "txt=Can we please help Puerto Rico? Mayor of San Juan is literally begging for aid! Instead of helping @realDonaldTrump is golfing! #PuertoRico\n",
      "candidate 0=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 1, 'pobj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Juan', 'PROPN', 1, 'pobj', 3]\n",
      "NE parent token:\n",
      "['of', 'ADP', 0, 'prep', 1]\n",
      "parent node subtree [['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 1, 'pobj', 3]]\n",
      "txt=Wow, @potus tries to help Puerto Rico and all the mayor of San Juan can say is how bad he is. Thanks for nothing I guess. #puertorico\n",
      "candidate 0=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 13, 'compound', 12], ['Juan', 'PROPN', 11, 'pobj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Juan', 'PROPN', 11, 'pobj', 13]\n",
      "NE parent token:\n",
      "['of', 'ADP', 10, 'prep', 11]\n",
      "parent node subtree [['San', 'PROPN', 13, 'compound', 12], ['Juan', 'PROPN', 11, 'pobj', 13]]\n",
      "txt=El SNM emite aviso de inundaciones repentinas para los municipios de Fajardo, Naguabo, Luquillo, Ceiba hasta las 5:45 p.m. #HuracanMaria E…\n",
      "candidate 0=Naguabo\n",
      "anchor NE candidates = \n",
      "candidate 1=Luquillo\n",
      "anchor NE candidates = Naguabo\n",
      "data NE tree=[['Luquillo', 'PROPN', 11, 'flat', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Luquillo', 'PROPN', 11, 'flat', 13]\n",
      "NE parent token:\n",
      "['Fajardo', 'PROPN', 9, 'nmod', 11]\n",
      "txt=We are on the ground delivering Food helping our people in #PuertoRico this weekend, Toa Baja, Morovis , Orocovis. @FeedingAmerica <URL>\n",
      "candidate 0=Toa Baja\n",
      "anchor NE candidates = \n",
      "candidate 1=Morovis\n",
      "anchor NE candidates = Toa Baja\n",
      "data NE tree=[['Morovis', 'PROPN', 17, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Morovis', 'PROPN', 17, 'compound', 16]\n",
      "NE parent token:\n",
      "['Orocovis', 'PROPN', 17, 'ROOT', 17]\n",
      "parent node subtree [['Toa', 'PROPN', 17, 'compound', 14], ['Baja', 'PROPN', 17, 'compound', 15], ['Morovis', 'PROPN', 17, 'compound', 16], ['.', 'PUNCT', 17, 'punct', 18]]\n",
      "candidate 2=Orocovis\n",
      "anchor NE candidates = Toa Baja,Morovis\n",
      "data NE tree=[['Orocovis', 'PROPN', 17, 'ROOT', 17]]\n",
      "NE=Orocovis subtree=[['Toa', 'PROPN', 17, 'compound', 14], ['Baja', 'PROPN', 17, 'compound', 15], ['Morovis', 'PROPN', 17, 'compound', 16], ['.', 'PUNCT', 17, 'punct', 18]]\n",
      "min node deps ['compound', 'compound', 'compound', 'punct']\n",
      "txt=President @realDonaldTrump the Mayor of San Juan does not represent the majority in Puerto Rico. Thanks for your support. #PuertoRico\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 4, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Juan', 'PROPN', 4, 'pobj', 6]\n",
      "NE parent token:\n",
      "['of', 'ADP', 3, 'prep', 4]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 4, 'pobj', 6]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=Pres Trump expected to travel to Puerto Rico tom as scheduled to Survey damage from #Maria . Then heads to Vegas on Wed. #VegasShooting\n",
      "candidate 0=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 1=Vegas\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Vegas', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Vegas', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['to', 'ADP', 1, 'prep', 2]\n",
      "parent node subtree [['Vegas', 'PROPN', 2, 'pobj', 3]]\n",
      "txt=Eye of the Storm: A dispatch from San Juan, Puerto Rico by @sodapopcomics <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Juan', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 7, 'pobj', 11]\n",
      "parent node subtree [['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=Our potus is in Guaynabo -one of the wealthiest towns in Puerto Rico - does anyone know if he plans to go out of San Juan?? #hurricanemaria\n",
      "candidate 0=Guaynabo\n",
      "anchor NE candidates = Puerto Rico,San Juan\n",
      "data NE tree=[['Guaynabo', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Guaynabo', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "parent node subtree [['Guaynabo', 'PROPN', 3, 'pobj', 4], ['one', 'NUM', 4, 'nummod', 5], ['of', 'ADP', 5, 'prep', 6], ['the', 'DET', 9, 'det', 7], ['wealthiest', 'ADJ', 9, 'amod', 8], ['towns', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 10, 'pobj', 12]]\n",
      "NE=Guaynabo subtree=[['one', 'NUM', 4, 'nummod', 5], ['of', 'ADP', 5, 'prep', 6], ['the', 'DET', 9, 'det', 7], ['wealthiest', 'ADJ', 9, 'amod', 8], ['towns', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 10, 'pobj', 12]]\n",
      "min node deps ['nummod']\n",
      "subtree = one of the wealthiest towns in Puerto Rico\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 2=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 24, 'compound', 23], ['Juan', 'PROPN', 22, 'pobj', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Juan', 'PROPN', 22, 'pobj', 24]\n",
      "NE parent token:\n",
      "['of', 'ADP', 21, 'prep', 22]\n",
      "parent node subtree [['San', 'PROPN', 24, 'compound', 23], ['Juan', 'PROPN', 22, 'pobj', 24]]\n",
      "txt=Welcome to PR, Mr. President @Old San Juan, Puerto Rico. @realDonaldTrump #PuertoRico #HuracanMaria #TrumpBully <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 10, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Juan', 'PROPN', 10, 'compound', 8]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 6, 'dobj', 10]\n",
      "parent node subtree [['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 10, 'compound', 8], ['Puerto', 'PROPN', 10, 'compound', 9]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=Photos of the land in front of my family's house in Cidra, Puerto Rico. My heart continues to ache for my people @PuertoRicoPUR #Maria <URL>\n",
      "candidate 0=Cidra\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Cidra', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Cidra', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 10, 'pobj', 13]\n",
      "parent node subtree [['Cidra', 'PROPN', 13, 'compound', 11], ['Puerto', 'PROPN', 13, 'compound', 12]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=Watch: A CG aircrew air drops much needed supplies to the residents of Utuado, Puerto Rico after #HurricaneMaria left them stranded <URL>\n",
      "candidate 0=Utuado\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Utuado', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Utuado', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 13, 'pobj', 16]\n",
      "parent node subtree [['Utuado', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15]]\n",
      "candidate 1=Puerto Rico\n",
      "anchor NE candidates = \n",
      "txt=St John, St Croix, St Thomas, Water Island, Puerto Rico, Culebra, Vieques are ALL US territories & ALL need help! #hurricanemaria\n",
      "candidate 0=St John\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['John', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['St', 'PROPN', 4, 'compound', 2]\n",
      "parent node subtree [['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1]]\n",
      "candidate 1=St Croix\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Croix', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['St', 'PROPN', 7, 'compound', 4]\n",
      "parent node subtree [['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3]]\n",
      "NE=St Croix subtree=[['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1]]\n",
      "min node deps ['compound', 'compound']\n",
      "candidate 2=St Thomas\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Thomas', 'PROPN', 7, 'compound', 5]\n",
      "NE parent token:\n",
      "['Island', 'PROPN', 11, 'compound', 7]\n",
      "parent node subtree [['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5], ['Water', 'PROPN', 7, 'compound', 6]]\n",
      "NE=St Thomas subtree=[['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3]]\n",
      "min node deps ['compound', 'compound']\n",
      "candidate 3=Water Island\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Water', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 11, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Island', 'PROPN', 11, 'compound', 7]\n",
      "NE parent token:\n",
      "['Vieques', 'PROPN', 12, 'nsubj', 11]\n",
      "parent node subtree [['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5], ['Water', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 11, 'compound', 7], ['Puerto', 'PROPN', 9, 'compound', 8], ['Rico', 'PROPN', 11, 'compound', 9], ['Culebra', 'PROPN', 11, 'compound', 10]]\n",
      "NE=Water Island subtree=[['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5]]\n",
      "min node deps ['compound', 'compound']\n",
      "candidate 4=Puerto Rico\n",
      "anchor NE candidates = \n",
      "candidate 5=Culebra\n",
      "anchor NE candidates = Puerto Rico,Vieques\n",
      "data NE tree=[['Culebra', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Culebra', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Vieques', 'PROPN', 12, 'nsubj', 11]\n",
      "parent node subtree [['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5], ['Water', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 11, 'compound', 7], ['Puerto', 'PROPN', 9, 'compound', 8], ['Rico', 'PROPN', 11, 'compound', 9], ['Culebra', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 6=Vieques\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Vieques', 'PROPN', 12, 'nsubj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Vieques', 'PROPN', 12, 'nsubj', 11]\n",
      "NE parent token:\n",
      "['are', 'VERB', 12, 'ROOT', 12]\n",
      "NE=Vieques subtree=[['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5], ['Water', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 11, 'compound', 7], ['Puerto', 'PROPN', 9, 'compound', 8], ['Rico', 'PROPN', 11, 'compound', 9], ['Culebra', 'PROPN', 11, 'compound', 10]]\n",
      "min node deps ['compound', 'compound']\n",
      "false positive with NE=culebra, txt=St John, St Croix, St Thomas, Water Island, Puerto Rico, Culebra, Vieques are ALL US territories & ALL need help! #hurricanemaria\n",
      "txt=The latest reliable models available (from this morning) ALL keep Hurricane force *sustained* winds out of #Tallahassee from #HurricaneMichael . However Gadsden & Liberty will still per these models get Hurricane force winds so it’s close enough to Tallahassee to worry.\n",
      "candidate 0=Gadsden\n",
      "anchor NE candidates = Liberty,Tallahassee\n",
      "data NE tree=[['Gadsden', 'PROPN', 6, 'nsubj', 1]]\n",
      "NE parse token at tree=1, token=2:\n",
      "['Gadsden', 'PROPN', 6, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['per', 'ADP', 9, 'prep', 6]\n",
      "NE=Gadsden subtree=[['&', 'CCONJ', 1, 'cc', 2], ['Liberty', 'PROPN', 1, 'conj', 3]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Liberty\n",
      "anchor NE candidates = Tallahassee\n",
      "data NE tree=[['Liberty', 'PROPN', 1, 'conj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Liberty', 'PROPN', 1, 'conj', 3]\n",
      "NE parent token:\n",
      "['Gadsden', 'PROPN', 6, 'nsubj', 1]\n",
      "candidate 2=Tallahassee\n",
      "anchor NE candidates = \n",
      "txt=HurriCation Self Portrait 3. Nice work on the backdrop katebackdrops #hurricanemichaelmademedoit #longexposure @ Tallahassee, Florida <URL>\n",
      "candidate 0=Tallahassee\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Tallahassee', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Tallahassee', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 10, 'ROOT', 10]\n",
      "parent node subtree [['Tallahassee', 'PROPN', 10, 'compound', 9]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=tallahassee, txt=HurriCation Self Portrait 3. Nice work on the backdrop katebackdrops #hurricanemichaelmademedoit #longexposure @ Tallahassee, Florida <URL>\n",
      "txt=RT @weartv: Massive construction cranes loom over the skyline in Panama City Beach as #HurricaneMichael takes aim at the #Florida Panhandle…\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = \n",
      "candidate 1=Panhandle\n",
      "anchor NE candidates = Panama City Beach\n",
      "data NE tree=[['Panhandle', 'PROPN', 18, 'pobj', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Panhandle', 'PROPN', 18, 'pobj', 21]\n",
      "NE parent token:\n",
      "['at', 'ADP', 16, 'prep', 18]\n",
      "parent node subtree [['the', 'DET', 20, 'det', 19], ['#Florida', 'PROPN', 21, 'compound', 20], ['Panhandle', 'PROPN', 18, 'pobj', 21]]\n",
      "NE=Panhandle subtree=[['the', 'DET', 20, 'det', 19], ['#Florida', 'PROPN', 21, 'compound', 20]]\n",
      "min node deps ['det']\n",
      "txt=Please be safe my Florida and Gulf Shores friends!! Praying for you! #HurricaneMichael\n",
      "candidate 0=Florida\n",
      "anchor NE candidates = \n",
      "candidate 1=Gulf Shores\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Gulf', 'PROPN', 7, 'compound', 6], ['Shores', 'PROPN', 4, 'conj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Shores', 'PROPN', 4, 'conj', 7]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 8, 'nmod', 4]\n",
      "false positive with NE=gulf_shores, txt=Please be safe my Florida and Gulf Shores friends!! Praying for you! #HurricaneMichael\n",
      "txt=#hurricanemichael, Siesta Key Beach, Sarasota, Florida.Only brits 🇬🇧 left on the beach. Sending love further up the panhandle. <URL>\n",
      "candidate 0=Sarasota\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Sarasota', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Sarasota', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['brits', 'NOUN', 9, 'nsubj', 6]\n",
      "parent node subtree [['Siesta', 'PROPN', 2, 'compound', 1], ['Key', 'PROPN', 3, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3], ['Sarasota', 'PROPN', 6, 'compound', 4], ['Florida.Only', 'ADV', 6, 'compound', 5]]\n",
      "NE=Sarasota subtree=[['Siesta', 'PROPN', 2, 'compound', 1], ['Key', 'PROPN', 3, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=sarasota, txt=#hurricanemichael, Siesta Key Beach, Sarasota, Florida.Only brits 🇬🇧 left on the beach. Sending love further up the panhandle. <URL>\n",
      "txt=Our first #HurricaneMichael response teams have arrived at a staging area in Okaloosa County, FL, just across the b… <URL>\n",
      "candidate 0=Okaloosa County\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Okaloosa', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['County', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 11, 'pobj', 14]\n",
      "parent node subtree [['Okaloosa', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 14, 'compound', 13]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=okaloosa_county, txt=Our first #HurricaneMichael response teams have arrived at a staging area in Okaloosa County, FL, just across the b… <URL>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Posting for a friend: “If anyone knows what conditions are like or has pics near Delaware Ave (right outside the Lynn Haven Country Club) or on Lisenby near 390, Lynn Haven, FL north of Panama City Beach, FL. Still can get ahold of my mom or grandparents.” #HurricaneMichael\n",
      "candidate 0=Delaware\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Delaware', 'PROPN', 18, 'compound', 17]]\n",
      "NE parse token at tree=0, token=18:\n",
      "['Delaware', 'PROPN', 18, 'compound', 17]\n",
      "NE parent token:\n",
      "['Ave', 'PROPN', 16, 'pobj', 18]\n",
      "parent node subtree [['Delaware', 'PROPN', 18, 'compound', 17], ['(', 'PUNCT', 18, 'punct', 19]]\n",
      "candidate 1=Lynn Haven\n",
      "anchor NE candidates = Delaware,FL\n",
      "data NE tree=[['Lynn', 'PROPN', 26, 'compound', 23], ['Haven', 'PROPN', 26, 'compound', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Haven', 'PROPN', 26, 'compound', 24]\n",
      "NE parent token:\n",
      "['Club', 'PROPN', 21, 'pobj', 26]\n",
      "parent node subtree [['the', 'DET', 26, 'det', 22], ['Lynn', 'PROPN', 26, 'compound', 23], ['Haven', 'PROPN', 26, 'compound', 24], ['Country', 'PROPN', 26, 'compound', 25]]\n",
      "candidate 2=Panama City Beach\n",
      "anchor NE candidates = Delaware,Lynn Haven,FL\n",
      "data NE tree=[['Panama', 'PROPN', 41, 'compound', 38], ['City', 'PROPN', 41, 'compound', 39], ['Beach', 'PROPN', 41, 'compound', 40]]\n",
      "NE parse token at tree=0, token=41:\n",
      "['Beach', 'PROPN', 41, 'compound', 40]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 37, 'pobj', 41]\n",
      "parent node subtree [['Panama', 'PROPN', 41, 'compound', 38], ['City', 'PROPN', 41, 'compound', 39], ['Beach', 'PROPN', 41, 'compound', 40]]\n",
      "candidate 3=FL\n",
      "anchor NE candidates = \n",
      "txt=More than 80% of our customers in Bay, Franklin, Gulf, Jefferson & Wakulla counties lost power as #Michael roared on shore as a cat. 4 hurricane. Damage assessment & repairs to the electric system are underway in areas that crews are able to access. <URL>\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Franklin,Gulf,Jefferson\n",
      "data NE tree=[['Bay', 'PROPN', 11, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Bay', 'PROPN', 11, 'compound', 8]\n",
      "NE parent token:\n",
      "['Jefferson', 'PROPN', 14, 'nmod', 11]\n",
      "parent node subtree [['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "candidate 1=Franklin\n",
      "anchor NE candidates = \n",
      "candidate 2=Gulf\n",
      "anchor NE candidates = Franklin,Jefferson\n",
      "data NE tree=[['Gulf', 'PROPN', 11, 'nmod', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Gulf', 'PROPN', 11, 'nmod', 10]\n",
      "NE parent token:\n",
      "['Jefferson', 'PROPN', 14, 'nmod', 11]\n",
      "parent node subtree [['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "candidate 3=Jefferson\n",
      "anchor NE candidates = Franklin\n",
      "data NE tree=[['Jefferson', 'PROPN', 14, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Jefferson', 'PROPN', 14, 'nmod', 11]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 7, 'pobj', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['Jefferson', 'PROPN', 14, 'nmod', 11], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "NE=Jefferson subtree=[['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "min node deps ['compound', 'compound', 'nmod', 'cc', 'conj']\n",
      "false positive with NE=bay, txt=More than 80% of our customers in Bay, Franklin, Gulf, Jefferson & Wakulla counties lost power as #Michael roared on shore as a cat. 4 hurricane. Damage assessment & repairs to the electric system are underway in areas that crews are able to access. <URL>\n",
      "txt=Sadly, we now have 6 confirmed fatalities due to #Michael , all inland. 4 in Gadsden County, FL (NW of Tallahassee), one in Seminole County in SW Georgia, and one north of Charlotte in Iredell County, NC. Most known to be due to wind knocking down trees or structures onto victims.\n",
      "candidate 0=Gadsden County\n",
      "anchor NE candidates = FL,Tallahassee,Seminole County,Charlotte,Iredell County,NC\n",
      "data NE tree=[['Gadsden', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['County', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 1, 'pobj', 4]\n",
      "parent node subtree [['Gadsden', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 4, 'compound', 3], ['(', 'PUNCT', 4, 'punct', 5], ['NW', 'PROPN', 4, 'appos', 6], ['of', 'ADP', 6, 'prep', 7], ['Tallahassee', 'PROPN', 7, 'pobj', 8], [')', 'PUNCT', 4, 'punct', 9], ['one', 'NUM', 4, 'appos', 10], ['in', 'ADP', 10, 'prep', 11], ['Seminole', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 11, 'pobj', 13], ['in', 'ADP', 13, 'prep', 14], ['SW', 'PROPN', 16, 'compound', 15], ['Georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['Charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24], ['NC', 'PROPN', 22, 'pobj', 25]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "candidate 2=Tallahassee\n",
      "anchor NE candidates = FL,Seminole County,Charlotte,NC\n",
      "data NE tree=[['Tallahassee', 'PROPN', 7, 'pobj', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['Tallahassee', 'PROPN', 7, 'pobj', 8]\n",
      "NE parent token:\n",
      "['of', 'ADP', 6, 'prep', 7]\n",
      "parent node subtree [['Tallahassee', 'PROPN', 7, 'pobj', 8]]\n",
      "candidate 3=Seminole County\n",
      "anchor NE candidates = FL,Charlotte,NC\n",
      "data NE tree=[['Seminole', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 11, 'pobj', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['County', 'PROPN', 11, 'pobj', 13]\n",
      "NE parent token:\n",
      "['in', 'ADP', 10, 'prep', 11]\n",
      "parent node subtree [['Seminole', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 11, 'pobj', 13], ['in', 'ADP', 13, 'prep', 14], ['SW', 'PROPN', 16, 'compound', 15], ['Georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['Charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24], ['NC', 'PROPN', 22, 'pobj', 25]]\n",
      "NE=Seminole County subtree=[['in', 'ADP', 13, 'prep', 14], ['SW', 'PROPN', 16, 'compound', 15], ['Georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['Charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24], ['NC', 'PROPN', 22, 'pobj', 25]]\n",
      "min node deps ['prep', 'cc', 'conj']\n",
      "subtree = in SW Georgia and one north of Charlotte in Iredell County NC\n",
      "candidate 4=Charlotte\n",
      "anchor NE candidates = FL,NC\n",
      "data NE tree=[['Charlotte', 'PROPN', 20, 'pobj', 21]]\n",
      "NE parse token at tree=1, token=22:\n",
      "['Charlotte', 'PROPN', 20, 'pobj', 21]\n",
      "NE parent token:\n",
      "['of', 'ADP', 19, 'prep', 20]\n",
      "parent node subtree [['Charlotte', 'PROPN', 20, 'pobj', 21]]\n",
      "candidate 5=Iredell County\n",
      "anchor NE candidates = FL,Tallahassee,Seminole County,Charlotte,NC\n",
      "data NE tree=[['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24]]\n",
      "NE parse token at tree=1, token=25:\n",
      "['County', 'PROPN', 25, 'compound', 24]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 22, 'pobj', 25]\n",
      "parent node subtree [['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24]]\n",
      "candidate 6=NC\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['NC', 'PROPN', 22, 'pobj', 25]]\n",
      "NE parse token at tree=1, token=26:\n",
      "['NC', 'PROPN', 22, 'pobj', 25]\n",
      "NE parent token:\n",
      "['in', 'ADP', 19, 'prep', 22]\n",
      "parent node subtree [['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24], ['NC', 'PROPN', 22, 'pobj', 25]]\n",
      "NE=NC subtree=[['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24]]\n",
      "min node deps ['compound']\n",
      "txt=But here I am, always watching other places have outside help in a disaster and here we live with police and fire from Jacksonville, Miami, Hillsborough, Tallahassee and other places roll up and down the roads #PanamaCity #HurricaneMichael\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = \n",
      "candidate 1=Miami\n",
      "anchor NE candidates = Jacksonville\n",
      "data NE tree=[['Miami', 'PROPN', 26, 'compound', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Miami', 'PROPN', 26, 'compound', 24]\n",
      "NE parent token:\n",
      "['Tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "candidate 2=Hillsborough\n",
      "anchor NE candidates = Jacksonville,Miami,Tallahassee\n",
      "data NE tree=[['Hillsborough', 'PROPN', 26, 'compound', 25]]\n",
      "NE parse token at tree=0, token=26:\n",
      "['Hillsborough', 'PROPN', 26, 'compound', 25]\n",
      "NE parent token:\n",
      "['Tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "candidate 3=Tallahassee\n",
      "anchor NE candidates = Jacksonville,Miami\n",
      "data NE tree=[['Tallahassee', 'PROPN', 22, 'pobj', 26]]\n",
      "NE parse token at tree=0, token=27:\n",
      "['Tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "NE parent token:\n",
      "['from', 'ADP', 17, 'prep', 22]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['Tallahassee', 'PROPN', 22, 'pobj', 26], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "NE=Tallahassee subtree=[['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "min node deps ['compound', 'compound', 'compound', 'cc', 'conj']\n",
      "txt=IDES is responding to #HurricaneMichael IDES staff is en route to Florida where we will be #partnering with our Anchor Church, Christ's Church of Jacksonville, @ccontheweb to connect with churches in communities affected by #Hurricane Michael. <URL>\n",
      "candidate 0=Florida\n",
      "anchor NE candidates = \n",
      "candidate 1=Jacksonville\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Jacksonville', 'PROPN', 25, 'compound', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Jacksonville', 'PROPN', 25, 'compound', 24]\n",
      "NE parent token:\n",
      "['@ccontheweb', 'PUNCT', 2, 'dobj', 25]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 25, 'compound', 24]]\n",
      "txt=TS #Michael knocked down some trees, left thousands without power, and blocked several roadways in Darlington, SC. <URL>\n",
      "candidate 0=Darlington\n",
      "anchor NE candidates = SC\n",
      "data NE tree=[['Darlington', 'PROPN', 16, 'compound', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Darlington', 'PROPN', 16, 'compound', 15]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 14, 'pobj', 16]\n",
      "parent node subtree [['Darlington', 'PROPN', 16, 'compound', 15]]\n",
      "candidate 1=SC\n",
      "anchor NE candidates = \n",
      "false positive with NE=darlington, txt=TS #Michael knocked down some trees, left thousands without power, and blocked several roadways in Darlington, SC. <URL>\n",
      "txt=All day we've all seen the horrific landscape in Panama City Beach and Mexico Beach, Florida and other parts of the Panhandle. But every new drone or aerial shot continues to stun. #Michael was swift. In the morning things were there. In the afternoon, they weren't. <URL>\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Panama', 'PROPN', 11, 'compound', 9], ['City', 'PROPN', 11, 'nmod', 10], ['Beach', 'PROPN', 8, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "NE parent token:\n",
      "['in', 'ADP', 7, 'prep', 8]\n",
      "parent node subtree [['Panama', 'PROPN', 11, 'compound', 9], ['City', 'PROPN', 11, 'nmod', 10], ['Beach', 'PROPN', 8, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Mexico', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 11, 'conj', 14], ['Florida', 'PROPN', 11, 'conj', 15], ['and', 'CCONJ', 11, 'cc', 16], ['other', 'ADJ', 18, 'amod', 17], ['parts', 'NOUN', 11, 'conj', 18], ['of', 'ADP', 18, 'prep', 19], ['the', 'DET', 21, 'det', 20], ['Panhandle', 'PROPN', 19, 'pobj', 21]]\n",
      "NE=Panama City Beach subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Mexico', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 11, 'conj', 14], ['Florida', 'PROPN', 11, 'conj', 15], ['and', 'CCONJ', 11, 'cc', 16], ['other', 'ADJ', 18, 'amod', 17], ['parts', 'NOUN', 11, 'conj', 18], ['of', 'ADP', 18, 'prep', 19], ['the', 'DET', 21, 'det', 20], ['Panhandle', 'PROPN', 19, 'pobj', 21]]\n",
      "min node deps ['cc', 'conj', 'conj', 'cc', 'conj']\n",
      "candidate 1=Mexico Beach\n",
      "anchor NE candidates = Panama City Beach,Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 11, 'conj', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Beach', 'PROPN', 11, 'conj', 14]\n",
      "NE parent token:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "candidate 2=Florida\n",
      "anchor NE candidates = \n",
      "txt=Keep all the cities affected by #HurricaneMichael in your prayers. Jackson County Bay County Washington County Houston County and others. We all need help!\n",
      "candidate 0=Jackson County\n",
      "anchor NE candidates = \n",
      "candidate 1=Houston County\n",
      "anchor NE candidates = Jackson County\n",
      "data NE tree=[['Houston', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 7, 'ROOT', 7]]\n",
      "NE=Houston County subtree=[['Jackson', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'compound', 1], ['Bay', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['Washington', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 7, 'compound', 5], ['and', 'CCONJ', 7, 'cc', 8], ['others', 'NOUN', 7, 'conj', 9], ['.', 'PUNCT', 7, 'punct', 10]]\n",
      "min node deps ['compound']\n",
      "txt=All orders to Mexico Beach, FL will be refunded FOC and sent in due course! Please contact info@wave97.com for more information. #HurricaneMichael\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Mexico', 'PROPN', 5, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Beach', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Mexico', 'PROPN', 5, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=mexico_beach, txt=All orders to Mexico Beach, FL will be refunded FOC and sent in due course! Please contact info@wave97.com for more information. #HurricaneMichael\n",
      "txt=@Dove it would be the perfect time to send extra dry shampoo to Panama City and Beach. No water for maybe weeks #HurricaneMichael #PanamaCityBeach\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = \n",
      "candidate 1=Beach\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Beach', 'PROPN', 14, 'conj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Beach', 'PROPN', 14, 'conj', 16]\n",
      "NE parent token:\n",
      "['City', 'PROPN', 12, 'pobj', 14]\n",
      "txt=ICYMI: This reporter hunkered down in a Panama City, Florida parking deck as Hurricane Michael roared ashore Wednesday More #HurricaneMichael video: <URL>\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Panama', 'PROPN', 10, 'compound', 8], ['City', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['City', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 12, 'compound', 10]\n",
      "parent node subtree [['Panama', 'PROPN', 10, 'compound', 8], ['City', 'PROPN', 10, 'compound', 9]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=panama_city, txt=ICYMI: This reporter hunkered down in a Panama City, Florida parking deck as Hurricane Michael roared ashore Wednesday More #HurricaneMichael video: <URL>\n",
      "txt=#HurricaneRelief #HurricaneMichael #MAGA #AmericaFirst #NationalGuard #FEMA @fema #KAG From Congressman Matt Gaetz, for areas having trouble getting supplies, food, water around Bonifay, Holmes County, Ponce De Leon areas. Disaster relief contact info below. @RepMattGaetz <URL>\n",
      "candidate 0=Bonifay\n",
      "anchor NE candidates = Holmes County\n",
      "data NE tree=[['Bonifay', 'PROPN', 23, 'compound', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Bonifay', 'PROPN', 23, 'compound', 21]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 27, 'compound', 23]\n",
      "parent node subtree [['Bonifay', 'PROPN', 23, 'compound', 21], ['Holmes', 'PROPN', 23, 'compound', 22]]\n",
      "candidate 1=Holmes County\n",
      "anchor NE candidates = \n",
      "candidate 2=Ponce De Leon\n",
      "anchor NE candidates = Bonifay,Holmes County\n",
      "data NE tree=[['Ponce', 'PROPN', 26, 'compound', 24], ['De', 'PROPN', 26, 'compound', 25], ['Leon', 'PROPN', 27, 'compound', 26]]\n",
      "NE parse token at tree=0, token=27:\n",
      "['Leon', 'PROPN', 27, 'compound', 26]\n",
      "NE parent token:\n",
      "['areas', 'NOUN', 20, 'pobj', 27]\n",
      "parent node subtree [['Bonifay', 'PROPN', 23, 'compound', 21], ['Holmes', 'PROPN', 23, 'compound', 22], ['County', 'PROPN', 27, 'compound', 23], ['Ponce', 'PROPN', 26, 'compound', 24], ['De', 'PROPN', 26, 'compound', 25], ['Leon', 'PROPN', 27, 'compound', 26]]\n",
      "txt=New aerial video of the massive destruction at Mexico Beach, Florida. Thanks once again to our exclusive partners at @Livestormsmedia #arwx #Michael <URL>\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 10, 'compound', 8], ['Beach', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Beach', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 7, 'pobj', 10]\n",
      "parent node subtree [['Mexico', 'PROPN', 10, 'compound', 8], ['Beach', 'PROPN', 10, 'compound', 9]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=mexico_beach, txt=New aerial video of the massive destruction at Mexico Beach, Florida. Thanks once again to our exclusive partners at @Livestormsmedia #arwx #Michael <URL>\n",
      "txt=DEVASTATING DAMAGE: This is my 2nd year living in Florida during Hurricane Season and the images don't get easier to watch. This picture shows the devastation left behind by #HurricaneMichael in Mexico Beach. Praying for the victims and their families. #PrayersforthePanhandle <URL>\n",
      "candidate 0=Florida\n",
      "anchor NE candidates = \n",
      "candidate 1=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 9, 'pobj', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['Beach', 'PROPN', 9, 'pobj', 11]\n",
      "NE parent token:\n",
      "['in', 'ADP', 5, 'prep', 9]\n",
      "parent node subtree [['Mexico', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 9, 'pobj', 11]]\n",
      "txt=Thank you, this Panama City Beach #hurricanemichael survivor appreciates what you are doing for us!! Your store in Santa Rosa Beach helped us today when we drove over from Panama City to purchase food/water/supplies for our friends and coworkers. The employees were so kind! <URL>\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 7, 'nmod', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Beach', 'PROPN', 7, 'nmod', 5]\n",
      "NE parent token:\n",
      "['survivor', 'NOUN', 8, 'nsubj', 7]\n",
      "parent node subtree [['this', 'DET', 7, 'det', 2], ['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 7, 'nmod', 5], ['#hurricanemichael', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 1=Santa Rosa Beach\n",
      "anchor NE candidates = Panama City Beach,Panama City\n",
      "data NE tree=[['Santa', 'PROPN', 4, 'compound', 3], ['Rosa', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Beach', 'PROPN', 2, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "parent node subtree [['Santa', 'PROPN', 4, 'compound', 3], ['Rosa', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5]]\n",
      "candidate 2=Panama City\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive with NE=panama_city_beach, txt=Thank you, this Panama City Beach #hurricanemichael survivor appreciates what you are doing for us!! Your store in Santa Rosa Beach helped us today when we drove over from Panama City to purchase food/water/supplies for our friends and coworkers. The employees were so kind! <URL>\n",
      "txt=Rob Golding drove to Springfield, Florida to be with his 89-year-old dad during #HurricaneMichael . His home was spared, but the area suffered damage, so they started taking in neighbors, going out to rescue friends, and organizing food for the community. <URL>\n",
      "candidate 0=Springfield\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Springfield', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Springfield', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Springfield', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=springfield, txt=Rob Golding drove to Springfield, Florida to be with his 89-year-old dad during #HurricaneMichael . His home was spared, but the area suffered damage, so they started taking in neighbors, going out to rescue friends, and organizing food for the community. <URL>\n",
      "txt=#BREAKING: President Trump approves Emergency Disaster Declaration for  the following Alabama counties: Dale, Geneva, Henry, and Houston #HurricaneMichael\n",
      "candidate 0=Alabama\n",
      "anchor NE candidates = \n",
      "candidate 1=Dale\n",
      "anchor NE candidates = Alabama,Geneva,Houston\n",
      "data NE tree=[['Dale', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Dale', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Henry', 'PROPN', 4, 'appos', 16]\n",
      "parent node subtree [['Dale', 'PROPN', 16, 'compound', 14], ['Geneva', 'PROPN', 16, 'compound', 15], ['and', 'CCONJ', 16, 'cc', 17], ['Houston', 'PROPN', 16, 'conj', 18]]\n",
      "candidate 2=Geneva\n",
      "anchor NE candidates = Alabama,Houston\n",
      "data NE tree=[['Geneva', 'PROPN', 16, 'compound', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Geneva', 'PROPN', 16, 'compound', 15]\n",
      "NE parent token:\n",
      "['Henry', 'PROPN', 4, 'appos', 16]\n",
      "parent node subtree [['Dale', 'PROPN', 16, 'compound', 14], ['Geneva', 'PROPN', 16, 'compound', 15], ['and', 'CCONJ', 16, 'cc', 17], ['Houston', 'PROPN', 16, 'conj', 18]]\n",
      "candidate 3=Houston\n",
      "anchor NE candidates = Alabama\n",
      "data NE tree=[['Houston', 'PROPN', 16, 'conj', 18]]\n",
      "NE parse token at tree=0, token=19:\n",
      "['Houston', 'PROPN', 16, 'conj', 18]\n",
      "NE parent token:\n",
      "['Henry', 'PROPN', 4, 'appos', 16]\n",
      "false positive with NE=dale, txt=#BREAKING: President Trump approves Emergency Disaster Declaration for  the following Alabama counties: Dale, Geneva, Henry, and Houston #HurricaneMichael\n",
      "txt=Heard you guys are bringing prepaid phones and charging stations. Please don’t do this on Panama City Beach. They have electricity and access to Destin. Come into Panama City, Callaway, Lynn Haven @TMobile @TMobileHelp #hurricanemichael\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Destin,Panama City,Callaway,Lynn Haven\n",
      "data NE tree=[['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['Beach', 'PROPN', 6, 'pobj', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Beach', 'PROPN', 6, 'pobj', 9]\n",
      "NE parent token:\n",
      "['on', 'ADP', 4, 'prep', 6]\n",
      "parent node subtree [['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['Beach', 'PROPN', 6, 'pobj', 9]]\n",
      "candidate 1=Destin\n",
      "anchor NE candidates = Panama City,Callaway,Lynn Haven\n",
      "data NE tree=[['Destin', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=2, token=7:\n",
      "['Destin', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['to', 'ADP', 2, 'prep', 5]\n",
      "parent node subtree [['Destin', 'PROPN', 5, 'pobj', 6]]\n",
      "candidate 2=Panama City\n",
      "anchor NE candidates = \n",
      "candidate 3=Callaway\n",
      "anchor NE candidates = Panama City,Lynn Haven\n",
      "data NE tree=[['Callaway', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=3, token=5:\n",
      "['Callaway', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['Haven', 'PROPN', 7, 'compound', 6]\n",
      "parent node subtree [['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4], ['Lynn', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 4=Lynn Haven\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Lynn', 'PROPN', 6, 'compound', 5], ['Haven', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=3, token=7:\n",
      "['Haven', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['@TMobile', 'PROPN', 1, 'pobj', 7]\n",
      "parent node subtree [['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4], ['Lynn', 'PROPN', 6, 'compound', 5], ['Haven', 'PROPN', 7, 'compound', 6]]\n",
      "NE=Lynn Haven subtree=[['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4]]\n",
      "min node deps ['compound']\n",
      "txt=Devastation in Mexico Beach, Florida from Hurricane #Michael . <URL>\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 4, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Beach', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 1, 'pobj', 4]\n",
      "parent node subtree [['Mexico', 'PROPN', 4, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=mexico_beach, txt=Devastation in Mexico Beach, Florida from Hurricane #Michael . <URL>\n",
      "txt=Vacasa office in Panama City Beach. Not too bad... property assessments are under way looks promising and positive so far #hurricanemichael @vacasarentals @RickyHaskins @ Panama City… <URL>\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Beach', 'PROPN', 2, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "parent node subtree [['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5]]\n",
      "candidate 1=Panama City\n",
      "anchor NE candidates = \n",
      "txt=#HurricaneMichael , current #SNAP households in Bay, Calhoun, Franklin, Gadsden, Gulf, Holmes, Jackson, Jefferson, Leon, Liberty, Wakulla, and Washington counties will receive replacement benefits at a 40% rate as early as 10/15/18 <URL>\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Calhoun,Franklin,Gadsden,Gulf,Jefferson,Washington\n",
      "data NE tree=[['Bay', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Bay', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['Calhoun', 'PROPN', 9, 'compound', 6]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=Calhoun\n",
      "anchor NE candidates = Franklin,Gadsden,Jefferson,Washington\n",
      "data NE tree=[['Calhoun', 'PROPN', 9, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Calhoun', 'PROPN', 9, 'compound', 6]\n",
      "NE parent token:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "NE=Calhoun subtree=[['Bay', 'PROPN', 6, 'compound', 5]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Franklin\n",
      "anchor NE candidates = Washington\n",
      "data NE tree=[['Franklin', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Franklin', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "candidate 3=Gadsden\n",
      "anchor NE candidates = Franklin,Washington\n",
      "data NE tree=[['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Gadsden', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "candidate 4=Gulf\n",
      "anchor NE candidates = Calhoun,Franklin,Gadsden,Jefferson,Washington\n",
      "data NE tree=[['Gulf', 'PROPN', 14, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "NE parent token:\n",
      "['Liberty', 'PROPN', 15, 'compound', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9], ['Holmes', 'PROPN', 14, 'compound', 10], ['Jackson', 'PROPN', 14, 'compound', 11], ['Jefferson', 'PROPN', 14, 'compound', 12], ['Leon', 'PROPN', 14, 'compound', 13]]\n",
      "NE=Gulf subtree=[['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 5=Jefferson\n",
      "anchor NE candidates = Franklin,Gadsden,Washington\n",
      "data NE tree=[['Jefferson', 'PROPN', 14, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Jefferson', 'PROPN', 14, 'compound', 12]\n",
      "NE parent token:\n",
      "['Liberty', 'PROPN', 15, 'compound', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9], ['Holmes', 'PROPN', 14, 'compound', 10], ['Jackson', 'PROPN', 14, 'compound', 11], ['Jefferson', 'PROPN', 14, 'compound', 12], ['Leon', 'PROPN', 14, 'compound', 13]]\n",
      "candidate 6=Washington\n",
      "anchor NE candidates = \n",
      "false positive with NE=bay, txt=#HurricaneMichael , current #SNAP households in Bay, Calhoun, Franklin, Gadsden, Gulf, Holmes, Jackson, Jefferson, Leon, Liberty, Wakulla, and Washington counties will receive replacement benefits at a 40% rate as early as 10/15/18 <URL>\n",
      "txt=At least 46 people remained unaccounted for on Sunday in Mexico Beach, Florida, an area pulverized by #HurricaneMichael 289 people, including 10 children, decided to stay put, despite evacuation orders, and ride out the Category 4 storm <URL>\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 12, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Mexico', 'PROPN', 12, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=mexico_beach, txt=At least 46 people remained unaccounted for on Sunday in Mexico Beach, Florida, an area pulverized by #HurricaneMichael 289 people, including 10 children, decided to stay put, despite evacuation orders, and ride out the Category 4 storm <URL>\n",
      "txt=President Trump in Florida to tour #HurricaneMichael damage in panhandle: <URL>\n",
      "candidate 0=Florida\n",
      "anchor NE candidates = \n",
      "candidate 1=panhandle\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['panhandle', 'NOUN', 8, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['panhandle', 'NOUN', 8, 'pobj', 9]\n",
      "NE parent token:\n",
      "['in', 'ADP', 7, 'prep', 8]\n",
      "parent node subtree [['panhandle', 'NOUN', 8, 'pobj', 9]]\n",
      "txt=Jackie, a #HurricaneMichael survivor in Panama City Beach, FL, is desperate to contact family and friends as cell service remains down following the storm: \"\"I hope you all are all okay...We're all okay.\"\" <URL>\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Panama', 'PROPN', 8, 'compound', 5], ['City', 'PROPN', 8, 'compound', 6], ['Beach', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Beach', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 4, 'pobj', 8]\n",
      "parent node subtree [['Panama', 'PROPN', 8, 'compound', 5], ['City', 'PROPN', 8, 'compound', 6], ['Beach', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=panama_city_beach, txt=Jackie, a #HurricaneMichael survivor in Panama City Beach, FL, is desperate to contact family and friends as cell service remains down following the storm: \"\"I hope you all are all okay...We're all okay.\"\" <URL>\n",
      "txt=I would like to give a great big thank you to @TMobile for having your emergency management truck here in Blountstown, FL and making it possible for us to have WiFi during the aftermath of #HurricaneMichael\n",
      "candidate 0=Blountstown\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Blountstown', 'PROPN', 21, 'compound', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Blountstown', 'PROPN', 21, 'compound', 20]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 19, 'pobj', 21]\n",
      "parent node subtree [['Blountstown', 'PROPN', 21, 'compound', 20]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=blountstown, txt=I would like to give a great big thank you to @TMobile for having your emergency management truck here in Blountstown, FL and making it possible for us to have WiFi during the aftermath of #HurricaneMichael\n",
      "txt=#HappyMonday - If you think your Monday's bad... be reminded by the pics from #HurricaneMichael that it can ALWAYS get worse. Listen, we are here in Panama City, FL at groundZero delivering supplies to those impacted... <URL>\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Panama', 'PROPN', 7, 'compound', 5], ['City', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['City', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['Panama', 'PROPN', 7, 'compound', 5], ['City', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=panama_city, txt=#HappyMonday - If you think your Monday's bad... be reminded by the pics from #HurricaneMichael that it can ALWAYS get worse. Listen, we are here in Panama City, FL at groundZero delivering supplies to those impacted... <URL>\n",
      "txt=The people ravaged by #HurricaneMichael in Panama City, Florida and Mexico Beach, Florida need our help. Let’s do this by donating to the American Red Cross.\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Florida,Florida\n",
      "data NE tree=[['Panama', 'PROPN', 7, 'compound', 6], ['City', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['City', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 5, 'pobj', 8]\n",
      "parent node subtree [['Panama', 'PROPN', 7, 'compound', 6], ['City', 'PROPN', 8, 'compound', 7], ['and', 'CCONJ', 8, 'cc', 9], ['Mexico', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11], ['Florida', 'PROPN', 8, 'conj', 12]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "candidate 2=Mexico Beach\n",
      "anchor NE candidates = Panama City,Florida,Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 8, 'conj', 12]\n",
      "parent node subtree [['Mexico', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11]]\n",
      "candidate 3=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=panama_city, txt=The people ravaged by #HurricaneMichael in Panama City, Florida and Mexico Beach, Florida need our help. Let’s do this by donating to the American Red Cross.\n",
      "txt=Day #2 of Hurricane #Michael Damage Surveys - Unbelievable tree damage. We surveyed spots in Southport, Youngstown, & Resota Beach (north of Lynn Haven & Panama City) where all trees were snapped, uprooted, or bent/twisted. Pictures do NOT do the damage justice at all... <URL>\n",
      "candidate 0=Southport\n",
      "anchor NE candidates = \n",
      "candidate 1=Youngstown\n",
      "anchor NE candidates = Southport\n",
      "data NE tree=[['Youngstown', 'PROPN', 3, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Youngstown', 'PROPN', 3, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "parent node subtree [['Southport', 'PROPN', 5, 'compound', 4], ['Youngstown', 'PROPN', 3, 'pobj', 5], ['&', 'CCONJ', 5, 'cc', 6], ['Resota', 'PROPN', 8, 'compound', 7], ['Beach', 'PROPN', 5, 'conj', 8], ['(', 'PUNCT', 5, 'punct', 9], ['north', 'NOUN', 5, 'advmod', 10], ['of', 'ADP', 10, 'prep', 11], ['Lynn', 'PROPN', 13, 'compound', 12], ['Haven', 'PROPN', 11, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16], [')', 'PUNCT', 5, 'punct', 17], ['where', 'ADV', 22, 'advmod', 18], ['all', 'DET', 20, 'det', 19], ['trees', 'NOUN', 22, 'nsubjpass', 20], ['were', 'VERB', 22, 'auxpass', 21], ['snapped', 'VERB', 5, 'relcl', 22], ['uprooted', 'VERB', 22, 'advcl', 23], ['or', 'CCONJ', 23, 'cc', 24], ['bent', 'ADJ', 27, 'amod', 25], ['/', 'SYM', 27, 'punct', 26], ['twisted', 'ADJ', 23, 'conj', 27]]\n",
      "NE=Youngstown subtree=[['Southport', 'PROPN', 5, 'compound', 4], ['&', 'CCONJ', 5, 'cc', 6], ['Resota', 'PROPN', 8, 'compound', 7], ['Beach', 'PROPN', 5, 'conj', 8], ['(', 'PUNCT', 5, 'punct', 9], ['north', 'NOUN', 5, 'advmod', 10], ['of', 'ADP', 10, 'prep', 11], ['Lynn', 'PROPN', 13, 'compound', 12], ['Haven', 'PROPN', 11, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16], [')', 'PUNCT', 5, 'punct', 17], ['where', 'ADV', 22, 'advmod', 18], ['all', 'DET', 20, 'det', 19], ['trees', 'NOUN', 22, 'nsubjpass', 20], ['were', 'VERB', 22, 'auxpass', 21], ['snapped', 'VERB', 5, 'relcl', 22], ['uprooted', 'VERB', 22, 'advcl', 23], ['or', 'CCONJ', 23, 'cc', 24], ['bent', 'ADJ', 27, 'amod', 25], ['/', 'SYM', 27, 'punct', 26], ['twisted', 'ADJ', 23, 'conj', 27]]\n",
      "min node deps ['compound', 'cc', 'conj', 'punct', 'advmod', 'punct', 'relcl']\n",
      "candidate 2=Resota Beach\n",
      "anchor NE candidates = Southport,Youngstown,Lynn Haven,Panama City\n",
      "data NE tree=[['Resota', 'PROPN', 8, 'compound', 7], ['Beach', 'PROPN', 5, 'conj', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['Beach', 'PROPN', 5, 'conj', 8]\n",
      "NE parent token:\n",
      "['Youngstown', 'PROPN', 3, 'pobj', 5]\n",
      "candidate 3=Lynn Haven\n",
      "anchor NE candidates = Southport,Youngstown,Panama City\n",
      "data NE tree=[['Lynn', 'PROPN', 13, 'compound', 12], ['Haven', 'PROPN', 11, 'pobj', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['Haven', 'PROPN', 11, 'pobj', 13]\n",
      "NE parent token:\n",
      "['of', 'ADP', 10, 'prep', 11]\n",
      "parent node subtree [['Lynn', 'PROPN', 13, 'compound', 12], ['Haven', 'PROPN', 11, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16]]\n",
      "NE=Lynn Haven subtree=[['&', 'CCONJ', 13, 'cc', 14], ['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 4=Panama City\n",
      "anchor NE candidates = Southport,Youngstown\n",
      "data NE tree=[['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16]]\n",
      "NE parse token at tree=1, token=17:\n",
      "['City', 'PROPN', 13, 'conj', 16]\n",
      "NE parent token:\n",
      "['Haven', 'PROPN', 11, 'pobj', 13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=#HurricaneMichael | Tide Loads of Hope is washing clothes for free from 9am-5pm at Walmart Supercenter (25 N Tyndall Pkwy, Callaway, FL 32404) #PanhandleStrong #PanamaCity <URL>\n",
      "candidate 0=Callaway\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Callaway', 'PROPN', 22, 'compound', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Callaway', 'PROPN', 22, 'compound', 21]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 15, 'appos', 22]\n",
      "parent node subtree [['25', 'NUM', 22, 'nummod', 17], ['N', 'NOUN', 22, 'compound', 18], ['Tyndall', 'PROPN', 22, 'compound', 19], ['Pkwy', 'PROPN', 22, 'compound', 20], ['Callaway', 'PROPN', 22, 'compound', 21], ['32404', 'NUM', 22, 'nummod', 23]]\n",
      "candidate 1=FL\n",
      "anchor NE candidates = \n",
      "false positive with NE=callaway, txt=#HurricaneMichael | Tide Loads of Hope is washing clothes for free from 9am-5pm at Walmart Supercenter (25 N Tyndall Pkwy, Callaway, FL 32404) #PanhandleStrong #PanamaCity <URL>\n",
      "txt=Check out Calhoun (98% out), Gulf (86%), Jackson (83%), Liberty (71%), and Bay (56%). Then donate some money or critical supplies & lend a hand. #FloridaStrong #HurricaneMichael #beagoodneighbor <URL>\n",
      "candidate 0=Calhoun\n",
      "anchor NE candidates = Liberty\n",
      "data NE tree=[['Calhoun', 'PROPN', 0, 'dobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Calhoun', 'PROPN', 0, 'dobj', 2]\n",
      "NE parent token:\n",
      "['Check', 'VERB', 0, 'ROOT', 0]\n",
      "NE=Calhoun subtree=[['(', 'PUNCT', 2, 'punct', 3], ['98', 'NUM', 5, 'nummod', 4], ['%', 'NOUN', 2, 'appos', 5], ['out', 'PART', 5, 'prt', 6], [')', 'PUNCT', 2, 'punct', 7]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( 98 % out )\n",
      "candidate 1=Gulf\n",
      "anchor NE candidates = Calhoun,Liberty\n",
      "data NE tree=[['Gulf', 'PROPN', 8, 'ROOT', 8]]\n",
      "NE=Gulf subtree=[['(8', 'PROPN', 8, 'punct', 9], ['6', 'NUM', 11, 'nummod', 10], ['%', 'NOUN', 8, 'appos', 11], [')', 'PUNCT', 8, 'punct', 12]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = (8 6 % )\n",
      "candidate 2=Liberty\n",
      "anchor NE candidates = \n",
      "candidate 3=Bay\n",
      "anchor NE candidates = Calhoun,Gulf,Liberty\n",
      "data NE tree=[['Bay', 'PROPN', 18, 'conj', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Bay', 'PROPN', 18, 'conj', 24]\n",
      "NE parent token:\n",
      "['Liberty', 'PROPN', 18, 'ROOT', 18]\n",
      "NE=Bay subtree=[['(', 'PUNCT', 24, 'punct', 25], ['56', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], [')', 'PUNCT', 24, 'punct', 28]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( 56 % )\n",
      "txt=Beach Surveys have been completed in Bay, Escambia, Franklin, Okaloosa, Santa Rosa and Gulf counties. #HurricaneMichael\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Santa Rosa,Gulf\n",
      "data NE tree=[['Bay', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Bay', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['Escambia', 'PROPN', 9, 'compound', 7]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 1=Okaloosa\n",
      "anchor NE candidates = Bay,Santa Rosa,Gulf\n",
      "data NE tree=[['Okaloosa', 'PROPN', 5, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Okaloosa', 'PROPN', 5, 'pobj', 9]\n",
      "NE parent token:\n",
      "['in', 'ADP', 4, 'prep', 5]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 6], ['Escambia', 'PROPN', 9, 'compound', 7], ['Franklin', 'PROPN', 9, 'compound', 8], ['Okaloosa', 'PROPN', 5, 'pobj', 9], ['Santa', 'PROPN', 11, 'compound', 10], ['Rosa', 'PROPN', 9, 'appos', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 14, 'compound', 13], ['counties', 'NOUN', 11, 'conj', 14]]\n",
      "NE=Okaloosa subtree=[['Bay', 'PROPN', 7, 'compound', 6], ['Escambia', 'PROPN', 9, 'compound', 7], ['Franklin', 'PROPN', 9, 'compound', 8], ['Santa', 'PROPN', 11, 'compound', 10], ['Rosa', 'PROPN', 9, 'appos', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 14, 'compound', 13], ['counties', 'NOUN', 11, 'conj', 14]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Santa Rosa\n",
      "anchor NE candidates = \n",
      "candidate 3=Gulf\n",
      "anchor NE candidates = Santa Rosa\n",
      "data NE tree=[['Gulf', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Gulf', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 11, 'conj', 14]\n",
      "parent node subtree [['Gulf', 'PROPN', 14, 'compound', 13]]\n",
      "txt=AMR Leaders were able to visit crews today in Panama City, Florida as the crews were coming and going from missions. Crews are all pretty upbeat and so glad to be able to be in the area to help people! #HurricaneMichael <URL>\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Panama', 'PROPN', 10, 'compound', 9], ['City', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['City', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 8, 'pobj', 11]\n",
      "parent node subtree [['Panama', 'PROPN', 10, 'compound', 9], ['City', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=panama_city, txt=AMR Leaders were able to visit crews today in Panama City, Florida as the crews were coming and going from missions. Crews are all pretty upbeat and so glad to be able to be in the area to help people! #HurricaneMichael <URL>\n",
      "txt=Clean Water is on the way to Sneads, Florida! Want to help us deliver more water to victims of #HurricaneMichael ? Visit our website to make a donation! USA: <URL>\n",
      "candidate 0=Sneads\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Sneads', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Sneads', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Sneads', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=sneads, txt=Clean Water is on the way to Sneads, Florida! Want to help us deliver more water to victims of #HurricaneMichael ? Visit our website to make a donation! USA: <URL>\n",
      "txt=One Week After #Michael County By County #FLwx Power Outage Update: Calhoun: 97% Jackson: 81% Liberty: 67% Gulf: 58% Bay/Gadsden: 52% Washington: 18% Holmes: 17%\n",
      "candidate 0=Calhoun\n",
      "anchor NE candidates = Jackson,Liberty,Gadsden\n",
      "data NE tree=[['Calhoun', 'PROPN', 10, 'appos', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Calhoun', 'PROPN', 10, 'appos', 12]\n",
      "NE parent token:\n",
      "['Update', 'PROPN', 10, 'ROOT', 10]\n",
      "NE=Calhoun subtree=[[':', 'PUNCT', 12, 'punct', 13], ['97', 'NUM', 15, 'nummod', 14], ['%', 'NOUN', 16, 'compound', 15], ['Jackson', 'PROPN', 12, 'appos', 16], [':', 'PUNCT', 16, 'punct', 17], ['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['Liberty', 'PROPN', 19, 'appos', 20], [':', 'PUNCT', 16, 'punct', 21]]\n",
      "min node deps ['punct', 'appos']\n",
      "subtree = : 97 % Jackson : 81 % Liberty :\n",
      "candidate 1=Jackson\n",
      "anchor NE candidates = \n",
      "candidate 2=Liberty\n",
      "anchor NE candidates = Jackson\n",
      "data NE tree=[['Liberty', 'PROPN', 19, 'appos', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Liberty', 'PROPN', 19, 'appos', 20]\n",
      "NE parent token:\n",
      "['%', 'NOUN', 16, 'appos', 19]\n",
      "candidate 3=Bay\n",
      "anchor NE candidates = Calhoun,Jackson,Liberty,Gadsden\n",
      "data NE tree=[['Bay', 'PROPN', 30, 'nmod', 28]]\n",
      "NE parse token at tree=0, token=29:\n",
      "['Bay', 'PROPN', 30, 'nmod', 28]\n",
      "NE parent token:\n",
      "['Gadsden', 'PROPN', 27, 'appos', 30]\n",
      "parent node subtree [['Bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29]]\n",
      "candidate 4=Gadsden\n",
      "anchor NE candidates = Jackson,Liberty\n",
      "data NE tree=[['Gadsden', 'PROPN', 27, 'appos', 30]]\n",
      "NE parse token at tree=0, token=31:\n",
      "['Gadsden', 'PROPN', 27, 'appos', 30]\n",
      "NE parent token:\n",
      "['%', 'NOUN', 24, 'appos', 27]\n",
      "NE=Gadsden subtree=[['Bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29]]\n",
      "min node deps ['nmod', 'punct']\n",
      "txt=Want to see the real #AHSApocalypse ? Come down here to Mexico beach or Panama City, FL! #HurricaneMichael #hurricanemichael2018 @CNN @weatherchannel\n",
      "candidate 0=Mexico beach\n",
      "anchor NE candidates = Panama City,FL\n",
      "data NE tree=[['Mexico', 'PROPN', 5, 'compound', 4], ['beach', 'NOUN', 3, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['beach', 'NOUN', 3, 'pobj', 5]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 3]\n",
      "parent node subtree [['Mexico', 'PROPN', 5, 'compound', 4], ['beach', 'NOUN', 3, 'pobj', 5], ['or', 'CCONJ', 5, 'cc', 6], ['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['FL', 'PROPN', 5, 'conj', 9]]\n",
      "NE=Mexico beach subtree=[['or', 'CCONJ', 5, 'cc', 6], ['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['FL', 'PROPN', 5, 'conj', 9]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Panama City\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['City', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 5, 'conj', 9]\n",
      "parent node subtree [['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8]]\n",
      "candidate 2=FL\n",
      "anchor NE candidates = \n",
      "txt=Orange County Utilities’ Water Reclamation and Field Services team members are helping restore sewer systems impacted by #HurricaneMichael in Tallahassee and Panama City. We are proud to support our neighbors, just as they did, following past storms that affected Central Florida. <URL>\n",
      "candidate 0=Orange County\n",
      "anchor NE candidates = \n",
      "candidate 1=Tallahassee\n",
      "anchor NE candidates = Orange County\n",
      "data NE tree=[['Tallahassee', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Tallahassee', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['in', 'ADP', 16, 'prep', 19]\n",
      "parent node subtree [['Tallahassee', 'PROPN', 19, 'pobj', 20], ['and', 'CCONJ', 20, 'cc', 21], ['Panama', 'PROPN', 23, 'compound', 22], ['City', 'PROPN', 20, 'conj', 23]]\n",
      "NE=Tallahassee subtree=[['and', 'CCONJ', 20, 'cc', 21], ['Panama', 'PROPN', 23, 'compound', 22], ['City', 'PROPN', 20, 'conj', 23]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 2=Panama City\n",
      "anchor NE candidates = Orange County,Tallahassee\n",
      "data NE tree=[['Panama', 'PROPN', 23, 'compound', 22], ['City', 'PROPN', 20, 'conj', 23]]\n",
      "NE parse token at tree=0, token=24:\n",
      "['City', 'PROPN', 20, 'conj', 23]\n",
      "NE parent token:\n",
      "['Tallahassee', 'PROPN', 19, 'pobj', 20]\n",
      "txt=@verizon is offering 3 free months of service to customers in Bay and Gulf counties in FL supporting people affected by #HurricaneMichael . Good stuff! Any chance you will extend that offer to those of us in the National Guard who have been here since day 1 with no cell signal?\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Gulf,FL\n",
      "data NE tree=[['Bay', 'PROPN', 14, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Bay', 'PROPN', 14, 'nmod', 11]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 10, 'pobj', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 11, 'conj', 13], ['in', 'ADP', 14, 'prep', 15], ['FL', 'PROPN', 15, 'pobj', 16]]\n",
      "NE=Bay subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 11, 'conj', 13]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Gulf\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Gulf', 'PROPN', 11, 'conj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Gulf', 'PROPN', 11, 'conj', 13]\n",
      "NE parent token:\n",
      "['Bay', 'PROPN', 14, 'nmod', 11]\n",
      "candidate 2=FL\n",
      "anchor NE candidates = \n",
      "txt=Reminders from #hurricanemichael . Posted orignally by \"\"The Most Excellent Way\"\" of Panama City, Fl. \"\"And we know that for those who love God all things work together for good, for those… <URL>\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Fl\n",
      "data NE tree=[['Panama', 'PROPN', 14, 'compound', 12], ['City', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['City', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['Fl', 'PROPN', 11, 'pobj', 14]\n",
      "parent node subtree [['Panama', 'PROPN', 14, 'compound', 12], ['City', 'PROPN', 14, 'compound', 13]]\n",
      "candidate 1=Fl\n",
      "anchor NE candidates = \n",
      "false positive with NE=panama_city, txt=Reminders from #hurricanemichael . Posted orignally by \"\"The Most Excellent Way\"\" of Panama City, Fl. \"\"And we know that for those who love God all things work together for good, for those… <URL>\n",
      "txt=One home in Mexico Beach, Florida, appeared largely untouched amid the incredible destruction of #HurricaneMichael . And its owners, Lebron Lackey and his uncle, Russell King, say it's no… <URL>\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 4, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Beach', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Mexico', 'PROPN', 4, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 1=Florida\n",
      "anchor NE candidates = \n",
      "false positive with NE=mexico_beach, txt=One home in Mexico Beach, Florida, appeared largely untouched amid the incredible destruction of #HurricaneMichael . And its owners, Lebron Lackey and his uncle, Russell King, say it's no… <URL>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Hey guys... PLEASE come to Panama City, Fl. We need some laughs after #HurricaneMichael The beach didn't get hit bad at all. There are many venues. Club La Vila is a huge one. We'd love to see ya'll. Please consider it.\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Fl\n",
      "data NE tree=[['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['City', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Fl', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 1=Fl\n",
      "anchor NE candidates = \n",
      "false positive with NE=panama_city, txt=Hey guys... PLEASE come to Panama City, Fl. We need some laughs after #HurricaneMichael The beach didn't get hit bad at all. There are many venues. Club La Vila is a huge one. We'd love to see ya'll. Please consider it.\n",
      "txt=This afternoon, state and federal partners held a call to coordinate housing solutions in areas impacted by #HurricaneMichael . Thanks to Franklin County, Liberty County and Washington County for joining us on the call. em2franklin LibertyCoFLEM <URL>\n",
      "candidate 0=Franklin County\n",
      "anchor NE candidates = Washington County\n",
      "data NE tree=[['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['County', 'PROPN', 5, 'compound', 3]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 1, 'pobj', 5]\n",
      "parent node subtree [['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['Liberty', 'PROPN', 5, 'compound', 4], ['and', 'CCONJ', 5, 'cc', 6], ['Washington', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 5, 'conj', 8]]\n",
      "candidate 1=Liberty County\n",
      "anchor NE candidates = Franklin County,Washington County\n",
      "data NE tree=[['Liberty', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 1, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['County', 'PROPN', 1, 'pobj', 5]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "parent node subtree [['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['Liberty', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 1, 'pobj', 5], ['and', 'CCONJ', 5, 'cc', 6], ['Washington', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 5, 'conj', 8]]\n",
      "NE=Liberty County subtree=[['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['and', 'CCONJ', 5, 'cc', 6], ['Washington', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 5, 'conj', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Washington County\n",
      "anchor NE candidates = \n",
      "false positive with NE=franklin_county, txt=This afternoon, state and federal partners held a call to coordinate housing solutions in areas impacted by #HurricaneMichael . Thanks to Franklin County, Liberty County and Washington County for joining us on the call. em2franklin LibertyCoFLEM <URL>\n",
      "txt=Unless you live in Bay, Gulf, Jackson, Calhoun and Gadsden counties. #850Strong #FloridaStrong #HurricaneMichael\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Gulf,Calhoun,Gadsden\n",
      "data NE tree=[['Bay', 'PROPN', 7, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Bay', 'PROPN', 7, 'compound', 4]\n",
      "NE parent token:\n",
      "['Calhoun', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "candidate 1=Gulf\n",
      "anchor NE candidates = Calhoun,Gadsden\n",
      "data NE tree=[['Gulf', 'PROPN', 7, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Gulf', 'PROPN', 7, 'compound', 5]\n",
      "NE parent token:\n",
      "['Calhoun', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "candidate 2=Calhoun\n",
      "anchor NE candidates = Gadsden\n",
      "data NE tree=[['Calhoun', 'PROPN', 3, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Calhoun', 'PROPN', 3, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['Calhoun', 'PROPN', 3, 'pobj', 7], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "NE=Calhoun subtree=[['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "min node deps ['compound', 'compound', 'compound', 'cc', 'conj']\n",
      "candidate 3=Gadsden\n",
      "anchor NE candidates = \n",
      "false positive with NE=bay, txt=Unless you live in Bay, Gulf, Jackson, Calhoun and Gadsden counties. #850Strong #FloridaStrong #HurricaneMichael\n"
     ]
    }
   ],
   "source": [
    "for idx_i, annotated_data_i in annotated_anchor_data.iterrows():\n",
    "    annotated_NE_i = annotated_data_i.loc['NE']\n",
    "    txt_i = annotated_data_i.loc['txt']\n",
    "    data_i = anchor_data[anchor_data.loc[:, 'txt']==txt_i]\n",
    "    data_NE_i = data_i.loc[:, 'NE_fixed'].values\n",
    "    # restrict to data where NE only occurs once per status\n",
    "    if(len([x for x in data_NE_i if x.replace(' ', '_').lower()==annotated_NE_i]) == 1):\n",
    "        print('txt=%s'%(txt_i))\n",
    "        parent_subclause_anchor_i, subclause_anchor_i = detect_subclause_anchor(data_i, verbose=True)\n",
    "        parent_subclause_anchor_i.index = [x.replace(' ','_').lower() for x in parent_subclause_anchor_i.index]\n",
    "        if(parent_subclause_anchor_i.loc[annotated_NE_i] - annotated_data_i.loc['context_subclause'] == 1):\n",
    "            print('false positive with NE=%s, txt=%s'%(annotated_NE_i, txt_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! Based on manual inspection it looks like we need to capture the following categories:\n",
    "\n",
    "- (child) child_dep=noun-modifier/preposition/apposition + LOC (\"Guaynabo - one of the wealthiest towns in Puerto Rico\")\n",
    "- (child) child=conj + STATE (\"Port Aransas and Port O'Conner, TX\")\n",
    "- (parent) NE_dep=compound/nmod + STATE (\"Mayfair neighborhood of Lumberton, NC\")\n",
    "\n",
    "Let's re-write the detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "STATES_SHORT_FULL_LOOKUP = {\n",
    "    'FL' : 'Florida', 'NC' : 'North Carolina', 'SC' : 'South Carolina', \n",
    "    'VA' : 'Virginia', 'GA' : 'Georgia', 'PR' : 'Puerto Rico',\n",
    "    'LA' : 'Louisiana', 'TX' : 'Texas',\n",
    "}\n",
    "DATA_NAME_STATES_SHORT_LOOKUP = {\n",
    "    'florence' : ['FL', 'NC', 'SC', 'VA', 'GA'],\n",
    "    'irma' : ['FL', 'GA', 'SC'],\n",
    "    'harvey' : ['TX', 'LA'],\n",
    "    'maria' : ['PR', 'NC'],\n",
    "    'michael' : ['FL', 'GA', 'NC', 'SC']\n",
    "}\n",
    "DATA_NAME_STATES_LONG_LOOKUP = {k : [STATES_SHORT_FULL_LOOKUP[v] for v in vs] for k, vs in DATA_NAME_STATES_SHORT_LOOKUP.items()}\n",
    "DATA_NAME_STATES_LOOKUP = {k : DATA_NAME_STATES_SHORT_LOOKUP[k]+DATA_NAME_STATES_LONG_LOOKUP[k] for k in DATA_NAME_STATES_SHORT_LOOKUP.keys()}\n",
    "DATA_NAME_STATES_MATCHERS = {k : re.compile('|'.join([' %s |^%s | %s$|^%s$'%((v1.lower(),)*4) for v1 in v])) for k,v in DATA_NAME_STATES_LOOKUP.items()}\n",
    "from data_helpers import extract_NE_subtree, extract_full_tree\n",
    "def detect_subclause_anchor_parents_children(data, valid_var='valid_loc', \n",
    "                                             anchor_var='max_population', NE_var='NE', \n",
    "                                             data_name_var='data_name_fixed',\n",
    "                                             child_dep_types=['acl', 'appos', 'prep', 'nummod'],\n",
    "                                             parent_dep_types=['nmod', 'compound'],\n",
    "                                             verbose=False):\n",
    "    data_NEs = data.loc[:, NE_var].values\n",
    "    # fix format to match parse\n",
    "    data_NEs = [x.replace('_', ' ') for x in data_NEs]\n",
    "    data_valid = data.loc[:, valid_var].values\n",
    "    data_NEs_valid = [x for x,y in zip(data_NEs, data_valid) if y==1]\n",
    "    data_anchor_vals = data.loc[:, anchor_var].values\n",
    "    parent_subclause_anchor = []\n",
    "    subclause_anchor = []\n",
    "    trees = data.loc[:, 'parse'].iloc[0]\n",
    "    tree_graphs = [extract_full_tree(t) for t in trees]\n",
    "    tree_ctr = 0\n",
    "    tree_token_ctr = 0\n",
    "    data_name = data.loc[:, data_name_var].iloc[0]\n",
    "    state_matcher = DATA_NAME_STATES_MATCHERS[data_name]\n",
    "    for i, data_NE in enumerate(data_NEs_valid):\n",
    "        if(verbose):\n",
    "            print('candidate %d=%s'%(i, data_NE))\n",
    "        anchor_val_i = data_anchor_vals[i]\n",
    "        anchor_NE_candidates = [x for x,y in zip(data_NEs, data_anchor_vals) if y > anchor_val_i]\n",
    "        if(verbose):\n",
    "            print('anchor NE candidates = %s'%(','.join(anchor_NE_candidates)))\n",
    "        parent_subclause_anchor_i = 0\n",
    "        subclause_anchor_i = 0\n",
    "        if(len(anchor_NE_candidates) > 0):\n",
    "            \n",
    "            # add whitespace to candidates to avoid matching substrings e.g. \"FL\" doesn't match \"FLOW\"\n",
    "            anchor_NE_candidate_matcher = re.compile('|'.join([' %s |^%s | %s$'%(x,x,x) for x in anchor_NE_candidates]))\n",
    "            data_NE_tree, data_NE_subtree, tree_ctr, tree_token_ctr = extract_NE_subtree(data_NE, trees, tree_graphs, tree_ctr, tree_token_ctr)\n",
    "            \n",
    "            ## parent test: test if sibling contains state\n",
    "            if(len(data_NE_tree) > 0):\n",
    "                if(verbose):\n",
    "                    print('data NE tree=%s'%(str(data_NE_tree)))\n",
    "                # find parent node for noun, preposition tests\n",
    "                # parent node => index that is not included in NE indices\n",
    "                data_NE_tree_idx = [x[4] for x in data_NE_tree]\n",
    "                NE_child_nodes = [x for x in data_NE_tree if x[2] not in data_NE_tree_idx]\n",
    "                if(len(NE_child_nodes) > 0):\n",
    "                    highest_child_node = NE_child_nodes[0]\n",
    "                    parent_node_idx = highest_child_node[2]\n",
    "                    parent_node_dep = highest_child_node[3]\n",
    "                    parent_node = trees[tree_ctr][parent_node_idx]\n",
    "                    if(verbose):\n",
    "                        print('NE parse token at tree=%d, token=%d:'%(tree_ctr, tree_token_ctr))\n",
    "                        print(str(trees[tree_ctr][tree_token_ctr-1]))\n",
    "                        print('NE parent token:')\n",
    "                        print(str(parent_node))\n",
    "                    # if parent is connected by valid dep, find children and look for state mention\n",
    "                    if(parent_node_dep in parent_dep_types):\n",
    "                        parent_node_subtree_idx = get_subtree(parent_node[4], tree_graphs[tree_ctr])\n",
    "                        parent_node_subtree = [x for x in trees[tree_ctr] if x[4] in parent_node_subtree_idx]\n",
    "                        if(verbose):\n",
    "                            print('parent node subtree %s'%(str(parent_node_subtree)))\n",
    "                        parent_node_subtree_str = ' '.join([x[0] for x in parent_node_subtree]).lower()\n",
    "#                         if(verbose):\n",
    "#                             print('matching states %s on tree %s'%(state_matcher.pattern, parent_node_subtree_str.lower()))\n",
    "                        parent_subclause_anchor_i = int(state_matcher.search(parent_node_subtree_str) is not None)\n",
    "#                         parent_subclause_anchor_i = int(anchor_NE_candidate_matcher.search(parent_node_subtree_str) is not None)\n",
    "                    # special case: if parent node string matches candidate\n",
    "                    # then we count it as anchor e.g. \"CITY, STATE\" pattern\n",
    "#                     if(parent_node[0] in anchor_NE_candidates):\n",
    "#                         parent_subclause_anchor_i = 1\n",
    "            \n",
    "            ## child test: test if child contains anchor\n",
    "            if(len(data_NE_subtree) > 0):\n",
    "                if(verbose):\n",
    "                    print('NE=%s subtree=%s'%(data_NE, str(data_NE_subtree)))\n",
    "                ## filter for allowed dependency trees\n",
    "                ## find dep type for highest node (lowest parent index) in subtree\n",
    "                min_node_dep_idx = min(data_NE_subtree, key=lambda x: x[2])\n",
    "                min_node_deps = [x[3] for x in data_NE_subtree if x[2]==min_node_dep_idx[2]]\n",
    "                if(verbose):\n",
    "                    print('min node deps %s'%(str(min_node_deps)))\n",
    "                subtree_str = ' '.join([x[0] for x in data_NE_subtree])\n",
    "                if(len(set(min_node_deps) & set(child_dep_types)) > 0):\n",
    "                    ## look for NE in phrase\n",
    "                    if(verbose):\n",
    "                        print('subtree = %s'%(subtree_str))\n",
    "                    subclause_anchor_i = int(anchor_NE_candidate_matcher.search(subtree_str) is not None)\n",
    "                    ## conjuction is a special case: anchor NE must occur \n",
    "                    ## in format NE CONJ NE, state\n",
    "                elif('conj' in min_node_deps):\n",
    "                    subclause_anchor_i = int(state_matcher.search(subtree_str.lower()) is not None)\n",
    "        parent_subclause_anchor.append(parent_subclause_anchor_i)\n",
    "        subclause_anchor.append(subclause_anchor_i)\n",
    "    parent_subclause_anchor = pd.Series(parent_subclause_anchor, index=data_NEs_valid)\n",
    "    subclause_anchor = pd.Series(subclause_anchor, index=data_NEs_valid)\n",
    "    return parent_subclause_anchor, subclause_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/20 anchors detected with subclause results; recall=0.500\n",
      "5/20 anchors detected with parent subclause results; recall=0.250\n",
      "15/20 anchors detected with combined results; recall=0.750\n",
      "subclause precision=0.942\n",
      "parent subclause precision=0.905\n",
      "combined precision=0.930\n"
     ]
    }
   ],
   "source": [
    "## load annotated\n",
    "annotated_anchor_data = pd.read_csv('../../data/mined_tweets/combined_tweet_tag_data_NE_flat_anchor_examples.tsv', sep='\\t', index_col=False)\n",
    "annotated_anchor_NEs = annotated_anchor_data[annotated_anchor_data.loc[:, 'context_subclause']==1].loc[:, 'NE']\n",
    "annotated_anchor_txt = annotated_anchor_data[annotated_anchor_data.loc[:, 'context_subclause']==1].loc[:, 'txt']\n",
    "## track all types of anchors\n",
    "subclause_anchor = []\n",
    "subclause_parent_anchor = []\n",
    "subclause_combined_anchor = []\n",
    "for annotated_anchor_NE_i, txt_i in zip(annotated_anchor_NEs, annotated_anchor_txt.values):\n",
    "    data_i = anchor_data[anchor_data.loc[:, 'txt']==txt_i]\n",
    "    id_i = data_i.loc[:, 'id'].iloc[0]\n",
    "    NE_i = data_i.loc[:, 'NE_fixed'].values\n",
    "#     print('id=%d; NE=%s'%(id_i, ','.join(NE_i)))\n",
    "#     print('txt=%s'%(txt_i))\n",
    "    ## goal: get parse data, extract the subclause, determine if anchoring NE exists\n",
    "    parse_i = data_i.loc[:, 'parse'].iloc[0]\n",
    "#     print('parse=%s'%(str(parse_i)))\n",
    "    parent_subclause_anchor_i, subclause_anchor_i = detect_subclause_anchor_parents_children(data_i, verbose=False)\n",
    "    parent_subclause_anchor_i.index = [x.replace(' ','_').lower() for x in parent_subclause_anchor_i.index]\n",
    "    subclause_anchor_i.index = [x.replace(' ','_').lower() for x in subclause_anchor_i.index]\n",
    "    anchor_final_i = pd.concat([parent_subclause_anchor_i, subclause_anchor_i], axis=1).max(axis=1)\n",
    "#     print('NE=%s, subclause_anchor=%d, parent_subclause_anchor=%d'%\n",
    "#           (annotated_anchor_NE_i, \n",
    "#            subclause_anchor_i.loc[annotated_anchor_NE_i],\n",
    "#            parent_subclause_anchor_i.loc[annotated_anchor_NE_i]))\n",
    "#     print('parent subclause anchors = \\n%s'%(str(parent_subclause_anchor_i)))\n",
    "#     print('subclause anchors = \\n%s'%(str(subclause_anchor_i)))\n",
    "    # combine parent/subclause results\n",
    "#     anchor_final_i = pd.concat([parent_subclause_anchor_i, subclause_anchor_i], axis=1).max(axis=1)\n",
    "    # fix index to match annotated format\n",
    "#     anchor_final_i.index = [x.replace(' ','_').lower() for x in anchor_final_i.index]\n",
    "    subclause_anchor.append(subclause_anchor_i.loc[annotated_anchor_NE_i])\n",
    "    subclause_parent_anchor.append(parent_subclause_anchor_i.loc[annotated_anchor_NE_i])\n",
    "    subclause_combined_anchor.append(anchor_final_i.loc[annotated_anchor_NE_i])\n",
    "\n",
    "print('%d/%d anchors detected with subclause results; recall=%.3f'%(sum(subclause_anchor), len(subclause_combined_anchor), sum(subclause_anchor) / len(subclause_combined_anchor)))\n",
    "print('%d/%d anchors detected with parent subclause results; recall=%.3f'%(sum(subclause_parent_anchor), len(subclause_combined_anchor), sum(subclause_parent_anchor) / len(subclause_combined_anchor)))\n",
    "print('%d/%d anchors detected with combined results; recall=%.3f'%(sum(subclause_combined_anchor), len(subclause_combined_anchor), sum(subclause_combined_anchor) / len(subclause_combined_anchor)))\n",
    "\n",
    "## compute precision over all annotated data\n",
    "subclause_anchor_estimate = []\n",
    "parent_subclause_anchor_estimate = []\n",
    "subclause_combined_anchor_estimate = []\n",
    "subclause_anchor_gold = []\n",
    "for idx_i, annotated_data_i in annotated_anchor_data.iterrows():\n",
    "    annotated_NE_i = annotated_data_i.loc['NE']\n",
    "#     print('NE=%s'%(annotated_NE_i))\n",
    "    txt_i = annotated_data_i.loc['txt']\n",
    "    data_i = anchor_data[anchor_data.loc[:, 'txt']==txt_i]\n",
    "    data_NE_i = data_i.loc[:, 'NE_fixed'].values\n",
    "    # restrict to data where NE only occurs once per status\n",
    "    if(len([x for x in data_NE_i if x.replace(' ', '_').lower()==annotated_NE_i]) == 1):\n",
    "        parent_subclause_anchor_i, subclause_anchor_i = detect_subclause_anchor_parents_children(data_i, verbose=False)\n",
    "        parent_subclause_anchor_i.index = [x.replace(' ','_').lower() for x in parent_subclause_anchor_i.index]\n",
    "        subclause_anchor_i.index = [x.replace(' ','_').lower() for x in subclause_anchor_i.index]\n",
    "        anchor_final_i = pd.concat([parent_subclause_anchor_i, subclause_anchor_i], axis=1).max(axis=1)\n",
    "        parent_subclause_anchor_estimate.append(parent_subclause_anchor_i.loc[annotated_NE_i])\n",
    "        subclause_anchor_estimate.append(subclause_anchor_i.loc[annotated_NE_i])\n",
    "        subclause_combined_anchor_estimate.append(anchor_final_i.loc[annotated_NE_i])\n",
    "        subclause_anchor_gold.append(annotated_data_i.loc['context_subclause'])\n",
    "subclause_anchor_estimate = np.array(subclause_anchor_estimate)\n",
    "parent_subclause_anchor_estimate = np.array(parent_subclause_anchor_estimate)\n",
    "subclause_combined_anchor_estimate = np.array(subclause_combined_anchor_estimate)\n",
    "subclause_anchor_gold = np.array(subclause_anchor_gold)\n",
    "# TP = annotated_anchor_data.loc[:, 'context_subclause'].values && subclause_anchor_full\n",
    "sub_prec = 1 - abs(subclause_anchor_gold - subclause_anchor_estimate).sum() / len(subclause_anchor_gold)\n",
    "parent_prec = 1 - abs(subclause_anchor_gold - parent_subclause_anchor_estimate).sum() / len(subclause_anchor_gold)\n",
    "prec = 1 - abs(subclause_anchor_gold - subclause_combined_anchor_estimate).sum() / len(subclause_anchor_gold)\n",
    "print('subclause precision=%.3f'%(sub_prec))\n",
    "print('parent subclause precision=%.3f'%(parent_prec))\n",
    "print('combined precision=%.3f'%(prec))\n",
    "# anchor_data_i = anchor_data[anchor_data.loc[:, 'id']==id_i]\n",
    "# display(anchor_data_i.head())\n",
    "# display(anchor_data_i.loc[:, 'txt'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=RT @EdValleeWx: Our models specifically used for forecasting hurricanes have great agreement in #Florence making landfall near New Bern, NC…\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['New', 'PROPN', 20, 'compound', 18], ['Bern', 'PROPN', 20, 'compound', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Bern', 'PROPN', 20, 'compound', 19]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 17, 'pobj', 20]\n",
      "parent node subtree [['New', 'PROPN', 20, 'compound', 18], ['Bern', 'PROPN', 20, 'compound', 19]]\n",
      "txt=RT @WMO: Hurricane #Florence is likely to make landfall near Wilmington (North Carolina) . The tidal data shows a sea level rise of around…\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Wilmington', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Wilmington', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['near', 'ADP', 9, 'prep', 10]\n",
      "NE=Wilmington subtree=[['(', 'PUNCT', 11, 'punct', 12], ['North', 'PROPN', 14, 'compound', 13], ['Carolina', 'PROPN', 11, 'appos', 14], [')', 'PUNCT', 11, 'punct', 15]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( North Carolina )\n",
      "txt=RT @ABC: LATEST: Hurricane #Florence a Category 4 storm 670 miles ESE of Cape Fear, North Carolina, with maximum sustained winds of 140 mph…\n",
      "candidate 0=Cape Fear\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Cape', 'PROPN', 16, 'compound', 15], ['Fear', 'PROPN', 18, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Fear', 'PROPN', 18, 'compound', 16]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 14, 'pobj', 18]\n",
      "parent node subtree [['Cape', 'PROPN', 16, 'compound', 15], ['Fear', 'PROPN', 18, 'compound', 16], ['North', 'PROPN', 18, 'compound', 17]]\n",
      "txt=You put your lips on them cigars more than you do on me\" GF says. #cigar #lastselfie #sotl #botl #hurricaneflorence @ Fayetteville, North Carolina <URL>\n",
      "candidate 0=Fayetteville\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Fayetteville', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['Fayetteville', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 8, 'ROOT', 8]\n",
      "parent node subtree [['Fayetteville', 'PROPN', 8, 'compound', 6], ['North', 'PROPN', 8, 'compound', 7]]\n",
      "txt=RT @FoxNewsResearch: #HurricaneFlorence - latest •Cat 2 •170 mi ESE of Wilmington, NC •220 mi E of Myrtle Beach, SC •10M+ in its path •1.7M…\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = NC,SC\n",
      "data NE tree=[['Wilmington', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Wilmington', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 12, 'pobj', 14]\n",
      "parent node subtree [['Wilmington', 'PROPN', 14, 'compound', 13]]\n",
      "candidate 1=Myrtle Beach\n",
      "anchor NE candidates = \n",
      "txt=Met Reyna and her whole family who evacuated from the coast to a Red Cross shelter in Wilson, NC. She says they left everything behind, so they are hoping to have something to go back to. #hurricaneflorence <URL>\n",
      "candidate 0=Red Cross\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Red', 'PROPN', 14, 'compound', 13], ['Cross', 'PROPN', 15, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Cross', 'PROPN', 15, 'compound', 14]\n",
      "NE parent token:\n",
      "['shelter', 'NOUN', 11, 'pobj', 15]\n",
      "parent node subtree [['a', 'DET', 15, 'det', 12], ['Red', 'PROPN', 14, 'compound', 13], ['Cross', 'PROPN', 15, 'compound', 14], ['in', 'ADP', 15, 'prep', 16], ['Wilson', 'PROPN', 18, 'compound', 17], ['NC', 'PROPN', 16, 'pobj', 18]]\n",
      "txt=UPDATE: The @WaffleHouse in North Myrtle Beach remains open this morning even as #HurricaneFlorence bears down. And who do I meet? Barrett - the tenacious employee from Shallotte who refused to shut down as long as @Bojangles1977 was still slingin’ hash. <URL>\n",
      "candidate 0=Myrtle Beach\n",
      "anchor NE candidates = \n",
      "candidate 1=Shallotte\n",
      "anchor NE candidates = Myrtle Beach\n",
      "data NE tree=[['Shallotte', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=2, token=6:\n",
      "['Shallotte', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['from', 'ADP', 3, 'prep', 4]\n",
      "txt=Fast move Ng low clouds and trees starting to dance! #florence @ Kensington at Regency, Cary <URL>\n",
      "candidate 0=Kensington\n",
      "anchor NE candidates = Cary\n",
      "data NE tree=[['Kensington', 'PROPN', 2, 'ROOT', 2]]\n",
      "NE=Kensington subtree=[['at', 'ADP', 2, 'prep', 3], ['Regency', 'PROPN', 5, 'compound', 4], ['Cary', 'PROPN', 3, 'pobj', 5]]\n",
      "min node deps ['prep']\n",
      "subtree = at Regency Cary\n",
      "candidate 1=Cary\n",
      "anchor NE candidates = \n",
      "txt=#hurricaneflorence in downtown Wilmington, NC @TheNOWtv @ Downtown Wilmington By Cape Fear River <URL>\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Wilmington', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Wilmington', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'compound', 4]\n",
      "parent node subtree [['downtown', 'NOUN', 4, 'compound', 2], ['Wilmington', 'PROPN', 4, 'compound', 3]]\n",
      "txt=#hurricaneflorence #sunsetbeachnc #oceanislebeach #northcarolina #sup #veterinary @wildearthpets lauraw1717 madisonwardd _taylor_51 @ Sunset Beach, North Carolina <URL>\n",
      "candidate 0=Sunset Beach\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Sunset', 'PROPN', 13, 'compound', 12], ['Beach', 'PROPN', 15, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Beach', 'PROPN', 15, 'compound', 13]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 15, 'ROOT', 15]\n",
      "parent node subtree [['Sunset', 'PROPN', 13, 'compound', 12], ['Beach', 'PROPN', 15, 'compound', 13], ['North', 'PROPN', 15, 'compound', 14]]\n",
      "txt=Morehead City, NC decimated by #HurricaneFlorence with @DukeEnergy experts doing damage assessments—saying it’s the worst they’ve seen. Flooded areas will make accessing our equipment extremely difficult. Stay safe, stay informed. <URL>\n",
      "candidate 0=Morehead City\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Morehead', 'PROPN', 1, 'compound', 0], ['City', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['City', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 3, 'nsubj', 2]\n",
      "parent node subtree [['Morehead', 'PROPN', 1, 'compound', 0], ['City', 'PROPN', 2, 'compound', 1]]\n",
      "txt=Walking around the development, so far so good regarding #Florence. Just some branches & pine needles down. #southcarolina #murrellsinlet #nofilter #scwx #wx @ Murrells Inlet, South Carolina <URL>\n",
      "candidate 0=Murrells Inlet\n",
      "anchor NE candidates = South Carolina\n",
      "data NE tree=[['Murrells', 'PROPN', 9, 'compound', 6], ['Inlet', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=2, token=8:\n",
      "['Inlet', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 9, 'ROOT', 9]\n",
      "parent node subtree [['Murrells', 'PROPN', 9, 'compound', 6], ['Inlet', 'PROPN', 9, 'compound', 7], ['South', 'PROPN', 9, 'compound', 8]]\n",
      "txt=The edge of Hurricane Florence #hurricaneflorence moving into Georgia. @ Suwanee, Georgia <URL>\n",
      "candidate 0=Suwanee\n",
      "anchor NE candidates = \n",
      "txt=Late dinner for linemen in Maxton, NC tonight. It’s windy and rainy, but the base camp up and operational and is able to get crews a hot meal.  #HurricaneFlorence2018 <URL>\n",
      "candidate 0=Maxton\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Maxton', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Maxton', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 4, 'pobj', 6]\n",
      "parent node subtree [['Maxton', 'PROPN', 6, 'compound', 5]]\n",
      "txt=Downtown New Bern, North Carolina #Florence #1010WINS #NewBernStrong <URL>\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['New', 'PROPN', 2, 'compound', 1], ['Bern', 'PROPN', 5, 'compound', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Bern', 'PROPN', 5, 'compound', 2]\n",
      "NE parent token:\n",
      "['#Florence', 'ADP', 5, 'ROOT', 5]\n",
      "parent node subtree [['Downtown', 'NOUN', 2, 'compound', 0], ['New', 'PROPN', 2, 'compound', 1], ['Bern', 'PROPN', 5, 'compound', 2], ['North', 'PROPN', 4, 'compound', 3], ['Carolina', 'PROPN', 5, 'compound', 4], ['#1010WINS', 'PROPN', 7, 'compound', 6], ['#NewBernStrong', 'X', 5, 'appos', 7]]\n",
      "NE=New Bern subtree=[['Downtown', 'NOUN', 2, 'compound', 0]]\n",
      "min node deps ['compound']\n",
      "txt=#HurricaneFlorence update! @ Charlotte, North Carolina <URL>\n",
      "candidate 0=Charlotte\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Charlotte', 'PROPN', 3, 'compound', 1]]\n",
      "NE parse token at tree=1, token=2:\n",
      "['Charlotte', 'PROPN', 3, 'compound', 1]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 3, 'ROOT', 3]\n",
      "parent node subtree [['Charlotte', 'PROPN', 3, 'compound', 1], ['North', 'PROPN', 3, 'compound', 2]]\n",
      "txt=@bentonblount Lincolnton NC still okay! Also, our little Holden beach home survived. Bought with the retirement money from a 36 year Cop. .. my Hubby! #HurricaneFlorence2018 #policewife\n",
      "candidate 0=Holden beach\n",
      "anchor NE candidates = \n",
      "txt=HerMight&Mercy...Captured in Jacksonville, NC. Large oak uprooted but small chicken coop left in exact spot! 3 hens left nestled together w additional shelter. Amazing! #HurricaneFlorenceNC #Florence #jacksonvillenc <URL>\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Jacksonville', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Jacksonville', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 7, 'compound', 6]]\n",
      "txt=We didn’t think it would be this bad #hurricaneflorence @ Lumberton, North Carolina <URL>\n",
      "candidate 0=Lumberton\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Lumberton', 'PROPN', 14, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Lumberton', 'PROPN', 14, 'compound', 12]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 14, 'ROOT', 14]\n",
      "parent node subtree [['Lumberton', 'PROPN', 14, 'compound', 12], ['North', 'PROPN', 14, 'compound', 13]]\n",
      "txt=Deputies from the Rockingham County Sheriff's Office are here in Kinston, NC helping out with issues caused by #flooding. #HurricaneFlorence #KinstonNC <URL>\n",
      "candidate 0=Kinston\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Kinston', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Kinston', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Kinston', 'PROPN', 11, 'compound', 10]]\n",
      "txt=Homes in the Mayfair neighborhood of Lumberton, NC are underwater again, after being flooded in 2016 during Hurricane Matthew..and water levels continue to rise. #HurricaneFlorence #lumbertonnc #northcarolina #lumberriver @TheNOWtv <URL>\n",
      "candidate 0=Mayfair\n",
      "anchor NE candidates = Lumberton,NC\n",
      "data NE tree=[['Mayfair', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Mayfair', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['neighborhood', 'NOUN', 1, 'pobj', 4]\n",
      "parent node subtree [['the', 'DET', 4, 'det', 2], ['Mayfair', 'PROPN', 4, 'compound', 3], ['of', 'ADP', 4, 'prep', 5], ['Lumberton', 'PROPN', 7, 'compound', 6], ['NC', 'PROPN', 5, 'pobj', 7]]\n",
      "candidate 1=Lumberton\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Lumberton', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Lumberton', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['Lumberton', 'PROPN', 7, 'compound', 6]]\n",
      "txt=The Little River in Manchester, NC, near Spring Lake and upstream from #FayettevilleNC , has hit a record level, according to @NWS . River at 34.96 ft as of 3:30PM Monday. During Hurricane Matthew (previous all-time high) it reached 32.19 ft. #florence #ncwx @newsobserver <URL>\n",
      "candidate 0=Little River\n",
      "anchor NE candidates = Manchester,NC,Spring Lake\n",
      "data NE tree=[['Little', 'PROPN', 2, 'compound', 1], ['River', 'PROPN', 14, 'nsubj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['River', 'PROPN', 14, 'nsubj', 2]\n",
      "NE parent token:\n",
      "['hit', 'VERB', 14, 'ROOT', 14]\n",
      "NE=Little River subtree=[['The', 'DET', 2, 'det', 0], ['in', 'ADP', 2, 'prep', 3], ['Manchester', 'PROPN', 5, 'compound', 4], ['NC', 'PROPN', 3, 'pobj', 5], ['near', 'ADP', 2, 'prep', 6], ['Spring', 'PROPN', 8, 'compound', 7], ['Lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#FayettevilleNC', 'PROPN', 11, 'pobj', 12]]\n",
      "min node deps ['det', 'prep', 'prep']\n",
      "subtree = The in Manchester NC near Spring Lake and upstream from #FayettevilleNC\n",
      "candidate 1=Manchester\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Manchester', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Manchester', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Manchester', 'PROPN', 5, 'compound', 4]]\n",
      "candidate 2=Spring Lake\n",
      "anchor NE candidates = \n",
      "txt=So people outside NC can understand the incredible amount of rain: Elizabethtown in Bladen county got over 36 inches in four days. CHICAGO gets roughly that in a YEAR. Our average in Raleigh is 46. For the YEAR. #HurricaneFlorence\n",
      "candidate 0=Bladen county\n",
      "anchor NE candidates = CHICAGO,Raleigh\n",
      "data NE tree=[['Bladen', 'PROPN', 15, 'compound', 14], ['county', 'NOUN', 13, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['county', 'NOUN', 13, 'pobj', 15]\n",
      "NE parent token:\n",
      "['in', 'ADP', 12, 'prep', 13]\n",
      "candidate 1=Raleigh\n",
      "anchor NE candidates = \n",
      "false negative with NE=bladen_county, txt=So people outside NC can understand the incredible amount of rain: Elizabethtown in Bladen county got over 36 inches in four days. CHICAGO gets roughly that in a YEAR. Our average in Raleigh is 46. For the YEAR. #HurricaneFlorence\n",
      "txt=ROAD CLOSURE: Another closure just added to the list in Union County. This is on Chesnut Lane in Indian Trail. The area was flooded yesterday. Today... This. @wsoctv #Florence <URL>\n",
      "candidate 0=Union County\n",
      "anchor NE candidates = \n",
      "candidate 1=Indian Trail\n",
      "anchor NE candidates = Union County\n",
      "data NE tree=[['Indian', 'PROPN', 7, 'compound', 6], ['Trail', 'PROPN', 5, 'pobj', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Trail', 'PROPN', 5, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 4, 'prep', 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Luckily both boxes were delivered and were delayed by #hurricaneflorence but I fly out tomorrow for a weeks vacation in Canada (Montreal and Quebec) then to #nyc for a week for work and… <URL>\n",
      "candidate 0=Montreal\n",
      "anchor NE candidates = Quebec\n",
      "data NE tree=[['Montreal', 'PROPN', 20, 'appos', 22]]\n",
      "NE parse token at tree=0, token=23:\n",
      "['Montreal', 'PROPN', 20, 'appos', 22]\n",
      "NE parent token:\n",
      "['Canada', 'PROPN', 19, 'pobj', 20]\n",
      "NE=Montreal subtree=[['and', 'CCONJ', 22, 'cc', 23], ['Quebec', 'PROPN', 22, 'conj', 24]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Quebec\n",
      "anchor NE candidates = \n",
      "txt=The remains of #Florence spared Rochester. However, it's a different story from Ithaca to Oneonta. 3 to 4\"\" of rain has fallen from Chemung to southern Cortland counties. Flood Warnings are up for some there. <URL>\n",
      "candidate 0=Ithaca\n",
      "anchor NE candidates = \n",
      "txt=Yesterday, our crews teamed up with @insideFPL to assess damage throughout Columbus and Bladen counties in North Carolina. Crews continue to work through challenging conditions to restore power to customers impacted by #Florence . Track progress: <URL>\n",
      "candidate 0=Columbus\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Columbus', 'PROPN', 14, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Columbus', 'PROPN', 14, 'nmod', 11]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 10, 'pobj', 14]\n",
      "parent node subtree [['Columbus', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Bladen', 'PROPN', 11, 'conj', 13], ['in', 'ADP', 14, 'prep', 15], ['North', 'PROPN', 17, 'compound', 16], ['Carolina', 'PROPN', 15, 'pobj', 17]]\n",
      "NE=Columbus subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Bladen', 'PROPN', 11, 'conj', 13]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Bladen\n",
      "anchor NE candidates = Columbus,North Carolina\n",
      "data NE tree=[['Bladen', 'PROPN', 11, 'conj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Bladen', 'PROPN', 11, 'conj', 13]\n",
      "NE parent token:\n",
      "['Columbus', 'PROPN', 14, 'nmod', 11]\n",
      "txt=@weatherchannel this is from Williamstown, MA. Our bridge is about to get wiped out! Even Mass is being affected by #Florence <URL>\n",
      "candidate 0=Williamstown\n",
      "anchor NE candidates = MA\n",
      "data NE tree=[['Williamstown', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Williamstown', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['MA', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Williamstown', 'PROPN', 5, 'compound', 4]]\n",
      "txt=Looks like I made it to Brooklyn not a moment too soon. The remnants of #Florence have arrived here in NYC...\n",
      "candidate 0=Brooklyn\n",
      "anchor NE candidates = NYC\n",
      "data NE tree=[['Brooklyn', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Brooklyn', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['to', 'ADP', 3, 'prep', 5]\n",
      "txt=After almost 30\"\" of rain during #Florence , Jones county is now experiencing historic flooding along the Trent River. Here r some pics from Pollocksville where rescue crews have worked tirelessly assisting residents. Special thank you to @NYPDnews , who have come a long way 2 help! <URL>\n",
      "candidate 0=Jones county\n",
      "anchor NE candidates = \n",
      "candidate 1=Pollocksville\n",
      "anchor NE candidates = Jones county,Pollocksville\n",
      "data NE tree=[['Pollocksville', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Pollocksville', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['from', 'ADP', 3, 'prep', 4]\n",
      "txt=Aviators of the 82nd Airborne Division Combat Aviation Brigade began returning aircraft to Fort Bragg today. They were placed out of harms way at Robins Air Force Base in Georgia. #hurricaneflorence ; #Armyhurricaneresponse #Armyhurricaneflorence #HUREVAC2018 #ArmyResponse ; #18ABC <URL>\n",
      "candidate 0=Fort Bragg\n",
      "anchor NE candidates = Georgia\n",
      "data NE tree=[['Fort', 'PROPN', 14, 'compound', 13], ['Bragg', 'PROPN', 12, 'pobj', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Bragg', 'PROPN', 12, 'pobj', 14]\n",
      "NE parent token:\n",
      "['to', 'ADP', 10, 'prep', 12]\n",
      "txt=Houses sit in floodwater caused by #HurricaneFlorence , in this aerial picture, on the outskirts of Lumberton, North Carolina, via @Reuters photographer Jason Miczek See Reuters top photos from the last 24 hours: <URL>\n",
      "candidate 0=Lumberton\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Lumberton', 'PROPN', 17, 'compound', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Lumberton', 'PROPN', 17, 'compound', 15]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 14, 'pobj', 17]\n",
      "parent node subtree [['Lumberton', 'PROPN', 17, 'compound', 15], ['North', 'PROPN', 17, 'compound', 16]]\n",
      "txt=New WCK kitchen opening in New Bern! This is one of the worst hit areas in North Carolina...Tonight we served hundreds of residents & we activate a local food truck tomorrow! My brother @cheftkilcoyne showing how food relief should be done! #Florence @WCKitchen @NC_Governor <URL>\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['New', 'PROPN', 6, 'compound', 5], ['Bern', 'PROPN', 4, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Bern', 'PROPN', 4, 'pobj', 6]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 4]\n",
      "txt=Our teams returned to the command base in Darlington this evening with eyes still on a concerning river and dam situation in Hartsville. Here is a look at the area they staged at today. #Florence #LouisianaProud <URL>\n",
      "candidate 0=Darlington\n",
      "anchor NE candidates = \n",
      "candidate 1=Hartsville\n",
      "anchor NE candidates = Darlington\n",
      "data NE tree=[['Hartsville', 'PROPN', 21, 'pobj', 22]]\n",
      "NE parse token at tree=0, token=23:\n",
      "['Hartsville', 'PROPN', 21, 'pobj', 22]\n",
      "NE parent token:\n",
      "['in', 'ADP', 20, 'prep', 21]\n",
      "txt=Thanks. My wife & I were driving that road 16 days ago heading from Myrtle Beach to the NASCAR race in Darlington. The PeeDee River is halfway between Marion and Darlington. Very sad what is happening. We're thinking about everyone in the Carolinas affected by #HurricaneFlorence .\n",
      "candidate 0=Myrtle Beach\n",
      "anchor NE candidates = Darlington,Marion,Darlington\n",
      "data NE tree=[['Myrtle', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 12, 'pobj', 14]]\n",
      "NE parse token at tree=1, token=15:\n",
      "['Beach', 'PROPN', 12, 'pobj', 14]\n",
      "NE parent token:\n",
      "['from', 'ADP', 11, 'prep', 12]\n",
      "candidate 1=Darlington\n",
      "anchor NE candidates = \n",
      "candidate 2=Marion\n",
      "anchor NE candidates = Darlington,Darlington\n",
      "data NE tree=[['Marion', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=2, token=7:\n",
      "['Marion', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['between', 'ADP', 4, 'prep', 5]\n",
      "NE=Marion subtree=[['and', 'CCONJ', 6, 'cc', 7], ['Darlington', 'PROPN', 6, 'conj', 8]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 3=Darlington\n",
      "anchor NE candidates = \n",
      "txt=Argentina expresses its sincere condolences to the Government and the people of the United States over the tragic loss of several lives left by #HurricaneFlorence in various States mainly in North and South Carolina. Read the press release here: <URL>\n",
      "candidate 0=North\n",
      "anchor NE candidates = United States\n",
      "data NE tree=[['North', 'PROPN', 33, 'nmod', 30]]\n",
      "NE parse token at tree=0, token=31:\n",
      "['North', 'PROPN', 33, 'nmod', 30]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 29, 'pobj', 33]\n",
      "parent node subtree [['North', 'PROPN', 33, 'nmod', 30], ['and', 'CCONJ', 30, 'cc', 31], ['South', 'PROPN', 30, 'conj', 32]]\n",
      "NE=North subtree=[['and', 'CCONJ', 30, 'cc', 31], ['South', 'PROPN', 30, 'conj', 32]]\n",
      "min node deps ['cc', 'conj']\n",
      "txt=ONLY ON @WXII : A multi-state operation to check on/rescue a stranded community. The Deep River here in Chatham County has cut off Everett Dowdy Rd. Food and water are being distributed. If needed people can be boated back and transported on a NG truck. #Florence <URL>\n",
      "candidate 0=Chatham County\n",
      "anchor NE candidates = \n",
      "candidate 1=Everett\n",
      "anchor NE candidates = Chatham County\n",
      "data NE tree=[['Everett', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['Everett', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['Rd', 'PROPN', 8, 'dobj', 12]\n",
      "parent node subtree [['Everett', 'PROPN', 12, 'compound', 10], ['Dowdy', 'PROPN', 12, 'compound', 11]]\n",
      "txt=My aunt & uncle have lived in Southport, North Carolina for about 35 years. They evacuated from #HurricaneFlorence and stayed with family a couple hours away. They are still away, but I heard from my mother today that their house is structurally safe. So much flooding though. :(\n",
      "candidate 0=Southport\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Southport', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Southport', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['Southport', 'PROPN', 9, 'compound', 7], ['North', 'PROPN', 9, 'compound', 8]]\n",
      "txt=CHECK THIS OUT! Viewer video of Mayesville Rd in Anson County during #Florence. @NCDOT crews say it will take several months until all impacted roads are reopened. There are 44 closed roads in Anson County alone. NCDOT has 12 assessment teams checking damage in Anson and Union. <URL>\n",
      "candidate 0=Anson County\n",
      "anchor NE candidates = \n",
      "candidate 1=Anson County\n",
      "anchor NE candidates = \n",
      "candidate 2=Anson\n",
      "anchor NE candidates = Anson County,Anson County,Union\n",
      "data NE tree=[['Anson', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['Anson', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['Anson', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 3=Union\n",
      "anchor NE candidates = Anson County,Anson County\n",
      "data NE tree=[['Union', 'PROPN', 8, 'conj', 10]]\n",
      "NE parse token at tree=4, token=11:\n",
      "['Union', 'PROPN', 8, 'conj', 10]\n",
      "NE parent token:\n",
      "['Anson', 'PROPN', 7, 'pobj', 8]\n",
      "txt=More evacuations coming in Horry County, SC. #Florence #flooding <URL>\n",
      "candidate 0=Horry County\n",
      "anchor NE candidates = SC\n",
      "data NE tree=[['Horry', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['County', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 3, 'pobj', 6]\n",
      "parent node subtree [['Horry', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 6, 'compound', 5]]\n",
      "txt=New Bern, NC & Conway, SC got visits from @POTUS Trump yesterday as they recover from the devastation brought by #Florence . Coming up hear what ppl in area had to say about his visit @WBTV_News <URL>\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = NC,Conway,SC\n",
      "data NE tree=[['New', 'PROPN', 2, 'compound', 0], ['Bern', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Bern', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 6, 'nsubj', 2]\n",
      "parent node subtree [['New', 'PROPN', 2, 'compound', 0], ['Bern', 'PROPN', 2, 'compound', 1], ['&', 'CCONJ', 2, 'cc', 3], ['Conway', 'PROPN', 5, 'compound', 4], ['SC', 'PROPN', 2, 'conj', 5]]\n",
      "candidate 1=Conway\n",
      "anchor NE candidates = \n",
      "txt=Thanks to the amazing generosity of people in and around the Triangle, @WRAL helped fill 5 buses, 5 trailers, 3 vans and a small truck with supplies for #Florence victims. 130,500 lbs in supplies will be delivered next week to Wilmington, Lumberton and New Bern. #wral\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = Wilmington,Lumberton,New Bern\n",
      "data NE tree=[['Wilmington', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['Wilmington', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Lumberton', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Wilmington', 'PROPN', 11, 'compound', 10], ['and', 'CCONJ', 11, 'cc', 12], ['New', 'PROPN', 14, 'compound', 13], ['Bern', 'PROPN', 11, 'conj', 14]]\n",
      "candidate 1=Lumberton\n",
      "anchor NE candidates = \n",
      "candidate 2=New Bern\n",
      "anchor NE candidates = Wilmington,New Bern\n",
      "data NE tree=[['New', 'PROPN', 14, 'compound', 13], ['Bern', 'PROPN', 11, 'conj', 14]]\n",
      "NE parse token at tree=1, token=15:\n",
      "['Bern', 'PROPN', 11, 'conj', 14]\n",
      "NE parent token:\n",
      "['Lumberton', 'PROPN', 9, 'pobj', 11]\n",
      "txt=Update: #HurricaneFlorence Brunswick County will have food and water available for distribution Friday, Sept. 21 from 11 a.m. To 5 p.m. at: Spring Lake Park (210 Pine Road in Boiling Spring Lakes) Northwest... <URL>\n",
      "candidate 0=Brunswick County\n",
      "anchor NE candidates = \n",
      "candidate 1=Boiling Spring Lakes\n",
      "anchor NE candidates = Brunswick County\n",
      "data NE tree=[['Boiling', 'VERB', 41, 'compound', 39], ['Spring', 'PROPN', 41, 'compound', 40], ['Lakes', 'PROPN', 38, 'pobj', 41]]\n",
      "NE parse token at tree=0, token=42:\n",
      "['Lakes', 'PROPN', 38, 'pobj', 41]\n",
      "NE parent token:\n",
      "['in', 'ADP', 37, 'prep', 38]\n",
      "candidate 2=Northwest\n",
      "anchor NE candidates = Brunswick County,Spring Lake Park\n",
      "data NE tree=[['Northwest', 'PROPN', 43, 'ROOT', 43]]\n",
      "NE=Northwest subtree=[['...', 'PUNCT', 43, 'punct', 44]]\n",
      "min node deps ['punct']\n",
      "txt=. @COJacksonville NC​ officials recommend avoiding a major intersection at the end of the Jacksonville bypass because of heavy traffic use by those heading to the southern coast. #HurricaneFlorence #FlorenceNC <URL>\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = \n",
      "txt=Please pay attention to #WilmingtonNC and surrounding areas near the Cape Fear, NE Cape Fear & Black Rivers today and through the weekend. Many in Pender County were evacuated last night by National Guard, now this today. #HurricaneFlorence <URL>\n",
      "candidate 0=Cape Fear\n",
      "anchor NE candidates = Pender County\n",
      "data NE tree=[['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'NOUN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Fear', 'NOUN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['NE', 'PROPN', 14, 'compound', 12]\n",
      "parent node subtree [['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'NOUN', 12, 'compound', 11]]\n",
      "candidate 1=Pender County\n",
      "anchor NE candidates = \n",
      "txt=Boiling Spring Lakes, NC #CarolinaStrong #HurricaneFlorence #GiveBack @EdPiotrowski @wpdeabc15 @jamiearnoldWMBF @wmbfweather <URL>\n",
      "candidate 0=Spring Lakes\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Spring', 'PROPN', 2, 'compound', 1], ['Lakes', 'PROPN', 3, 'compound', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Lakes', 'PROPN', 3, 'compound', 2]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'compound', 3]\n",
      "parent node subtree [['Boiling', 'VERB', 3, 'amod', 0], ['Spring', 'PROPN', 2, 'compound', 1], ['Lakes', 'PROPN', 3, 'compound', 2]]\n",
      "txt=Georgetown County will open emergency shelters at 7 a.m. Monday at the following locations: • Georgetown High School, 2500 Anthuan Maybank Drive, Georgetown • Waccamaw Middle School, 247 Wildcat Way, Pawleys Island @SCPublicRadio #HurricaneFlorence @GCEMD\n",
      "candidate 0=Georgetown County\n",
      "anchor NE candidates = Georgetown\n",
      "data NE tree=[['Georgetown', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['County', 'PROPN', 3, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['open', 'VERB', 3, 'ROOT', 3]\n",
      "candidate 1=Georgetown\n",
      "anchor NE candidates = \n",
      "candidate 2=Pawleys Island\n",
      "anchor NE candidates = Georgetown County,Georgetown\n",
      "data NE tree=[['Pawleys', 'PROPN', 35, 'compound', 34], ['Island', 'PROPN', 35, 'ROOT', 35]]\n",
      "NE=Pawleys Island subtree=[['Waccamaw', 'PROPN', 30, 'compound', 28], ['Middle', 'PROPN', 30, 'compound', 29], ['School', 'PROPN', 35, 'compound', 30], ['247', 'NUM', 33, 'nummod', 31], ['Wildcat', 'PROPN', 33, 'compound', 32], ['Way', 'PROPN', 35, 'compound', 33], ['@SCPublicRadio', 'PROPN', 35, 'punct', 36]]\n",
      "min node deps ['compound', 'compound']\n",
      "txt=Eat at #beachsidebistro and 10% of your purchase will be donated to the Red Cross of North Carolina to help our fellow #northcarolinians affected by #hurricaneflorence #foodforflo … <URL>\n",
      "candidate 0=Red Cross\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Red', 'PROPN', 15, 'compound', 14], ['Cross', 'PROPN', 12, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Cross', 'PROPN', 12, 'pobj', 15]\n",
      "NE parent token:\n",
      "['to', 'ADP', 11, 'prep', 12]\n",
      "NE=Red Cross subtree=[['the', 'DET', 15, 'det', 13], ['of', 'ADP', 15, 'prep', 16], ['North', 'PROPN', 18, 'compound', 17], ['Carolina', 'PROPN', 16, 'pobj', 18]]\n",
      "min node deps ['det', 'prep']\n",
      "subtree = the of North Carolina\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Coal ash flowing like pudding in Neuse River near Duke's Goldsboro power plant <URL>\n",
      "candidate 0=Duke\n",
      "anchor NE candidates = Duke,Goldsboro\n",
      "candidate 1=Goldsboro\n",
      "anchor NE candidates = Goldsboro\n",
      "data NE tree=[['Goldsboro', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Goldsboro', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['plant', 'NOUN', 8, 'pobj', 12]\n",
      "parent node subtree [[\"Duke's\", 'PROPN', 12, 'compound', 9], ['Goldsboro', 'PROPN', 12, 'compound', 10], ['power', 'NOUN', 12, 'compound', 11]]\n",
      "txt=The first Hurricane Watches for this part of #Texas in 3,267 days (9yrs!) like Houston & Corpus Christi #TXwx #Harvey h/t @KathrynProciv <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Corpus Christi\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Corpus', 'PROPN', 5, 'compound', 3], ['Christi', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Christi', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['#TXwx', 'PROPN', 1, 'conj', 5]\n",
      "parent node subtree [['Corpus', 'PROPN', 5, 'compound', 3], ['Christi', 'PROPN', 5, 'compound', 4]]\n",
      "txt=As of 10 a.m., the modeling has #Harvey making landfall north of Rockport, which would spare Corpus Christi the worst of the storm.\n",
      "candidate 0=Rockport\n",
      "anchor NE candidates = Corpus Christi\n",
      "data NE tree=[['Rockport', 'PROPN', 14, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Rockport', 'PROPN', 14, 'pobj', 15]\n",
      "NE parent token:\n",
      "['of', 'ADP', 13, 'prep', 14]\n",
      "candidate 1=Corpus Christi\n",
      "anchor NE candidates = \n",
      "txt=The eye of #HurricaneHarvey is now showing on the Brownsville, Texas long range radar. <URL>\n",
      "candidate 0=Brownsville\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Brownsville', 'PROPN', 10, 'nmod', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Brownsville', 'PROPN', 10, 'nmod', 9]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 13, 'nmod', 10]\n",
      "parent node subtree [['Brownsville', 'PROPN', 10, 'nmod', 9]]\n",
      "txt=Praying for Texas, esp my other home Corpus Christi. #HurricaneHarvey\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "txt=Heavy squall headed toward Matagorda and Brazoria County coasts. Watch for waterspouts. #txwx #harvey <URL>\n",
      "candidate 0=Matagorda\n",
      "anchor NE candidates = Brazoria County\n",
      "data NE tree=[['Matagorda', 'PROPN', 8, 'nmod', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Matagorda', 'PROPN', 8, 'nmod', 4]\n",
      "NE parent token:\n",
      "['coasts', 'NOUN', 3, 'pobj', 8]\n",
      "parent node subtree [['Matagorda', 'PROPN', 8, 'nmod', 4], ['and', 'CCONJ', 4, 'cc', 5], ['Brazoria', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 4, 'conj', 7]]\n",
      "NE=Matagorda subtree=[['and', 'CCONJ', 4, 'cc', 5], ['Brazoria', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 4, 'conj', 7]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Brazoria County\n",
      "anchor NE candidates = \n",
      "txt=#Live . @mikebettes on #Periscope : Streaming cam from Galveston, Texas as Hurricane #Harvey approaches coast. #txwx <URL>\n",
      "candidate 0=Galveston\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Galveston', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Galveston', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Galveston', 'PROPN', 8, 'compound', 7]]\n",
      "txt=Headed to Galveston as #Harvey pushes closer to the TX coast. Look for updates here & live reports on @KPRC2 at 10 #HurricaneHarvey #kprc2 <URL>\n",
      "candidate 0=Galveston\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Galveston', 'PROPN', 1, 'pobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Galveston', 'PROPN', 1, 'pobj', 2]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "txt=#Harvey up to Cat 4 now. Just hours from landfall near Rockport, TX. Winds sustained at 130 mph. <URL>\n",
      "candidate 0=Rockport\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Rockport', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Rockport', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 4, 'pobj', 6]\n",
      "parent node subtree [['Rockport', 'PROPN', 6, 'compound', 5]]\n",
      "txt=@UnitedAirways I know you will do the right thing and refund my flight from Corpus Christi to Lubbock. #harvey . Thanks\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "candidate 1=Lubbock\n",
      "anchor NE candidates = Corpus Christi\n",
      "data NE tree=[['Lubbock', 'PROPN', 16, 'pobj', 17]]\n",
      "NE parse token at tree=0, token=18:\n",
      "['Lubbock', 'PROPN', 16, 'pobj', 17]\n",
      "NE parent token:\n",
      "['to', 'ADP', 10, 'prep', 16]\n",
      "txt=Eyewall of #Harvey moving over San Jose Island north of Port Aransas, TX. #txwx <URL>\n",
      "candidate 0=San Jose Island\n",
      "anchor NE candidates = Port Aransas,TX\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Jose', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Island', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['north', 'ADV', 3, 'advmod', 8]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Jose', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 8, 'compound', 7], ['of', 'ADP', 8, 'prep', 9], ['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11], ['TX', 'PROPN', 9, 'pobj', 12]]\n",
      "candidate 1=Port Aransas\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Aransas', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11]]\n",
      "txt=#BREAKING #HurricaneHarvey makes landfall on TX coast over the northern end of San Jose Island about 4 miles east of Rockport. #nprnewscast\n",
      "candidate 0=San Jose Island\n",
      "anchor NE candidates = \n",
      "candidate 1=Rockport\n",
      "anchor NE candidates = TX,Rockport\n",
      "data NE tree=[['Rockport', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Rockport', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['of', 'ADP', 18, 'prep', 19]\n",
      "false negative with NE=san_jose_island, txt=#BREAKING #HurricaneHarvey makes landfall on TX coast over the northern end of San Jose Island about 4 miles east of Rockport. #nprnewscast\n",
      "txt=#HurricaneHarvey makes landfall on San Jose Island, TX near Rockport, TX as a Cat. 4 hurricane. @WCCBCharlotte <URL>\n",
      "candidate 0=San Jose Island\n",
      "anchor NE candidates = TX,Rockport,TX\n",
      "data NE tree=[['San', 'PROPN', 5, 'compound', 4], ['Jose', 'PROPN', 6, 'compound', 5], ['Island', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Island', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['San', 'PROPN', 5, 'compound', 4], ['Jose', 'PROPN', 6, 'compound', 5], ['Island', 'PROPN', 7, 'compound', 6], ['near', 'ADP', 7, 'prep', 8], ['Rockport', 'PROPN', 10, 'compound', 9], ['TX', 'PROPN', 8, 'pobj', 10]]\n",
      "candidate 1=Rockport\n",
      "anchor NE candidates = \n",
      "txt=The eye of Hurricane #Harvey has made landfall between Port Aransas and Port O'Conner, TX. This is still only the beginning.\n",
      "candidate 0=Port Aransas\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Port', 'PROPN', 10, 'compound', 9], ['Aransas', 'PROPN', 8, 'pobj', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Aransas', 'PROPN', 8, 'pobj', 10]\n",
      "NE parent token:\n",
      "['between', 'ADP', 7, 'prep', 8]\n",
      "NE=Port Aransas subtree=[['and', 'CCONJ', 10, 'cc', 11], ['Port', 'PROPN', 13, 'compound', 12], [\"O'Conner\", 'PROPN', 14, 'compound', 13], ['TX', 'PROPN', 10, 'conj', 14]]\n",
      "min node deps ['cc', 'conj']\n",
      "txt=praying for my family all around texas, especially most of my family that resides in houston. stay safe! #prayfortexas #hurricaneharvey\n",
      "candidate 0=houston\n",
      "anchor NE candidates = \n",
      "txt=My hometown Houston be safe people texting me i'm chill i'm in Dallas we should be gucci #HurricaneHarvey\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Dallas\n",
      "data NE tree=[['Houston', 'PROPN', 1, 'appos', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Houston', 'PROPN', 1, 'appos', 2]\n",
      "NE parent token:\n",
      "['hometown', 'NOUN', 3, 'nsubj', 1]\n",
      "candidate 1=Dallas\n",
      "anchor NE candidates = \n",
      "txt=CBS NEWS: Reports that portions of high school in Rockport, Texas, where #HurricaneHarvey made landfall, have collapsed <URL>\n",
      "candidate 0=Rockport\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Rockport', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Rockport', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Rockport', 'PROPN', 11, 'compound', 10]]\n",
      "txt=Hurricane #Harvey Makes Landfall Near Corpus Christi, Texas but the danger is not over <URL>\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Corpus', 'PROPN', 6, 'compound', 5], ['Christi', 'PROPN', 4, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Christi', 'PROPN', 4, 'pobj', 6]\n",
      "NE parent token:\n",
      "['Near', 'PROPN', 3, 'prep', 4]\n",
      "NE=Corpus Christi subtree=[['Texas', 'PROPN', 6, 'appos', 7]]\n",
      "min node deps ['appos']\n",
      "subtree = Texas\n",
      "txt=Rain and lots wind in San Marcos,Tx. Checked in with my parentals and everyone is ok with a little damage. Thanks #HurricaneHarvey\n",
      "candidate 0=San Marcos\n",
      "anchor NE candidates = Tx\n",
      "txt=The tale of Hurricane #Harvey from two Texas cities: Corpus Christi's peak wind gust was 63 mph while Rockport's... <URL>\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "candidate 1=Rockport\n",
      "anchor NE candidates = Texas\n",
      "txt=Tornado damage in Sienna Plantation S of Houston and Katy W of Houston #HurricaneHarvey #Harvey2017 Flooding Mayde Creek - Katy W of Houston\n",
      "candidate 0=Sienna Plantation\n",
      "anchor NE candidates = Houston,Houston,Houston\n",
      "data NE tree=[['Sienna', 'PROPN', 4, 'compound', 3], ['Plantation', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Plantation', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['S', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Sienna', 'PROPN', 4, 'compound', 3], ['Plantation', 'PROPN', 5, 'compound', 4], ['of', 'ADP', 5, 'prep', 6], ['Houston', 'PROPN', 6, 'pobj', 7], ['and', 'CCONJ', 5, 'cc', 8], ['Katy', 'PROPN', 10, 'compound', 9], ['W', 'PROPN', 5, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Houston', 'PROPN', 13, 'compound', 12], ['#HurricaneHarvey', 'PROPN', 14, 'compound', 13], ['#Harvey2017', 'PUNCT', 11, 'pobj', 14]]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "candidate 2=Houston\n",
      "anchor NE candidates = \n",
      "candidate 3=Houston\n",
      "anchor NE candidates = \n",
      "false negative with NE=sienna_plantation, txt=Tornado damage in Sienna Plantation S of Houston and Katy W of Houston #HurricaneHarvey #Harvey2017 Flooding Mayde Creek - Katy W of Houston\n",
      "txt=I'm at a shelter in Austin, TX, where @govabbott is meeting with evacuated Texans. #harvey #txlege <URL>\n",
      "candidate 0=Austin\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Austin', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Austin', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 4, 'pobj', 6]\n",
      "parent node subtree [['Austin', 'PROPN', 6, 'compound', 5], ['where', 'ADV', 10, 'advmod', 7], ['@govabbott', 'PROPN', 10, 'nsubj', 8], ['is', 'VERB', 10, 'aux', 9], ['meeting', 'VERB', 6, 'relcl', 10], ['with', 'ADP', 10, 'prep', 11], ['evacuated', 'VERB', 13, 'amod', 12], ['Texans', 'PROPN', 11, 'pobj', 13]]\n",
      "txt=Convoy of wildlife agents from Louisiana towing boats leave gas station in Wharton and head toward Houston #harvey <URL>\n",
      "candidate 0=Wharton\n",
      "anchor NE candidates = \n",
      "candidate 1=Houston\n",
      "anchor NE candidates = Louisiana,Houston\n",
      "data NE tree=[['Houston', 'PROPN', 17, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Houston', 'PROPN', 17, 'compound', 16]\n",
      "NE parent token:\n",
      "['#harvey', 'PROPN', 15, 'pobj', 17]\n",
      "parent node subtree [['Houston', 'PROPN', 17, 'compound', 16]]\n",
      "txt=ALL of my District is under siege-Brays Oaks, Med Center, Meyerland, Sharpstown, Southpark, Sunnyside, 3rd Ward, & Westbury. #Harvey #Flood <URL>\n",
      "candidate 0=Sharpstown\n",
      "anchor NE candidates = Westbury\n",
      "data NE tree=[['Sharpstown', 'PROPN', 15, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Sharpstown', 'PROPN', 15, 'compound', 11]\n",
      "NE parent token:\n",
      "['Ward', 'PROPN', 5, 'pobj', 15]\n",
      "parent node subtree [['siegeBrays', 'NOUN', 9, 'compound', 6], ['Oaks', 'PROPN', 9, 'compound', 7], ['Med', 'PROPN', 9, 'compound', 8], ['Center', 'PROPN', 15, 'compound', 9], ['Meyerland', 'PROPN', 11, 'compound', 10], ['Sharpstown', 'PROPN', 15, 'compound', 11], ['Southpark', 'PROPN', 15, 'compound', 12], ['Sunnyside', 'PROPN', 15, 'compound', 13], ['3rd', 'PROPN', 15, 'compound', 14], ['&', 'CCONJ', 15, 'cc', 16], ['Westbury', 'PROPN', 15, 'conj', 17]]\n",
      "NE=Sharpstown subtree=[['Meyerland', 'PROPN', 11, 'compound', 10]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Southpark\n",
      "anchor NE candidates = Westbury\n",
      "data NE tree=[['Southpark', 'PROPN', 15, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Southpark', 'PROPN', 15, 'compound', 12]\n",
      "NE parent token:\n",
      "['Ward', 'PROPN', 5, 'pobj', 15]\n",
      "parent node subtree [['siegeBrays', 'NOUN', 9, 'compound', 6], ['Oaks', 'PROPN', 9, 'compound', 7], ['Med', 'PROPN', 9, 'compound', 8], ['Center', 'PROPN', 15, 'compound', 9], ['Meyerland', 'PROPN', 11, 'compound', 10], ['Sharpstown', 'PROPN', 15, 'compound', 11], ['Southpark', 'PROPN', 15, 'compound', 12], ['Sunnyside', 'PROPN', 15, 'compound', 13], ['3rd', 'PROPN', 15, 'compound', 14], ['&', 'CCONJ', 15, 'cc', 16], ['Westbury', 'PROPN', 15, 'conj', 17]]\n",
      "candidate 2=Westbury\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Wolff said patients from Ben Taub in Houston might be transported to San Antonio area hospitals. Not confirmed yet. #Harvey\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Houston,San Antonio\n",
      "data NE tree=[['Houston', 'PROPN', 6, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Houston', 'PROPN', 6, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 5, 'prep', 6]\n",
      "candidate 1=San Antonio\n",
      "anchor NE candidates = \n",
      "txt=Plano efforts w/ #HurricaneHarvey (1/2) - Plano Fire-Rescue: 2 members deployed w/ TX Task Force One & 3 (incl K-9) w/ TX Task Force Two. <URL>\n",
      "candidate 0=Plano\n",
      "anchor NE candidates = TX,TX\n",
      "data NE tree=[['Plano', 'PROPN', 1, 'compound', 0]]\n",
      "NE parse token at tree=0, token=1:\n",
      "['Plano', 'PROPN', 1, 'compound', 0]\n",
      "NE parent token:\n",
      "['efforts', 'NOUN', 1, 'ROOT', 1]\n",
      "parent node subtree [['Plano', 'PROPN', 1, 'compound', 0]]\n",
      "txt=VIDEO: I-10 at Yale, The Heights, Houston (residential area on the north side of downtown.) ( - @euzkera ) #Harvey <URL>\n",
      "candidate 0=Yale\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Yale', 'PROPN', 10, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Yale', 'PROPN', 10, 'compound', 4]\n",
      "NE parent token:\n",
      "['area', 'NOUN', 3, 'pobj', 10]\n",
      "parent node subtree [['Yale', 'PROPN', 10, 'compound', 4], ['The', 'DET', 10, 'det', 5], ['Heights', 'PROPN', 7, 'nmod', 6], ['Houston', 'PROPN', 10, 'nmod', 7], ['(', 'PUNCT', 10, 'punct', 8], ['residential', 'ADJ', 10, 'amod', 9], ['on', 'ADP', 10, 'prep', 11], ['the', 'DET', 14, 'det', 12], ['north', 'NOUN', 14, 'compound', 13], ['side', 'NOUN', 11, 'pobj', 14], ['of', 'ADP', 14, 'prep', 15], ['downtown', 'NOUN', 15, 'pobj', 16]]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "false negative with NE=yale, txt=VIDEO: I-10 at Yale, The Heights, Houston (residential area on the north side of downtown.) ( - @euzkera ) #Harvey <URL>\n",
      "txt=The latest rainfall totals (since Thurs) compiled by @NWSWPC are INSANE! 39.2 inches (so far) in Dayton, TX. 30+ in south Houston. #harvey <URL>\n",
      "candidate 0=Dayton\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Dayton', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Dayton', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Dayton', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=south Houston\n",
      "anchor NE candidates = \n",
      "txt=CONTACT?!!!!!!!!!!!!! 2 KAYAKS 4 #HELP inner LOOP: LINDALE, IRVINGTON, CAVALCADE area and BEYOND! #HurricaneHarvey #Houston <URL>\n",
      "candidate 0=LINDALE\n",
      "anchor NE candidates = IRVINGTON\n",
      "data NE tree=[['LINDALE', 'PROPN', 10, 'compound', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['LINDALE', 'PROPN', 10, 'compound', 7]\n",
      "NE parent token:\n",
      "['area', 'NOUN', 10, 'ROOT', 10]\n",
      "parent node subtree [['LINDALE', 'PROPN', 10, 'compound', 7], ['IRVINGTON', 'PROPN', 9, 'compound', 8], ['CAVALCADE', 'NOUN', 10, 'compound', 9], ['and', 'CCONJ', 10, 'cc', 11], ['BEYOND', 'ADV', 10, 'conj', 12], ['!', 'PUNCT', 10, 'punct', 13]]\n",
      "txt=From New York to Houston- our thoughts are with the safety and well-being of everyone in Texas. #HoustonStong #HurricaneHarvey <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Houston', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Houston', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 3]\n",
      "txt=@realDonaldTrump You bypassed Houston? If NYC had a 1,000-year flood wd you visit Albany & Rochester, bypass NYC? #Harvey #HurricaneHarvey\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Albany\n",
      "data NE tree=[['Houston', 'PROPN', 2, 'dobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Houston', 'PROPN', 2, 'dobj', 3]\n",
      "NE parent token:\n",
      "['bypassed', 'VERB', 2, 'ROOT', 2]\n",
      "candidate 1=Rochester\n",
      "anchor NE candidates = \n",
      "txt=Teague's Tavern in Round Top is offering 10 percent of their sales to flood relief efforts in La Grange and Houston. Check them out! #Harvey\n",
      "candidate 0=Round Top\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Round', 'PROPN', 4, 'compound', 3], ['Top', 'PROPN', 2, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Top', 'PROPN', 2, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "txt=NOAA: rainfall total from #Harvey for Cedar Bayou in Harris County, Texas, is at 51.88”, a contiguous US record for any tropical system.\n",
      "candidate 0=Harris County\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Harris', 'PROPN', 11, 'compound', 10], ['County', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['County', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Harris', 'PROPN', 11, 'compound', 10], ['County', 'PROPN', 12, 'compound', 11]]\n",
      "txt=President Trump and First Lady Melania at Annaville Fire Rescue | Corpus Christi, TX #HurricaneHarvey <URL>\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Corpus', 'PROPN', 12, 'compound', 11], ['Christi', 'PROPN', 14, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Christi', 'PROPN', 14, 'compound', 12]\n",
      "NE parent token:\n",
      "['#HurricaneHarvey', 'PROPN', 9, 'appos', 14]\n",
      "parent node subtree [['|', 'PROPN', 14, 'punct', 10], ['Corpus', 'PROPN', 12, 'compound', 11], ['Christi', 'PROPN', 14, 'compound', 12], ['TX', 'PROPN', 14, 'compound', 13]]\n",
      "txt=1927 Freeman Ave. 77642 Port Arthur, Tx elderly lady and her granddaughter stuck #HurricaneHarvey #portarthur\n",
      "candidate 0=Port Arthur\n",
      "anchor NE candidates = Tx\n",
      "data NE tree=[['Port', 'PROPN', 7, 'nmod', 5], ['Arthur', 'PROPN', 7, 'nmod', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Arthur', 'PROPN', 7, 'nmod', 6]\n",
      "NE parent token:\n",
      "['Tx', 'PROPN', 9, 'nmod', 7]\n",
      "parent node subtree [['Port', 'PROPN', 7, 'nmod', 5], ['Arthur', 'PROPN', 7, 'nmod', 6]]\n",
      "txt=Has anyone in Houston been successful driving to Austin or are roads still under? #Houston #Harvey\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Austin\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Austin', 'PROPN', 7, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Austin', 'PROPN', 7, 'pobj', 8]\n",
      "NE parent token:\n",
      "['to', 'ADP', 6, 'prep', 7]\n",
      "txt=#HurricaneHarvey #MumbaiRains Houston Vs Mumbai Divided by oceans, United in Grief <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=United\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['United', 'PROPN', 7, 'appos', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['United', 'PROPN', 7, 'appos', 8]\n",
      "NE parent token:\n",
      "['oceans', 'NOUN', 6, 'pobj', 7]\n",
      "txt=Coast Guard and Port Arthur officials involved in rescues in the city, Bevil Oaks FD rescuing in that area. #SETXNews #Harvey\n",
      "candidate 0=Port Arthur\n",
      "anchor NE candidates = \n",
      "candidate 1=Bevil Oaks\n",
      "anchor NE candidates = Port Arthur\n",
      "data NE tree=[['Bevil', 'PROPN', 14, 'compound', 12], ['Oaks', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Oaks', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['FD', 'PROPN', 15, 'nsubj', 14]\n",
      "parent node subtree [['Bevil', 'PROPN', 14, 'compound', 12], ['Oaks', 'PROPN', 14, 'compound', 13]]\n",
      "txt=Sending prayers - More than 1,700 square miles of Harris County in Texas in underwater - more than New York City & Chicago combined. #Harvey <URL>\n",
      "candidate 0=Harris County\n",
      "anchor NE candidates = Texas,New York City\n",
      "data NE tree=[['Harris', 'PROPN', 9, 'compound', 8], ['County', 'PROPN', 7, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['County', 'PROPN', 7, 'pobj', 9]\n",
      "NE parent token:\n",
      "['of', 'ADP', 6, 'prep', 7]\n",
      "NE=Harris County subtree=[['in', 'ADP', 9, 'prep', 10], ['Texas', 'PROPN', 10, 'pobj', 11]]\n",
      "min node deps ['prep']\n",
      "subtree = in Texas\n",
      "candidate 1=Chicago\n",
      "anchor NE candidates = \n",
      "txt=Treviño on #HurricaneHarvey : We are getting ready for refugees. Let's not forget Coastal Bend communities. It is not just Houston.\n",
      "candidate 0=Bend\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Bend', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Bend', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['communities', 'NOUN', 2, 'dobj', 5]\n",
      "parent node subtree [['Coastal', 'PROPN', 4, 'compound', 3], ['Bend', 'PROPN', 5, 'compound', 4]]\n",
      "NE=Bend subtree=[['Coastal', 'PROPN', 4, 'compound', 3]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "txt=So... #Harvey for (European) scale. Corpus Christi is ~Milan Houston is ~München Beumont ~Salzburg Shreveport ~Prague <URL>\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "candidate 1=Prague\n",
      "anchor NE candidates = Corpus Christi,Prague\n",
      "data NE tree=[['Prague', 'PROPN', 12, 'appos', 14]]\n",
      "NE parse token at tree=1, token=0:\n",
      "['Prague', 'PROPN', 12, 'appos', 14]\n",
      "NE parent token:\n",
      "['Shreveport', 'PROPN', 9, 'appos', 12]\n",
      "txt=Because the horror and devastation of #Harvey was in Houston and Galveston not Corpus Cristi. Go to the heart of it all not a safe area <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Galveston\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Galveston', 'PROPN', 9, 'conj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Galveston', 'PROPN', 9, 'conj', 11]\n",
      "NE parent token:\n",
      "['Houston', 'PROPN', 8, 'pobj', 9]\n",
      "txt=Another crew from Euless and Haltom City heading out with a N. Texas strike team headed to Southeast Texas #Harvey <URL>\n",
      "candidate 0=Euless\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Euless', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Euless', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['from', 'ADP', 1, 'prep', 2]\n",
      "NE=Euless subtree=[['and', 'CCONJ', 3, 'cc', 4], ['Haltom', 'PROPN', 6, 'compound', 5], ['City', 'PROPN', 3, 'conj', 6]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Haltom City\n",
      "anchor NE candidates = Euless,Texas\n",
      "data NE tree=[['Haltom', 'PROPN', 6, 'compound', 5], ['City', 'PROPN', 3, 'conj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['City', 'PROPN', 3, 'conj', 6]\n",
      "NE parent token:\n",
      "['Euless', 'PROPN', 2, 'pobj', 3]\n",
      "txt=While airports are resuming service, getting a flight to Houston is not easy; Some folks flying to San Antonio, then driving. #Harvey\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=San Antonio\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['San', 'PROPN', 19, 'compound', 18], ['Antonio', 'PROPN', 17, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Antonio', 'PROPN', 17, 'pobj', 19]\n",
      "NE parent token:\n",
      "['to', 'ADP', 16, 'prep', 17]\n",
      "txt=Our claims adjusters are in Corpus Christi, Victoria & limited areas of Houston. To contact our claims team: <URL>\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Corpus', 'PROPN', 7, 'compound', 5], ['Christi', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Christi', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['Victoria', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['Corpus', 'PROPN', 7, 'compound', 5], ['Christi', 'PROPN', 7, 'compound', 6], ['&', 'CCONJ', 7, 'cc', 8], ['limited', 'ADJ', 10, 'amod', 9], ['areas', 'NOUN', 7, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Houston', 'PROPN', 11, 'pobj', 12]]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "txt=Sweet! There's no age limit on kindness. We're taking donations today @KATUNews - ocated at NE 21st & Sandy in PDX. #Harvey #TexasStrong <URL>\n",
      "candidate 0=Sandy\n",
      "anchor NE candidates = \n",
      "false negative with NE=sandy, txt=Sweet! There's no age limit on kindness. We're taking donations today @KATUNews - ocated at NE 21st & Sandy in PDX. #Harvey #TexasStrong <URL>\n",
      "txt=Better have a plan for DC, Baltimore, Philly, NYC, CLEVELAND, BUFFALO, TORONTO, OTTOWA, MONTREAL. And all between. GFS Model #harvey correct <URL>\n",
      "candidate 0=CLEVELAND\n",
      "anchor NE candidates = Philly,NYC\n",
      "data NE tree=[['CLEVELAND', 'PROPN', 13, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['CLEVELAND', 'PROPN', 13, 'compound', 9]\n",
      "NE parent token:\n",
      "['MONTREAL', 'PROPN', 4, 'pobj', 13]\n",
      "parent node subtree [['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8], ['CLEVELAND', 'PROPN', 13, 'compound', 9], ['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11], ['OTTOWA', 'PROPN', 13, 'compound', 12]]\n",
      "NE=CLEVELAND subtree=[['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound', 'compound', 'compound', 'compound']\n",
      "candidate 1=BUFFALO\n",
      "anchor NE candidates = NYC\n",
      "data NE tree=[['BUFFALO', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['BUFFALO', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['TORONTO', 'PROPN', 13, 'compound', 11]\n",
      "parent node subtree [['BUFFALO', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 2=TORONTO\n",
      "anchor NE candidates = \n",
      "candidate 3=MONTREAL\n",
      "anchor NE candidates = Baltimore,Philly,NYC\n",
      "data NE tree=[['MONTREAL', 'PROPN', 4, 'pobj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['MONTREAL', 'PROPN', 4, 'pobj', 13]\n",
      "NE parent token:\n",
      "['for', 'ADP', 3, 'prep', 4]\n",
      "NE=MONTREAL subtree=[['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8], ['CLEVELAND', 'PROPN', 13, 'compound', 9], ['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11], ['OTTOWA', 'PROPN', 13, 'compound', 12]]\n",
      "min node deps ['compound', 'compound', 'compound', 'compound']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=We're gonna be headed to Woodsboro, TX pop. 1,512 tomorrow to drop off supplies. #Harvey Amazon Wish List - <URL>\n",
      "candidate 0=Woodsboro\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Woodsboro', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Woodsboro', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 7, 'compound', 6]\n",
      "parent node subtree [['Woodsboro', 'PROPN', 6, 'compound', 5]]\n",
      "txt=@kellycass Good morning from Morgantown,WV. Watching today's rain & that impact on Cheat River watershed before #Irma arrives.\n",
      "candidate 0=Morgantown\n",
      "anchor NE candidates = WV\n",
      "txt=@ShiriSpear do you think #IRMA will directly hit North Florida / Orlando / WDW area. Flying from London to Orlando Thursday curious to kno?\n",
      "candidate 0=Orlando\n",
      "anchor NE candidates = Orlando,London,Orlando\n",
      "data NE tree=[['Orlando', 'PROPN', 13, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Orlando', 'PROPN', 13, 'nmod', 11]\n",
      "NE parent token:\n",
      "['WDW', 'PROPN', 14, 'compound', 13]\n",
      "parent node subtree [['/', 'SYM', 13, 'punct', 10], ['Orlando', 'PROPN', 13, 'nmod', 11], ['/', 'SYM', 13, 'punct', 12]]\n",
      "candidate 1=London\n",
      "anchor NE candidates = \n",
      "candidate 2=Orlando\n",
      "anchor NE candidates = Orlando,Orlando\n",
      "data NE tree=[['Orlando', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Orlando', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 3]\n",
      "txt=If #irma is still on FL track in two days, why not fill up all cruise ships in Miami, Cape canaveral etc with ppl - ship away from storm?\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "candidate 1=Cape canaveral\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Cape', 'PROPN', 21, 'compound', 19], ['canaveral', 'ADJ', 21, 'compound', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['canaveral', 'ADJ', 21, 'compound', 20]\n",
      "NE parent token:\n",
      "['etc', 'X', 17, 'pobj', 21]\n",
      "parent node subtree [['Miami', 'PROPN', 19, 'compound', 18], ['Cape', 'PROPN', 21, 'compound', 19], ['canaveral', 'ADJ', 21, 'compound', 20]]\n",
      "NE=Cape canaveral subtree=[['Miami', 'PROPN', 19, 'compound', 18]]\n",
      "min node deps ['compound']\n",
      "txt=@AmericanAir supposed to fly to the Dominican Republic, connection in Miami. Trying to switch to Mexico & you want to charge me? #Help #Irma\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Mexico\n",
      "data NE tree=[['Miami', 'PROPN', 9, 'pobj', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Miami', 'PROPN', 9, 'pobj', 10]\n",
      "NE parent token:\n",
      "['in', 'ADP', 8, 'prep', 9]\n",
      "txt=Hoping for a safe week for our friends at Hillsborough Area Regional Transit in Tampa, FL as they prepare for #HurricaneIrma .\n",
      "candidate 0=Tampa\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Tampa', 'PROPN', 15, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Tampa', 'PROPN', 15, 'compound', 14]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 13, 'pobj', 15]\n",
      "parent node subtree [['Tampa', 'PROPN', 15, 'compound', 14]]\n",
      "txt=Anna Maria Island evacuating 9/7/17 at 12:40 PM. Mileage check zero. Destination Clearwater then sweet home Alabama. #Irma please .\n",
      "candidate 0=Anna Maria Island\n",
      "anchor NE candidates = Alabama\n",
      "data NE tree=[['Anna', 'PROPN', 2, 'compound', 0], ['Maria', 'PROPN', 2, 'compound', 1], ['Island', 'PROPN', 3, 'nsubj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Island', 'PROPN', 3, 'nsubj', 2]\n",
      "NE parent token:\n",
      "['evacuating', 'VERB', 3, 'ROOT', 3]\n",
      "txt=My thoughts and prayers are with Miami and the entire State of Florida #HurricaneIrma\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Miami', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['with', 'ADP', 4, 'prep', 5]\n",
      "NE=Miami subtree=[['and', 'CCONJ', 6, 'cc', 7], ['the', 'DET', 10, 'det', 8], ['entire', 'ADJ', 10, 'amod', 9], ['State', 'NOUN', 6, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Florida', 'PROPN', 11, 'pobj', 12]]\n",
      "min node deps ['cc', 'conj']\n",
      "txt=#HurricaneIrma please go hit Washington DC *Specifically White House* Thanks the hole world\n",
      "candidate 0=White House\n",
      "anchor NE candidates = \n",
      "txt=JUST IN - A MANDATORY EVACUATION has been issued for Jacksonville, Florida. #CNN #Irma\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Jacksonville', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Jacksonville', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 8, 'pobj', 10]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 10, 'compound', 9]]\n",
      "txt=Made it to Tulsa last night from Fort Myers escaping #hurricaneirma . Just home we have a home back in FL when we get back. @jamesaydelott\n",
      "candidate 0=Fort Myers\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Fort', 'PROPN', 8, 'compound', 7], ['Myers', 'PROPN', 6, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Myers', 'PROPN', 6, 'pobj', 8]\n",
      "NE parent token:\n",
      "['from', 'ADP', 0, 'prep', 6]\n",
      "NE=Fort Myers subtree=[['escaping', 'VERB', 10, 'compound', 9], ['#hurricaneirma', 'PROPN', 8, 'appos', 10]]\n",
      "min node deps ['appos']\n",
      "subtree = escaping #hurricaneirma\n",
      "txt=Friends in Miami and Florida, good luck and be safe! #hurricaneirma #irma #miamibeach <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 1, 'pobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Miami', 'PROPN', 1, 'pobj', 2]\n",
      "NE parent token:\n",
      "['in', 'ADP', 0, 'prep', 1]\n",
      "NE=Miami subtree=[['and', 'CCONJ', 2, 'cc', 3], ['Florida', 'PROPN', 2, 'conj', 4]]\n",
      "min node deps ['cc', 'conj']\n",
      "txt=Left FL to help in Houston, now the hope is that FL will weather the storm. Let's pray for all those in the path of #hurricaneirma\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Houston', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Houston', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 4]\n",
      "txt=LATEST: Hurricane #Irma is 405 miles southeast of Miami; it's spreading westward over parts of Cuba and the... <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Cuba\n",
      "data NE tree=[['Miami', 'PROPN', 8, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Miami', 'PROPN', 8, 'pobj', 9]\n",
      "NE parent token:\n",
      "['of', 'ADP', 7, 'prep', 8]\n",
      "txt=I hope everyone staying at the theme parks, Orlando, and throughout the entire state of Florida remains as safe as possible! #Irma\n",
      "candidate 0=Orlando\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Orlando', 'PROPN', 7, 'appos', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Orlando', 'PROPN', 7, 'appos', 8]\n",
      "NE parent token:\n",
      "['parks', 'NOUN', 4, 'pobj', 7]\n",
      "txt=No planes over Miami right now. That one you see is Air Europa 787 leaving soon for Madrid tonight. #HurricaneIrma <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "candidate 1=Madrid\n",
      "anchor NE candidates = Miami\n",
      "data NE tree=[['Madrid', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['Madrid', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['for', 'ADP', 8, 'prep', 10]\n",
      "txt=My family in Miami evacuated yesterday to Tampa. They aren't out of #Irma 's path completely, but I'm so grateful they were able to leave.\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = Miami\n",
      "data NE tree=[['Tampa', 'PROPN', 6, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Tampa', 'PROPN', 6, 'pobj', 7]\n",
      "NE parent token:\n",
      "['to', 'ADP', 4, 'prep', 6]\n",
      "txt=milfordonmove: Local Statement for Jacksonville, FL #disney #dcl #Irma <URL>\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Jacksonville', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Jacksonville', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 9, 'compound', 6]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 6, 'compound', 5]]\n",
      "txt=I expect #Irma to make landfall on MO 8 AM nearby Naples. Will hit Tampa at 2PM.\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Tampa\n",
      "data NE tree=[['Naples', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Naples', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['nearby', 'ADP', 4, 'advmod', 10]\n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = \n",
      "txt=#Irma is forecast to make landfall somewhere between Naples & Sarasota sometime Sun night & pass very near or over Tampa early Mon am. #flwx\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Sarasota,Tampa\n",
      "data NE tree=[['Naples', 'PROPN', 7, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Naples', 'PROPN', 7, 'pobj', 8]\n",
      "NE parent token:\n",
      "['between', 'ADP', 6, 'prep', 7]\n",
      "NE=Naples subtree=[['&', 'CCONJ', 8, 'cc', 9], ['Sarasota', 'PROPN', 8, 'conj', 10]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Sarasota\n",
      "anchor NE candidates = \n",
      "candidate 2=Tampa\n",
      "anchor NE candidates = Sarasota\n",
      "data NE tree=[['Tampa', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Tampa', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['over', 'ADP', 17, 'conj', 19]\n",
      "NE=Tampa subtree=[['early', 'ADJ', 22, 'amod', 21], ['Mon', 'PROPN', 20, 'appos', 22]]\n",
      "min node deps ['appos']\n",
      "subtree = early Mon\n",
      "txt=Friends and family in Florida facing Hurricane Irma, know you are in our thoughts and prayers in Charleston #hurricaneirma #charleston <URL>\n",
      "candidate 0=Charleston\n",
      "anchor NE candidates = \n",
      "txt=Curfews in effect during #HurricaneIrma in the cities of Miami, Miami Beach and North Miami Beach. No curfew for unincorporated Dade County. <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Dade County\n",
      "data NE tree=[['Miami', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Miami', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "parent node subtree [['Miami', 'PROPN', 11, 'compound', 9], ['Miami', 'PROPN', 11, 'compound', 10], ['and', 'CCONJ', 11, 'cc', 12], ['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "candidate 1=Miami Beach\n",
      "anchor NE candidates = Miami,Dade County\n",
      "data NE tree=[['Miami', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 8, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "NE parent token:\n",
      "['of', 'ADP', 7, 'prep', 8]\n",
      "NE=Miami Beach subtree=[['Miami', 'PROPN', 11, 'compound', 9], ['and', 'CCONJ', 11, 'cc', 12], ['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 2=North Miami Beach\n",
      "anchor NE candidates = Miami,Miami Beach,Dade County\n",
      "data NE tree=[['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Beach', 'PROPN', 11, 'conj', 15]\n",
      "NE parent token:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "candidate 3=Dade County\n",
      "anchor NE candidates = \n",
      "txt=Sincerely hope everyone in Florida & Miami is safe and prepared for #Irma (as well as you can be) thoughts and prayers for those affected.\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "txt=#JewishTimes #Florida #RickScott #HurricaneIrma Irma closes in with Tampa, not Miami, in the crosshairs <URL>\n",
      "candidate 0=Tampa\n",
      "anchor NE candidates = Miami\n",
      "data NE tree=[['Tampa', 'PROPN', 10, 'nmod', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Tampa', 'PROPN', 10, 'nmod', 8]\n",
      "NE parent token:\n",
      "['Miami', 'PROPN', 7, 'pobj', 10]\n",
      "parent node subtree [['Tampa', 'PROPN', 10, 'nmod', 8], ['not', 'ADV', 10, 'neg', 9], ['in', 'ADP', 10, 'prep', 11], ['the', 'DET', 13, 'det', 12], ['crosshairs', 'NOUN', 11, 'pobj', 13]]\n",
      "candidate 1=Miami\n",
      "anchor NE candidates = \n",
      "txt=High wind watch for Cleveland county and lake wind adv. for Lancaster and Chesterfield due to #Irma . #scwx #ncwx <URL>\n",
      "candidate 0=Lancaster\n",
      "anchor NE candidates = \n",
      "candidate 1=Chesterfield\n",
      "anchor NE candidates = Cleveland county\n",
      "data NE tree=[['Chesterfield', 'PROPN', 1, 'conj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Chesterfield', 'PROPN', 1, 'conj', 3]\n",
      "NE parent token:\n",
      "['Lancaster', 'PROPN', 0, 'pobj', 1]\n",
      "txt=. @CityofMiami mayor tells @MLauer he reached out to mayors of Naples, Ft. Myers, Sarasota & Tampa yesterday to offer help #HurricaneIrma\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Myers,Sarasota,Tampa\n",
      "data NE tree=[['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['Naples', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Ft', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=Myers\n",
      "anchor NE candidates = Sarasota,Tampa\n",
      "data NE tree=[['Myers', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['Myers', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['Sarasota', 'PROPN', 14, 'ROOT', 14]\n",
      "parent node subtree [['Myers', 'PROPN', 14, 'compound', 13], ['&', 'CCONJ', 14, 'cc', 15], ['Tampa', 'PROPN', 14, 'conj', 16], ['yesterday', 'NOUN', 14, 'npadvmod', 17], ['to', 'PART', 19, 'aux', 18], ['offer', 'VERB', 14, 'relcl', 19], ['help', 'NOUN', 19, 'dobj', 20], ['#HurricaneIrma', 'PUNCT', 14, 'punct', 21]]\n",
      "candidate 2=Sarasota\n",
      "anchor NE candidates = \n",
      "candidate 3=Tampa\n",
      "anchor NE candidates = Sarasota\n",
      "data NE tree=[['Tampa', 'PROPN', 14, 'conj', 16]]\n",
      "NE parse token at tree=1, token=17:\n",
      "['Tampa', 'PROPN', 14, 'conj', 16]\n",
      "NE parent token:\n",
      "['Sarasota', 'PROPN', 14, 'ROOT', 14]\n",
      "txt=Evacuation! Keep safe everyone! #hurricane #irma — traveling to Greenville, South Carolina\n",
      "candidate 0=Greenville\n",
      "anchor NE candidates = South Carolina\n",
      "data NE tree=[['Greenville', 'PROPN', 7, 'compound', 5]]\n",
      "NE parse token at tree=2, token=6:\n",
      "['Greenville', 'PROPN', 7, 'compound', 5]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['Greenville', 'PROPN', 7, 'compound', 5], ['South', 'PROPN', 7, 'compound', 6]]\n",
      "txt=@MSNBC Appreciate thoroughness on #Irma but at what point do you cover prep/problems NORTH of Keys/Miami? & how's Houston? Nature itself?!\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Miami', 'PROPN', 16, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Miami', 'PROPN', 16, 'pobj', 19]\n",
      "NE parent token:\n",
      "['of', 'ADP', 15, 'prep', 16]\n",
      "NE=Miami subtree=[['Keys', 'PROPN', 19, 'nmod', 17], ['/', 'SYM', 19, 'punct', 18]]\n",
      "min node deps ['nmod', 'punct']\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Heavy flooding right now on the streets of Downtown Miami in Florida #Irma\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 7, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Miami', 'PROPN', 7, 'pobj', 9]\n",
      "NE parent token:\n",
      "['of', 'ADP', 6, 'prep', 7]\n",
      "NE=Miami subtree=[['Downtown', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "txt=Still a long way to go but it is looking like #Irma may make landfall between Naples and Fort Myers.\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Fort Myers\n",
      "data NE tree=[['Naples', 'PROPN', 15, 'pobj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Naples', 'PROPN', 15, 'pobj', 16]\n",
      "NE parent token:\n",
      "['between', 'ADP', 14, 'prep', 15]\n",
      "NE=Naples subtree=[['and', 'CCONJ', 16, 'cc', 17], ['Fort', 'PROPN', 19, 'compound', 18], ['Myers', 'PROPN', 16, 'conj', 19]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Fort Myers\n",
      "anchor NE candidates = \n",
      "txt=Pray for Florida as hurricane Irma impacts Miami. #hurricaneirma <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "txt=cnnbrk: #HurricaneIrma ’s intense rain and wind pound JohnBerman in Miami. 75% of Miami-Dade County is now without… <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Miami-Dade County\n",
      "data NE tree=[['Miami', 'PROPN', 11, 'pobj', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Miami', 'PROPN', 11, 'pobj', 12]\n",
      "NE parent token:\n",
      "['in', 'ADP', 10, 'prep', 11]\n",
      "candidate 1=Miami-Dade County\n",
      "anchor NE candidates = \n",
      "txt=#Irma just made landfall with FL mainland on Marco Island as a Category 3!! @yohoster @GaryBrennan10 @MichaelDillman @MrJShupp @Skena3 <URL>\n",
      "candidate 0=Marco Island\n",
      "anchor NE candidates = \n",
      "txt=Indian River Dr and Sunset Terrace, Cocoa. Drivers need to use Highview Dr from the south or Forest Hill Dr from the North #Irma <URL>\n",
      "candidate 0=Sunset Terrace\n",
      "anchor NE candidates = Cocoa,Forest Hill\n",
      "data NE tree=[['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Terrace', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['Cocoa', 'PROPN', 2, 'conj', 6]\n",
      "parent node subtree [['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=Cocoa\n",
      "anchor NE candidates = Indian River,Cocoa,Forest Hill\n",
      "data NE tree=[['Cocoa', 'PROPN', 2, 'conj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Cocoa', 'PROPN', 2, 'conj', 6]\n",
      "NE parent token:\n",
      "['Dr', 'PROPN', 2, 'ROOT', 2]\n",
      "NE=Cocoa subtree=[['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5]]\n",
      "min node deps ['compound', 'compound']\n",
      "txt=3.3 million in Florida w/o power, 80% of Miami-Dade w/o power #HurricaneIrma\n",
      "candidate 0=Miami-Dade\n",
      "anchor NE candidates = \n",
      "txt=Flash Flood Warning in effect in Clay, Duval, Nassau and St. Johns Counties until 830 AM #flwx #HurricaneIrma <URL>\n",
      "candidate 0=Duval\n",
      "anchor NE candidates = Nassau\n",
      "data NE tree=[['Duval', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Duval', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Nassau', 'PROPN', 5, 'pobj', 8]\n",
      "parent node subtree [['Clay', 'PROPN', 8, 'compound', 6], ['Duval', 'PROPN', 8, 'compound', 7], ['and', 'CCONJ', 8, 'cc', 9], ['St', 'PROPN', 8, 'conj', 10]]\n",
      "candidate 1=Nassau\n",
      "anchor NE candidates = \n",
      "txt=Power outages from my friends in Miami-dade, to Orlando, and now Tallahassee #HurricaneIrma\n",
      "candidate 0=Orlando\n",
      "anchor NE candidates = \n",
      "candidate 1=Tallahassee\n",
      "anchor NE candidates = Orlando\n",
      "data NE tree=[['Tallahassee', 'PROPN', 8, 'conj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Tallahassee', 'PROPN', 8, 'conj', 11]\n",
      "NE parent token:\n",
      "['Orlando', 'PROPN', 7, 'pobj', 8]\n",
      "NE=Tallahassee subtree=[['now', 'ADV', 11, 'advmod', 10]]\n",
      "min node deps ['advmod']\n",
      "txt=Irma has arrived in Augusta, Georgia. The power just went out. #hurricaneirma\n",
      "candidate 0=Augusta\n",
      "anchor NE candidates = Georgia\n",
      "data NE tree=[['Augusta', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Augusta', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Georgia', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Augusta', 'PROPN', 5, 'compound', 4]]\n",
      "txt=New tornado warning for parts of Beaufort, Colleton County #Irma #Chswx <URL>\n",
      "candidate 0=Beaufort\n",
      "anchor NE candidates = Colleton County\n",
      "data NE tree=[['Beaufort', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Beaufort', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 10, 'compound', 8]\n",
      "parent node subtree [['Beaufort', 'PROPN', 8, 'compound', 6], ['Colleton', 'PROPN', 8, 'compound', 7]]\n",
      "candidate 1=Colleton County\n",
      "anchor NE candidates = \n",
      "txt=Power outages in GA/ flooding in Charleston, SC and Jacksonville. Just a few of the reports today as #Irma moves North. #GAwx #SCwx <URL>\n",
      "candidate 0=Charleston\n",
      "anchor NE candidates = \n",
      "candidate 1=Jacksonville\n",
      "anchor NE candidates = GA,SC,Jacksonville\n",
      "data NE tree=[['Jacksonville', 'PROPN', 8, 'conj', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Jacksonville', 'PROPN', 8, 'conj', 10]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 6, 'pobj', 8]\n",
      "txt=Told someone I was from Cleveland while covering #HurricaneIrma in Jacksonville, FL. First question: What number are the @indians on #19baby\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Jacksonville', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Jacksonville', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 11, 'compound', 10]]\n",
      "txt=#Irma Seeing pockets of heavy traffic SB I-75 from Gainesville thru Ocala as people return to their homes\n",
      "candidate 0=Gainesville\n",
      "anchor NE candidates = \n",
      "candidate 1=Ocala\n",
      "anchor NE candidates = Gainesville\n",
      "data NE tree=[['Ocala', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Ocala', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['thru', 'ADP', 5, 'prep', 10]\n",
      "txt=Volunteers from @MuslimYouthUSA working with @HFUSA in Miami, Tampa, Naples and Jacksonville doing #HurricaneIrma cleanup work <URL>\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Jacksonville\n",
      "data NE tree=[['Miami', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Miami', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Naples', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = Miami,Jacksonville\n",
      "data NE tree=[['Tampa', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Tampa', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['Naples', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "candidate 2=Naples\n",
      "anchor NE candidates = Miami,Tampa,Jacksonville\n",
      "data NE tree=[['Naples', 'PROPN', 6, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Naples', 'PROPN', 6, 'pobj', 9]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 6]\n",
      "NE=Naples subtree=[['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "min node deps ['compound', 'compound', 'cc', 'conj']\n",
      "candidate 3=Jacksonville\n",
      "anchor NE candidates = \n",
      "txt=Sarasota County have been very fortunate, that hurricane #Irma did not impact our area as much as it did to other counties in Florida.\n",
      "candidate 0=Sarasota County\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Sarasota', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['County', 'PROPN', 3, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['been', 'VERB', 3, 'ROOT', 3]\n",
      "txt=Day 5 no power, limited gas after #hurricaneirma came across us in Naples, FL. Hoping and praying we get power soon. We are safe\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Naples', 'PROPN', 13, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Naples', 'PROPN', 13, 'compound', 12]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 11, 'pobj', 13]\n",
      "parent node subtree [['Naples', 'PROPN', 13, 'compound', 12]]\n",
      "txt=@mitchellreports We have major destruction in Polk County Florida. Including Lakeland, bartow,Lake Whales. No power. #Irma\n",
      "candidate 0=Lakeland\n",
      "anchor NE candidates = \n",
      "candidate 1=Lake\n",
      "anchor NE candidates = Lakeland\n",
      "txt=Update on lifting of boil water alert for Hollywood, Pembroke park, Miramar, West Park & Dania Beach. #Irma <URL>\n",
      "candidate 0=Hollywood\n",
      "anchor NE candidates = \n",
      "candidate 1=Pembroke park\n",
      "anchor NE candidates = Hollywood,Miramar,West Park,Dania Beach\n",
      "data NE tree=[['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['park', 'NOUN', 13, 'compound', 10]\n",
      "NE parent token:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "parent node subtree [['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['West', 'PROPN', 13, 'compound', 12], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "NE=Pembroke park subtree=[['Hollywood', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Miramar\n",
      "anchor NE candidates = Hollywood\n",
      "data NE tree=[['Miramar', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Miramar', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "parent node subtree [['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['West', 'PROPN', 13, 'compound', 12], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "candidate 3=West Park\n",
      "anchor NE candidates = Hollywood,Miramar,Dania Beach\n",
      "data NE tree=[['West', 'PROPN', 13, 'compound', 12], ['Park', 'PROPN', 7, 'pobj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "NE parent token:\n",
      "['for', 'ADP', 2, 'prep', 7]\n",
      "NE=West Park subtree=[['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "min node deps ['compound']\n",
      "candidate 4=Dania Beach\n",
      "anchor NE candidates = Hollywood,Miramar\n",
      "data NE tree=[['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Beach', 'PROPN', 13, 'conj', 16]\n",
      "NE parent token:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "txt=@andersoncooper #HurricaneIrma Glad to have you in Tampa. I was in Clearwater riding out the storm-I wanted to race to Tampa to meet you.\n",
      "candidate 0=Tampa\n",
      "anchor NE candidates = \n",
      "candidate 1=Clearwater\n",
      "anchor NE candidates = Tampa,Tampa\n",
      "data NE tree=[['Clearwater', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Clearwater', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "NE=Clearwater subtree=[['riding', 'VERB', 3, 'acl', 4], ['out', 'PART', 4, 'prt', 5], ['the', 'DET', 7, 'det', 6], ['stormI', 'NOUN', 4, 'dobj', 7]]\n",
      "min node deps ['acl']\n",
      "subtree = riding out the stormI\n",
      "candidate 2=Tampa\n",
      "anchor NE candidates = \n",
      "txt=Emotional homecoming for our 80-person AZ TaskForce 1. First deployed for search & rescue in Houston for #Harvey then to Florida for #Irma . <URL>\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Houston', 'PROPN', 6, 'pobj', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Houston', 'PROPN', 6, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 6]\n",
      "txt=The Status of Our Parks - Along the Gulfshore - September 2017 - Naples, FL #HurricaneIrma <URL>\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Naples', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 12, 'compound', 11]\n",
      "parent node subtree [['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "txt=A Hurricane Warning has been issued for Puerto Rico, Culebra, and Vieques. #Maria <URL>\n",
      "candidate 0=Vieques\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=first band of #maria in San Juan , Puerto Rico <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Juan', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 4, 'pobj', 8]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6], ['Puerto', 'PROPN', 8, 'compound', 7]]\n",
      "txt=#Hurricane warnings for: U.S. Virgin Islands, British Virgin Islands, Puerto Rico, Culebra, and Vieques #Maria @680NEWS @680NEWS\n",
      "candidate 0=Culebra\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Culebra', 'PROPN', 15, 'ROOT', 15]]\n",
      "NE=Culebra subtree=[['Virgin', 'PROPN', 9, 'compound', 8], ['Islands', 'PROPN', 12, 'compound', 9], ['British', 'ADJ', 12, 'amod', 10], ['Virgin', 'PROPN', 12, 'compound', 11], ['Islands', 'PROPN', 15, 'compound', 12], ['Puerto', 'PROPN', 15, 'compound', 13], ['Rico', 'PROPN', 15, 'compound', 14], ['and', 'CCONJ', 15, 'cc', 16], ['Vieques', 'PROPN', 18, 'compound', 17], ['#Maria', 'X', 15, 'conj', 18]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Vieques\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Vieques', 'PROPN', 18, 'compound', 17]]\n",
      "NE parse token at tree=0, token=18:\n",
      "['Vieques', 'PROPN', 18, 'compound', 17]\n",
      "NE parent token:\n",
      "['#Maria', 'X', 15, 'conj', 18]\n",
      "parent node subtree [['Vieques', 'PROPN', 18, 'compound', 17]]\n",
      "txt=This is how Ponce, Puerto Rico looked about 30 mins ago. #Maria <URL>\n",
      "candidate 0=Ponce\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Ponce', 'PROPN', 5, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Ponce', 'PROPN', 5, 'compound', 3]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 6, 'nsubj', 5]\n",
      "parent node subtree [['Ponce', 'PROPN', 5, 'compound', 3], ['Puerto', 'PROPN', 5, 'compound', 4]]\n",
      "txt=RT @hurrtrackerapp: BREAKING: Hurricane #Maria makes landfall near Yabucoa, Puerto Rico as a 155 mph, category 4 storm. <URL>\n",
      "candidate 0=Yabucoa\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Yabucoa', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Yabucoa', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Yabucoa', 'PROPN', 12, 'compound', 10], ['Puerto', 'PROPN', 12, 'compound', 11]]\n",
      "txt=Went to Humacao, Yabucoa and Vieques multiple times in the mid-aughts. So scary to watch Maria right now #puertorico\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 1, 'pobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Yabucoa', 'PROPN', 1, 'pobj', 3]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "NE=Yabucoa subtree=[['Humacao', 'PROPN', 3, 'compound', 2], ['and', 'CCONJ', 3, 'cc', 4], ['Vieques', 'PROPN', 3, 'conj', 5]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 2=Vieques\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Vieques', 'PROPN', 3, 'conj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Vieques', 'PROPN', 3, 'conj', 5]\n",
      "NE parent token:\n",
      "['Yabucoa', 'PROPN', 1, 'pobj', 3]\n",
      "txt=Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 6, 'flat', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Yabucoa', 'PROPN', 6, 'flat', 8]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 4, 'obl', 6]\n",
      "candidate 2=Maunabo\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Maunabo', 'PROPN', 6, 'flat', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Maunabo', 'PROPN', 6, 'flat', 9]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 4, 'obl', 6]\n",
      "txt=NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria — NWS San Juan (NWSS…\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 8, 'flat', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Yabucoa', 'PROPN', 8, 'flat', 10]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 6, 'obl', 8]\n",
      "candidate 2=Maunabo\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Maunabo', 'PROPN', 8, 'flat', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Maunabo', 'PROPN', 8, 'flat', 11]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 6, 'obl', 8]\n",
      "txt=Anyone having luck connecting with San Juan, Puerto Rico? Are your texts going through? #PuertoRico #SanJuan #HurricaneMaria\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Juan', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 4, 'pobj', 8]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6], ['Puerto', 'PROPN', 8, 'compound', 7]]\n",
      "txt=#Maria ... footage from Guayama, Puerto Rico #huracanmaria #hurricanemaria <URL>\n",
      "candidate 0=Guayama\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Guayama', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Guayama', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 3, 'pobj', 6]\n",
      "parent node subtree [['Guayama', 'PROPN', 6, 'compound', 4], ['Puerto', 'PROPN', 6, 'compound', 5]]\n",
      "txt=UPDATE: Our San Juan office remains closed today as Puerto Rico is in a state of total devastation after #HurricaneMaria @NWSSanJuan\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Juan', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['office', 'NOUN', 6, 'nsubj', 5]\n",
      "parent node subtree [['Our', 'ADJ', 5, 'poss', 2], ['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 5, 'compound', 4]]\n",
      "txt=My heart & prayers are w/ my family in Puerto Rico. Aguadilla, Moca, San Sebastian, San Lorenzo & Mayaguez. ! #PuertoRicoStrong #PuertoRico\n",
      "candidate 0=San Sebastian\n",
      "anchor NE candidates = \n",
      "candidate 1=San Lorenzo\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 5, 'compound', 4], ['Lorenzo', 'PROPN', 5, 'ROOT', 5]]\n",
      "NE=San Lorenzo subtree=[['Aguadilla', 'PROPN', 1, 'compound', 0], ['Moca', 'PROPN', 5, 'compound', 1], ['San', 'PROPN', 3, 'compound', 2], ['Sebastian', 'PROPN', 5, 'compound', 3], ['&', 'CCONJ', 5, 'cc', 6], ['Mayaguez', 'PROPN', 5, 'conj', 7], ['.', 'PUNCT', 5, 'punct', 8]]\n",
      "min node deps ['compound']\n",
      "txt=Hurricane #Maria batters San Juan, Puerto Rico, with strong winds as the powerful storm comes ashore. <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Juan', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 2, 'dobj', 6]\n",
      "parent node subtree [['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 6, 'compound', 4], ['Puerto', 'PROPN', 6, 'compound', 5]]\n",
      "txt=Incredible video from earlier today of the strong winds and flooded road in San Juan, Puerto Rico. #Maria : @TheHungryCondor <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Juan', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 12, 'pobj', 16]\n",
      "parent node subtree [['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15]]\n",
      "txt=RT @NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 9, 'flat', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Yabucoa', 'PROPN', 9, 'flat', 11]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 7, 'obl', 9]\n",
      "candidate 2=Maunabo\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Maunabo', 'PROPN', 9, 'flat', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Maunabo', 'PROPN', 9, 'flat', 12]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 7, 'obl', 9]\n",
      "txt=Our prayers are with the staff and students of UM-related @robinson_school , located in San Juan, Puerto Rico, in the wake of #HurricaneMaria <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Juan', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 12, 'pobj', 16]\n",
      "parent node subtree [['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15]]\n",
      "txt=More destruction photos from Bayamón, Guaynabo and San Juan #Maria <URL>\n",
      "candidate 0=Bayamón\n",
      "anchor NE candidates = Bayamón,Guaynabo\n",
      "data NE tree=[['Bayamón', 'PROPN', 3, 'obj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Bayamón', 'PROPN', 3, 'obj', 4]\n",
      "NE parent token:\n",
      "['from', 'NOUN', 3, 'ROOT', 3]\n",
      "NE=Bayamón subtree=[['Guaynabo', 'PROPN', 4, 'flat', 5], ['and', 'PROPN', 4, 'flat', 6], ['San', 'PROPN', 4, 'flat', 7], ['Juan', 'PROPN', 4, 'flat', 8]]\n",
      "min node deps ['flat', 'flat', 'flat', 'flat']\n",
      "candidate 1=Guaynabo\n",
      "anchor NE candidates = \n",
      "txt=Si usted se dializa con Fresenius. Caguas, Rio Grande y Humacao van a estar ofreciendo servicios desde las 10am #puertorico\n",
      "candidate 0=Caguas\n",
      "anchor NE candidates = \n",
      "candidate 1=Humacao\n",
      "anchor NE candidates = Caguas\n",
      "data NE tree=[['Humacao', 'PROPN', 0, 'conj', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Humacao', 'PROPN', 0, 'conj', 4]\n",
      "NE parent token:\n",
      "['Caguas', 'PROPN', 8, 'nsubj', 0]\n",
      "NE=Humacao subtree=[['y', 'CONJ', 4, 'cc', 3]]\n",
      "min node deps ['cc']\n",
      "txt=#HuracanMaria Se deja sentir en Samana, Nagua, Santiago, La Altagracia, Santo Domingo Este y otras localidades. #Maria <URL>\n",
      "candidate 0=Santiago\n",
      "anchor NE candidates = \n",
      "candidate 1=Altagracia\n",
      "anchor NE candidates = Santiago\n",
      "data NE tree=[['Altagracia', 'PROPN', 5, 'flat', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Altagracia', 'PROPN', 5, 'flat', 9]\n",
      "NE parent token:\n",
      "['Samana', 'PROPN', 3, 'obl', 5]\n",
      "NE=Altagracia subtree=[['La', 'DET', 9, 'det', 8], ['Santo', 'PROPN', 9, 'flat', 10], ['Domingo', 'PROPN', 9, 'flat', 11], ['Este', 'PROPN', 9, 'flat', 12]]\n",
      "min node deps ['det', 'flat', 'flat', 'flat']\n",
      "txt=@weatherchannel is there any way we can hear of other towns in Puerto Rico? There aren’t only people in San Juan! #PuertoRico\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "txt=RT UnivisionNews: Exclusive video: The devastating path of Hurricane #Maria across #Puerto Rico, from Yabucoa to San Juan\n",
      "candidate 0=Yabucoa\n",
      "anchor NE candidates = Yabucoa,San Juan\n",
      "data NE tree=[['Yabucoa', 'PROPN', 15, 'pobj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Yabucoa', 'PROPN', 15, 'pobj', 16]\n",
      "NE parent token:\n",
      "['from', 'ADP', 8, 'prep', 15]\n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = San Juan\n",
      "data NE tree=[['San', 'PROPN', 19, 'compound', 18], ['Juan', 'PROPN', 17, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=0:\n",
      "['Juan', 'PROPN', 17, 'pobj', 19]\n",
      "NE parent token:\n",
      "['to', 'ADP', 8, 'prep', 17]\n",
      "txt=Seeking info on my aunt Milly Bodon & Luis in Jayuya, Puerto Rico (Cuabey). Its only accessible by helicopter.No power/phone #HurricaneMaria <URL>\n",
      "candidate 0=Jayuya\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Jayuya', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Jayuya', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Jayuya', 'PROPN', 12, 'compound', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['(', 'PUNCT', 12, 'punct', 13], ['Cuabey', 'PROPN', 12, 'appos', 14], [')', 'PUNCT', 12, 'punct', 15]]\n",
      "txt=#SanJuan #PuertoRico Drone footage shows flooded streets in San Juan, Puerto Rico, after Hurricane #Maria . <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Juan', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 7, 'pobj', 11]\n",
      "parent node subtree [['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10]]\n",
      "txt=Inundación en áreas de Ocean Park y Santurce. #María #PuertoRico <URL>\n",
      "candidate 0=Ocean Park\n",
      "anchor NE candidates = \n",
      "candidate 1=Santurce\n",
      "anchor NE candidates = Ocean Park\n",
      "data NE tree=[['Santurce', 'PROPN', 4, 'conj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Santurce', 'PROPN', 4, 'conj', 7]\n",
      "NE parent token:\n",
      "['Ocean', 'PROPN', 2, 'nmod', 4]\n",
      "NE=Santurce subtree=[['y', 'CONJ', 7, 'cc', 6]]\n",
      "min node deps ['cc']\n",
      "txt=The current photos of Loíza, San Isidro & Toa baja are heartbreaking! The rebuild needed will be massive #HurricaneMaria #PuertoRico <URL>\n",
      "candidate 0=San Isidro\n",
      "anchor NE candidates = Toa baja\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Isidro', 'PROPN', 3, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Isidro', 'PROPN', 3, 'pobj', 6]\n",
      "NE parent token:\n",
      "['of', 'ADP', 2, 'prep', 3]\n",
      "NE=San Isidro subtree=[['Loíza', 'PROPN', 6, 'compound', 4], ['&', 'CCONJ', 6, 'cc', 7], ['Toa', 'PROPN', 6, 'conj', 8]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 1=Toa baja\n",
      "anchor NE candidates = \n",
      "txt=9-22-2017 Mabu Las Piedras, Juncos, Garabo, Caguas, southern San Juan Helicopter Video #Maria <URL>\n",
      "candidate 0=Las Piedras\n",
      "anchor NE candidates = Caguas,San Juan\n",
      "data NE tree=[['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Piedras', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['Juncos', 'PROPN', 6, 'nmod', 4]\n",
      "parent node subtree [['Mabu', 'PROPN', 3, 'compound', 1], ['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3]]\n",
      "NE=Las Piedras subtree=[['Mabu', 'PROPN', 3, 'compound', 1]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Caguas\n",
      "anchor NE candidates = San Juan\n",
      "data NE tree=[['Caguas', 'PROPN', 6, 'ROOT', 6]]\n",
      "NE=Caguas subtree=[['Mabu', 'PROPN', 3, 'compound', 1], ['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3], ['Juncos', 'PROPN', 6, 'nmod', 4], ['Garabo', 'PROPN', 6, 'nmod', 5], ['southern', 'ADJ', 12, 'amod', 7], ['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 12, 'compound', 9], ['Helicopter', 'PROPN', 12, 'compound', 10], ['Video', 'PROPN', 12, 'compound', 11], ['#Maria', 'PUNCT', 6, 'appos', 12]]\n",
      "min node deps ['compound', 'compound']\n",
      "candidate 2=San Juan\n",
      "anchor NE candidates = \n",
      "txt=Flash Flood Emergency for Quebradillas and Isabela, PR <URL>\n",
      "candidate 0=Quebradillas\n",
      "anchor NE candidates = Isabela\n",
      "data NE tree=[['Quebradillas', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Quebradillas', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['for', 'ADP', 2, 'prep', 3]\n",
      "NE=Quebradillas subtree=[['and', 'CCONJ', 4, 'cc', 5], ['Isabela', 'PROPN', 7, 'compound', 6], ['PR', 'PROPN', 4, 'conj', 7]]\n",
      "min node deps ['cc', 'conj']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=Retweeted ABC News ( @ABC ): Streets in San Juan, Puerto Rico remain flooded days after #Maria made landfall as a... <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Juan', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 7, 'pobj', 11]\n",
      "parent node subtree [['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10]]\n",
      "txt=Woohoo, Ponce and adjacent areas, help is coming! This is an update from mi tio in Tampa, who is monitoring faith organizations. #PuertoRico <URL>\n",
      "candidate 0=Ponce\n",
      "anchor NE candidates = Tampa\n",
      "data NE tree=[['Ponce', 'PROPN', 5, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Ponce', 'PROPN', 5, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['help', 'VERB', 7, 'nsubj', 5]\n",
      "NE=Ponce subtree=[['Woohoo', 'PROPN', 1, 'compound', 0], ['and', 'CCONJ', 1, 'cc', 2], ['adjacent', 'ADJ', 4, 'amod', 3], ['areas', 'NOUN', 1, 'conj', 4]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "txt=Update on #HurricaneMaria . My cousin drove to #Yauco and said Costa Sur, Barinas, Almácigo, Palomas, La Quinta are ok. Luchetti is destroyed\n",
      "candidate 0=Barinas\n",
      "anchor NE candidates = Palomas,La Quinta\n",
      "data NE tree=[['Barinas', 'PROPN', 13, 'compound', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Barinas', 'PROPN', 13, 'compound', 9]\n",
      "NE parent token:\n",
      "['Quinta', 'PROPN', 14, 'nsubj', 13]\n",
      "parent node subtree [['Costa', 'PROPN', 13, 'compound', 7], ['Sur', 'PROPN', 13, 'compound', 8], ['Barinas', 'PROPN', 13, 'compound', 9], ['Almácigo', 'PROPN', 13, 'compound', 10], ['Palomas', 'PROPN', 13, 'compound', 11], ['La', 'PROPN', 13, 'compound', 12]]\n",
      "candidate 1=Palomas\n",
      "anchor NE candidates = La Quinta\n",
      "data NE tree=[['Palomas', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['Palomas', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['Quinta', 'PROPN', 14, 'nsubj', 13]\n",
      "parent node subtree [['Costa', 'PROPN', 13, 'compound', 7], ['Sur', 'PROPN', 13, 'compound', 8], ['Barinas', 'PROPN', 13, 'compound', 9], ['Almácigo', 'PROPN', 13, 'compound', 10], ['Palomas', 'PROPN', 13, 'compound', 11], ['La', 'PROPN', 13, 'compound', 12]]\n",
      "candidate 2=La Quinta\n",
      "anchor NE candidates = \n",
      "txt=Vega Alta, a 40 min drive from San Juan, has not seen aid a week after #Maria . Hospital on verge of shutting down. <URL>\n",
      "candidate 0=Vega Alta\n",
      "anchor NE candidates = San Juan\n",
      "data NE tree=[['Vega', 'PROPN', 1, 'compound', 0], ['Alta', 'PROPN', 11, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Alta', 'PROPN', 11, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['seen', 'VERB', 11, 'ROOT', 11]\n",
      "NE=Vega Alta subtree=[['a', 'DET', 5, 'det', 2], ['40', 'NUM', 4, 'nummod', 3], ['min', 'NOUN', 5, 'compound', 4], ['drive', 'NOUN', 1, 'appos', 5], ['from', 'ADP', 5, 'prep', 6], ['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 6, 'pobj', 8]]\n",
      "min node deps ['appos']\n",
      "subtree = a 40 min drive from San Juan\n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = \n",
      "txt=Toa Alta, Puerto Rico: A cyclist rides over a bridge damaged by #HurricaneMaria . Photograph: Ricardo Arduengo/AFP #ClimateChange #Capitalism <URL>\n",
      "candidate 0=Toa Alta\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Toa', 'PROPN', 3, 'compound', 0], ['Alta', 'PROPN', 3, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Alta', 'PROPN', 3, 'compound', 1]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 3, 'ROOT', 3]\n",
      "parent node subtree [['Toa', 'PROPN', 3, 'compound', 0], ['Alta', 'PROPN', 3, 'compound', 1], ['Puerto', 'PROPN', 3, 'compound', 2], [':', 'PUNCT', 3, 'punct', 4]]\n",
      "txt=Puerto Rico humanitarian crisis Trump talking about Wall Street + banks San Juan Mayor Carmen Yulin Cruz #Maria <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "txt=#PuertoRico Some towns in Puerto Rico have been able to set up hotlines to find family: San Juan 787-294-0277... <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "txt=From the San Juan, Puerto Rico mayor. Heart wrenching. #PuertoRico <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 6, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Juan', 'PROPN', 6, 'compound', 3]\n",
      "NE parent token:\n",
      "['mayor', 'NOUN', 0, 'pobj', 6]\n",
      "parent node subtree [['the', 'DET', 6, 'det', 1], ['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 6, 'compound', 3], ['Puerto', 'PROPN', 5, 'compound', 4], ['Rico', 'PROPN', 6, 'compound', 5]]\n",
      "txt=Trump: If the mayor of San Juan doesn't start praising me, I'll pull ALL relief efforts from Puerto Rico. @realdonaldtRump #maga #PuertoRico\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 7, 'compound', 6], ['Juan', 'PROPN', 5, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Juan', 'PROPN', 5, 'pobj', 7]\n",
      "NE parent token:\n",
      "['of', 'ADP', 4, 'prep', 5]\n",
      "txt=Dodges the draft, attacks John McCain. Plays golf in NJ, attacks mayor of hurricane ravaged San Juan. #puertorico #weakness #trump <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "txt=Can we please help Puerto Rico? Mayor of San Juan is literally begging for aid! Instead of helping @realDonaldTrump is golfing! #PuertoRico\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "txt=Wow, @potus tries to help Puerto Rico and all the mayor of San Juan can say is how bad he is. Thanks for nothing I guess. #puertorico\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "txt=El SNM emite aviso de inundaciones repentinas para los municipios de Fajardo, Naguabo, Luquillo, Ceiba hasta las 5:45 p.m. #HuracanMaria E…\n",
      "candidate 0=Naguabo\n",
      "anchor NE candidates = \n",
      "candidate 1=Luquillo\n",
      "anchor NE candidates = Naguabo\n",
      "data NE tree=[['Luquillo', 'PROPN', 11, 'flat', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Luquillo', 'PROPN', 11, 'flat', 13]\n",
      "NE parent token:\n",
      "['Fajardo', 'PROPN', 9, 'nmod', 11]\n",
      "txt=We are on the ground delivering Food helping our people in #PuertoRico this weekend, Toa Baja, Morovis , Orocovis. @FeedingAmerica <URL>\n",
      "candidate 0=Toa Baja\n",
      "anchor NE candidates = \n",
      "candidate 1=Morovis\n",
      "anchor NE candidates = Toa Baja\n",
      "data NE tree=[['Morovis', 'PROPN', 17, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Morovis', 'PROPN', 17, 'compound', 16]\n",
      "NE parent token:\n",
      "['Orocovis', 'PROPN', 17, 'ROOT', 17]\n",
      "parent node subtree [['Toa', 'PROPN', 17, 'compound', 14], ['Baja', 'PROPN', 17, 'compound', 15], ['Morovis', 'PROPN', 17, 'compound', 16], ['.', 'PUNCT', 17, 'punct', 18]]\n",
      "candidate 2=Orocovis\n",
      "anchor NE candidates = Toa Baja,Morovis\n",
      "data NE tree=[['Orocovis', 'PROPN', 17, 'ROOT', 17]]\n",
      "NE=Orocovis subtree=[['Toa', 'PROPN', 17, 'compound', 14], ['Baja', 'PROPN', 17, 'compound', 15], ['Morovis', 'PROPN', 17, 'compound', 16], ['.', 'PUNCT', 17, 'punct', 18]]\n",
      "min node deps ['compound', 'compound', 'compound', 'punct']\n",
      "txt=President @realDonaldTrump the Mayor of San Juan does not represent the majority in Puerto Rico. Thanks for your support. #PuertoRico\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 4, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Juan', 'PROPN', 4, 'pobj', 6]\n",
      "NE parent token:\n",
      "['of', 'ADP', 3, 'prep', 4]\n",
      "txt=Pres Trump expected to travel to Puerto Rico tom as scheduled to Survey damage from #Maria . Then heads to Vegas on Wed. #VegasShooting\n",
      "candidate 0=Vegas\n",
      "anchor NE candidates = \n",
      "txt=Eye of the Storm: A dispatch from San Juan, Puerto Rico by @sodapopcomics <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Juan', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 7, 'pobj', 11]\n",
      "parent node subtree [['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10]]\n",
      "txt=Our potus is in Guaynabo -one of the wealthiest towns in Puerto Rico - does anyone know if he plans to go out of San Juan?? #hurricanemaria\n",
      "candidate 0=Guaynabo\n",
      "anchor NE candidates = Puerto Rico,San Juan\n",
      "data NE tree=[['Guaynabo', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Guaynabo', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "NE=Guaynabo subtree=[['one', 'NUM', 4, 'nummod', 5], ['of', 'ADP', 5, 'prep', 6], ['the', 'DET', 9, 'det', 7], ['wealthiest', 'ADJ', 9, 'amod', 8], ['towns', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 10, 'pobj', 12]]\n",
      "min node deps ['nummod']\n",
      "subtree = one of the wealthiest towns in Puerto Rico\n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = \n",
      "txt=Welcome to PR, Mr. President @Old San Juan, Puerto Rico. @realDonaldTrump #PuertoRico #HuracanMaria #TrumpBully <URL>\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 10, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Juan', 'PROPN', 10, 'compound', 8]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 6, 'dobj', 10]\n",
      "parent node subtree [['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 10, 'compound', 8], ['Puerto', 'PROPN', 10, 'compound', 9]]\n",
      "txt=Photos of the land in front of my family's house in Cidra, Puerto Rico. My heart continues to ache for my people @PuertoRicoPUR #Maria <URL>\n",
      "candidate 0=Cidra\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Cidra', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Cidra', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 10, 'pobj', 13]\n",
      "parent node subtree [['Cidra', 'PROPN', 13, 'compound', 11], ['Puerto', 'PROPN', 13, 'compound', 12]]\n",
      "txt=Watch: A CG aircrew air drops much needed supplies to the residents of Utuado, Puerto Rico after #HurricaneMaria left them stranded <URL>\n",
      "candidate 0=Utuado\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Utuado', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Utuado', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 13, 'pobj', 16]\n",
      "parent node subtree [['Utuado', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15]]\n",
      "txt=St John, St Croix, St Thomas, Water Island, Puerto Rico, Culebra, Vieques are ALL US territories & ALL need help! #hurricanemaria\n",
      "candidate 0=Culebra\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Culebra', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Culebra', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Vieques', 'PROPN', 12, 'nsubj', 11]\n",
      "parent node subtree [['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5], ['Water', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 11, 'compound', 7], ['Puerto', 'PROPN', 9, 'compound', 8], ['Rico', 'PROPN', 11, 'compound', 9], ['Culebra', 'PROPN', 11, 'compound', 10]]\n",
      "candidate 1=Vieques\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Vieques', 'PROPN', 12, 'nsubj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Vieques', 'PROPN', 12, 'nsubj', 11]\n",
      "NE parent token:\n",
      "['are', 'VERB', 12, 'ROOT', 12]\n",
      "NE=Vieques subtree=[['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5], ['Water', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 11, 'compound', 7], ['Puerto', 'PROPN', 9, 'compound', 8], ['Rico', 'PROPN', 11, 'compound', 9], ['Culebra', 'PROPN', 11, 'compound', 10]]\n",
      "min node deps ['compound', 'compound']\n",
      "txt=The latest reliable models available (from this morning) ALL keep Hurricane force *sustained* winds out of #Tallahassee from #HurricaneMichael . However Gadsden & Liberty will still per these models get Hurricane force winds so it’s close enough to Tallahassee to worry.\n",
      "candidate 0=Gadsden\n",
      "anchor NE candidates = Liberty,Tallahassee\n",
      "data NE tree=[['Gadsden', 'PROPN', 6, 'nsubj', 1]]\n",
      "NE parse token at tree=1, token=2:\n",
      "['Gadsden', 'PROPN', 6, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['per', 'ADP', 9, 'prep', 6]\n",
      "NE=Gadsden subtree=[['&', 'CCONJ', 1, 'cc', 2], ['Liberty', 'PROPN', 1, 'conj', 3]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Liberty\n",
      "anchor NE candidates = Tallahassee\n",
      "data NE tree=[['Liberty', 'PROPN', 1, 'conj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Liberty', 'PROPN', 1, 'conj', 3]\n",
      "NE parent token:\n",
      "['Gadsden', 'PROPN', 6, 'nsubj', 1]\n",
      "candidate 2=Tallahassee\n",
      "anchor NE candidates = \n",
      "txt=HurriCation Self Portrait 3. Nice work on the backdrop katebackdrops #hurricanemichaelmademedoit #longexposure @ Tallahassee, Florida <URL>\n",
      "candidate 0=Tallahassee\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Tallahassee', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Tallahassee', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 10, 'ROOT', 10]\n",
      "parent node subtree [['Tallahassee', 'PROPN', 10, 'compound', 9]]\n",
      "txt=RT @weartv: Massive construction cranes loom over the skyline in Panama City Beach as #HurricaneMichael takes aim at the #Florida Panhandle…\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = \n",
      "candidate 1=Panhandle\n",
      "anchor NE candidates = Panama City Beach\n",
      "data NE tree=[['Panhandle', 'PROPN', 18, 'pobj', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Panhandle', 'PROPN', 18, 'pobj', 21]\n",
      "NE parent token:\n",
      "['at', 'ADP', 16, 'prep', 18]\n",
      "NE=Panhandle subtree=[['the', 'DET', 20, 'det', 19], ['#Florida', 'PROPN', 21, 'compound', 20]]\n",
      "min node deps ['det']\n",
      "txt=Please be safe my Florida and Gulf Shores friends!! Praying for you! #HurricaneMichael\n",
      "candidate 0=Gulf Shores\n",
      "anchor NE candidates = \n",
      "txt=#hurricanemichael, Siesta Key Beach, Sarasota, Florida.Only brits 🇬🇧 left on the beach. Sending love further up the panhandle. <URL>\n",
      "candidate 0=Sarasota\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Sarasota', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Sarasota', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['brits', 'NOUN', 9, 'nsubj', 6]\n",
      "parent node subtree [['Siesta', 'PROPN', 2, 'compound', 1], ['Key', 'PROPN', 3, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3], ['Sarasota', 'PROPN', 6, 'compound', 4], ['Florida.Only', 'ADV', 6, 'compound', 5]]\n",
      "NE=Sarasota subtree=[['Siesta', 'PROPN', 2, 'compound', 1], ['Key', 'PROPN', 3, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3]]\n",
      "min node deps ['compound']\n",
      "txt=Our first #HurricaneMichael response teams have arrived at a staging area in Okaloosa County, FL, just across the b… <URL>\n",
      "candidate 0=Okaloosa County\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Okaloosa', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['County', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 11, 'pobj', 14]\n",
      "parent node subtree [['Okaloosa', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 14, 'compound', 13]]\n",
      "txt=Posting for a friend: “If anyone knows what conditions are like or has pics near Delaware Ave (right outside the Lynn Haven Country Club) or on Lisenby near 390, Lynn Haven, FL north of Panama City Beach, FL. Still can get ahold of my mom or grandparents.” #HurricaneMichael\n",
      "candidate 0=Lynn Haven\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Lynn', 'PROPN', 26, 'compound', 23], ['Haven', 'PROPN', 26, 'compound', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Haven', 'PROPN', 26, 'compound', 24]\n",
      "NE parent token:\n",
      "['Club', 'PROPN', 21, 'pobj', 26]\n",
      "parent node subtree [['the', 'DET', 26, 'det', 22], ['Lynn', 'PROPN', 26, 'compound', 23], ['Haven', 'PROPN', 26, 'compound', 24], ['Country', 'PROPN', 26, 'compound', 25]]\n",
      "candidate 1=Panama City Beach\n",
      "anchor NE candidates = Delaware,FL\n",
      "data NE tree=[['Panama', 'PROPN', 41, 'compound', 38], ['City', 'PROPN', 41, 'compound', 39], ['Beach', 'PROPN', 41, 'compound', 40]]\n",
      "NE parse token at tree=0, token=41:\n",
      "['Beach', 'PROPN', 41, 'compound', 40]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 37, 'pobj', 41]\n",
      "parent node subtree [['Panama', 'PROPN', 41, 'compound', 38], ['City', 'PROPN', 41, 'compound', 39], ['Beach', 'PROPN', 41, 'compound', 40]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=More than 80% of our customers in Bay, Franklin, Gulf, Jefferson & Wakulla counties lost power as #Michael roared on shore as a cat. 4 hurricane. Damage assessment & repairs to the electric system are underway in areas that crews are able to access. <URL>\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Franklin,Gulf,Jefferson\n",
      "data NE tree=[['Bay', 'PROPN', 11, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Bay', 'PROPN', 11, 'compound', 8]\n",
      "NE parent token:\n",
      "['Jefferson', 'PROPN', 14, 'nmod', 11]\n",
      "parent node subtree [['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "candidate 1=Franklin\n",
      "anchor NE candidates = \n",
      "candidate 2=Gulf\n",
      "anchor NE candidates = Franklin,Jefferson\n",
      "data NE tree=[['Gulf', 'PROPN', 11, 'nmod', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Gulf', 'PROPN', 11, 'nmod', 10]\n",
      "NE parent token:\n",
      "['Jefferson', 'PROPN', 14, 'nmod', 11]\n",
      "parent node subtree [['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "candidate 3=Jefferson\n",
      "anchor NE candidates = Franklin\n",
      "data NE tree=[['Jefferson', 'PROPN', 14, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Jefferson', 'PROPN', 14, 'nmod', 11]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 7, 'pobj', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['Jefferson', 'PROPN', 14, 'nmod', 11], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "NE=Jefferson subtree=[['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "min node deps ['compound', 'compound', 'nmod', 'cc', 'conj']\n",
      "txt=Sadly, we now have 6 confirmed fatalities due to #Michael , all inland. 4 in Gadsden County, FL (NW of Tallahassee), one in Seminole County in SW Georgia, and one north of Charlotte in Iredell County, NC. Most known to be due to wind knocking down trees or structures onto victims.\n",
      "candidate 0=Gadsden County\n",
      "anchor NE candidates = FL,Tallahassee,Seminole County,Charlotte,Iredell County,NC\n",
      "data NE tree=[['Gadsden', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['County', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 1, 'pobj', 4]\n",
      "parent node subtree [['Gadsden', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 4, 'compound', 3], ['(', 'PUNCT', 4, 'punct', 5], ['NW', 'PROPN', 4, 'appos', 6], ['of', 'ADP', 6, 'prep', 7], ['Tallahassee', 'PROPN', 7, 'pobj', 8], [')', 'PUNCT', 4, 'punct', 9], ['one', 'NUM', 4, 'appos', 10], ['in', 'ADP', 10, 'prep', 11], ['Seminole', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 11, 'pobj', 13], ['in', 'ADP', 13, 'prep', 14], ['SW', 'PROPN', 16, 'compound', 15], ['Georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['Charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24], ['NC', 'PROPN', 22, 'pobj', 25]]\n",
      "candidate 1=Tallahassee\n",
      "anchor NE candidates = \n",
      "candidate 2=Seminole County\n",
      "anchor NE candidates = FL,Seminole County,Charlotte,NC\n",
      "data NE tree=[['Seminole', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 11, 'pobj', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['County', 'PROPN', 11, 'pobj', 13]\n",
      "NE parent token:\n",
      "['in', 'ADP', 10, 'prep', 11]\n",
      "NE=Seminole County subtree=[['in', 'ADP', 13, 'prep', 14], ['SW', 'PROPN', 16, 'compound', 15], ['Georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['Charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24], ['NC', 'PROPN', 22, 'pobj', 25]]\n",
      "min node deps ['prep', 'cc', 'conj']\n",
      "subtree = in SW Georgia and one north of Charlotte in Iredell County NC\n",
      "txt=But here I am, always watching other places have outside help in a disaster and here we live with police and fire from Jacksonville, Miami, Hillsborough, Tallahassee and other places roll up and down the roads #PanamaCity #HurricaneMichael\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = \n",
      "candidate 1=Miami\n",
      "anchor NE candidates = Jacksonville\n",
      "data NE tree=[['Miami', 'PROPN', 26, 'compound', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Miami', 'PROPN', 26, 'compound', 24]\n",
      "NE parent token:\n",
      "['Tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "candidate 2=Hillsborough\n",
      "anchor NE candidates = Jacksonville,Miami,Tallahassee\n",
      "data NE tree=[['Hillsborough', 'PROPN', 26, 'compound', 25]]\n",
      "NE parse token at tree=0, token=26:\n",
      "['Hillsborough', 'PROPN', 26, 'compound', 25]\n",
      "NE parent token:\n",
      "['Tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "candidate 3=Tallahassee\n",
      "anchor NE candidates = Jacksonville,Miami\n",
      "data NE tree=[['Tallahassee', 'PROPN', 22, 'pobj', 26]]\n",
      "NE parse token at tree=0, token=27:\n",
      "['Tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "NE parent token:\n",
      "['from', 'ADP', 17, 'prep', 22]\n",
      "NE=Tallahassee subtree=[['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "min node deps ['compound', 'compound', 'compound', 'cc', 'conj']\n",
      "txt=IDES is responding to #HurricaneMichael IDES staff is en route to Florida where we will be #partnering with our Anchor Church, Christ's Church of Jacksonville, @ccontheweb to connect with churches in communities affected by #Hurricane Michael. <URL>\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = \n",
      "txt=TS #Michael knocked down some trees, left thousands without power, and blocked several roadways in Darlington, SC. <URL>\n",
      "candidate 0=Darlington\n",
      "anchor NE candidates = SC\n",
      "data NE tree=[['Darlington', 'PROPN', 16, 'compound', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Darlington', 'PROPN', 16, 'compound', 15]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 14, 'pobj', 16]\n",
      "parent node subtree [['Darlington', 'PROPN', 16, 'compound', 15]]\n",
      "txt=All day we've all seen the horrific landscape in Panama City Beach and Mexico Beach, Florida and other parts of the Panhandle. But every new drone or aerial shot continues to stun. #Michael was swift. In the morning things were there. In the afternoon, they weren't. <URL>\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Panama', 'PROPN', 11, 'compound', 9], ['City', 'PROPN', 11, 'nmod', 10], ['Beach', 'PROPN', 8, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "NE parent token:\n",
      "['in', 'ADP', 7, 'prep', 8]\n",
      "NE=Panama City Beach subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Mexico', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 11, 'conj', 14], ['Florida', 'PROPN', 11, 'conj', 15], ['and', 'CCONJ', 11, 'cc', 16], ['other', 'ADJ', 18, 'amod', 17], ['parts', 'NOUN', 11, 'conj', 18], ['of', 'ADP', 18, 'prep', 19], ['the', 'DET', 21, 'det', 20], ['Panhandle', 'PROPN', 19, 'pobj', 21]]\n",
      "min node deps ['cc', 'conj', 'conj', 'cc', 'conj']\n",
      "candidate 1=Mexico Beach\n",
      "anchor NE candidates = Panama City Beach,Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 11, 'conj', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Beach', 'PROPN', 11, 'conj', 14]\n",
      "NE parent token:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "txt=Keep all the cities affected by #HurricaneMichael in your prayers. Jackson County Bay County Washington County Houston County and others. We all need help!\n",
      "candidate 0=Jackson County\n",
      "anchor NE candidates = \n",
      "candidate 1=Houston County\n",
      "anchor NE candidates = Jackson County\n",
      "data NE tree=[['Houston', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 7, 'ROOT', 7]]\n",
      "NE=Houston County subtree=[['Jackson', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'compound', 1], ['Bay', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['Washington', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 7, 'compound', 5], ['and', 'CCONJ', 7, 'cc', 8], ['others', 'NOUN', 7, 'conj', 9], ['.', 'PUNCT', 7, 'punct', 10]]\n",
      "min node deps ['compound']\n",
      "txt=All orders to Mexico Beach, FL will be refunded FOC and sent in due course! Please contact info@wave97.com for more information. #HurricaneMichael\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Mexico', 'PROPN', 5, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Beach', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Mexico', 'PROPN', 5, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "txt=@Dove it would be the perfect time to send extra dry shampoo to Panama City and Beach. No water for maybe weeks #HurricaneMichael #PanamaCityBeach\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = \n",
      "candidate 1=Beach\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Beach', 'PROPN', 14, 'conj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Beach', 'PROPN', 14, 'conj', 16]\n",
      "NE parent token:\n",
      "['City', 'PROPN', 12, 'pobj', 14]\n",
      "txt=ICYMI: This reporter hunkered down in a Panama City, Florida parking deck as Hurricane Michael roared ashore Wednesday More #HurricaneMichael video: <URL>\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Panama', 'PROPN', 10, 'compound', 8], ['City', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['City', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 12, 'compound', 10]\n",
      "parent node subtree [['Panama', 'PROPN', 10, 'compound', 8], ['City', 'PROPN', 10, 'compound', 9]]\n",
      "txt=#HurricaneRelief #HurricaneMichael #MAGA #AmericaFirst #NationalGuard #FEMA @fema #KAG From Congressman Matt Gaetz, for areas having trouble getting supplies, food, water around Bonifay, Holmes County, Ponce De Leon areas. Disaster relief contact info below. @RepMattGaetz <URL>\n",
      "candidate 0=Bonifay\n",
      "anchor NE candidates = Holmes County\n",
      "data NE tree=[['Bonifay', 'PROPN', 23, 'compound', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Bonifay', 'PROPN', 23, 'compound', 21]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 27, 'compound', 23]\n",
      "parent node subtree [['Bonifay', 'PROPN', 23, 'compound', 21], ['Holmes', 'PROPN', 23, 'compound', 22]]\n",
      "candidate 1=Holmes County\n",
      "anchor NE candidates = \n",
      "candidate 2=Ponce De Leon\n",
      "anchor NE candidates = Bonifay,Holmes County\n",
      "data NE tree=[['Ponce', 'PROPN', 26, 'compound', 24], ['De', 'PROPN', 26, 'compound', 25], ['Leon', 'PROPN', 27, 'compound', 26]]\n",
      "NE parse token at tree=0, token=27:\n",
      "['Leon', 'PROPN', 27, 'compound', 26]\n",
      "NE parent token:\n",
      "['areas', 'NOUN', 20, 'pobj', 27]\n",
      "parent node subtree [['Bonifay', 'PROPN', 23, 'compound', 21], ['Holmes', 'PROPN', 23, 'compound', 22], ['County', 'PROPN', 27, 'compound', 23], ['Ponce', 'PROPN', 26, 'compound', 24], ['De', 'PROPN', 26, 'compound', 25], ['Leon', 'PROPN', 27, 'compound', 26]]\n",
      "txt=New aerial video of the massive destruction at Mexico Beach, Florida. Thanks once again to our exclusive partners at @Livestormsmedia #arwx #Michael <URL>\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 10, 'compound', 8], ['Beach', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Beach', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 7, 'pobj', 10]\n",
      "parent node subtree [['Mexico', 'PROPN', 10, 'compound', 8], ['Beach', 'PROPN', 10, 'compound', 9]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=DEVASTATING DAMAGE: This is my 2nd year living in Florida during Hurricane Season and the images don't get easier to watch. This picture shows the devastation left behind by #HurricaneMichael in Mexico Beach. Praying for the victims and their families. #PrayersforthePanhandle <URL>\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = \n",
      "txt=Thank you, this Panama City Beach #hurricanemichael survivor appreciates what you are doing for us!! Your store in Santa Rosa Beach helped us today when we drove over from Panama City to purchase food/water/supplies for our friends and coworkers. The employees were so kind! <URL>\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 7, 'nmod', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Beach', 'PROPN', 7, 'nmod', 5]\n",
      "NE parent token:\n",
      "['survivor', 'NOUN', 8, 'nsubj', 7]\n",
      "parent node subtree [['this', 'DET', 7, 'det', 2], ['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 7, 'nmod', 5], ['#hurricanemichael', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 1=Santa Rosa Beach\n",
      "anchor NE candidates = Panama City Beach,Panama City\n",
      "data NE tree=[['Santa', 'PROPN', 4, 'compound', 3], ['Rosa', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Beach', 'PROPN', 2, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "candidate 2=Panama City\n",
      "anchor NE candidates = \n",
      "txt=Rob Golding drove to Springfield, Florida to be with his 89-year-old dad during #HurricaneMichael . His home was spared, but the area suffered damage, so they started taking in neighbors, going out to rescue friends, and organizing food for the community. <URL>\n",
      "candidate 0=Springfield\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Springfield', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Springfield', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Springfield', 'PROPN', 5, 'compound', 4]]\n",
      "txt=#BREAKING: President Trump approves Emergency Disaster Declaration for  the following Alabama counties: Dale, Geneva, Henry, and Houston #HurricaneMichael\n",
      "candidate 0=Dale\n",
      "anchor NE candidates = \n",
      "candidate 1=Geneva\n",
      "anchor NE candidates = Alabama,Geneva,Houston\n",
      "data NE tree=[['Geneva', 'PROPN', 16, 'compound', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Geneva', 'PROPN', 16, 'compound', 15]\n",
      "NE parent token:\n",
      "['Henry', 'PROPN', 4, 'appos', 16]\n",
      "parent node subtree [['Dale', 'PROPN', 16, 'compound', 14], ['Geneva', 'PROPN', 16, 'compound', 15], ['and', 'CCONJ', 16, 'cc', 17], ['Houston', 'PROPN', 16, 'conj', 18]]\n",
      "candidate 2=Houston\n",
      "anchor NE candidates = Alabama,Houston\n",
      "data NE tree=[['Houston', 'PROPN', 16, 'conj', 18]]\n",
      "NE parse token at tree=0, token=19:\n",
      "['Houston', 'PROPN', 16, 'conj', 18]\n",
      "NE parent token:\n",
      "['Henry', 'PROPN', 4, 'appos', 16]\n",
      "txt=Heard you guys are bringing prepaid phones and charging stations. Please don’t do this on Panama City Beach. They have electricity and access to Destin. Come into Panama City, Callaway, Lynn Haven @TMobile @TMobileHelp #hurricanemichael\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Destin,Panama City,Callaway,Lynn Haven\n",
      "data NE tree=[['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['Beach', 'PROPN', 6, 'pobj', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Beach', 'PROPN', 6, 'pobj', 9]\n",
      "NE parent token:\n",
      "['on', 'ADP', 4, 'prep', 6]\n",
      "candidate 1=Destin\n",
      "anchor NE candidates = Panama City,Callaway,Lynn Haven\n",
      "data NE tree=[['Destin', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=2, token=7:\n",
      "['Destin', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['to', 'ADP', 2, 'prep', 5]\n",
      "candidate 2=Panama City\n",
      "anchor NE candidates = \n",
      "candidate 3=Callaway\n",
      "anchor NE candidates = Panama City,Lynn Haven\n",
      "data NE tree=[['Callaway', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=3, token=5:\n",
      "['Callaway', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['Haven', 'PROPN', 7, 'compound', 6]\n",
      "parent node subtree [['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4], ['Lynn', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 4=Lynn Haven\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Lynn', 'PROPN', 6, 'compound', 5], ['Haven', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=3, token=7:\n",
      "['Haven', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['@TMobile', 'PROPN', 1, 'pobj', 7]\n",
      "parent node subtree [['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4], ['Lynn', 'PROPN', 6, 'compound', 5], ['Haven', 'PROPN', 7, 'compound', 6]]\n",
      "NE=Lynn Haven subtree=[['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4]]\n",
      "min node deps ['compound']\n",
      "txt=Devastation in Mexico Beach, Florida from Hurricane #Michael . <URL>\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 4, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Beach', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 1, 'pobj', 4]\n",
      "parent node subtree [['Mexico', 'PROPN', 4, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3]]\n",
      "txt=Vacasa office in Panama City Beach. Not too bad... property assessments are under way looks promising and positive so far #hurricanemichael @vacasarentals @RickyHaskins @ Panama City… <URL>\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Beach', 'PROPN', 2, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "candidate 1=Panama City\n",
      "anchor NE candidates = \n",
      "txt=#HurricaneMichael , current #SNAP households in Bay, Calhoun, Franklin, Gadsden, Gulf, Holmes, Jackson, Jefferson, Leon, Liberty, Wakulla, and Washington counties will receive replacement benefits at a 40% rate as early as 10/15/18 <URL>\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Calhoun,Franklin,Gadsden,Gulf,Jefferson,Washington\n",
      "data NE tree=[['Bay', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Bay', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['Calhoun', 'PROPN', 9, 'compound', 6]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5]]\n",
      "candidate 1=Calhoun\n",
      "anchor NE candidates = Franklin,Gadsden,Jefferson,Washington\n",
      "data NE tree=[['Calhoun', 'PROPN', 9, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Calhoun', 'PROPN', 9, 'compound', 6]\n",
      "NE parent token:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "NE=Calhoun subtree=[['Bay', 'PROPN', 6, 'compound', 5]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Franklin\n",
      "anchor NE candidates = Washington\n",
      "data NE tree=[['Franklin', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Franklin', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "candidate 3=Gadsden\n",
      "anchor NE candidates = Franklin,Washington\n",
      "data NE tree=[['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Gadsden', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "candidate 4=Gulf\n",
      "anchor NE candidates = Calhoun,Franklin,Gadsden,Jefferson,Washington\n",
      "data NE tree=[['Gulf', 'PROPN', 14, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "NE parent token:\n",
      "['Liberty', 'PROPN', 15, 'compound', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9], ['Holmes', 'PROPN', 14, 'compound', 10], ['Jackson', 'PROPN', 14, 'compound', 11], ['Jefferson', 'PROPN', 14, 'compound', 12], ['Leon', 'PROPN', 14, 'compound', 13]]\n",
      "NE=Gulf subtree=[['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 5=Jefferson\n",
      "anchor NE candidates = Franklin,Gadsden,Washington\n",
      "data NE tree=[['Jefferson', 'PROPN', 14, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Jefferson', 'PROPN', 14, 'compound', 12]\n",
      "NE parent token:\n",
      "['Liberty', 'PROPN', 15, 'compound', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9], ['Holmes', 'PROPN', 14, 'compound', 10], ['Jackson', 'PROPN', 14, 'compound', 11], ['Jefferson', 'PROPN', 14, 'compound', 12], ['Leon', 'PROPN', 14, 'compound', 13]]\n",
      "txt=At least 46 people remained unaccounted for on Sunday in Mexico Beach, Florida, an area pulverized by #HurricaneMichael 289 people, including 10 children, decided to stay put, despite evacuation orders, and ride out the Category 4 storm <URL>\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 12, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Mexico', 'PROPN', 12, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11]]\n",
      "txt=President Trump in Florida to tour #HurricaneMichael damage in panhandle: <URL>\n",
      "candidate 0=panhandle\n",
      "anchor NE candidates = \n",
      "txt=Jackie, a #HurricaneMichael survivor in Panama City Beach, FL, is desperate to contact family and friends as cell service remains down following the storm: \"\"I hope you all are all okay...We're all okay.\"\" <URL>\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Panama', 'PROPN', 8, 'compound', 5], ['City', 'PROPN', 8, 'compound', 6], ['Beach', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Beach', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 4, 'pobj', 8]\n",
      "parent node subtree [['Panama', 'PROPN', 8, 'compound', 5], ['City', 'PROPN', 8, 'compound', 6], ['Beach', 'PROPN', 8, 'compound', 7]]\n",
      "txt=I would like to give a great big thank you to @TMobile for having your emergency management truck here in Blountstown, FL and making it possible for us to have WiFi during the aftermath of #HurricaneMichael\n",
      "candidate 0=Blountstown\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Blountstown', 'PROPN', 21, 'compound', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Blountstown', 'PROPN', 21, 'compound', 20]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 19, 'pobj', 21]\n",
      "parent node subtree [['Blountstown', 'PROPN', 21, 'compound', 20]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=#HappyMonday - If you think your Monday's bad... be reminded by the pics from #HurricaneMichael that it can ALWAYS get worse. Listen, we are here in Panama City, FL at groundZero delivering supplies to those impacted... <URL>\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Panama', 'PROPN', 7, 'compound', 5], ['City', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['City', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['Panama', 'PROPN', 7, 'compound', 5], ['City', 'PROPN', 7, 'compound', 6]]\n",
      "txt=The people ravaged by #HurricaneMichael in Panama City, Florida and Mexico Beach, Florida need our help. Let’s do this by donating to the American Red Cross.\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Florida,Florida\n",
      "data NE tree=[['Panama', 'PROPN', 7, 'compound', 6], ['City', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['City', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 5, 'pobj', 8]\n",
      "parent node subtree [['Panama', 'PROPN', 7, 'compound', 6], ['City', 'PROPN', 8, 'compound', 7], ['and', 'CCONJ', 8, 'cc', 9], ['Mexico', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11], ['Florida', 'PROPN', 8, 'conj', 12]]\n",
      "candidate 1=Mexico Beach\n",
      "anchor NE candidates = \n",
      "txt=Day #2 of Hurricane #Michael Damage Surveys - Unbelievable tree damage. We surveyed spots in Southport, Youngstown, & Resota Beach (north of Lynn Haven & Panama City) where all trees were snapped, uprooted, or bent/twisted. Pictures do NOT do the damage justice at all... <URL>\n",
      "candidate 0=Southport\n",
      "anchor NE candidates = \n",
      "candidate 1=Youngstown\n",
      "anchor NE candidates = Southport\n",
      "data NE tree=[['Youngstown', 'PROPN', 3, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Youngstown', 'PROPN', 3, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "NE=Youngstown subtree=[['Southport', 'PROPN', 5, 'compound', 4], ['&', 'CCONJ', 5, 'cc', 6], ['Resota', 'PROPN', 8, 'compound', 7], ['Beach', 'PROPN', 5, 'conj', 8], ['(', 'PUNCT', 5, 'punct', 9], ['north', 'NOUN', 5, 'advmod', 10], ['of', 'ADP', 10, 'prep', 11], ['Lynn', 'PROPN', 13, 'compound', 12], ['Haven', 'PROPN', 11, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16], [')', 'PUNCT', 5, 'punct', 17], ['where', 'ADV', 22, 'advmod', 18], ['all', 'DET', 20, 'det', 19], ['trees', 'NOUN', 22, 'nsubjpass', 20], ['were', 'VERB', 22, 'auxpass', 21], ['snapped', 'VERB', 5, 'relcl', 22], ['uprooted', 'VERB', 22, 'advcl', 23], ['or', 'CCONJ', 23, 'cc', 24], ['bent', 'ADJ', 27, 'amod', 25], ['/', 'SYM', 27, 'punct', 26], ['twisted', 'ADJ', 23, 'conj', 27]]\n",
      "min node deps ['compound', 'cc', 'conj', 'punct', 'advmod', 'punct', 'relcl']\n",
      "candidate 2=Resota Beach\n",
      "anchor NE candidates = Southport,Youngstown,Lynn Haven,Panama City\n",
      "data NE tree=[['Resota', 'PROPN', 8, 'compound', 7], ['Beach', 'PROPN', 5, 'conj', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['Beach', 'PROPN', 5, 'conj', 8]\n",
      "NE parent token:\n",
      "['Youngstown', 'PROPN', 3, 'pobj', 5]\n",
      "candidate 3=Lynn Haven\n",
      "anchor NE candidates = Southport,Youngstown,Panama City\n",
      "data NE tree=[['Lynn', 'PROPN', 13, 'compound', 12], ['Haven', 'PROPN', 11, 'pobj', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['Haven', 'PROPN', 11, 'pobj', 13]\n",
      "NE parent token:\n",
      "['of', 'ADP', 10, 'prep', 11]\n",
      "NE=Lynn Haven subtree=[['&', 'CCONJ', 13, 'cc', 14], ['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 4=Panama City\n",
      "anchor NE candidates = Southport,Youngstown\n",
      "data NE tree=[['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16]]\n",
      "NE parse token at tree=1, token=17:\n",
      "['City', 'PROPN', 13, 'conj', 16]\n",
      "NE parent token:\n",
      "['Haven', 'PROPN', 11, 'pobj', 13]\n",
      "txt=#HurricaneMichael | Tide Loads of Hope is washing clothes for free from 9am-5pm at Walmart Supercenter (25 N Tyndall Pkwy, Callaway, FL 32404) #PanhandleStrong #PanamaCity <URL>\n",
      "candidate 0=Callaway\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Callaway', 'PROPN', 22, 'compound', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Callaway', 'PROPN', 22, 'compound', 21]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 15, 'appos', 22]\n",
      "parent node subtree [['25', 'NUM', 22, 'nummod', 17], ['N', 'NOUN', 22, 'compound', 18], ['Tyndall', 'PROPN', 22, 'compound', 19], ['Pkwy', 'PROPN', 22, 'compound', 20], ['Callaway', 'PROPN', 22, 'compound', 21], ['32404', 'NUM', 22, 'nummod', 23]]\n",
      "txt=Check out Calhoun (98% out), Gulf (86%), Jackson (83%), Liberty (71%), and Bay (56%). Then donate some money or critical supplies & lend a hand. #FloridaStrong #HurricaneMichael #beagoodneighbor <URL>\n",
      "candidate 0=Calhoun\n",
      "anchor NE candidates = Liberty\n",
      "data NE tree=[['Calhoun', 'PROPN', 0, 'dobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Calhoun', 'PROPN', 0, 'dobj', 2]\n",
      "NE parent token:\n",
      "['Check', 'VERB', 0, 'ROOT', 0]\n",
      "NE=Calhoun subtree=[['(', 'PUNCT', 2, 'punct', 3], ['98', 'NUM', 5, 'nummod', 4], ['%', 'NOUN', 2, 'appos', 5], ['out', 'PART', 5, 'prt', 6], [')', 'PUNCT', 2, 'punct', 7]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( 98 % out )\n",
      "candidate 1=Gulf\n",
      "anchor NE candidates = Calhoun,Liberty\n",
      "data NE tree=[['Gulf', 'PROPN', 8, 'ROOT', 8]]\n",
      "NE=Gulf subtree=[['(8', 'PROPN', 8, 'punct', 9], ['6', 'NUM', 11, 'nummod', 10], ['%', 'NOUN', 8, 'appos', 11], [')', 'PUNCT', 8, 'punct', 12]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = (8 6 % )\n",
      "candidate 2=Liberty\n",
      "anchor NE candidates = \n",
      "candidate 3=Bay\n",
      "anchor NE candidates = Calhoun,Gulf,Liberty\n",
      "data NE tree=[['Bay', 'PROPN', 18, 'conj', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Bay', 'PROPN', 18, 'conj', 24]\n",
      "NE parent token:\n",
      "['Liberty', 'PROPN', 18, 'ROOT', 18]\n",
      "NE=Bay subtree=[['(', 'PUNCT', 24, 'punct', 25], ['56', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], [')', 'PUNCT', 24, 'punct', 28]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( 56 % )\n",
      "txt=Beach Surveys have been completed in Bay, Escambia, Franklin, Okaloosa, Santa Rosa and Gulf counties. #HurricaneMichael\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Santa Rosa,Gulf\n",
      "data NE tree=[['Bay', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Bay', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['Escambia', 'PROPN', 9, 'compound', 7]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 6]]\n",
      "candidate 1=Santa Rosa\n",
      "anchor NE candidates = Bay,Santa Rosa,Gulf\n",
      "data NE tree=[['Santa', 'PROPN', 11, 'compound', 10], ['Rosa', 'PROPN', 9, 'appos', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Rosa', 'PROPN', 9, 'appos', 11]\n",
      "NE parent token:\n",
      "['Okaloosa', 'PROPN', 5, 'pobj', 9]\n",
      "NE=Santa Rosa subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 14, 'compound', 13], ['counties', 'NOUN', 11, 'conj', 14]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 2=Gulf\n",
      "anchor NE candidates = \n",
      "txt=AMR Leaders were able to visit crews today in Panama City, Florida as the crews were coming and going from missions. Crews are all pretty upbeat and so glad to be able to be in the area to help people! #HurricaneMichael <URL>\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Panama', 'PROPN', 10, 'compound', 9], ['City', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['City', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 8, 'pobj', 11]\n",
      "parent node subtree [['Panama', 'PROPN', 10, 'compound', 9], ['City', 'PROPN', 11, 'compound', 10]]\n",
      "txt=Clean Water is on the way to Sneads, Florida! Want to help us deliver more water to victims of #HurricaneMichael ? Visit our website to make a donation! USA: <URL>\n",
      "candidate 0=Sneads\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Sneads', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Sneads', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Sneads', 'PROPN', 8, 'compound', 7]]\n",
      "txt=One Week After #Michael County By County #FLwx Power Outage Update: Calhoun: 97% Jackson: 81% Liberty: 67% Gulf: 58% Bay/Gadsden: 52% Washington: 18% Holmes: 17%\n",
      "candidate 0=Calhoun\n",
      "anchor NE candidates = Jackson,Liberty,Gadsden\n",
      "data NE tree=[['Calhoun', 'PROPN', 10, 'appos', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Calhoun', 'PROPN', 10, 'appos', 12]\n",
      "NE parent token:\n",
      "['Update', 'PROPN', 10, 'ROOT', 10]\n",
      "NE=Calhoun subtree=[[':', 'PUNCT', 12, 'punct', 13], ['97', 'NUM', 15, 'nummod', 14], ['%', 'NOUN', 16, 'compound', 15], ['Jackson', 'PROPN', 12, 'appos', 16], [':', 'PUNCT', 16, 'punct', 17], ['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['Liberty', 'PROPN', 19, 'appos', 20], [':', 'PUNCT', 16, 'punct', 21]]\n",
      "min node deps ['punct', 'appos']\n",
      "subtree = : 97 % Jackson : 81 % Liberty :\n",
      "candidate 1=Jackson\n",
      "anchor NE candidates = \n",
      "candidate 2=Liberty\n",
      "anchor NE candidates = Jackson\n",
      "data NE tree=[['Liberty', 'PROPN', 19, 'appos', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Liberty', 'PROPN', 19, 'appos', 20]\n",
      "NE parent token:\n",
      "['%', 'NOUN', 16, 'appos', 19]\n",
      "candidate 3=Bay\n",
      "anchor NE candidates = Calhoun,Jackson,Liberty,Gadsden\n",
      "data NE tree=[['Bay', 'PROPN', 30, 'nmod', 28]]\n",
      "NE parse token at tree=0, token=29:\n",
      "['Bay', 'PROPN', 30, 'nmod', 28]\n",
      "NE parent token:\n",
      "['Gadsden', 'PROPN', 27, 'appos', 30]\n",
      "parent node subtree [['Bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29]]\n",
      "candidate 4=Gadsden\n",
      "anchor NE candidates = Jackson,Liberty\n",
      "data NE tree=[['Gadsden', 'PROPN', 27, 'appos', 30]]\n",
      "NE parse token at tree=0, token=31:\n",
      "['Gadsden', 'PROPN', 27, 'appos', 30]\n",
      "NE parent token:\n",
      "['%', 'NOUN', 24, 'appos', 27]\n",
      "NE=Gadsden subtree=[['Bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29]]\n",
      "min node deps ['nmod', 'punct']\n",
      "txt=Want to see the real #AHSApocalypse ? Come down here to Mexico beach or Panama City, FL! #HurricaneMichael #hurricanemichael2018 @CNN @weatherchannel\n",
      "candidate 0=Mexico beach\n",
      "anchor NE candidates = Panama City,FL\n",
      "data NE tree=[['Mexico', 'PROPN', 5, 'compound', 4], ['beach', 'NOUN', 3, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['beach', 'NOUN', 3, 'pobj', 5]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 3]\n",
      "NE=Mexico beach subtree=[['or', 'CCONJ', 5, 'cc', 6], ['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['FL', 'PROPN', 5, 'conj', 9]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Panama City\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['City', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 5, 'conj', 9]\n",
      "parent node subtree [['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8]]\n",
      "txt=Orange County Utilities’ Water Reclamation and Field Services team members are helping restore sewer systems impacted by #HurricaneMichael in Tallahassee and Panama City. We are proud to support our neighbors, just as they did, following past storms that affected Central Florida. <URL>\n",
      "candidate 0=Orange County\n",
      "anchor NE candidates = \n",
      "candidate 1=Tallahassee\n",
      "anchor NE candidates = Orange County\n",
      "data NE tree=[['Tallahassee', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Tallahassee', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['in', 'ADP', 16, 'prep', 19]\n",
      "NE=Tallahassee subtree=[['and', 'CCONJ', 20, 'cc', 21], ['Panama', 'PROPN', 23, 'compound', 22], ['City', 'PROPN', 20, 'conj', 23]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 2=Panama City\n",
      "anchor NE candidates = Orange County,Tallahassee\n",
      "data NE tree=[['Panama', 'PROPN', 23, 'compound', 22], ['City', 'PROPN', 20, 'conj', 23]]\n",
      "NE parse token at tree=0, token=24:\n",
      "['City', 'PROPN', 20, 'conj', 23]\n",
      "NE parent token:\n",
      "['Tallahassee', 'PROPN', 19, 'pobj', 20]\n",
      "txt=@verizon is offering 3 free months of service to customers in Bay and Gulf counties in FL supporting people affected by #HurricaneMichael . Good stuff! Any chance you will extend that offer to those of us in the National Guard who have been here since day 1 with no cell signal?\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Gulf,FL\n",
      "data NE tree=[['Bay', 'PROPN', 14, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Bay', 'PROPN', 14, 'nmod', 11]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 10, 'pobj', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 11, 'conj', 13], ['in', 'ADP', 14, 'prep', 15], ['FL', 'PROPN', 15, 'pobj', 16]]\n",
      "NE=Bay subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 11, 'conj', 13]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Gulf\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Gulf', 'PROPN', 11, 'conj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Gulf', 'PROPN', 11, 'conj', 13]\n",
      "NE parent token:\n",
      "['Bay', 'PROPN', 14, 'nmod', 11]\n",
      "txt=Reminders from #hurricanemichael . Posted orignally by \"\"The Most Excellent Way\"\" of Panama City, Fl. \"\"And we know that for those who love God all things work together for good, for those… <URL>\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Fl\n",
      "data NE tree=[['Panama', 'PROPN', 14, 'compound', 12], ['City', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['City', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['Fl', 'PROPN', 11, 'pobj', 14]\n",
      "parent node subtree [['Panama', 'PROPN', 14, 'compound', 12], ['City', 'PROPN', 14, 'compound', 13]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt=One home in Mexico Beach, Florida, appeared largely untouched amid the incredible destruction of #HurricaneMichael . And its owners, Lebron Lackey and his uncle, Russell King, say it's no… <URL>\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 4, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Beach', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Mexico', 'PROPN', 4, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "txt=Hey guys... PLEASE come to Panama City, Fl. We need some laughs after #HurricaneMichael The beach didn't get hit bad at all. There are many venues. Club La Vila is a huge one. We'd love to see ya'll. Please consider it.\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Fl\n",
      "data NE tree=[['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['City', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Fl', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4]]\n",
      "txt=This afternoon, state and federal partners held a call to coordinate housing solutions in areas impacted by #HurricaneMichael . Thanks to Franklin County, Liberty County and Washington County for joining us on the call. em2franklin LibertyCoFLEM <URL>\n",
      "candidate 0=Franklin County\n",
      "anchor NE candidates = Washington County\n",
      "data NE tree=[['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['County', 'PROPN', 5, 'compound', 3]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 1, 'pobj', 5]\n",
      "parent node subtree [['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['Liberty', 'PROPN', 5, 'compound', 4], ['and', 'CCONJ', 5, 'cc', 6], ['Washington', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 5, 'conj', 8]]\n",
      "candidate 1=Liberty County\n",
      "anchor NE candidates = Franklin County,Washington County\n",
      "data NE tree=[['Liberty', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 1, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['County', 'PROPN', 1, 'pobj', 5]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "NE=Liberty County subtree=[['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['and', 'CCONJ', 5, 'cc', 6], ['Washington', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 5, 'conj', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Washington County\n",
      "anchor NE candidates = \n",
      "txt=Unless you live in Bay, Gulf, Jackson, Calhoun and Gadsden counties. #850Strong #FloridaStrong #HurricaneMichael\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Gulf,Calhoun,Gadsden\n",
      "data NE tree=[['Bay', 'PROPN', 7, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Bay', 'PROPN', 7, 'compound', 4]\n",
      "NE parent token:\n",
      "['Calhoun', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "candidate 1=Gulf\n",
      "anchor NE candidates = Calhoun,Gadsden\n",
      "data NE tree=[['Gulf', 'PROPN', 7, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Gulf', 'PROPN', 7, 'compound', 5]\n",
      "NE parent token:\n",
      "['Calhoun', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "candidate 2=Calhoun\n",
      "anchor NE candidates = Gadsden\n",
      "data NE tree=[['Calhoun', 'PROPN', 3, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Calhoun', 'PROPN', 3, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "NE=Calhoun subtree=[['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "min node deps ['compound', 'compound', 'compound', 'cc', 'conj']\n",
      "candidate 3=Gadsden\n",
      "anchor NE candidates = \n"
     ]
    }
   ],
   "source": [
    "for idx_i, annotated_data_i in annotated_anchor_data.iterrows():\n",
    "    annotated_NE_i = annotated_data_i.loc['NE']\n",
    "    txt_i = annotated_data_i.loc['txt']\n",
    "    data_i = anchor_data[anchor_data.loc[:, 'txt']==txt_i]\n",
    "    data_NE_i = data_i.loc[:, 'NE_fixed'].values\n",
    "    # restrict to data where NE only occurs once per status\n",
    "    if(len([x for x in data_NE_i if x.replace(' ', '_').lower()==annotated_NE_i]) == 1):\n",
    "        print('txt=%s'%(txt_i))\n",
    "        parent_subclause_anchor_i, subclause_anchor_i = detect_subclause_anchor_parents_children(data_i, verbose=True)\n",
    "        subclause_anchor_i.index = [x.replace(' ', '_').lower() for x in subclause_anchor_i.index]\n",
    "        parent_subclause_anchor_i.index = [x.replace(' ','_').lower() for x in parent_subclause_anchor_i.index]\n",
    "        anchor_final_i = pd.concat([parent_subclause_anchor_i, subclause_anchor_i], axis=1).max(axis=1)\n",
    "        if(anchor_final_i.loc[annotated_NE_i] - annotated_data_i.loc['context_subclause'] == -1):\n",
    "            print('false negative with NE=%s, txt=%s'%(annotated_NE_i, txt_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We see that the false negatives are unavailable from the parses, so we did the best that we could. We may have to revisit the conjunction + state rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the precision/recall for each of the subclause classes:\n",
    "\n",
    "1. subclause_state\n",
    "2. subclause_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NE</th>\n",
       "      <th>txt</th>\n",
       "      <th>data_name</th>\n",
       "      <th>context_subclause</th>\n",
       "      <th>context_subclause_state</th>\n",
       "      <th>context_subclause_descriptor</th>\n",
       "      <th>context_subclause_compound</th>\n",
       "      <th>context_subclause_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_bern</td>\n",
       "      <td>RT @EdValleeWx: Our models specifically used f...</td>\n",
       "      <td>florence</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wilmington</td>\n",
       "      <td>RT @WMO: Hurricane #Florence is likely to make...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cape_fear</td>\n",
       "      <td>RT @ABC: LATEST: Hurricane #Florence a Categor...</td>\n",
       "      <td>florence</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fayetteville</td>\n",
       "      <td>You put your lips on them cigars more than you...</td>\n",
       "      <td>florence</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wilmington</td>\n",
       "      <td>RT @FoxNewsResearch: #HurricaneFlorence - late...</td>\n",
       "      <td>florence</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             NE                                                txt data_name  \\\n",
       "0      new_bern  RT @EdValleeWx: Our models specifically used f...  florence   \n",
       "1    wilmington  RT @WMO: Hurricane #Florence is likely to make...  florence   \n",
       "2     cape_fear  RT @ABC: LATEST: Hurricane #Florence a Categor...  florence   \n",
       "3  fayetteville  You put your lips on them cigars more than you...  florence   \n",
       "4    wilmington  RT @FoxNewsResearch: #HurricaneFlorence - late...  florence   \n",
       "\n",
       "   context_subclause  context_subclause_state  context_subclause_descriptor  \\\n",
       "0                0.0                      1.0                           0.0   \n",
       "1                1.0                      1.0                           0.0   \n",
       "2                0.0                      1.0                           0.0   \n",
       "3                0.0                      1.0                           0.0   \n",
       "4                0.0                      1.0                           0.0   \n",
       "\n",
       "   context_subclause_compound  context_subclause_list  \n",
       "0                         0.0                     0.0  \n",
       "1                         0.0                     0.0  \n",
       "2                         0.0                     0.0  \n",
       "3                         0.0                     0.0  \n",
       "4                         0.0                     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_subclause_state         96.0\n",
      "context_subclause_descriptor    12.0\n",
      "context_subclause_compound       3.0\n",
      "context_subclause_list           4.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "annotated_anchor_data = pd.read_csv('../../data/mined_tweets/combined_tweet_tag_data_NE_flat_anchor_examples.tsv', sep='\\t', index_col=False)\n",
    "annotated_anchor_NEs = annotated_anchor_data[annotated_anchor_data.loc[:, 'context_subclause']==1].loc[:, 'NE']\n",
    "annotated_anchor_txt = annotated_anchor_data[annotated_anchor_data.loc[:, 'context_subclause']==1].loc[:, 'txt']\n",
    "display(annotated_anchor_data.head())\n",
    "context_subclause_types = [x for x in annotated_anchor_data.columns if 'context_subclause_' in x]\n",
    "print(annotated_anchor_data.loc[:, context_subclause_types].sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rewrite the descriptor detection code to output the different types of context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_subclause_anchor_by_type(data, valid_var='valid_loc', \n",
    "                                    anchor_var='max_population', NE_var='NE', \n",
    "                                    data_name_var='data_name_fixed',\n",
    "                                    child_dep_types=['acl', 'appos', 'prep', 'nummod'],\n",
    "                                    parent_dep_types=['nmod', 'compound', 'appos'],\n",
    "                                    parent_state_dep='nmod',\n",
    "                                    parent_compound_dep='compound',\n",
    "                                    verbose=False):\n",
    "    data_NEs = data.loc[:, NE_var].values\n",
    "    # fix format to match parse\n",
    "    data_NEs = [x.replace('_', ' ') for x in data_NEs]\n",
    "    data_valid = data.loc[:, valid_var].values\n",
    "    data_NEs_valid = [x for x,y in zip(data_NEs, data_valid) if y==1]\n",
    "    data_anchor_vals = data.loc[:, anchor_var].values\n",
    "    data_txt = data.loc[:, 'txt'].iloc[0]\n",
    "    data_txt_clean = data_txt.lower()\n",
    "#     subclause_state = []\n",
    "    subclause_descriptor = []\n",
    "    subclause_state = []\n",
    "#     subclause_compound = []\n",
    "#     subclause_list = []\n",
    "    trees = data.loc[:, 'parse'].iloc[0]\n",
    "    if(verbose):\n",
    "        print('full parse %s'%(str(trees)))\n",
    "    tree_graphs = [extract_full_tree(t) for t in trees]\n",
    "    tree_ctr = 0\n",
    "    tree_token_ctr = 0\n",
    "    data_name = data.loc[:, data_name_var].iloc[0]\n",
    "    states = DATA_NAME_STATES_LOOKUP[data_name]\n",
    "    state_matcher = DATA_NAME_STATES_MATCHERS[data_name]\n",
    "    for i, data_NE in enumerate(data_NEs_valid):\n",
    "        if(verbose):\n",
    "            print('candidate %d=%s'%(i, data_NE))\n",
    "        anchor_val_i = data_anchor_vals[i]\n",
    "        anchor_NE_candidates = [x for x,y in zip(data_NEs, data_anchor_vals) if y > anchor_val_i]\n",
    "        if(verbose):\n",
    "            print('anchor NE candidates = %s'%(','.join(anchor_NE_candidates)))\n",
    "        subclause_state_i = 0\n",
    "        subclause_descriptor_i = 0\n",
    "#         subclause_compound_i = 0\n",
    "#         subclause_list_i = 0\n",
    "        ## easiest case: LOC, STATE pattern\n",
    "        data_NE_state_matcher = re.compile('|'.join(['%s\\s?,?\\s?%s'%(data_NE, x) for x in states]).lower())\n",
    "        subclause_state_i = int(data_NE_state_matcher.search(data_txt_clean) is not None)\n",
    "        if(len(anchor_NE_candidates) > 0):\n",
    "            # add whitespace to candidates to avoid matching substrings e.g. \"FL\" doesn't match \"FLOW\"\n",
    "            anchor_NE_candidate_matcher = re.compile('|'.join([' %s |^%s | %s$|^%s$'%((x,)*4) for x in anchor_NE_candidates]))\n",
    "            data_NE_tree, data_NE_subtree, tree_ctr, tree_token_ctr = extract_NE_subtree(data_NE, trees, tree_graphs, tree_ctr, tree_token_ctr)\n",
    "            ## parent test: test if sibling contains state\n",
    "            if(len(data_NE_tree) > 0):\n",
    "                if(verbose):\n",
    "                    print('data NE tree=%s'%(str(data_NE_tree)))\n",
    "                # find parent node for noun, preposition tests\n",
    "                # parent node => index that is not included in NE indices\n",
    "                data_NE_tree_idx = [x[4] for x in data_NE_tree]\n",
    "                NE_child_nodes = [x for x in data_NE_tree if x[2] not in data_NE_tree_idx]\n",
    "                if(len(NE_child_nodes) > 0):\n",
    "                    highest_child_node = NE_child_nodes[0]\n",
    "                    parent_node_idx = highest_child_node[2]\n",
    "                    parent_node_dep = highest_child_node[3]\n",
    "                    parent_node = trees[tree_ctr][parent_node_idx]\n",
    "                    if(verbose):\n",
    "                        print('NE parse token at tree=%d, token=%d:'%(tree_ctr, tree_token_ctr))\n",
    "                        print(str(trees[tree_ctr][tree_token_ctr-1]))\n",
    "                        print('NE parent token:')\n",
    "                        print(str(parent_node))\n",
    "                    # if parent is connected by valid dep, find children and look for state mention\n",
    "                    if(parent_node_dep in parent_dep_types):\n",
    "                        parent_node_subtree_idx = get_subtree(parent_node[4], tree_graphs[tree_ctr])\n",
    "                        # include parent in subtree\n",
    "                        parent_node_subtree = [x for x in trees[tree_ctr] if x[4] in parent_node_subtree_idx or x[4]==parent_node_idx]\n",
    "                        parent_node_subtree_str = ' '.join([x[0] for x in parent_node_subtree]).lower()\n",
    "                        if(verbose):\n",
    "                            print('parent node subtree %s'%(str(parent_node_subtree)))\n",
    "                            print('parent node subtree str %s'%(parent_node_subtree_str))\n",
    "#                         if(verbose):\n",
    "#                             print('matching states %s on tree %s'%(state_matcher.pattern, parent_node_subtree_str.lower()))\n",
    "                        ## collapse compound/nmod because they're arbitrary\n",
    "#                         if(parent_node_dep in parent_dep_types):\n",
    "#                         subclause_state_i = int(state_matcher.search(parent_node_subtree_str) is not None) \n",
    "#                         elif(parent_node_dep == parent_compound_dep):\n",
    "#                         subclause_compound_i = int(state_matcher.search(parent_node_subtree_str) is not None) \n",
    "#                         parent_subclause_anchor_i = int(state_matcher.search(parent_node_subtree_str) is not None)\n",
    "            \n",
    "            ## child test: test if child contains anchor\n",
    "            if(len(data_NE_subtree) > 0):\n",
    "                if(verbose):\n",
    "                    print('NE=%s subtree=%s'%(data_NE, str(data_NE_subtree)))\n",
    "                ## filter for allowed dependency trees\n",
    "                ## find dep type for highest node (lowest parent index) in subtree\n",
    "                min_node_dep_idx = min(data_NE_subtree, key=lambda x: x[2])\n",
    "                min_node_deps = [x[3] for x in data_NE_subtree if x[2]==min_node_dep_idx[2]]\n",
    "                if(verbose):\n",
    "                    print('min node deps %s'%(str(min_node_deps)))\n",
    "                subtree_str = ' '.join([x[0] for x in data_NE_subtree])\n",
    "                if(len(set(min_node_deps) & set(child_dep_types)) > 0):\n",
    "                    ## look for NE in phrase\n",
    "                    if(verbose):\n",
    "                        print('subtree = %s'%(subtree_str))\n",
    "                    subclause_descriptor_i = int(anchor_NE_candidate_matcher.search(subtree_str) is not None)\n",
    "                    # sometimes the state comes as an appositive\n",
    "#                     subclause_state_i = int(state_matcher.search(subtree_str.lower()) is not None)\n",
    "                    ## conjuction is a special case: anchor NE must occur \n",
    "                    ## in format NE CONJ NE, state\n",
    "#                 elif('conj' in min_node_deps):\n",
    "#                     subclause_list_i = int(state_matcher.search(subtree_str.lower()) is not None)\n",
    "        subclause_state.append(subclause_state_i)\n",
    "        subclause_descriptor.append(subclause_descriptor_i)\n",
    "#         subclause_compound.append(subclause_compound_i)\n",
    "#         subclause_list.append(subclause_list_i)\n",
    "    subclause_state = pd.Series(subclause_state, index=data_NEs_valid)\n",
    "    subclause_descriptor = pd.Series(subclause_descriptor, index=data_NEs_valid)\n",
    "#     subclause_compound = pd.Series(subclause_compound, index=data_NEs_valid)\n",
    "#     subclause_list = pd.Series(subclause_list, index=data_NEs_valid)\n",
    "#     return subclause_state, subclause_descriptor, subclause_compound, subclause_list\n",
    "    return subclause_state, subclause_descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the predicted subclause types to the annotated data, get a second set of annotations, and then compute precision/recall over the majority labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NE                                                                        mayfair\n",
       "txt                             Homes in the Mayfair neighborhood of Lumberton...\n",
       "data_name                                                                florence\n",
       "context_subclause                                                               1\n",
       "context_subclause_state                                                         0\n",
       "context_subclause_descriptor                                                    0\n",
       "context_subclause_compound                                                      1\n",
       "context_subclause_list                                                          0\n",
       "context_subclause_any                                                           1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load annotated\n",
    "annotated_anchor_data = pd.read_csv('../../data/mined_tweets/combined_tweet_tag_data_NE_flat_anchor_examples.tsv', sep='\\t', index_col=False)\n",
    "subclause_types = ['state', 'descriptor']\n",
    "annotated_anchor_data_preds = []\n",
    "for idx_i, annotated_data_i in annotated_anchor_data.iterrows():\n",
    "    txt_i = annotated_data_i.loc['txt']\n",
    "    data_i = anchor_data[anchor_data.loc[:, 'txt']==txt_i]\n",
    "    NE_i = annotated_data_i.loc['NE']\n",
    "    data_name_i = data_i.loc[:, 'data_name_fixed'].iloc[0]\n",
    "    state_gold_i = annotated_data_i.loc['context_subclause_state']\n",
    "    descriptor_gold_i = annotated_data_i.loc['context_subclause_descriptor']\n",
    "    # restrict to data where NE only occurs once per status\n",
    "    if(len([x for x in data_i.loc[:, 'NE'] if x.replace(' ', '_').lower()==NE_i]) == 1):\n",
    "#         print('testing NE %s, txt:%s'%(NE_i, txt_i))\n",
    "        subclause_state_i, subclause_descriptor_i = detect_subclause_anchor_by_type(data_i, verbose=False)\n",
    "        subclause_state_i.index = [x.replace(' ', '_').lower() for x in subclause_state_i.index]\n",
    "        subclause_descriptor_i.index = [x.replace(' ', '_').lower() for x in subclause_descriptor_i.index]\n",
    "        subclause_state_i = subclause_state_i.loc[NE_i]\n",
    "        subclause_descriptor_i = subclause_descriptor_i.loc[NE_i]\n",
    "        annotated_anchor_data_preds.append([data_i.loc[:, 'id'].iloc[0], data_name_i, NE_i, txt_i, state_gold_i, descriptor_gold_i, subclause_state_i, subclause_descriptor_i])\n",
    "annotated_anchor_data_preds = pd.DataFrame(annotated_anchor_data_preds, columns=['id', 'data_name', 'NE', 'txt', 'state_gold', 'descriptor_gold', 'state_pred', 'descriptor_pred'])\n",
    "annotated_anchor_data_pred_out_file = '../../data/mined_tweets/NE_anchor_examples_with_pred.tsv'\n",
    "annotated_anchor_data_preds.to_csv(annotated_anchor_data_pred_out_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE mayfair, txt:Homes in the Mayfair neighborhood of Lumberton, NC are underwater again, after being flooded in 2016 during Hurricane Matthew..and water levels continue to rise. #HurricaneFlorence #lumbertonnc #northcarolina #lumberriver @TheNOWtv <URL>\n",
      "full parse [[['Homes', 'NOUN', 8, 'nsubj', 0], ['in', 'ADP', 0, 'prep', 1], ['the', 'DET', 4, 'det', 2], ['Mayfair', 'PROPN', 4, 'compound', 3], ['neighborhood', 'NOUN', 1, 'pobj', 4], ['of', 'ADP', 4, 'prep', 5], ['Lumberton', 'PROPN', 7, 'compound', 6], ['NC', 'PROPN', 5, 'pobj', 7], ['are', 'VERB', 8, 'ROOT', 8], ['underwater', 'ADJ', 8, 'acomp', 9], ['again', 'ADV', 8, 'advmod', 10], ['after', 'ADP', 8, 'prep', 11], ['being', 'VERB', 13, 'auxpass', 12], ['flooded', 'VERB', 11, 'pcomp', 13], ['in', 'ADP', 13, 'prep', 14], ['2016', 'NUM', 14, 'pobj', 15], ['during', 'ADP', 13, 'prep', 16], ['Hurricane', 'PROPN', 18, 'compound', 17], ['Matthew', 'PROPN', 16, 'pobj', 18], ['..', 'PUNCT', 8, 'punct', 19], ['and', 'CCONJ', 8, 'cc', 20], ['water', 'NOUN', 22, 'compound', 21], ['levels', 'NOUN', 23, 'nsubj', 22], ['continue', 'VERB', 8, 'conj', 23], ['to', 'PART', 25, 'aux', 24], ['rise', 'VERB', 23, 'xcomp', 25], ['.', 'PUNCT', 23, 'punct', 26]], [['#HurricaneFlorence', 'PROPN', 2, 'compound', 0], ['#lumbertonnc', 'PROPN', 2, 'compound', 1], ['#northcarolina', 'PROPN', 2, 'ROOT', 2], ['#lumberriver', 'PROPN', 2, 'appos', 3], ['@TheNOWtv', 'PROPN', 2, 'punct', 4]]]\n",
      "candidate 0=Mayfair\n",
      "anchor NE candidates = Lumberton,NC\n",
      "data NE tree=[['Mayfair', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Mayfair', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['neighborhood', 'NOUN', 1, 'pobj', 4]\n",
      "parent node subtree [['the', 'DET', 4, 'det', 2], ['Mayfair', 'PROPN', 4, 'compound', 3], ['neighborhood', 'NOUN', 1, 'pobj', 4], ['of', 'ADP', 4, 'prep', 5], ['Lumberton', 'PROPN', 7, 'compound', 6], ['NC', 'PROPN', 5, 'pobj', 7]]\n",
      "parent node subtree str the mayfair neighborhood of lumberton nc\n",
      "candidate 1=Lumberton\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Lumberton', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Lumberton', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['Lumberton', 'PROPN', 7, 'compound', 6], ['NC', 'PROPN', 5, 'pobj', 7]]\n",
      "parent node subtree str lumberton nc\n",
      "testing NE yale, txt:VIDEO: I-10 at Yale, The Heights, Houston (residential area on the north side of downtown.) ( - @euzkera ) #Harvey <URL>\n",
      "full parse [[['VIDEO', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['I10', 'NOUN', 0, 'appos', 2], ['at', 'ADP', 2, 'prep', 3], ['Yale', 'PROPN', 10, 'compound', 4], ['The', 'DET', 10, 'det', 5], ['Heights', 'PROPN', 7, 'nmod', 6], ['Houston', 'PROPN', 10, 'nmod', 7], ['(', 'PUNCT', 10, 'punct', 8], ['residential', 'ADJ', 10, 'amod', 9], ['area', 'NOUN', 3, 'pobj', 10], ['on', 'ADP', 10, 'prep', 11], ['the', 'DET', 14, 'det', 12], ['north', 'NOUN', 14, 'compound', 13], ['side', 'NOUN', 11, 'pobj', 14], ['of', 'ADP', 14, 'prep', 15], ['downtown', 'NOUN', 15, 'pobj', 16], ['.', 'PUNCT', 0, 'punct', 17], [')', 'PUNCT', 0, 'punct', 18]], [['(', 'PUNCT', 3, 'punct', 0], ['@euzkera', 'PROPN', 3, 'nmod', 1], [')', 'PUNCT', 3, 'punct', 2], ['#Harvey', 'PROPN', 3, 'ROOT', 3]]]\n",
      "candidate 0=Yale\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Yale', 'PROPN', 10, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Yale', 'PROPN', 10, 'compound', 4]\n",
      "NE parent token:\n",
      "['area', 'NOUN', 3, 'pobj', 10]\n",
      "parent node subtree [['Yale', 'PROPN', 10, 'compound', 4], ['The', 'DET', 10, 'det', 5], ['Heights', 'PROPN', 7, 'nmod', 6], ['Houston', 'PROPN', 10, 'nmod', 7], ['(', 'PUNCT', 10, 'punct', 8], ['residential', 'ADJ', 10, 'amod', 9], ['area', 'NOUN', 3, 'pobj', 10], ['on', 'ADP', 10, 'prep', 11], ['the', 'DET', 14, 'det', 12], ['north', 'NOUN', 14, 'compound', 13], ['side', 'NOUN', 11, 'pobj', 14], ['of', 'ADP', 14, 'prep', 15], ['downtown', 'NOUN', 15, 'pobj', 16]]\n",
      "parent node subtree str yale the heights houston ( residential area on the north side of downtown\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "testing NE bay, txt:@verizon is offering 3 free months of service to customers in Bay and Gulf counties in FL supporting people affected by #HurricaneMichael . Good stuff! Any chance you will extend that offer to those of us in the National Guard who have been here since day 1 with no cell signal?\n",
      "full parse [[['@verizon', 'PROPN', 2, 'nsubj', 0], ['is', 'VERB', 2, 'aux', 1], ['offering', 'VERB', 2, 'ROOT', 2], ['3', 'NUM', 5, 'nummod', 3], ['free', 'ADJ', 5, 'amod', 4], ['months', 'NOUN', 2, 'dobj', 5], ['of', 'ADP', 5, 'prep', 6], ['service', 'NOUN', 6, 'pobj', 7], ['to', 'ADP', 7, 'prep', 8], ['customers', 'NOUN', 8, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Bay', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 11, 'conj', 13], ['counties', 'NOUN', 10, 'pobj', 14], ['in', 'ADP', 14, 'prep', 15], ['FL', 'PROPN', 15, 'pobj', 16], ['supporting', 'VERB', 2, 'advcl', 17], ['people', 'NOUN', 17, 'dobj', 18], ['affected', 'VERB', 18, 'acl', 19], ['by', 'ADP', 19, 'agent', 20], ['#HurricaneMichael', 'PROPN', 20, 'pobj', 21], ['.', 'PUNCT', 2, 'punct', 22]], [['Good', 'ADJ', 1, 'amod', 0], ['stuff', 'NOUN', 1, 'ROOT', 1], ['!', 'PUNCT', 1, 'punct', 2]], [['Any', 'DET', 1, 'det', 0], ['chance', 'NOUN', 1, 'ROOT', 1], ['you', 'PRON', 4, 'nsubj', 2], ['will', 'VERB', 4, 'aux', 3], ['extend', 'VERB', 1, 'acl', 4], ['that', 'DET', 6, 'det', 5], ['offer', 'NOUN', 4, 'dobj', 6], ['to', 'ADP', 4, 'prep', 7], ['those', 'DET', 7, 'pobj', 8], ['of', 'ADP', 8, 'prep', 9], ['us', 'PRON', 9, 'pobj', 10], ['in', 'ADP', 8, 'prep', 11], ['the', 'DET', 14, 'det', 12], ['National', 'PROPN', 14, 'compound', 13], ['Guard', 'PROPN', 11, 'pobj', 14], ['who', 'NOUN', 17, 'nsubj', 15], ['have', 'VERB', 17, 'aux', 16], ['been', 'VERB', 8, 'relcl', 17], ['here', 'ADV', 17, 'advmod', 18], ['since', 'ADP', 17, 'prep', 19], ['day', 'NOUN', 19, 'pobj', 20], ['1', 'NUM', 20, 'nummod', 21], ['with', 'ADP', 17, 'prep', 22], ['no', 'DET', 25, 'det', 23], ['cell', 'NOUN', 25, 'compound', 24], ['signal', 'NOUN', 22, 'pobj', 25], ['?', 'PUNCT', 1, 'punct', 26]]]\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Gulf,FL\n",
      "data NE tree=[['Bay', 'PROPN', 14, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Bay', 'PROPN', 14, 'nmod', 11]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 10, 'pobj', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 11, 'conj', 13], ['counties', 'NOUN', 10, 'pobj', 14], ['in', 'ADP', 14, 'prep', 15], ['FL', 'PROPN', 15, 'pobj', 16]]\n",
      "parent node subtree str bay and gulf counties in fl\n",
      "NE=Bay subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 11, 'conj', 13]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Gulf\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Gulf', 'PROPN', 11, 'conj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Gulf', 'PROPN', 11, 'conj', 13]\n",
      "NE parent token:\n",
      "['Bay', 'PROPN', 14, 'nmod', 11]\n",
      "testing NE new_bern, txt:RT @EdValleeWx: Our models specifically used for forecasting hurricanes have great agreement in #Florence making landfall near New Bern, NC…\n",
      "full parse [[['RT', 'PROPN', 1, 'compound', 0], ['@EdValleeWx', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['Our', 'ADJ', 4, 'poss', 3], ['models', 'NOUN', 10, 'nsubj', 4], ['specifically', 'ADV', 6, 'advmod', 5], ['used', 'VERB', 4, 'acl', 6], ['for', 'ADP', 6, 'prep', 7], ['forecasting', 'VERB', 7, 'pcomp', 8], ['hurricanes', 'NOUN', 8, 'dobj', 9], ['have', 'VERB', 10, 'ROOT', 10], ['great', 'ADJ', 12, 'amod', 11], ['agreement', 'NOUN', 10, 'dobj', 12], ['in', 'ADP', 12, 'prep', 13], ['#Florence', 'NOUN', 15, 'nsubj', 14], ['making', 'VERB', 13, 'pcomp', 15], ['landfall', 'NOUN', 15, 'dobj', 16], ['near', 'ADP', 16, 'prep', 17], ['New', 'PROPN', 20, 'compound', 18], ['Bern', 'PROPN', 20, 'compound', 19], ['NC', 'PROPN', 17, 'pobj', 20], ['…', 'PUNCT', 10, 'punct', 21]]]\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['New', 'PROPN', 20, 'compound', 18], ['Bern', 'PROPN', 20, 'compound', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Bern', 'PROPN', 20, 'compound', 19]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 17, 'pobj', 20]\n",
      "parent node subtree [['New', 'PROPN', 20, 'compound', 18], ['Bern', 'PROPN', 20, 'compound', 19], ['NC', 'PROPN', 17, 'pobj', 20]]\n",
      "parent node subtree str new bern nc\n",
      "false positive: NE=new_bern, type=compound\n",
      "testing NE wilmington, txt:RT @WMO: Hurricane #Florence is likely to make landfall near Wilmington (North Carolina) . The tidal data shows a sea level rise of around…\n",
      "full parse [[['RT', 'PROPN', 1, 'compound', 0], ['@WMO', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['Hurricane', 'PROPN', 4, 'compound', 3], ['#Florence', 'PROPN', 5, 'nsubj', 4], ['is', 'VERB', 5, 'ROOT', 5], ['likely', 'ADJ', 5, 'acomp', 6], ['to', 'PART', 8, 'aux', 7], ['make', 'VERB', 6, 'xcomp', 8], ['landfall', 'NOUN', 8, 'dobj', 9], ['near', 'ADP', 9, 'prep', 10], ['Wilmington', 'PROPN', 10, 'pobj', 11], ['(', 'PUNCT', 11, 'punct', 12], ['North', 'PROPN', 14, 'compound', 13], ['Carolina', 'PROPN', 11, 'appos', 14], [')', 'PUNCT', 11, 'punct', 15], ['.', 'PUNCT', 5, 'punct', 16]], [['The', 'DET', 2, 'det', 0], ['tidal', 'ADJ', 2, 'amod', 1], ['data', 'NOUN', 3, 'nsubj', 2], ['shows', 'VERB', 3, 'ROOT', 3], ['a', 'DET', 7, 'det', 4], ['sea', 'NOUN', 6, 'compound', 5], ['level', 'NOUN', 7, 'compound', 6], ['rise', 'NOUN', 3, 'dobj', 7], ['of', 'ADP', 7, 'prep', 8], ['around', 'ADP', 8, 'pobj', 9], ['…', 'PUNCT', 3, 'punct', 10]]]\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Wilmington', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Wilmington', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['near', 'ADP', 9, 'prep', 10]\n",
      "NE=Wilmington subtree=[['(', 'PUNCT', 11, 'punct', 12], ['North', 'PROPN', 14, 'compound', 13], ['Carolina', 'PROPN', 11, 'appos', 14], [')', 'PUNCT', 11, 'punct', 15]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( North Carolina )\n",
      "false positive: NE=wilmington, type=descriptor\n",
      "testing NE cape_fear, txt:RT @ABC: LATEST: Hurricane #Florence a Category 4 storm 670 miles ESE of Cape Fear, North Carolina, with maximum sustained winds of 140 mph…\n",
      "full parse [[['RT', 'PROPN', 1, 'compound', 0], ['@ABC', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['LATEST', 'PROPN', 1, 'appos', 3], [':', 'PUNCT', 1, 'punct', 4], ['Hurricane', 'PROPN', 6, 'compound', 5], ['#Florence', 'PROPN', 6, 'ROOT', 6], ['a', 'DET', 10, 'det', 7], ['Category', 'NOUN', 10, 'nmod', 8], ['4', 'NUM', 8, 'nummod', 9], ['storm', 'NOUN', 6, 'appos', 10], ['670', 'NUM', 12, 'nummod', 11], ['miles', 'NOUN', 10, 'appos', 12], ['ESE', 'PROPN', 10, 'appos', 13], ['of', 'ADP', 13, 'prep', 14], ['Cape', 'PROPN', 16, 'compound', 15], ['Fear', 'PROPN', 18, 'compound', 16], ['North', 'PROPN', 18, 'compound', 17], ['Carolina', 'PROPN', 14, 'pobj', 18], ['with', 'ADP', 10, 'prep', 19], ['maximum', 'ADJ', 22, 'amod', 20], ['sustained', 'ADJ', 22, 'amod', 21], ['winds', 'NOUN', 19, 'pobj', 22], ['of', 'ADP', 22, 'prep', 23], ['140', 'NUM', 25, 'nummod', 24], ['mph', 'NOUN', 23, 'pobj', 25], ['…', 'PUNCT', 6, 'punct', 26]]]\n",
      "candidate 0=Cape Fear\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Cape', 'PROPN', 16, 'compound', 15], ['Fear', 'PROPN', 18, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Fear', 'PROPN', 18, 'compound', 16]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 14, 'pobj', 18]\n",
      "parent node subtree [['Cape', 'PROPN', 16, 'compound', 15], ['Fear', 'PROPN', 18, 'compound', 16], ['North', 'PROPN', 18, 'compound', 17], ['Carolina', 'PROPN', 14, 'pobj', 18]]\n",
      "parent node subtree str cape fear north carolina\n",
      "false positive: NE=cape_fear, type=compound\n",
      "testing NE fayetteville, txt:You put your lips on them cigars more than you do on me\" GF says. #cigar #lastselfie #sotl #botl #hurricaneflorence @ Fayetteville, North Carolina <URL>\n",
      "full parse [[['You', 'PRON', 1, 'nsubj', 0], ['put', 'VERB', 15, 'ccomp', 1], ['your', 'ADJ', 3, 'poss', 2], ['lips', 'NOUN', 1, 'dobj', 3], ['on', 'ADP', 1, 'prep', 4], ['them', 'PRON', 4, 'pobj', 5], ['cigars', 'NOUN', 1, 'dobj', 6], ['more', 'ADJ', 1, 'advmod', 7], ['than', 'ADP', 10, 'mark', 8], ['you', 'PRON', 10, 'nsubj', 9], ['do', 'VERB', 7, 'advcl', 10], ['on', 'ADP', 1, 'prep', 11], ['me', 'PRON', 11, 'pobj', 12], ['\"', 'PUNCT', 15, 'punct', 13], ['GF', 'PROPN', 15, 'nsubj', 14], ['says', 'VERB', 15, 'ROOT', 15], ['.', 'PUNCT', 15, 'punct', 16]], [['#cigar', 'PROPN', 1, 'compound', 0], ['#lastselfie', 'PROPN', 2, 'compound', 1], ['#sotl', 'PROPN', 2, 'ROOT', 2], ['#botl', 'PROPN', 4, 'compound', 3], ['#hurricaneflorence', 'PROPN', 2, 'appos', 4], ['@', 'ADP', 2, 'punct', 5], ['Fayetteville', 'PROPN', 8, 'compound', 6], ['North', 'PROPN', 8, 'compound', 7], ['Carolina', 'PROPN', 8, 'ROOT', 8]]]\n",
      "candidate 0=Fayetteville\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Fayetteville', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['Fayetteville', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 8, 'ROOT', 8]\n",
      "parent node subtree [['Fayetteville', 'PROPN', 8, 'compound', 6], ['North', 'PROPN', 8, 'compound', 7], ['Carolina', 'PROPN', 8, 'ROOT', 8]]\n",
      "parent node subtree str fayetteville north carolina\n",
      "false positive: NE=fayetteville, type=compound\n",
      "testing NE wilmington, txt:RT @FoxNewsResearch: #HurricaneFlorence - latest •Cat 2 •170 mi ESE of Wilmington, NC •220 mi E of Myrtle Beach, SC •10M+ in its path •1.7M…\n",
      "full parse [[['RT', 'PROPN', 0, 'ROOT', 0], ['@FoxNewsResearch', 'PROPN', 0, 'punct', 1], [':', 'PUNCT', 0, 'punct', 2], ['#HurricaneFlorence', 'PROPN', 6, 'nmod', 3], ['latest', 'ADJ', 6, 'amod', 4], ['•', 'PROPN', 6, 'nmod', 5], ['Cat', 'PROPN', 6, 'ROOT', 6], ['2', 'NUM', 6, 'nummod', 7], ['•', 'NOUN', 6, 'appos', 8], ['170', 'NUM', 11, 'nummod', 9], ['mi', 'ADP', 11, 'compound', 10], ['ESE', 'PROPN', 6, 'appos', 11], ['of', 'ADP', 11, 'prep', 12], ['Wilmington', 'PROPN', 14, 'compound', 13], ['NC', 'PROPN', 12, 'pobj', 14], ['•', 'PROPN', 6, 'appos', 15], ['220', 'NUM', 18, 'nummod', 16], ['mi', 'ADP', 18, 'compound', 17], ['E', 'NOUN', 6, 'appos', 18], ['of', 'ADP', 18, 'prep', 19], ['Myrtle', 'PROPN', 21, 'compound', 20], ['Beach', 'PROPN', 22, 'compound', 21], ['SC', 'PROPN', 19, 'pobj', 22], ['•', 'NUM', 24, 'compound', 23], ['10M', 'NUM', 29, 'npadvmod', 24], ['+', 'CCONJ', 24, 'cc', 25], ['in', 'ADP', 29, 'prep', 26], ['its', 'ADJ', 28, 'poss', 27], ['path', 'NOUN', 26, 'pobj', 28], ['•', 'NOUN', 29, 'ROOT', 29], ['1.7', 'NUM', 31, 'nummod', 30], ['M', 'NOUN', 31, 'ROOT', 31], ['…', 'NOUN', 31, 'punct', 32]]]\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = NC,SC\n",
      "data NE tree=[['Wilmington', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Wilmington', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 12, 'pobj', 14]\n",
      "parent node subtree [['Wilmington', 'PROPN', 14, 'compound', 13], ['NC', 'PROPN', 12, 'pobj', 14]]\n",
      "parent node subtree str wilmington nc\n",
      "candidate 1=Myrtle Beach\n",
      "anchor NE candidates = \n",
      "false positive: NE=wilmington, type=compound\n",
      "testing NE red_cross, txt:Met Reyna and her whole family who evacuated from the coast to a Red Cross shelter in Wilson, NC. She says they left everything behind, so they are hoping to have something to go back to. #hurricaneflorence <URL>\n",
      "full parse [[['Met', 'PROPN', 1, 'compound', 0], ['Reyna', 'PROPN', 1, 'ROOT', 1], ['and', 'CCONJ', 1, 'cc', 2], ['her', 'ADJ', 5, 'poss', 3], ['whole', 'ADJ', 5, 'amod', 4], ['family', 'NOUN', 1, 'conj', 5], ['who', 'NOUN', 7, 'nsubj', 6], ['evacuated', 'VERB', 5, 'relcl', 7], ['from', 'ADP', 7, 'prep', 8], ['the', 'DET', 10, 'det', 9], ['coast', 'NOUN', 8, 'pobj', 10], ['to', 'ADP', 7, 'prep', 11], ['a', 'DET', 15, 'det', 12], ['Red', 'PROPN', 14, 'compound', 13], ['Cross', 'PROPN', 15, 'compound', 14], ['shelter', 'NOUN', 11, 'pobj', 15], ['in', 'ADP', 15, 'prep', 16], ['Wilson', 'PROPN', 18, 'compound', 17], ['NC', 'PROPN', 16, 'pobj', 18], ['.', 'PUNCT', 1, 'punct', 19]], [['She', 'PRON', 1, 'nsubj', 0], ['says', 'VERB', 1, 'ROOT', 1], ['they', 'PRON', 3, 'nsubj', 2], ['left', 'VERB', 1, 'ccomp', 3], ['everything', 'NOUN', 3, 'dobj', 4], ['behind', 'ADV', 3, 'prt', 5], ['so', 'ADP', 9, 'mark', 6], ['they', 'PRON', 9, 'nsubj', 7], ['are', 'VERB', 9, 'aux', 8], ['hoping', 'VERB', 3, 'advcl', 9], ['to', 'PART', 11, 'aux', 10], ['have', 'VERB', 9, 'xcomp', 11], ['something', 'NOUN', 11, 'dobj', 12], ['to', 'PART', 14, 'aux', 13], ['go', 'VERB', 12, 'relcl', 14], ['back', 'ADV', 14, 'advmod', 15], ['to', 'ADP', 15, 'prep', 16], ['.', 'PUNCT', 1, 'punct', 17]], [['#hurricaneflorence', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Red Cross\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Red', 'PROPN', 14, 'compound', 13], ['Cross', 'PROPN', 15, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Cross', 'PROPN', 15, 'compound', 14]\n",
      "NE parent token:\n",
      "['shelter', 'NOUN', 11, 'pobj', 15]\n",
      "parent node subtree [['a', 'DET', 15, 'det', 12], ['Red', 'PROPN', 14, 'compound', 13], ['Cross', 'PROPN', 15, 'compound', 14], ['shelter', 'NOUN', 11, 'pobj', 15], ['in', 'ADP', 15, 'prep', 16], ['Wilson', 'PROPN', 18, 'compound', 17], ['NC', 'PROPN', 16, 'pobj', 18]]\n",
      "parent node subtree str a red cross shelter in wilson nc\n",
      "testing NE shallotte, txt:UPDATE: The @WaffleHouse in North Myrtle Beach remains open this morning even as #HurricaneFlorence bears down. And who do I meet? Barrett - the tenacious employee from Shallotte who refused to shut down as long as @Bojangles1977 was still slingin’ hash. <URL>\n",
      "full parse [[['UPDATE', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['The', 'DET', 3, 'det', 2], ['@WaffleHouse', 'NOUN', 8, 'nsubj', 3], ['in', 'ADP', 3, 'prep', 4], ['North', 'PROPN', 6, 'compound', 5], ['Myrtle', 'PROPN', 7, 'compound', 6], ['Beach', 'PROPN', 4, 'pobj', 7], ['remains', 'VERB', 8, 'ROOT', 8], ['open', 'ADJ', 8, 'acomp', 9], ['this', 'DET', 11, 'det', 10], ['morning', 'NOUN', 8, 'npadvmod', 11], ['even', 'ADV', 15, 'advmod', 12], ['as', 'ADP', 15, 'mark', 13], ['#HurricaneFlorence', 'PROPN', 15, 'nsubj', 14], ['bears', 'VERB', 8, 'advcl', 15], ['down', 'PART', 15, 'prt', 16], ['.', 'PUNCT', 8, 'punct', 17]], [['And', 'CCONJ', 4, 'cc', 0], ['who', 'NOUN', 4, 'dobj', 1], ['do', 'VERB', 4, 'aux', 2], ['I', 'PRON', 4, 'nsubj', 3], ['meet', 'VERB', 4, 'ROOT', 4], ['?', 'PUNCT', 4, 'punct', 5]], [['Barrett', 'PROPN', 0, 'ROOT', 0], ['the', 'DET', 3, 'det', 1], ['tenacious', 'ADJ', 3, 'amod', 2], ['employee', 'NOUN', 0, 'appos', 3], ['from', 'ADP', 3, 'prep', 4], ['Shallotte', 'PROPN', 4, 'pobj', 5], ['who', 'NOUN', 7, 'nsubj', 6], ['refused', 'VERB', 3, 'relcl', 7], ['to', 'PART', 9, 'aux', 8], ['shut', 'VERB', 7, 'xcomp', 9], ['down', 'PART', 9, 'prt', 10], ['as', 'ADV', 12, 'advmod', 11], ['long', 'ADV', 9, 'advmod', 12], ['as', 'ADP', 15, 'mark', 13], ['@Bojangles1977', 'NOUN', 15, 'nsubj', 14], ['was', 'VERB', 12, 'advcl', 15], ['still', 'ADV', 15, 'advmod', 16], ['slingin', 'NOUN', 19, 'compound', 17], ['’', 'NUM', 19, 'compound', 18], ['hash', 'NOUN', 15, 'attr', 19], ['.', 'PUNCT', 0, 'punct', 20]]]\n",
      "candidate 0=Myrtle Beach\n",
      "anchor NE candidates = \n",
      "candidate 1=Shallotte\n",
      "anchor NE candidates = Myrtle Beach\n",
      "data NE tree=[['Shallotte', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=2, token=6:\n",
      "['Shallotte', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['from', 'ADP', 3, 'prep', 4]\n",
      "testing NE kensington, txt:Fast move Ng low clouds and trees starting to dance! #florence @ Kensington at Regency, Cary <URL>\n",
      "full parse [[['Fast', 'ADJ', 1, 'amod', 0], ['move', 'NOUN', 1, 'ROOT', 1], ['Ng', 'NOUN', 4, 'nmod', 2], ['low', 'ADJ', 4, 'amod', 3], ['clouds', 'NOUN', 1, 'dobj', 4], ['and', 'CCONJ', 4, 'cc', 5], ['trees', 'NOUN', 4, 'conj', 6], ['starting', 'VERB', 1, 'advcl', 7], ['to', 'PART', 9, 'aux', 8], ['dance', 'VERB', 7, 'xcomp', 9], ['!', 'PUNCT', 1, 'punct', 10]], [['#florence', 'PROPN', 0, 'ROOT', 0], ['@', 'ADP', 0, 'prep', 1], ['Kensington', 'PROPN', 2, 'ROOT', 2], ['at', 'ADP', 2, 'prep', 3], ['Regency', 'PROPN', 5, 'compound', 4], ['Cary', 'PROPN', 3, 'pobj', 5]]]\n",
      "candidate 0=Kensington\n",
      "anchor NE candidates = Cary\n",
      "data NE tree=[['Kensington', 'PROPN', 2, 'ROOT', 2]]\n",
      "NE=Kensington subtree=[['at', 'ADP', 2, 'prep', 3], ['Regency', 'PROPN', 5, 'compound', 4], ['Cary', 'PROPN', 3, 'pobj', 5]]\n",
      "min node deps ['prep']\n",
      "subtree = at Regency Cary\n",
      "candidate 1=Cary\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive: NE=kensington, type=descriptor\n",
      "testing NE wilmington, txt:#hurricaneflorence in downtown Wilmington, NC @TheNOWtv @ Downtown Wilmington By Cape Fear River <URL>\n",
      "full parse [[['#hurricaneflorence', 'PROPN', 0, 'ROOT', 0], ['in', 'ADP', 0, 'prep', 1], ['downtown', 'NOUN', 4, 'compound', 2], ['Wilmington', 'PROPN', 4, 'compound', 3], ['NC', 'PROPN', 5, 'compound', 4], ['@TheNOWtv', 'PROPN', 1, 'pobj', 5], ['@', 'ADP', 0, 'punct', 6], ['Downtown', 'PROPN', 8, 'compound', 7], ['Wilmington', 'PROPN', 8, 'ROOT', 8], ['By', 'ADP', 8, 'prep', 9], ['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'PROPN', 12, 'compound', 11], ['River', 'PROPN', 9, 'pobj', 12]]]\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Wilmington', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Wilmington', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'compound', 4]\n",
      "parent node subtree [['downtown', 'NOUN', 4, 'compound', 2], ['Wilmington', 'PROPN', 4, 'compound', 3], ['NC', 'PROPN', 5, 'compound', 4]]\n",
      "parent node subtree str downtown wilmington nc\n",
      "false positive: NE=wilmington, type=compound\n",
      "testing NE sunset_beach, txt:#hurricaneflorence #sunsetbeachnc #oceanislebeach #northcarolina #sup #veterinary @wildearthpets lauraw1717 madisonwardd _taylor_51 @ Sunset Beach, North Carolina <URL>\n",
      "full parse [[['#hurricaneflorence', 'PROPN', 6, 'meta', 0], ['#sunsetbeachnc', 'PROPN', 3, 'compound', 1], ['#oceanislebeach', 'PROPN', 3, 'compound', 2], ['#northcarolina', 'PROPN', 6, 'nmod', 3], ['#sup', 'PUNCT', 3, 'appos', 4], ['#veterinary', 'ADJ', 6, 'amod', 5], ['@wildearthpets', 'NOUN', 7, 'nsubj', 6], ['lauraw', 'NOUN', 7, 'ROOT', 7], ['1717', 'NUM', 10, 'nummod', 8], ['madisonwardd', 'NOUN', 10, 'compound', 9], ['_taylor_51', 'PROPN', 7, 'appos', 10], ['@', 'PUNCT', 7, 'punct', 11], ['Sunset', 'PROPN', 13, 'compound', 12], ['Beach', 'PROPN', 15, 'compound', 13], ['North', 'PROPN', 15, 'compound', 14], ['Carolina', 'PROPN', 15, 'ROOT', 15]]]\n",
      "candidate 0=Sunset Beach\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Sunset', 'PROPN', 13, 'compound', 12], ['Beach', 'PROPN', 15, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Beach', 'PROPN', 15, 'compound', 13]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 15, 'ROOT', 15]\n",
      "parent node subtree [['Sunset', 'PROPN', 13, 'compound', 12], ['Beach', 'PROPN', 15, 'compound', 13], ['North', 'PROPN', 15, 'compound', 14], ['Carolina', 'PROPN', 15, 'ROOT', 15]]\n",
      "parent node subtree str sunset beach north carolina\n",
      "false positive: NE=sunset_beach, type=compound\n",
      "testing NE morehead_city, txt:Morehead City, NC decimated by #HurricaneFlorence with @DukeEnergy experts doing damage assessments—saying it’s the worst they’ve seen. Flooded areas will make accessing our equipment extremely difficult. Stay safe, stay informed. <URL>\n",
      "full parse [[['Morehead', 'PROPN', 1, 'compound', 0], ['City', 'PROPN', 2, 'compound', 1], ['NC', 'PROPN', 3, 'nsubj', 2], ['decimated', 'VERB', 3, 'ROOT', 3], ['by', 'ADP', 3, 'agent', 4], ['#HurricaneFlorence', 'PROPN', 4, 'pobj', 5], ['with', 'ADP', 3, 'prep', 6], ['@DukeEnergy', 'PUNCT', 8, 'nmod', 7], ['experts', 'NOUN', 9, 'nsubj', 8], ['doing', 'VERB', 6, 'pcomp', 9], ['damage', 'NOUN', 11, 'compound', 10], ['assessments', 'NOUN', 9, 'dobj', 11], ['—', 'NUM', 3, 'punct', 12], ['saying', 'VERB', 3, 'advcl', 13], ['it', 'PRON', 16, 'nsubj', 14], ['’', 'NOUN', 16, 'nsubj', 15], ['s', 'VERB', 13, 'ccomp', 16], ['the', 'DET', 18, 'det', 17], ['worst', 'ADJ', 16, 'attr', 18], ['they', 'PRON', 20, 'nmod', 19], ['’', 'NOUN', 22, 'nsubj', 20], ['ve', 'VERB', 22, 'aux', 21], ['seen', 'VERB', 18, 'relcl', 22], ['.', 'PUNCT', 3, 'punct', 23]], [['Flooded', 'ADJ', 1, 'amod', 0], ['areas', 'NOUN', 3, 'nsubj', 1], ['will', 'VERB', 3, 'aux', 2], ['make', 'VERB', 3, 'ROOT', 3], ['accessing', 'VERB', 8, 'csubj', 4], ['our', 'ADJ', 6, 'poss', 5], ['equipment', 'NOUN', 4, 'dobj', 6], ['extremely', 'ADV', 8, 'advmod', 7], ['difficult', 'ADJ', 3, 'ccomp', 8], ['.', 'PUNCT', 3, 'punct', 9]], [['Stay', 'VERB', 0, 'ROOT', 0], ['safe', 'ADJ', 2, 'amod', 1], ['stay', 'NOUN', 0, 'npadvmod', 2], ['informed', 'ADJ', 2, 'acomp', 3], ['.', 'PUNCT', 0, 'punct', 4]]]\n",
      "candidate 0=Morehead City\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Morehead', 'PROPN', 1, 'compound', 0], ['City', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['City', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 3, 'nsubj', 2]\n",
      "parent node subtree [['Morehead', 'PROPN', 1, 'compound', 0], ['City', 'PROPN', 2, 'compound', 1], ['NC', 'PROPN', 3, 'nsubj', 2]]\n",
      "parent node subtree str morehead city nc\n",
      "false positive: NE=morehead_city, type=compound\n",
      "testing NE murrells_inlet, txt:Walking around the development, so far so good regarding #Florence. Just some branches & pine needles down. #southcarolina #murrellsinlet #nofilter #scwx #wx @ Murrells Inlet, South Carolina <URL>\n",
      "full parse [[['Walking', 'VERB', 0, 'ROOT', 0], ['around', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['development', 'NOUN', 1, 'pobj', 3], ['so', 'ADV', 5, 'advmod', 4], ['far', 'ADV', 7, 'advmod', 5], ['so', 'ADV', 7, 'advmod', 6], ['good', 'ADJ', 0, 'acomp', 7], ['regarding', 'VERB', 7, 'prep', 8], ['#Florence', 'NOUN', 8, 'pobj', 9], ['.', 'PUNCT', 0, 'punct', 10]], [['Just', 'ADV', 2, 'advmod', 0], ['some', 'DET', 2, 'det', 1], ['branches', 'NOUN', 2, 'ROOT', 2], ['&', 'CCONJ', 2, 'cc', 3], ['pine', 'NOUN', 5, 'compound', 4], ['needles', 'NOUN', 2, 'conj', 5], ['down', 'PART', 2, 'prt', 6], ['.', 'PUNCT', 2, 'punct', 7]], [['#southcarolina', 'PROPN', 1, 'compound', 0], ['#murrellsinlet', 'PROPN', 2, 'nmod', 1], ['#nofilter', 'PROPN', 2, 'ROOT', 2], ['#scwx', 'PROPN', 4, 'compound', 3], ['#wx', 'PROPN', 2, 'appos', 4], ['@', 'PUNCT', 4, 'prep', 5], ['Murrells', 'PROPN', 9, 'compound', 6], ['Inlet', 'PROPN', 9, 'compound', 7], ['South', 'PROPN', 9, 'compound', 8], ['Carolina', 'PROPN', 9, 'ROOT', 9]]]\n",
      "candidate 0=Murrells Inlet\n",
      "anchor NE candidates = South Carolina\n",
      "data NE tree=[['Murrells', 'PROPN', 9, 'compound', 6], ['Inlet', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=2, token=8:\n",
      "['Inlet', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 9, 'ROOT', 9]\n",
      "parent node subtree [['Murrells', 'PROPN', 9, 'compound', 6], ['Inlet', 'PROPN', 9, 'compound', 7], ['South', 'PROPN', 9, 'compound', 8], ['Carolina', 'PROPN', 9, 'ROOT', 9]]\n",
      "parent node subtree str murrells inlet south carolina\n",
      "false positive: NE=murrells_inlet, type=compound\n",
      "testing NE suwanee, txt:The edge of Hurricane Florence #hurricaneflorence moving into Georgia. @ Suwanee, Georgia <URL>\n",
      "full parse [[['The', 'DET', 1, 'det', 0], ['edge', 'NOUN', 1, 'ROOT', 1], ['of', 'ADP', 1, 'prep', 2], ['Hurricane', 'PROPN', 4, 'compound', 3], ['Florence', 'PROPN', 2, 'pobj', 4], ['#hurricaneflorence', 'NOUN', 6, 'nsubj', 5], ['moving', 'VERB', 6, 'ROOT', 6], ['into', 'ADP', 6, 'prep', 7], ['Georgia', 'PROPN', 7, 'pobj', 8], ['.', 'PUNCT', 6, 'punct', 9]], [['@', 'ADP', 0, 'ROOT', 0], ['Suwanee', 'PROPN', 2, 'compound', 1], ['Georgia', 'PROPN', 0, 'pobj', 2]]]\n",
      "candidate 0=Suwanee\n",
      "anchor NE candidates = \n",
      "testing NE maxton, txt:Late dinner for linemen in Maxton, NC tonight. It’s windy and rainy, but the base camp up and operational and is able to get crews a hot meal.  #HurricaneFlorence2018 <URL>\n",
      "full parse [[['Late', 'ADJ', 1, 'amod', 0], ['dinner', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['linemen', 'NOUN', 2, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['Maxton', 'PROPN', 6, 'compound', 5], ['NC', 'PROPN', 4, 'pobj', 6], ['tonight', 'NOUN', 1, 'npadvmod', 7], ['.', 'PUNCT', 1, 'punct', 8]], [['It', 'PRON', 1, 'nsubj', 0], ['’', 'VERB', 1, 'ROOT', 1], ['s', 'VERB', 1, 'case', 2], ['windy', 'ADJ', 1, 'amod', 3], ['and', 'CCONJ', 3, 'cc', 4], ['rainy', 'ADJ', 3, 'conj', 5], ['but', 'CCONJ', 1, 'cc', 6], ['the', 'DET', 8, 'det', 7], ['base', 'NOUN', 9, 'nsubj', 8], ['camp', 'NOUN', 1, 'conj', 9], ['up', 'PART', 9, 'prt', 10], ['and', 'CCONJ', 10, 'cc', 11], ['operational', 'ADJ', 10, 'conj', 12], ['and', 'CCONJ', 9, 'cc', 13], ['is', 'VERB', 9, 'conj', 14], ['able', 'ADJ', 14, 'acomp', 15], ['to', 'PART', 17, 'aux', 16], ['get', 'VERB', 15, 'xcomp', 17], ['crews', 'NOUN', 21, 'nsubj', 18], ['a', 'DET', 21, 'det', 19], ['hot', 'ADJ', 21, 'amod', 20], ['meal', 'NOUN', 17, 'dobj', 21], ['.', 'PUNCT', 9, 'punct', 22]], [['#HurricaneFlorence2018', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Maxton\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Maxton', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Maxton', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 4, 'pobj', 6]\n",
      "parent node subtree [['Maxton', 'PROPN', 6, 'compound', 5], ['NC', 'PROPN', 4, 'pobj', 6]]\n",
      "parent node subtree str maxton nc\n",
      "false positive: NE=maxton, type=compound\n",
      "testing NE new_bern, txt:Downtown New Bern, North Carolina #Florence #1010WINS #NewBernStrong <URL>\n",
      "full parse [[['Downtown', 'NOUN', 2, 'compound', 0], ['New', 'PROPN', 2, 'compound', 1], ['Bern', 'PROPN', 5, 'compound', 2], ['North', 'PROPN', 4, 'compound', 3], ['Carolina', 'PROPN', 5, 'compound', 4], ['#Florence', 'ADP', 5, 'ROOT', 5], ['#1010WINS', 'PROPN', 7, 'compound', 6], ['#NewBernStrong', 'X', 5, 'appos', 7]]]\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['New', 'PROPN', 2, 'compound', 1], ['Bern', 'PROPN', 5, 'compound', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Bern', 'PROPN', 5, 'compound', 2]\n",
      "NE parent token:\n",
      "['#Florence', 'ADP', 5, 'ROOT', 5]\n",
      "parent node subtree [['Downtown', 'NOUN', 2, 'compound', 0], ['New', 'PROPN', 2, 'compound', 1], ['Bern', 'PROPN', 5, 'compound', 2], ['North', 'PROPN', 4, 'compound', 3], ['Carolina', 'PROPN', 5, 'compound', 4], ['#Florence', 'ADP', 5, 'ROOT', 5], ['#1010WINS', 'PROPN', 7, 'compound', 6], ['#NewBernStrong', 'X', 5, 'appos', 7]]\n",
      "parent node subtree str downtown new bern north carolina #florence #1010wins #newbernstrong\n",
      "NE=New Bern subtree=[['Downtown', 'NOUN', 2, 'compound', 0]]\n",
      "min node deps ['compound']\n",
      "false positive: NE=new_bern, type=compound\n",
      "testing NE charlotte, txt:#HurricaneFlorence update! @ Charlotte, North Carolina <URL>\n",
      "full parse [[['#HurricaneFlorence', 'PROPN', 1, 'nsubj', 0], ['update', 'NOUN', 1, 'ROOT', 1], ['!', 'PUNCT', 1, 'punct', 2]], [['@', 'ADP', 0, 'ROOT', 0], ['Charlotte', 'PROPN', 3, 'compound', 1], ['North', 'PROPN', 3, 'compound', 2], ['Carolina', 'PROPN', 3, 'ROOT', 3]]]\n",
      "candidate 0=Charlotte\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Charlotte', 'PROPN', 3, 'compound', 1]]\n",
      "NE parse token at tree=1, token=2:\n",
      "['Charlotte', 'PROPN', 3, 'compound', 1]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 3, 'ROOT', 3]\n",
      "parent node subtree [['Charlotte', 'PROPN', 3, 'compound', 1], ['North', 'PROPN', 3, 'compound', 2], ['Carolina', 'PROPN', 3, 'ROOT', 3]]\n",
      "parent node subtree str charlotte north carolina\n",
      "false positive: NE=charlotte, type=compound\n",
      "testing NE holden_beach, txt:@bentonblount Lincolnton NC still okay! Also, our little Holden beach home survived. Bought with the retirement money from a 36 year Cop. .. my Hubby! #HurricaneFlorence2018 #policewife\n",
      "full parse [[['@bentonblount', 'PROPN', 2, 'compound', 0], ['Lincolnton', 'PROPN', 2, 'compound', 1], ['NC', 'PROPN', 2, 'ROOT', 2], ['still', 'ADV', 4, 'advmod', 3], ['okay', 'INTJ', 4, 'ROOT', 4], ['!', 'PUNCT', 4, 'punct', 5]], [['Also', 'ADV', 6, 'advmod', 0], ['our', 'ADJ', 5, 'poss', 1], ['little', 'ADJ', 5, 'amod', 2], ['Holden', 'PROPN', 5, 'compound', 3], ['beach', 'NOUN', 5, 'compound', 4], ['home', 'NOUN', 6, 'nsubj', 5], ['survived', 'VERB', 6, 'ROOT', 6], ['.', 'PUNCT', 6, 'punct', 7]], [['Bought', 'VERB', 0, 'ROOT', 0], ['with', 'ADP', 0, 'prep', 1], ['the', 'DET', 4, 'det', 2], ['retirement', 'NOUN', 4, 'compound', 3], ['money', 'NOUN', 1, 'pobj', 4], ['from', 'ADP', 0, 'prep', 5], ['a', 'DET', 9, 'det', 6], ['36', 'NUM', 8, 'nummod', 7], ['year', 'NOUN', 9, 'compound', 8], ['Cop', 'PROPN', 5, 'pobj', 9], ['.', 'PUNCT', 0, 'punct', 10]], [['..', 'PUNCT', 2, 'punct', 0], ['my', 'ADJ', 2, 'poss', 1], ['Hubby', 'NOUN', 2, 'ROOT', 2], ['!', 'PUNCT', 2, 'punct', 3]], [['#HurricaneFlorence2018', 'PROPN', 1, 'compound', 0], ['#policewife', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Holden beach\n",
      "anchor NE candidates = \n",
      "testing NE jacksonville, txt:HerMight&Mercy...Captured in Jacksonville, NC. Large oak uprooted but small chicken coop left in exact spot! 3 hens left nestled together w additional shelter. Amazing! #HurricaneFlorenceNC #Florence #jacksonvillenc <URL>\n",
      "full parse [[['HerMight', 'PROPN', 0, 'ROOT', 0], ['&', 'CCONJ', 0, 'cc', 1], ['Mercy', 'PROPN', 0, 'conj', 2], ['...', 'PUNCT', 4, 'punct', 3], ['Captured', 'VERB', 0, 'acl', 4], ['in', 'ADP', 4, 'prep', 5], ['Jacksonville', 'PROPN', 7, 'compound', 6], ['NC', 'PROPN', 5, 'pobj', 7], ['.', 'PUNCT', 4, 'punct', 8]], [['Large', 'ADJ', 1, 'amod', 0], ['oak', 'NOUN', 2, 'nsubj', 1], ['uprooted', 'VERB', 2, 'ROOT', 2], ['but', 'CCONJ', 2, 'cc', 3], ['small', 'ADJ', 6, 'amod', 4], ['chicken', 'NOUN', 6, 'compound', 5], ['coop', 'NOUN', 7, 'nsubj', 6], ['left', 'VERB', 2, 'conj', 7], ['in', 'ADP', 7, 'prep', 8], ['exact', 'ADJ', 10, 'amod', 9], ['spot', 'NOUN', 8, 'pobj', 10], ['!', 'PUNCT', 7, 'punct', 11]], [['3', 'NUM', 1, 'nummod', 0], ['hens', 'NOUN', 3, 'nsubj', 1], ['left', 'VERB', 1, 'acl', 2], ['nestled', 'VERB', 3, 'ROOT', 3], ['together', 'ADV', 3, 'advmod', 4], ['w', 'ADP', 3, 'prep', 5], ['additional', 'ADJ', 7, 'amod', 6], ['shelter', 'NOUN', 5, 'pobj', 7], ['.', 'PUNCT', 3, 'punct', 8]], [['Amazing', 'ADJ', 0, 'ROOT', 0], ['!', 'PUNCT', 0, 'punct', 1]], [['#HurricaneFlorenceNC', 'PROPN', 1, 'compound', 0], ['#Florence', 'PROPN', 1, 'ROOT', 1], ['#jacksonvillenc', 'PUNCT', 2, 'ROOT', 2]]]\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Jacksonville', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Jacksonville', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 7, 'compound', 6], ['NC', 'PROPN', 5, 'pobj', 7]]\n",
      "parent node subtree str jacksonville nc\n",
      "false positive: NE=jacksonville, type=compound\n",
      "testing NE lumberton, txt:We didn’t think it would be this bad #hurricaneflorence @ Lumberton, North Carolina <URL>\n",
      "full parse [[['We', 'PRON', 1, 'nsubj', 0], ['didn', 'VERB', 1, 'ROOT', 1], ['’', 'NOUN', 3, 'compound', 2], ['t', 'NOUN', 4, 'nsubj', 3], ['think', 'VERB', 1, 'ccomp', 4], ['it', 'PRON', 7, 'nsubj', 5], ['would', 'VERB', 7, 'aux', 6], ['be', 'VERB', 4, 'ccomp', 7], ['this', 'DET', 9, 'advmod', 8], ['bad', 'ADJ', 10, 'amod', 9], ['#hurricaneflorence', 'NOUN', 7, 'attr', 10], ['@', 'ADP', 1, 'punct', 11], ['Lumberton', 'PROPN', 14, 'compound', 12], ['North', 'PROPN', 14, 'compound', 13], ['Carolina', 'PROPN', 14, 'ROOT', 14]]]\n",
      "candidate 0=Lumberton\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Lumberton', 'PROPN', 14, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Lumberton', 'PROPN', 14, 'compound', 12]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 14, 'ROOT', 14]\n",
      "parent node subtree [['Lumberton', 'PROPN', 14, 'compound', 12], ['North', 'PROPN', 14, 'compound', 13], ['Carolina', 'PROPN', 14, 'ROOT', 14]]\n",
      "parent node subtree str lumberton north carolina\n",
      "false positive: NE=lumberton, type=compound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE kinston, txt:Deputies from the Rockingham County Sheriff's Office are here in Kinston, NC helping out with issues caused by #flooding. #HurricaneFlorence #KinstonNC <URL>\n",
      "full parse [[['Deputies', 'NOUN', 7, 'nsubj', 0], ['from', 'ADP', 0, 'prep', 1], ['the', 'DET', 6, 'det', 2], ['Rockingham', 'PROPN', 4, 'compound', 3], ['County', 'PROPN', 6, 'compound', 4], [\"Sheriff's\", 'PROPN', 6, 'compound', 5], ['Office', 'PROPN', 1, 'pobj', 6], ['are', 'VERB', 7, 'ROOT', 7], ['here', 'ADV', 7, 'advmod', 8], ['in', 'ADP', 7, 'prep', 9], ['Kinston', 'PROPN', 11, 'compound', 10], ['NC', 'PROPN', 9, 'pobj', 11], ['helping', 'VERB', 7, 'advcl', 12], ['out', 'PART', 12, 'prt', 13], ['with', 'ADP', 12, 'prep', 14], ['issues', 'NOUN', 14, 'pobj', 15], ['caused', 'VERB', 15, 'acl', 16], ['by', 'ADP', 16, 'agent', 17], ['#flooding', 'VERB', 17, 'pobj', 18], ['.', 'PUNCT', 7, 'punct', 19]], [['#HurricaneFlorence', 'PROPN', 1, 'compound', 0], ['#KinstonNC', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Kinston\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Kinston', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Kinston', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Kinston', 'PROPN', 11, 'compound', 10], ['NC', 'PROPN', 9, 'pobj', 11]]\n",
      "parent node subtree str kinston nc\n",
      "false positive: NE=kinston, type=compound\n",
      "testing NE little_river, txt:The Little River in Manchester, NC, near Spring Lake and upstream from #FayettevilleNC , has hit a record level, according to @NWS . River at 34.96 ft as of 3:30PM Monday. During Hurricane Matthew (previous all-time high) it reached 32.19 ft. #florence #ncwx @newsobserver <URL>\n",
      "full parse [[['The', 'DET', 2, 'det', 0], ['Little', 'PROPN', 2, 'compound', 1], ['River', 'PROPN', 14, 'nsubj', 2], ['in', 'ADP', 2, 'prep', 3], ['Manchester', 'PROPN', 5, 'compound', 4], ['NC', 'PROPN', 3, 'pobj', 5], ['near', 'ADP', 2, 'prep', 6], ['Spring', 'PROPN', 8, 'compound', 7], ['Lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#FayettevilleNC', 'PROPN', 11, 'pobj', 12], ['has', 'VERB', 14, 'aux', 13], ['hit', 'VERB', 14, 'ROOT', 14], ['a', 'DET', 17, 'det', 15], ['record', 'NOUN', 17, 'compound', 16], ['level', 'NOUN', 14, 'dobj', 17], ['according', 'VERB', 14, 'prep', 18], ['to', 'ADP', 18, 'prep', 19], ['@NWS', 'X', 19, 'pobj', 20], ['.', 'PUNCT', 14, 'punct', 21]], [['River', 'NOUN', 0, 'ROOT', 0], ['at', 'ADP', 0, 'prep', 1], ['34.96', 'NUM', 3, 'nummod', 2], ['ft', 'NOUN', 1, 'pobj', 3], ['as', 'ADP', 0, 'prep', 4], ['of', 'ADP', 4, 'prep', 5], ['3:30', 'NUM', 7, 'nummod', 6], ['PM', 'NOUN', 5, 'pobj', 7], ['Monday', 'PROPN', 0, 'npadvmod', 8], ['.', 'PUNCT', 0, 'punct', 9]], [['During', 'ADP', 9, 'prep', 0], ['Hurricane', 'PROPN', 2, 'compound', 1], ['Matthew', 'PROPN', 0, 'pobj', 2], ['(', 'PUNCT', 6, 'punct', 3], ['previous', 'ADJ', 6, 'amod', 4], ['alltime', 'NOUN', 6, 'amod', 5], ['high', 'ADJ', 2, 'appos', 6], [')', 'PUNCT', 6, 'punct', 7], ['it', 'PRON', 9, 'nsubj', 8], ['reached', 'VERB', 9, 'ROOT', 9], ['32.19', 'NUM', 11, 'nummod', 10], ['ft', 'NOUN', 9, 'dobj', 11], ['.', 'PUNCT', 9, 'punct', 12], ['#florence', 'X', 14, 'compound', 13], ['#ncwx', 'PROPN', 14, 'ROOT', 14], ['@newsobserver', 'X', 14, 'punct', 15]]]\n",
      "candidate 0=Little River\n",
      "anchor NE candidates = Manchester,NC,Spring Lake\n",
      "data NE tree=[['Little', 'PROPN', 2, 'compound', 1], ['River', 'PROPN', 14, 'nsubj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['River', 'PROPN', 14, 'nsubj', 2]\n",
      "NE parent token:\n",
      "['hit', 'VERB', 14, 'ROOT', 14]\n",
      "NE=Little River subtree=[['The', 'DET', 2, 'det', 0], ['in', 'ADP', 2, 'prep', 3], ['Manchester', 'PROPN', 5, 'compound', 4], ['NC', 'PROPN', 3, 'pobj', 5], ['near', 'ADP', 2, 'prep', 6], ['Spring', 'PROPN', 8, 'compound', 7], ['Lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#FayettevilleNC', 'PROPN', 11, 'pobj', 12]]\n",
      "min node deps ['det', 'prep', 'prep']\n",
      "subtree = The in Manchester NC near Spring Lake and upstream from #FayettevilleNC\n",
      "candidate 1=Manchester\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Manchester', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Manchester', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Manchester', 'PROPN', 5, 'compound', 4], ['NC', 'PROPN', 3, 'pobj', 5]]\n",
      "parent node subtree str manchester nc\n",
      "candidate 2=Spring Lake\n",
      "anchor NE candidates = \n",
      "testing NE bladen_county, txt:So people outside NC can understand the incredible amount of rain: Elizabethtown in Bladen county got over 36 inches in four days. CHICAGO gets roughly that in a YEAR. Our average in Raleigh is 46. For the YEAR. #HurricaneFlorence\n",
      "full parse [[['So', 'ADP', 5, 'advmod', 0], ['people', 'NOUN', 5, 'nsubj', 1], ['outside', 'ADP', 1, 'prep', 2], ['NC', 'PROPN', 2, 'pobj', 3], ['can', 'VERB', 5, 'aux', 4], ['understand', 'VERB', 5, 'ROOT', 5], ['the', 'DET', 8, 'det', 6], ['incredible', 'ADJ', 8, 'amod', 7], ['amount', 'NOUN', 5, 'dobj', 8], ['of', 'ADP', 8, 'prep', 9], ['rain', 'NOUN', 9, 'pobj', 10], [':', 'PUNCT', 5, 'punct', 11], ['Elizabethtown', 'PROPN', 16, 'nsubj', 12], ['in', 'ADP', 12, 'prep', 13], ['Bladen', 'PROPN', 15, 'compound', 14], ['county', 'NOUN', 13, 'pobj', 15], ['got', 'VERB', 16, 'ROOT', 16], ['over', 'ADP', 18, 'quantmod', 17], ['36', 'NUM', 19, 'nummod', 18], ['inches', 'NOUN', 16, 'dobj', 19], ['in', 'ADP', 16, 'prep', 20], ['four', 'NUM', 22, 'nummod', 21], ['days', 'NOUN', 20, 'pobj', 22], ['.', 'PUNCT', 16, 'punct', 23]], [['CHICAGO', 'PROPN', 1, 'nsubj', 0], ['gets', 'VERB', 1, 'ROOT', 1], ['roughly', 'ADV', 3, 'advmod', 2], ['that', 'ADP', 1, 'dobj', 3], ['in', 'ADP', 1, 'prep', 4], ['a', 'DET', 6, 'det', 5], ['YEAR', 'NOUN', 4, 'pobj', 6], ['.', 'PUNCT', 1, 'punct', 7]], [['Our', 'ADJ', 1, 'poss', 0], ['average', 'NOUN', 4, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['Raleigh', 'PROPN', 2, 'pobj', 3], ['is', 'VERB', 4, 'ROOT', 4], ['46', 'NUM', 4, 'attr', 5], ['.', 'PUNCT', 4, 'punct', 6]], [['For', 'ADP', 0, 'ROOT', 0], ['the', 'DET', 2, 'det', 1], ['YEAR', 'NOUN', 0, 'pobj', 2], ['.', 'PUNCT', 0, 'punct', 3]], [['#HurricaneFlorence', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Bladen county\n",
      "anchor NE candidates = CHICAGO,Raleigh\n",
      "data NE tree=[['Bladen', 'PROPN', 15, 'compound', 14], ['county', 'NOUN', 13, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['county', 'NOUN', 13, 'pobj', 15]\n",
      "NE parent token:\n",
      "['in', 'ADP', 12, 'prep', 13]\n",
      "candidate 1=Raleigh\n",
      "anchor NE candidates = \n",
      "testing NE indian_trail, txt:ROAD CLOSURE: Another closure just added to the list in Union County. This is on Chesnut Lane in Indian Trail. The area was flooded yesterday. Today... This. @wsoctv #Florence <URL>\n",
      "full parse [[['ROAD', 'PROPN', 1, 'compound', 0], ['CLOSURE', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['Another', 'DET', 4, 'det', 3], ['closure', 'NOUN', 6, 'nsubj', 4], ['just', 'ADV', 6, 'advmod', 5], ['added', 'VERB', 6, 'ROOT', 6], ['to', 'ADP', 6, 'prep', 7], ['the', 'DET', 9, 'det', 8], ['list', 'NOUN', 7, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Union', 'PROPN', 12, 'compound', 11], ['County', 'PROPN', 10, 'pobj', 12], ['.', 'PUNCT', 6, 'punct', 13]], [['This', 'DET', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['on', 'ADP', 1, 'prep', 2], ['Chesnut', 'PROPN', 4, 'compound', 3], ['Lane', 'PROPN', 2, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['Indian', 'PROPN', 7, 'compound', 6], ['Trail', 'PROPN', 5, 'pobj', 7], ['.', 'PUNCT', 1, 'punct', 8]], [['The', 'DET', 1, 'det', 0], ['area', 'NOUN', 3, 'nsubjpass', 1], ['was', 'VERB', 3, 'auxpass', 2], ['flooded', 'VERB', 3, 'ROOT', 3], ['yesterday', 'NOUN', 3, 'npadvmod', 4], ['.', 'PUNCT', 3, 'punct', 5]], [['Today', 'NOUN', 0, 'ROOT', 0], ['...', 'PUNCT', 0, 'punct', 1]], [['This', 'DET', 0, 'ROOT', 0], ['.', 'PUNCT', 0, 'punct', 1]], [['@wsoctv', 'ADV', 1, 'compound', 0], ['#Florence', 'X', 1, 'ROOT', 1]]]\n",
      "candidate 0=Union County\n",
      "anchor NE candidates = \n",
      "candidate 1=Indian Trail\n",
      "anchor NE candidates = Union County\n",
      "data NE tree=[['Indian', 'PROPN', 7, 'compound', 6], ['Trail', 'PROPN', 5, 'pobj', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Trail', 'PROPN', 5, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 4, 'prep', 5]\n",
      "testing NE montreal, txt:Luckily both boxes were delivered and were delayed by #hurricaneflorence but I fly out tomorrow for a weeks vacation in Canada (Montreal and Quebec) then to #nyc for a week for work and… <URL>\n",
      "full parse [[['Luckily', 'ADV', 4, 'advmod', 0], ['both', 'DET', 2, 'det', 1], ['boxes', 'NOUN', 4, 'nsubjpass', 2], ['were', 'VERB', 4, 'auxpass', 3], ['delivered', 'VERB', 4, 'ROOT', 4], ['and', 'CCONJ', 4, 'cc', 5], ['were', 'VERB', 7, 'auxpass', 6], ['delayed', 'VERB', 4, 'conj', 7], ['by', 'ADP', 7, 'agent', 8], ['#hurricaneflorence', 'PROPN', 8, 'pobj', 9], ['but', 'CCONJ', 12, 'cc', 10], ['I', 'PRON', 12, 'nsubj', 11], ['fly', 'VERB', 12, 'ROOT', 12], ['out', 'PART', 12, 'prt', 13], ['tomorrow', 'NOUN', 12, 'npadvmod', 14], ['for', 'ADP', 12, 'prep', 15], ['a', 'DET', 17, 'det', 16], ['weeks', 'NOUN', 15, 'pobj', 17], ['vacation', 'NOUN', 18, 'ROOT', 18], ['in', 'ADP', 18, 'prep', 19], ['Canada', 'PROPN', 19, 'pobj', 20], ['(', 'PUNCT', 20, 'punct', 21], ['Montreal', 'PROPN', 20, 'appos', 22], ['and', 'CCONJ', 22, 'cc', 23], ['Quebec', 'PROPN', 22, 'conj', 24], [')', 'PUNCT', 20, 'punct', 25], ['then', 'ADV', 27, 'advmod', 26], ['to', 'ADP', 18, 'prep', 27], ['#nyc', 'PROPN', 27, 'pobj', 28], ['for', 'ADP', 27, 'prep', 29], ['a', 'DET', 31, 'det', 30], ['week', 'NOUN', 29, 'pobj', 31], ['for', 'ADP', 27, 'prep', 32], ['work', 'NOUN', 32, 'pobj', 33], ['and', 'CCONJ', 27, 'cc', 34], ['…', 'PUNCT', 18, 'punct', 35]]]\n",
      "candidate 0=Montreal\n",
      "anchor NE candidates = Quebec\n",
      "data NE tree=[['Montreal', 'PROPN', 20, 'appos', 22]]\n",
      "NE parse token at tree=0, token=23:\n",
      "['Montreal', 'PROPN', 20, 'appos', 22]\n",
      "NE parent token:\n",
      "['Canada', 'PROPN', 19, 'pobj', 20]\n",
      "parent node subtree [['Canada', 'PROPN', 19, 'pobj', 20], ['(', 'PUNCT', 20, 'punct', 21], ['Montreal', 'PROPN', 20, 'appos', 22], ['and', 'CCONJ', 22, 'cc', 23], ['Quebec', 'PROPN', 22, 'conj', 24], [')', 'PUNCT', 20, 'punct', 25]]\n",
      "parent node subtree str canada ( montreal and quebec )\n",
      "NE=Montreal subtree=[['and', 'CCONJ', 22, 'cc', 23], ['Quebec', 'PROPN', 22, 'conj', 24]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Quebec\n",
      "anchor NE candidates = \n",
      "testing NE ithaca, txt:The remains of #Florence spared Rochester. However, it's a different story from Ithaca to Oneonta. 3 to 4\"\" of rain has fallen from Chemung to southern Cortland counties. Flood Warnings are up for some there. <URL>\n",
      "full parse [[['The', 'DET', 1, 'det', 0], ['remains', 'NOUN', 4, 'nsubj', 1], ['of', 'ADP', 1, 'prep', 2], ['#Florence', 'NOUN', 2, 'pobj', 3], ['spared', 'VERB', 4, 'ROOT', 4], ['Rochester', 'PROPN', 4, 'dobj', 5], ['.', 'PUNCT', 4, 'punct', 6]], [['However', 'ADV', 4, 'advmod', 0], [\"it's\", 'ADJ', 4, 'poss', 1], ['a', 'DET', 4, 'det', 2], ['different', 'ADJ', 4, 'amod', 3], ['story', 'NOUN', 4, 'ROOT', 4], ['from', 'ADP', 4, 'prep', 5], ['Ithaca', 'PROPN', 5, 'pobj', 6], ['to', 'ADP', 4, 'prep', 7], ['Oneonta', 'PROPN', 7, 'pobj', 8], ['.', 'PUNCT', 4, 'punct', 9]], [['3', 'NUM', 2, 'quantmod', 0], ['to', 'ADP', 2, 'quantmod', 1], ['4', 'NUM', 8, 'nsubj', 2], ['\"', 'PUNCT', 2, 'punct', 3], ['\"', 'PUNCT', 2, 'punct', 4], ['of', 'ADP', 2, 'prep', 5], ['rain', 'NOUN', 5, 'pobj', 6], ['has', 'VERB', 8, 'aux', 7], ['fallen', 'VERB', 8, 'ROOT', 8], ['from', 'ADP', 8, 'prep', 9], ['Chemung', 'PROPN', 9, 'pobj', 10], ['to', 'ADP', 8, 'prep', 11], ['southern', 'ADJ', 13, 'amod', 12], ['Cortland', 'PROPN', 14, 'compound', 13], ['counties', 'NOUN', 11, 'pobj', 14], ['.', 'PUNCT', 8, 'punct', 15]], [['Flood', 'PROPN', 1, 'compound', 0], ['Warnings', 'PROPN', 2, 'nsubj', 1], ['are', 'VERB', 2, 'ROOT', 2], ['up', 'ADV', 2, 'advmod', 3], ['for', 'ADP', 2, 'prep', 4], ['some', 'DET', 4, 'pobj', 5], ['there', 'ADV', 2, 'advmod', 6], ['.', 'PUNCT', 2, 'punct', 7]]]\n",
      "candidate 0=Ithaca\n",
      "anchor NE candidates = \n",
      "testing NE columbus, txt:Yesterday, our crews teamed up with @insideFPL to assess damage throughout Columbus and Bladen counties in North Carolina. Crews continue to work through challenging conditions to restore power to customers impacted by #Florence . Track progress: <URL>\n",
      "full parse [[['Yesterday', 'NOUN', 3, 'npadvmod', 0], ['our', 'ADJ', 2, 'poss', 1], ['crews', 'NOUN', 3, 'nsubj', 2], ['teamed', 'VERB', 3, 'ROOT', 3], ['up', 'PART', 3, 'prt', 4], ['with', 'ADP', 3, 'prep', 5], ['@insideFPL', 'NOUN', 5, 'pobj', 6], ['to', 'PART', 8, 'aux', 7], ['assess', 'VERB', 3, 'advcl', 8], ['damage', 'NOUN', 8, 'dobj', 9], ['throughout', 'ADP', 9, 'prep', 10], ['Columbus', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Bladen', 'PROPN', 11, 'conj', 13], ['counties', 'NOUN', 10, 'pobj', 14], ['in', 'ADP', 14, 'prep', 15], ['North', 'PROPN', 17, 'compound', 16], ['Carolina', 'PROPN', 15, 'pobj', 17], ['.', 'PUNCT', 3, 'punct', 18]], [['Crews', 'NOUN', 1, 'nsubj', 0], ['continue', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['work', 'VERB', 1, 'xcomp', 3], ['through', 'ADP', 3, 'prep', 4], ['challenging', 'ADJ', 6, 'amod', 5], ['conditions', 'NOUN', 4, 'pobj', 6], ['to', 'PART', 8, 'aux', 7], ['restore', 'VERB', 6, 'acl', 8], ['power', 'NOUN', 8, 'dobj', 9], ['to', 'ADP', 8, 'prep', 10], ['customers', 'NOUN', 10, 'pobj', 11], ['impacted', 'VERB', 11, 'acl', 12], ['by', 'ADP', 12, 'agent', 13], ['#Florence', 'PROPN', 13, 'pobj', 14], ['.', 'PUNCT', 1, 'punct', 15]], [['Track', 'NOUN', 1, 'compound', 0], ['progress', 'NOUN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2]]]\n",
      "candidate 0=Columbus\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Columbus', 'PROPN', 14, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Columbus', 'PROPN', 14, 'nmod', 11]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 10, 'pobj', 14]\n",
      "parent node subtree [['Columbus', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Bladen', 'PROPN', 11, 'conj', 13], ['counties', 'NOUN', 10, 'pobj', 14], ['in', 'ADP', 14, 'prep', 15], ['North', 'PROPN', 17, 'compound', 16], ['Carolina', 'PROPN', 15, 'pobj', 17]]\n",
      "parent node subtree str columbus and bladen counties in north carolina\n",
      "NE=Columbus subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Bladen', 'PROPN', 11, 'conj', 13]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Bladen\n",
      "anchor NE candidates = Columbus,North Carolina\n",
      "data NE tree=[['Bladen', 'PROPN', 11, 'conj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Bladen', 'PROPN', 11, 'conj', 13]\n",
      "NE parent token:\n",
      "['Columbus', 'PROPN', 14, 'nmod', 11]\n",
      "false positive: NE=columbus, type=compound\n",
      "testing NE williamstown, txt:@weatherchannel this is from Williamstown, MA. Our bridge is about to get wiped out! Even Mass is being affected by #Florence <URL>\n",
      "full parse [[['@weatherchannel', 'PROPN', 2, 'punct', 0], ['this', 'DET', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['from', 'ADP', 2, 'prep', 3], ['Williamstown', 'PROPN', 5, 'compound', 4], ['MA', 'PROPN', 3, 'pobj', 5], ['.', 'PUNCT', 2, 'punct', 6]], [['Our', 'ADJ', 1, 'poss', 0], ['bridge', 'NOUN', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['about', 'ADJ', 2, 'acomp', 3], ['to', 'PART', 6, 'aux', 4], ['get', 'VERB', 6, 'auxpass', 5], ['wiped', 'VERB', 3, 'xcomp', 6], ['out', 'PART', 6, 'prt', 7], ['!', 'PUNCT', 2, 'punct', 8]], [['Even', 'ADV', 1, 'advmod', 0], ['Mass', 'PROPN', 4, 'nsubjpass', 1], ['is', 'VERB', 4, 'aux', 2], ['being', 'VERB', 4, 'auxpass', 3], ['affected', 'VERB', 4, 'ROOT', 4], ['by', 'ADP', 4, 'agent', 5], ['#Florence', 'PROPN', 5, 'pobj', 6]]]\n",
      "candidate 0=Williamstown\n",
      "anchor NE candidates = MA\n",
      "data NE tree=[['Williamstown', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Williamstown', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['MA', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Williamstown', 'PROPN', 5, 'compound', 4], ['MA', 'PROPN', 3, 'pobj', 5]]\n",
      "parent node subtree str williamstown ma\n",
      "testing NE brooklyn, txt:Looks like I made it to Brooklyn not a moment too soon. The remnants of #Florence have arrived here in NYC...\n",
      "full parse [[['Looks', 'VERB', 0, 'ROOT', 0], ['like', 'ADP', 3, 'mark', 1], ['I', 'PRON', 3, 'nsubj', 2], ['made', 'VERB', 0, 'advcl', 3], ['it', 'PRON', 3, 'dobj', 4], ['to', 'ADP', 3, 'prep', 5], ['Brooklyn', 'PROPN', 5, 'pobj', 6], ['not', 'ADV', 9, 'neg', 7], ['a', 'DET', 9, 'det', 8], ['moment', 'NOUN', 11, 'npadvmod', 9], ['too', 'ADV', 11, 'advmod', 10], ['soon', 'ADV', 3, 'advmod', 11], ['.', 'PUNCT', 0, 'punct', 12]], [['The', 'DET', 1, 'det', 0], ['remnants', 'NOUN', 5, 'nsubj', 1], ['of', 'ADP', 1, 'prep', 2], ['#Florence', 'NOUN', 2, 'pobj', 3], ['have', 'VERB', 5, 'aux', 4], ['arrived', 'VERB', 5, 'ROOT', 5], ['here', 'ADV', 5, 'advmod', 6], ['in', 'ADP', 5, 'prep', 7], ['NYC', 'PROPN', 7, 'pobj', 8], ['...', 'PUNCT', 5, 'punct', 9]]]\n",
      "candidate 0=Brooklyn\n",
      "anchor NE candidates = NYC\n",
      "data NE tree=[['Brooklyn', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Brooklyn', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['to', 'ADP', 3, 'prep', 5]\n",
      "testing NE pollocksville, txt:After almost 30\"\" of rain during #Florence , Jones county is now experiencing historic flooding along the Trent River. Here r some pics from Pollocksville where rescue crews have worked tirelessly assisting residents. Special thank you to @NYPDnews , who have come a long way 2 help! <URL>\n",
      "full parse [[['After', 'ADP', 13, 'prep', 0], ['almost', 'ADV', 2, 'advmod', 1], ['30', 'NUM', 0, 'pobj', 2], ['\"', 'PUNCT', 2, 'punct', 3], ['\"', 'PUNCT', 0, 'punct', 4], ['of', 'ADP', 0, 'prep', 5], ['rain', 'NOUN', 5, 'pobj', 6], ['during', 'ADP', 6, 'prep', 7], ['#Florence', 'PROPN', 9, 'compound', 8], ['Jones', 'PROPN', 10, 'compound', 9], ['county', 'NOUN', 7, 'pobj', 10], ['is', 'VERB', 13, 'aux', 11], ['now', 'ADV', 13, 'advmod', 12], ['experiencing', 'VERB', 13, 'ROOT', 13], ['historic', 'ADJ', 15, 'amod', 14], ['flooding', 'NOUN', 13, 'dobj', 15], ['along', 'ADP', 15, 'prep', 16], ['the', 'DET', 19, 'det', 17], ['Trent', 'PROPN', 19, 'compound', 18], ['River', 'PROPN', 16, 'pobj', 19], ['.', 'PUNCT', 13, 'punct', 20]], [['Here', 'ADV', 3, 'advmod', 0], ['r', 'ADV', 3, 'det', 1], ['some', 'DET', 3, 'det', 2], ['pics', 'NOUN', 3, 'ROOT', 3], ['from', 'ADP', 3, 'prep', 4], ['Pollocksville', 'PROPN', 4, 'pobj', 5], ['where', 'ADV', 10, 'advmod', 6], ['rescue', 'NOUN', 8, 'compound', 7], ['crews', 'NOUN', 10, 'nsubj', 8], ['have', 'VERB', 10, 'aux', 9], ['worked', 'VERB', 3, 'relcl', 10], ['tirelessly', 'ADV', 12, 'advmod', 11], ['assisting', 'VERB', 10, 'advcl', 12], ['residents', 'NOUN', 12, 'dobj', 13], ['.', 'PUNCT', 3, 'punct', 14]], [['Special', 'NOUN', 1, 'amod', 0], ['thank', 'VERB', 1, 'ROOT', 1], ['you', 'PRON', 1, 'dobj', 2], ['to', 'ADP', 1, 'prep', 3], ['@NYPDnews', 'PROPN', 3, 'pobj', 4], ['who', 'NOUN', 7, 'nsubj', 5], ['have', 'VERB', 7, 'aux', 6], ['come', 'VERB', 4, 'relcl', 7], ['a', 'DET', 10, 'det', 8], ['long', 'ADJ', 10, 'amod', 9], ['way', 'NOUN', 7, 'npadvmod', 10], ['2', 'NUM', 12, 'nummod', 11], ['help', 'NOUN', 7, 'npadvmod', 12], ['!', 'PUNCT', 1, 'punct', 13]]]\n",
      "candidate 0=Jones county\n",
      "anchor NE candidates = \n",
      "candidate 1=Pollocksville\n",
      "anchor NE candidates = Jones county,Pollocksville\n",
      "data NE tree=[['Pollocksville', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Pollocksville', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['from', 'ADP', 3, 'prep', 4]\n",
      "testing NE fort_bragg, txt:Aviators of the 82nd Airborne Division Combat Aviation Brigade began returning aircraft to Fort Bragg today. They were placed out of harms way at Robins Air Force Base in Georgia. #hurricaneflorence ; #Armyhurricaneresponse #Armyhurricaneflorence #HUREVAC2018 #ArmyResponse ; #18ABC <URL>\n",
      "full parse [[['Aviators', 'NOUN', 9, 'nsubj', 0], ['of', 'ADP', 0, 'prep', 1], ['the', 'DET', 8, 'det', 2], ['82nd', 'ADJ', 2, 'preconj', 3], ['Airborne', 'PROPN', 5, 'compound', 4], ['Division', 'PROPN', 8, 'compound', 5], ['Combat', 'PROPN', 8, 'compound', 6], ['Aviation', 'PROPN', 8, 'compound', 7], ['Brigade', 'PROPN', 1, 'pobj', 8], ['began', 'VERB', 9, 'ROOT', 9], ['returning', 'VERB', 9, 'xcomp', 10], ['aircraft', 'NOUN', 10, 'dobj', 11], ['to', 'ADP', 10, 'prep', 12], ['Fort', 'PROPN', 14, 'compound', 13], ['Bragg', 'PROPN', 12, 'pobj', 14], ['today', 'NOUN', 9, 'npadvmod', 15], ['.', 'PUNCT', 9, 'punct', 16]], [['They', 'PRON', 2, 'nsubjpass', 0], ['were', 'VERB', 2, 'auxpass', 1], ['placed', 'VERB', 2, 'ROOT', 2], ['out', 'ADP', 2, 'prep', 3], ['of', 'ADP', 3, 'prep', 4], ['harms', 'NOUN', 4, 'pobj', 5], ['way', 'NOUN', 2, 'npadvmod', 6], ['at', 'ADP', 2, 'prep', 7], ['Robins', 'PROPN', 11, 'compound', 8], ['Air', 'PROPN', 10, 'compound', 9], ['Force', 'PROPN', 11, 'compound', 10], ['Base', 'PROPN', 7, 'pobj', 11], ['in', 'ADP', 11, 'prep', 12], ['Georgia', 'PROPN', 12, 'pobj', 13], ['.', 'PUNCT', 2, 'punct', 14]], [['#hurricaneflorence', 'PROPN', 7, 'dep', 0], [';', 'PUNCT', 0, 'punct', 1], ['#Armyhurricaneresponse', 'PROPN', 3, 'compound', 2], ['#Armyhurricaneflorence', 'X', 0, 'appos', 3], ['#HUREVAC2018', 'PROPN', 5, 'compound', 4], ['#ArmyResponse', 'NOUN', 3, 'appos', 5], [';', 'PUNCT', 7, 'punct', 6], ['#18ABC', 'X', 7, 'ROOT', 7]]]\n",
      "candidate 0=Fort Bragg\n",
      "anchor NE candidates = Georgia\n",
      "data NE tree=[['Fort', 'PROPN', 14, 'compound', 13], ['Bragg', 'PROPN', 12, 'pobj', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Bragg', 'PROPN', 12, 'pobj', 14]\n",
      "NE parent token:\n",
      "['to', 'ADP', 10, 'prep', 12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE lumberton, txt:Houses sit in floodwater caused by #HurricaneFlorence , in this aerial picture, on the outskirts of Lumberton, North Carolina, via @Reuters photographer Jason Miczek See Reuters top photos from the last 24 hours: <URL>\n",
      "full parse [[['Houses', 'NOUN', 1, 'nsubj', 0], ['sit', 'VERB', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['floodwater', 'NOUN', 2, 'pobj', 3], ['caused', 'VERB', 3, 'acl', 4], ['by', 'ADP', 4, 'agent', 5], ['#HurricaneFlorence', 'NOUN', 5, 'pobj', 6], ['in', 'ADP', 4, 'prep', 7], ['this', 'DET', 10, 'det', 8], ['aerial', 'ADJ', 10, 'amod', 9], ['picture', 'NOUN', 7, 'pobj', 10], ['on', 'ADP', 10, 'prep', 11], ['the', 'DET', 13, 'det', 12], ['outskirts', 'NOUN', 11, 'pobj', 13], ['of', 'ADP', 13, 'prep', 14], ['Lumberton', 'PROPN', 17, 'compound', 15], ['North', 'PROPN', 17, 'compound', 16], ['Carolina', 'PROPN', 14, 'pobj', 17], ['via', 'ADP', 1, 'prep', 18], ['@Reuters', 'PROPN', 20, 'compound', 19], ['photographer', 'NOUN', 18, 'pobj', 20], ['Jason', 'PROPN', 22, 'compound', 21], ['Miczek', 'PROPN', 23, 'nsubj', 22], ['See', 'VERB', 23, 'ROOT', 23], ['Reuters', 'PROPN', 23, 'dobj', 24], ['top', 'VERB', 26, 'amod', 25], ['photos', 'NOUN', 23, 'dobj', 26], ['from', 'ADP', 26, 'prep', 27], ['the', 'DET', 31, 'det', 28], ['last', 'ADJ', 31, 'amod', 29], ['24', 'NUM', 31, 'nummod', 30], ['hours', 'NOUN', 27, 'pobj', 31], [':', 'PUNCT', 23, 'punct', 32]]]\n",
      "candidate 0=Lumberton\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Lumberton', 'PROPN', 17, 'compound', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Lumberton', 'PROPN', 17, 'compound', 15]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 14, 'pobj', 17]\n",
      "parent node subtree [['Lumberton', 'PROPN', 17, 'compound', 15], ['North', 'PROPN', 17, 'compound', 16], ['Carolina', 'PROPN', 14, 'pobj', 17]]\n",
      "parent node subtree str lumberton north carolina\n",
      "false positive: NE=lumberton, type=compound\n",
      "testing NE new_bern, txt:New WCK kitchen opening in New Bern! This is one of the worst hit areas in North Carolina...Tonight we served hundreds of residents & we activate a local food truck tomorrow! My brother @cheftkilcoyne showing how food relief should be done! #Florence @WCKitchen @NC_Governor <URL>\n",
      "full parse [[['New', 'ADJ', 1, 'compound', 0], ['WCK', 'PROPN', 3, 'compound', 1], ['kitchen', 'NOUN', 3, 'compound', 2], ['opening', 'NOUN', 3, 'ROOT', 3], ['in', 'ADP', 3, 'prep', 4], ['New', 'PROPN', 6, 'compound', 5], ['Bern', 'PROPN', 4, 'pobj', 6], ['!', 'PUNCT', 3, 'punct', 7]], [['This', 'DET', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['one', 'NUM', 1, 'attr', 2], ['of', 'ADP', 2, 'prep', 3], ['the', 'DET', 7, 'det', 4], ['worst', 'ADJ', 7, 'amod', 5], ['hit', 'VERB', 7, 'amod', 6], ['areas', 'NOUN', 3, 'pobj', 7], ['in', 'ADP', 7, 'prep', 8], ['North', 'PROPN', 10, 'compound', 9], ['Carolina', 'PROPN', 8, 'pobj', 10], ['...', 'PUNCT', 1, 'punct', 11], ['Tonight', 'NOUN', 14, 'npadvmod', 12], ['we', 'PRON', 14, 'nsubj', 13], ['served', 'VERB', 14, 'ROOT', 14], ['hundreds', 'NOUN', 14, 'dobj', 15], ['of', 'ADP', 15, 'prep', 16], ['residents', 'NOUN', 16, 'pobj', 17], ['&', 'CCONJ', 14, 'cc', 18], ['we', 'PRON', 20, 'nsubj', 19], ['activate', 'VERB', 14, 'conj', 20], ['a', 'DET', 24, 'det', 21], ['local', 'ADJ', 24, 'amod', 22], ['food', 'NOUN', 24, 'compound', 23], ['truck', 'NOUN', 20, 'dobj', 24], ['tomorrow', 'NOUN', 20, 'npadvmod', 25], ['!', 'PUNCT', 20, 'punct', 26]], [['My', 'ADJ', 1, 'poss', 0], ['brother', 'NOUN', 1, 'ROOT', 1], ['@cheftkilcoyne', 'PROPN', 1, 'appos', 2], ['showing', 'VERB', 1, 'acl', 3], ['how', 'ADV', 9, 'advmod', 4], ['food', 'NOUN', 6, 'compound', 5], ['relief', 'NOUN', 9, 'nsubjpass', 6], ['should', 'VERB', 9, 'aux', 7], ['be', 'VERB', 9, 'auxpass', 8], ['done', 'VERB', 3, 'ccomp', 9], ['!', 'PUNCT', 1, 'punct', 10]], [['#Florence', 'ADV', 1, 'compound', 0], ['@WCKitchen', 'PROPN', 1, 'ROOT', 1], ['@NC_Governor', 'PUNCT', 1, 'punct', 2]]]\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['New', 'PROPN', 6, 'compound', 5], ['Bern', 'PROPN', 4, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Bern', 'PROPN', 4, 'pobj', 6]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 4]\n",
      "testing NE hartsville, txt:Our teams returned to the command base in Darlington this evening with eyes still on a concerning river and dam situation in Hartsville. Here is a look at the area they staged at today. #Florence #LouisianaProud <URL>\n",
      "full parse [[['Our', 'ADJ', 1, 'poss', 0], ['teams', 'NOUN', 2, 'nsubj', 1], ['returned', 'VERB', 2, 'ROOT', 2], ['to', 'ADP', 2, 'prep', 3], ['the', 'DET', 6, 'det', 4], ['command', 'NOUN', 6, 'compound', 5], ['base', 'NOUN', 3, 'pobj', 6], ['in', 'ADP', 6, 'prep', 7], ['Darlington', 'PROPN', 7, 'pobj', 8], ['this', 'DET', 10, 'det', 9], ['evening', 'NOUN', 2, 'npadvmod', 10], ['with', 'ADP', 2, 'prep', 11], ['eyes', 'NOUN', 11, 'pobj', 12], ['still', 'ADV', 14, 'advmod', 13], ['on', 'ADP', 2, 'prep', 14], ['a', 'DET', 20, 'det', 15], ['concerning', 'VERB', 20, 'amod', 16], ['river', 'NOUN', 20, 'nmod', 17], ['and', 'CCONJ', 17, 'cc', 18], ['dam', 'NOUN', 17, 'conj', 19], ['situation', 'NOUN', 14, 'pobj', 20], ['in', 'ADP', 20, 'prep', 21], ['Hartsville', 'PROPN', 21, 'pobj', 22], ['.', 'PUNCT', 2, 'punct', 23]], [['Here', 'ADV', 1, 'advmod', 0], ['is', 'VERB', 1, 'ROOT', 1], ['a', 'DET', 3, 'det', 2], ['look', 'NOUN', 1, 'nsubj', 3], ['at', 'ADP', 3, 'prep', 4], ['the', 'DET', 6, 'det', 5], ['area', 'NOUN', 4, 'pobj', 6], ['they', 'PRON', 8, 'nsubj', 7], ['staged', 'VERB', 6, 'relcl', 8], ['at', 'ADP', 8, 'prep', 9], ['today', 'NOUN', 9, 'pobj', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['#Florence', 'PROPN', 1, 'compound', 0], ['#LouisianaProud', 'PUNCT', 1, 'ROOT', 1]]]\n",
      "candidate 0=Darlington\n",
      "anchor NE candidates = \n",
      "candidate 1=Hartsville\n",
      "anchor NE candidates = Darlington\n",
      "data NE tree=[['Hartsville', 'PROPN', 21, 'pobj', 22]]\n",
      "NE parse token at tree=0, token=23:\n",
      "['Hartsville', 'PROPN', 21, 'pobj', 22]\n",
      "NE parent token:\n",
      "['in', 'ADP', 20, 'prep', 21]\n",
      "testing NE myrtle_beach, txt:Thanks. My wife & I were driving that road 16 days ago heading from Myrtle Beach to the NASCAR race in Darlington. The PeeDee River is halfway between Marion and Darlington. Very sad what is happening. We're thinking about everyone in the Carolinas affected by #HurricaneFlorence .\n",
      "full parse [[['Thanks', 'NOUN', 0, 'ROOT', 0], ['.', 'PUNCT', 0, 'punct', 1]], [['My', 'ADJ', 1, 'poss', 0], ['wife', 'NOUN', 5, 'nsubj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['I', 'PRON', 1, 'conj', 3], ['were', 'VERB', 5, 'aux', 4], ['driving', 'VERB', 5, 'ROOT', 5], ['that', 'DET', 7, 'det', 6], ['road', 'NOUN', 5, 'dobj', 7], ['16', 'NUM', 9, 'nummod', 8], ['days', 'NOUN', 10, 'npadvmod', 9], ['ago', 'ADV', 5, 'advmod', 10], ['heading', 'VERB', 5, 'advcl', 11], ['from', 'ADP', 11, 'prep', 12], ['Myrtle', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 12, 'pobj', 14], ['to', 'ADP', 11, 'prep', 15], ['the', 'DET', 18, 'det', 16], ['NASCAR', 'PROPN', 18, 'compound', 17], ['race', 'NOUN', 15, 'pobj', 18], ['in', 'ADP', 18, 'prep', 19], ['Darlington', 'PROPN', 19, 'pobj', 20], ['.', 'PUNCT', 5, 'punct', 21]], [['The', 'DET', 2, 'det', 0], ['PeeDee', 'PROPN', 2, 'compound', 1], ['River', 'PROPN', 3, 'nsubj', 2], ['is', 'VERB', 3, 'ROOT', 3], ['halfway', 'ADV', 3, 'advmod', 4], ['between', 'ADP', 4, 'prep', 5], ['Marion', 'PROPN', 5, 'pobj', 6], ['and', 'CCONJ', 6, 'cc', 7], ['Darlington', 'PROPN', 6, 'conj', 8], ['.', 'PUNCT', 3, 'punct', 9]], [['Very', 'ADV', 1, 'advmod', 0], ['sad', 'ADJ', 1, 'ROOT', 1], ['what', 'NOUN', 4, 'nsubj', 2], ['is', 'VERB', 4, 'aux', 3], ['happening', 'VERB', 1, 'ccomp', 4], ['.', 'PUNCT', 1, 'punct', 5]], [[\"We're\", 'PROPN', 1, 'nsubj', 0], ['thinking', 'VERB', 1, 'ROOT', 1], ['about', 'ADP', 1, 'prep', 2], ['everyone', 'NOUN', 2, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['the', 'DET', 6, 'det', 5], ['Carolinas', 'PROPN', 4, 'pobj', 6], ['affected', 'VERB', 3, 'acl', 7], ['by', 'ADP', 7, 'agent', 8], ['#HurricaneFlorence', 'PROPN', 8, 'pobj', 9], ['.', 'PUNCT', 1, 'punct', 10]]]\n",
      "candidate 0=Myrtle Beach\n",
      "anchor NE candidates = Darlington,Marion,Darlington\n",
      "data NE tree=[['Myrtle', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 12, 'pobj', 14]]\n",
      "NE parse token at tree=1, token=15:\n",
      "['Beach', 'PROPN', 12, 'pobj', 14]\n",
      "NE parent token:\n",
      "['from', 'ADP', 11, 'prep', 12]\n",
      "candidate 1=Darlington\n",
      "anchor NE candidates = \n",
      "candidate 2=Marion\n",
      "anchor NE candidates = Darlington,Darlington\n",
      "data NE tree=[['Marion', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=2, token=7:\n",
      "['Marion', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['between', 'ADP', 4, 'prep', 5]\n",
      "NE=Marion subtree=[['and', 'CCONJ', 6, 'cc', 7], ['Darlington', 'PROPN', 6, 'conj', 8]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 3=Darlington\n",
      "anchor NE candidates = \n",
      "testing NE north, txt:Argentina expresses its sincere condolences to the Government and the people of the United States over the tragic loss of several lives left by #HurricaneFlorence in various States mainly in North and South Carolina. Read the press release here: <URL>\n",
      "full parse [[['Argentina', 'PROPN', 1, 'nsubj', 0], ['expresses', 'VERB', 1, 'ROOT', 1], ['its', 'ADJ', 4, 'poss', 2], ['sincere', 'ADJ', 4, 'amod', 3], ['condolences', 'NOUN', 1, 'dobj', 4], ['to', 'ADP', 1, 'prep', 5], ['the', 'DET', 7, 'det', 6], ['Government', 'PROPN', 5, 'pobj', 7], ['and', 'CCONJ', 7, 'cc', 8], ['the', 'DET', 10, 'det', 9], ['people', 'NOUN', 7, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['the', 'DET', 14, 'det', 12], ['United', 'PROPN', 14, 'compound', 13], ['States', 'PROPN', 11, 'pobj', 14], ['over', 'ADP', 1, 'prep', 15], ['the', 'DET', 18, 'det', 16], ['tragic', 'ADJ', 18, 'amod', 17], ['loss', 'NOUN', 15, 'pobj', 18], ['of', 'ADP', 18, 'prep', 19], ['several', 'ADJ', 21, 'amod', 20], ['lives', 'NOUN', 19, 'pobj', 21], ['left', 'VERB', 21, 'acl', 22], ['by', 'ADP', 22, 'agent', 23], ['#HurricaneFlorence', 'PROPN', 23, 'pobj', 24], ['in', 'ADP', 22, 'prep', 25], ['various', 'ADJ', 27, 'amod', 26], ['States', 'PROPN', 25, 'pobj', 27], ['mainly', 'ADV', 29, 'advmod', 28], ['in', 'ADP', 22, 'prep', 29], ['North', 'PROPN', 33, 'nmod', 30], ['and', 'CCONJ', 30, 'cc', 31], ['South', 'PROPN', 30, 'conj', 32], ['Carolina', 'PROPN', 29, 'pobj', 33], ['.', 'PUNCT', 1, 'punct', 34]], [['Read', 'VERB', 0, 'ROOT', 0], ['the', 'DET', 3, 'det', 1], ['press', 'NOUN', 3, 'compound', 2], ['release', 'NOUN', 0, 'dobj', 3], ['here', 'ADV', 0, 'advmod', 4], [':', 'PUNCT', 0, 'punct', 5]]]\n",
      "candidate 0=North\n",
      "anchor NE candidates = United States\n",
      "data NE tree=[['North', 'PROPN', 33, 'nmod', 30]]\n",
      "NE parse token at tree=0, token=31:\n",
      "['North', 'PROPN', 33, 'nmod', 30]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 29, 'pobj', 33]\n",
      "parent node subtree [['North', 'PROPN', 33, 'nmod', 30], ['and', 'CCONJ', 30, 'cc', 31], ['South', 'PROPN', 30, 'conj', 32], ['Carolina', 'PROPN', 29, 'pobj', 33]]\n",
      "parent node subtree str north and south carolina\n",
      "NE=North subtree=[['and', 'CCONJ', 30, 'cc', 31], ['South', 'PROPN', 30, 'conj', 32]]\n",
      "min node deps ['cc', 'conj']\n",
      "false positive: NE=north, type=compound\n",
      "testing NE everett, txt:ONLY ON @WXII : A multi-state operation to check on/rescue a stranded community. The Deep River here in Chatham County has cut off Everett Dowdy Rd. Food and water are being distributed. If needed people can be boated back and transported on a NG truck. #Florence <URL>\n",
      "full parse [[['ONLY', 'ADV', 1, 'advmod', 0], ['ON', 'ADP', 1, 'ROOT', 1], ['@WXII', 'PROPN', 1, 'pobj', 2], [':', 'PUNCT', 6, 'punct', 3], ['A', 'DET', 6, 'det', 4], ['multistate', 'NOUN', 6, 'compound', 5], ['operation', 'NOUN', 1, 'npadvmod', 6], ['to', 'PART', 8, 'aux', 7], ['check', 'VERB', 6, 'relcl', 8], ['on', 'ADP', 8, 'prt', 9], ['/', 'SYM', 9, 'punct', 10], ['rescue', 'VERB', 9, 'pobj', 11], ['a', 'DET', 14, 'det', 12], ['stranded', 'VERB', 14, 'amod', 13], ['community', 'NOUN', 8, 'dobj', 14], ['.', 'PUNCT', 1, 'punct', 15]], [['The', 'DET', 2, 'det', 0], ['Deep', 'PROPN', 2, 'compound', 1], ['River', 'PROPN', 8, 'nsubj', 2], ['here', 'ADV', 2, 'advmod', 3], ['in', 'ADP', 3, 'prep', 4], ['Chatham', 'PROPN', 6, 'compound', 5], ['County', 'PROPN', 4, 'pobj', 6], ['has', 'VERB', 8, 'aux', 7], ['cut', 'VERB', 8, 'ROOT', 8], ['off', 'PART', 8, 'prt', 9], ['Everett', 'PROPN', 12, 'compound', 10], ['Dowdy', 'PROPN', 12, 'compound', 11], ['Rd', 'PROPN', 8, 'dobj', 12], ['.', 'PUNCT', 8, 'punct', 13]], [['Food', 'NOUN', 5, 'nsubjpass', 0], ['and', 'CCONJ', 0, 'cc', 1], ['water', 'NOUN', 0, 'conj', 2], ['are', 'VERB', 5, 'aux', 3], ['being', 'VERB', 5, 'auxpass', 4], ['distributed', 'VERB', 5, 'ROOT', 5], ['.', 'PUNCT', 5, 'punct', 6]], [['If', 'ADP', 1, 'mark', 0], ['needed', 'VERB', 2, 'amod', 1], ['people', 'NOUN', 5, 'nsubjpass', 2], ['can', 'VERB', 5, 'aux', 3], ['be', 'VERB', 5, 'auxpass', 4], ['boated', 'VERB', 5, 'ROOT', 5], ['back', 'ADV', 5, 'advmod', 6], ['and', 'CCONJ', 5, 'cc', 7], ['transported', 'VERB', 5, 'conj', 8], ['on', 'ADP', 8, 'prep', 9], ['a', 'DET', 12, 'det', 10], ['NG', 'PROPN', 12, 'compound', 11], ['truck', 'NOUN', 9, 'pobj', 12], ['.', 'PUNCT', 5, 'punct', 13]], [['#Florence', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Chatham County\n",
      "anchor NE candidates = \n",
      "candidate 1=Everett\n",
      "anchor NE candidates = Chatham County\n",
      "data NE tree=[['Everett', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['Everett', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['Rd', 'PROPN', 8, 'dobj', 12]\n",
      "parent node subtree [['Everett', 'PROPN', 12, 'compound', 10], ['Dowdy', 'PROPN', 12, 'compound', 11], ['Rd', 'PROPN', 8, 'dobj', 12]]\n",
      "parent node subtree str everett dowdy rd\n",
      "testing NE southport, txt:My aunt & uncle have lived in Southport, North Carolina for about 35 years. They evacuated from #HurricaneFlorence and stayed with family a couple hours away. They are still away, but I heard from my mother today that their house is structurally safe. So much flooding though. :(\n",
      "full parse [[['My', 'ADJ', 1, 'poss', 0], ['aunt', 'NOUN', 5, 'nsubj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['uncle', 'NOUN', 1, 'conj', 3], ['have', 'VERB', 5, 'aux', 4], ['lived', 'VERB', 5, 'ROOT', 5], ['in', 'ADP', 5, 'prep', 6], ['Southport', 'PROPN', 9, 'compound', 7], ['North', 'PROPN', 9, 'compound', 8], ['Carolina', 'PROPN', 6, 'pobj', 9], ['for', 'ADP', 5, 'prep', 10], ['about', 'ADV', 12, 'advmod', 11], ['35', 'NUM', 13, 'nummod', 12], ['years', 'NOUN', 10, 'pobj', 13], ['.', 'PUNCT', 5, 'punct', 14]], [['They', 'PRON', 1, 'nsubj', 0], ['evacuated', 'VERB', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['#HurricaneFlorence', 'PROPN', 2, 'pobj', 3], ['and', 'CCONJ', 1, 'cc', 4], ['stayed', 'VERB', 1, 'conj', 5], ['with', 'ADP', 5, 'prep', 6], ['family', 'NOUN', 6, 'pobj', 7], ['a', 'DET', 9, 'quantmod', 8], ['couple', 'NOUN', 10, 'nummod', 9], ['hours', 'NOUN', 11, 'npadvmod', 10], ['away', 'ADV', 5, 'advmod', 11], ['.', 'PUNCT', 1, 'punct', 12]], [['They', 'PRON', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['still', 'ADV', 1, 'advmod', 2], ['away', 'ADV', 1, 'advmod', 3], ['but', 'CCONJ', 6, 'cc', 4], ['I', 'PRON', 6, 'nsubj', 5], ['heard', 'VERB', 6, 'ROOT', 6], ['from', 'ADP', 6, 'prep', 7], ['my', 'ADJ', 9, 'poss', 8], ['mother', 'NOUN', 7, 'pobj', 9], ['today', 'NOUN', 6, 'npadvmod', 10], ['that', 'ADP', 14, 'mark', 11], ['their', 'ADJ', 13, 'poss', 12], ['house', 'NOUN', 14, 'nsubj', 13], ['is', 'VERB', 6, 'ccomp', 14], ['structurally', 'ADV', 16, 'advmod', 15], ['safe', 'ADJ', 14, 'acomp', 16], ['.', 'PUNCT', 6, 'punct', 17]], [['So', 'ADV', 1, 'advmod', 0], ['much', 'ADJ', 2, 'amod', 1], ['flooding', 'NOUN', 2, 'ROOT', 2], ['though', 'ADV', 2, 'advmod', 3], ['.', 'PUNCT', 2, 'punct', 4]], [[':(', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=Southport\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Southport', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Southport', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['Southport', 'PROPN', 9, 'compound', 7], ['North', 'PROPN', 9, 'compound', 8], ['Carolina', 'PROPN', 6, 'pobj', 9]]\n",
      "parent node subtree str southport north carolina\n",
      "false positive: NE=southport, type=compound\n",
      "testing NE anson, txt:CHECK THIS OUT! Viewer video of Mayesville Rd in Anson County during #Florence. @NCDOT crews say it will take several months until all impacted roads are reopened. There are 44 closed roads in Anson County alone. NCDOT has 12 assessment teams checking damage in Anson and Union. <URL>\n",
      "full parse [[['CHECK', 'VERB', 1, 'compound', 0], ['THIS', 'VERB', 1, 'ROOT', 1], ['OUT', 'ADV', 1, 'advmod', 2], ['!', 'PUNCT', 1, 'punct', 3]], [['Viewer', 'PROPN', 1, 'compound', 0], ['video', 'NOUN', 1, 'ROOT', 1], ['of', 'ADP', 1, 'prep', 2], ['Mayesville', 'PROPN', 4, 'compound', 3], ['Rd', 'PROPN', 2, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['Anson', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 5, 'pobj', 7], ['during', 'ADP', 1, 'prep', 8], ['#Florence', 'PROPN', 8, 'pobj', 9], ['.', 'PUNCT', 1, 'punct', 10]], [['@NCDOT', 'PUNCT', 1, 'nummod', 0], ['crews', 'NOUN', 2, 'nsubj', 1], ['say', 'VERB', 2, 'ROOT', 2], ['it', 'PRON', 5, 'nsubj', 3], ['will', 'VERB', 5, 'aux', 4], ['take', 'VERB', 2, 'ccomp', 5], ['several', 'ADJ', 7, 'amod', 6], ['months', 'NOUN', 5, 'dobj', 7], ['until', 'ADP', 13, 'mark', 8], ['all', 'DET', 11, 'det', 9], ['impacted', 'VERB', 11, 'amod', 10], ['roads', 'NOUN', 13, 'nsubjpass', 11], ['are', 'VERB', 13, 'auxpass', 12], ['reopened', 'VERB', 5, 'advcl', 13], ['.', 'PUNCT', 2, 'punct', 14]], [['There', 'ADV', 1, 'expl', 0], ['are', 'VERB', 1, 'ROOT', 1], ['44', 'NUM', 4, 'nummod', 2], ['closed', 'ADJ', 4, 'amod', 3], ['roads', 'NOUN', 1, 'attr', 4], ['in', 'ADP', 4, 'prep', 5], ['Anson', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 5, 'pobj', 7], ['alone', 'ADV', 1, 'advmod', 8], ['.', 'PUNCT', 1, 'punct', 9]], [['NCDOT', 'PROPN', 1, 'nsubj', 0], ['has', 'VERB', 1, 'ROOT', 1], ['12', 'NUM', 4, 'nummod', 2], ['assessment', 'NOUN', 4, 'compound', 3], ['teams', 'NOUN', 1, 'dobj', 4], ['checking', 'VERB', 4, 'acl', 5], ['damage', 'NOUN', 5, 'dobj', 6], ['in', 'ADP', 6, 'prep', 7], ['Anson', 'PROPN', 7, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['Union', 'PROPN', 8, 'conj', 10], ['.', 'PUNCT', 1, 'punct', 11]]]\n",
      "candidate 0=Anson County\n",
      "anchor NE candidates = \n",
      "candidate 1=Anson County\n",
      "anchor NE candidates = \n",
      "candidate 2=Anson\n",
      "anchor NE candidates = Anson County,Anson County,Union\n",
      "data NE tree=[['Anson', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['Anson', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['Anson', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 5, 'pobj', 7]]\n",
      "parent node subtree str anson county\n",
      "candidate 3=Union\n",
      "anchor NE candidates = Anson County,Anson County\n",
      "data NE tree=[['Union', 'PROPN', 8, 'conj', 10]]\n",
      "NE parse token at tree=4, token=11:\n",
      "['Union', 'PROPN', 8, 'conj', 10]\n",
      "NE parent token:\n",
      "['Anson', 'PROPN', 7, 'pobj', 8]\n",
      "testing NE horry_county, txt:More evacuations coming in Horry County, SC. #Florence #flooding <URL>\n",
      "full parse [[['More', 'ADJ', 1, 'amod', 0], ['evacuations', 'NOUN', 1, 'ROOT', 1], ['coming', 'VERB', 1, 'acl', 2], ['in', 'ADP', 2, 'prep', 3], ['Horry', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 6, 'compound', 5], ['SC', 'PROPN', 3, 'pobj', 6], ['.', 'PUNCT', 1, 'punct', 7]], [['#Florence', 'X', 1, 'compound', 0], ['#flooding', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Horry County\n",
      "anchor NE candidates = SC\n",
      "data NE tree=[['Horry', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['County', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 3, 'pobj', 6]\n",
      "parent node subtree [['Horry', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 6, 'compound', 5], ['SC', 'PROPN', 3, 'pobj', 6]]\n",
      "parent node subtree str horry county sc\n",
      "false positive: NE=horry_county, type=compound\n",
      "testing NE new_bern, txt:New Bern, NC & Conway, SC got visits from @POTUS Trump yesterday as they recover from the devastation brought by #Florence . Coming up hear what ppl in area had to say about his visit @WBTV_News <URL>\n",
      "full parse [[['New', 'PROPN', 2, 'compound', 0], ['Bern', 'PROPN', 2, 'compound', 1], ['NC', 'PROPN', 6, 'nsubj', 2], ['&', 'CCONJ', 2, 'cc', 3], ['Conway', 'PROPN', 5, 'compound', 4], ['SC', 'PROPN', 2, 'conj', 5], ['got', 'VERB', 6, 'ROOT', 6], ['visits', 'NOUN', 6, 'dobj', 7], ['from', 'ADP', 7, 'prep', 8], ['@POTUS', 'X', 10, 'compound', 9], ['Trump', 'PROPN', 8, 'pobj', 10], ['yesterday', 'NOUN', 6, 'npadvmod', 11], ['as', 'ADP', 14, 'mark', 12], ['they', 'PRON', 14, 'nsubj', 13], ['recover', 'VERB', 6, 'advcl', 14], ['from', 'ADP', 14, 'prep', 15], ['the', 'DET', 17, 'det', 16], ['devastation', 'NOUN', 15, 'pobj', 17], ['brought', 'VERB', 17, 'acl', 18], ['by', 'ADP', 18, 'agent', 19], ['#Florence', 'NOUN', 19, 'pobj', 20], ['.', 'PUNCT', 6, 'punct', 21]], [['Coming', 'VERB', 2, 'advcl', 0], ['up', 'PART', 0, 'prt', 1], ['hear', 'VERB', 2, 'ROOT', 2], ['what', 'NOUN', 7, 'dobj', 3], ['ppl', 'NOUN', 7, 'nsubj', 4], ['in', 'ADP', 4, 'prep', 5], ['area', 'NOUN', 5, 'pobj', 6], ['had', 'VERB', 2, 'ccomp', 7], ['to', 'PART', 9, 'aux', 8], ['say', 'VERB', 7, 'xcomp', 9], ['about', 'ADP', 9, 'prep', 10], ['his', 'ADJ', 13, 'poss', 11], ['visit', 'NOUN', 13, 'compound', 12], ['@WBTV_News', 'X', 10, 'pobj', 13]]]\n",
      "candidate 0=New Bern\n",
      "anchor NE candidates = NC,Conway,SC\n",
      "data NE tree=[['New', 'PROPN', 2, 'compound', 0], ['Bern', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Bern', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 6, 'nsubj', 2]\n",
      "parent node subtree [['New', 'PROPN', 2, 'compound', 0], ['Bern', 'PROPN', 2, 'compound', 1], ['NC', 'PROPN', 6, 'nsubj', 2], ['&', 'CCONJ', 2, 'cc', 3], ['Conway', 'PROPN', 5, 'compound', 4], ['SC', 'PROPN', 2, 'conj', 5]]\n",
      "parent node subtree str new bern nc & conway sc\n",
      "candidate 1=Conway\n",
      "anchor NE candidates = \n",
      "false positive: NE=new_bern, type=compound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE lumberton, txt:Thanks to the amazing generosity of people in and around the Triangle, @WRAL helped fill 5 buses, 5 trailers, 3 vans and a small truck with supplies for #Florence victims. 130,500 lbs in supplies will be delivered next week to Wilmington, Lumberton and New Bern. #wral\n",
      "full parse [[['Thanks', 'NOUN', 13, 'npadvmod', 0], ['to', 'ADP', 0, 'prep', 1], ['the', 'DET', 4, 'det', 2], ['amazing', 'ADJ', 4, 'amod', 3], ['generosity', 'NOUN', 1, 'pobj', 4], ['of', 'ADP', 4, 'prep', 5], ['people', 'NOUN', 5, 'pobj', 6], ['in', 'ADP', 4, 'prep', 7], ['and', 'CCONJ', 7, 'cc', 8], ['around', 'ADP', 7, 'conj', 9], ['the', 'DET', 12, 'det', 10], ['Triangle', 'PROPN', 12, 'compound', 11], ['@WRAL', 'PROPN', 9, 'pobj', 12], ['helped', 'VERB', 13, 'ROOT', 13], ['fill', 'VERB', 13, 'xcomp', 14], ['5', 'NUM', 16, 'nummod', 15], ['buses', 'NOUN', 14, 'dative', 16], ['5', 'NUM', 18, 'nummod', 17], ['trailers', 'NOUN', 14, 'dobj', 18], ['3', 'NUM', 20, 'nummod', 19], ['vans', 'NOUN', 18, 'appos', 20], ['and', 'CCONJ', 20, 'cc', 21], ['a', 'DET', 24, 'det', 22], ['small', 'ADJ', 24, 'amod', 23], ['truck', 'NOUN', 20, 'conj', 24], ['with', 'ADP', 24, 'prep', 25], ['supplies', 'NOUN', 25, 'pobj', 26], ['for', 'ADP', 26, 'prep', 27], ['#Florence', 'NOUN', 29, 'compound', 28], ['victims', 'NOUN', 27, 'pobj', 29], ['.', 'PUNCT', 13, 'punct', 30]], [['130500', 'NUM', 1, 'nummod', 0], ['lbs', 'NOUN', 6, 'nsubjpass', 1], ['in', 'ADP', 1, 'prep', 2], ['supplies', 'NOUN', 2, 'pobj', 3], ['will', 'VERB', 6, 'aux', 4], ['be', 'VERB', 6, 'auxpass', 5], ['delivered', 'VERB', 6, 'ROOT', 6], ['next', 'ADJ', 8, 'amod', 7], ['week', 'NOUN', 6, 'npadvmod', 8], ['to', 'ADP', 6, 'prep', 9], ['Wilmington', 'PROPN', 11, 'compound', 10], ['Lumberton', 'PROPN', 9, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['New', 'PROPN', 14, 'compound', 13], ['Bern', 'PROPN', 11, 'conj', 14], ['.', 'PUNCT', 6, 'punct', 15]], [['#wral', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Wilmington\n",
      "anchor NE candidates = Wilmington,Lumberton,New Bern\n",
      "data NE tree=[['Wilmington', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['Wilmington', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Lumberton', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Wilmington', 'PROPN', 11, 'compound', 10], ['Lumberton', 'PROPN', 9, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['New', 'PROPN', 14, 'compound', 13], ['Bern', 'PROPN', 11, 'conj', 14]]\n",
      "parent node subtree str wilmington lumberton and new bern\n",
      "candidate 1=Lumberton\n",
      "anchor NE candidates = \n",
      "candidate 2=New Bern\n",
      "anchor NE candidates = Wilmington,New Bern\n",
      "data NE tree=[['New', 'PROPN', 14, 'compound', 13], ['Bern', 'PROPN', 11, 'conj', 14]]\n",
      "NE parse token at tree=1, token=15:\n",
      "['Bern', 'PROPN', 11, 'conj', 14]\n",
      "NE parent token:\n",
      "['Lumberton', 'PROPN', 9, 'pobj', 11]\n",
      "testing NE boiling_spring_lakes, txt:Update: #HurricaneFlorence Brunswick County will have food and water available for distribution Friday, Sept. 21 from 11 a.m. To 5 p.m. at: Spring Lake Park (210 Pine Road in Boiling Spring Lakes) Northwest... <URL>\n",
      "full parse [[['Update', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['#HurricaneFlorence', 'PROPN', 4, 'compound', 2], ['Brunswick', 'PROPN', 4, 'compound', 3], ['County', 'PROPN', 6, 'nsubj', 4], ['will', 'VERB', 6, 'aux', 5], ['have', 'VERB', 0, 'acl', 6], ['food', 'NOUN', 6, 'dobj', 7], ['and', 'CCONJ', 7, 'cc', 8], ['water', 'NOUN', 7, 'conj', 9], ['available', 'ADJ', 7, 'amod', 10], ['for', 'ADP', 10, 'prep', 11], ['distribution', 'NOUN', 11, 'pobj', 12], ['Friday', 'PROPN', 14, 'compound', 13], ['Sept', 'PROPN', 6, 'npadvmod', 14], ['.', 'PUNCT', 0, 'punct', 15], ['21', 'NUM', 16, 'ROOT', 16], ['from', 'ADP', 16, 'prep', 17], ['11', 'NUM', 17, 'pobj', 18], ['a', 'DET', 19, 'ROOT', 19], ['.', 'PUNCT', 19, 'punct', 20], ['m', 'NOUN', 21, 'ROOT', 21], ['.', 'PUNCT', 21, 'punct', 22], ['To', 'ADP', 23, 'ROOT', 23], ['5', 'NUM', 25, 'nummod', 24], ['p', 'NOUN', 23, 'pobj', 25], ['.', 'PUNCT', 23, 'punct', 26], ['m', 'NOUN', 27, 'ROOT', 27], ['.', 'PUNCT', 27, 'punct', 28], ['at', 'ADP', 29, 'ROOT', 29], [':', 'PUNCT', 29, 'punct', 30], ['Spring', 'PROPN', 33, 'compound', 31], ['Lake', 'PROPN', 33, 'compound', 32], ['Park', 'PROPN', 29, 'pobj', 33], ['(', 'PUNCT', 33, 'punct', 34], ['210', 'NUM', 37, 'nummod', 35], ['Pine', 'PROPN', 37, 'compound', 36], ['Road', 'PROPN', 33, 'appos', 37], ['in', 'ADP', 37, 'prep', 38], ['Boiling', 'VERB', 41, 'compound', 39], ['Spring', 'PROPN', 41, 'compound', 40], ['Lakes', 'PROPN', 38, 'pobj', 41], [')', 'PUNCT', 33, 'punct', 42], ['Northwest', 'PROPN', 43, 'ROOT', 43], ['...', 'PUNCT', 43, 'punct', 44]]]\n",
      "candidate 0=Brunswick County\n",
      "anchor NE candidates = \n",
      "candidate 1=Boiling Spring Lakes\n",
      "anchor NE candidates = Brunswick County\n",
      "data NE tree=[['Boiling', 'VERB', 41, 'compound', 39], ['Spring', 'PROPN', 41, 'compound', 40], ['Lakes', 'PROPN', 38, 'pobj', 41]]\n",
      "NE parse token at tree=0, token=42:\n",
      "['Lakes', 'PROPN', 38, 'pobj', 41]\n",
      "NE parent token:\n",
      "['in', 'ADP', 37, 'prep', 38]\n",
      "candidate 2=Northwest\n",
      "anchor NE candidates = Brunswick County,Spring Lake Park\n",
      "data NE tree=[['Northwest', 'PROPN', 43, 'ROOT', 43]]\n",
      "NE=Northwest subtree=[['...', 'PUNCT', 43, 'punct', 44]]\n",
      "min node deps ['punct']\n",
      "testing NE jacksonville, txt:. @COJacksonville NC​ officials recommend avoiding a major intersection at the end of the Jacksonville bypass because of heavy traffic use by those heading to the southern coast. #HurricaneFlorence #FlorenceNC <URL>\n",
      "full parse [[['.', 'PUNCT', 0, 'ROOT', 0]], [['@COJacksonville', 'PROPN', 0, 'ROOT', 0], ['NC', 'PROPN', 3, 'nmod', 1], ['\\u200b', 'PROPN', 3, 'amod', 2], ['officials', 'NOUN', 4, 'nsubj', 3], ['recommend', 'VERB', 4, 'ROOT', 4], ['avoiding', 'VERB', 4, 'xcomp', 5], ['a', 'DET', 8, 'det', 6], ['major', 'ADJ', 8, 'amod', 7], ['intersection', 'NOUN', 5, 'dobj', 8], ['at', 'ADP', 5, 'prep', 9], ['the', 'DET', 11, 'det', 10], ['end', 'NOUN', 9, 'pobj', 11], ['of', 'ADP', 11, 'prep', 12], ['the', 'DET', 15, 'det', 13], ['Jacksonville', 'PROPN', 15, 'compound', 14], ['bypass', 'NOUN', 12, 'pobj', 15], ['because', 'ADP', 4, 'prep', 16], ['of', 'ADP', 16, 'pcomp', 17], ['heavy', 'ADJ', 20, 'amod', 18], ['traffic', 'NOUN', 20, 'compound', 19], ['use', 'NOUN', 16, 'pobj', 20], ['by', 'ADP', 20, 'prep', 21], ['those', 'DET', 21, 'pobj', 22], ['heading', 'VERB', 22, 'acl', 23], ['to', 'ADP', 23, 'prep', 24], ['the', 'DET', 27, 'det', 25], ['southern', 'ADJ', 27, 'amod', 26], ['coast', 'NOUN', 24, 'pobj', 27], ['.', 'PUNCT', 4, 'punct', 28]], [['#HurricaneFlorence', 'PROPN', 1, 'compound', 0], ['#FlorenceNC', 'X', 1, 'ROOT', 1]]]\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = \n",
      "false positive: NE=jacksonville, type=state\n",
      "testing NE cape_fear, txt:Please pay attention to #WilmingtonNC and surrounding areas near the Cape Fear, NE Cape Fear & Black Rivers today and through the weekend. Many in Pender County were evacuated last night by National Guard, now this today. #HurricaneFlorence <URL>\n",
      "full parse [[['Please', 'INTJ', 1, 'intj', 0], ['pay', 'VERB', 1, 'ROOT', 1], ['attention', 'NOUN', 1, 'dobj', 2], ['to', 'ADP', 1, 'prep', 3], ['#WilmingtonNC', 'PROPN', 3, 'pobj', 4], ['and', 'CCONJ', 4, 'cc', 5], ['surrounding', 'VERB', 7, 'amod', 6], ['areas', 'NOUN', 4, 'conj', 7], ['near', 'ADP', 7, 'prep', 8], ['the', 'DET', 14, 'det', 9], ['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'NOUN', 12, 'compound', 11], ['NE', 'PROPN', 14, 'compound', 12], ['Cape', 'PROPN', 14, 'compound', 13], ['Fear', 'PROPN', 8, 'pobj', 14], ['&', 'CCONJ', 14, 'cc', 15], ['Black', 'PROPN', 17, 'compound', 16], ['Rivers', 'PROPN', 14, 'conj', 17], ['today', 'NOUN', 1, 'npadvmod', 18], ['and', 'CCONJ', 18, 'cc', 19], ['through', 'ADP', 18, 'conj', 20], ['the', 'DET', 22, 'det', 21], ['weekend', 'NOUN', 20, 'pobj', 22], ['.', 'PUNCT', 1, 'punct', 23]], [['Many', 'ADJ', 5, 'nsubjpass', 0], ['in', 'ADP', 0, 'prep', 1], ['Pender', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 1, 'pobj', 3], ['were', 'VERB', 5, 'auxpass', 4], ['evacuated', 'VERB', 5, 'ROOT', 5], ['last', 'ADJ', 7, 'amod', 6], ['night', 'NOUN', 5, 'npadvmod', 7], ['by', 'ADP', 5, 'agent', 8], ['National', 'PROPN', 10, 'compound', 9], ['Guard', 'PROPN', 8, 'pobj', 10], ['now', 'ADV', 13, 'advmod', 11], ['this', 'DET', 13, 'det', 12], ['today', 'NOUN', 5, 'npadvmod', 13], ['.', 'PUNCT', 5, 'punct', 14]], [['#HurricaneFlorence', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Cape Fear\n",
      "anchor NE candidates = Pender County\n",
      "data NE tree=[['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'NOUN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Fear', 'NOUN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['NE', 'PROPN', 14, 'compound', 12]\n",
      "parent node subtree [['Cape', 'PROPN', 12, 'compound', 10], ['Fear', 'NOUN', 12, 'compound', 11], ['NE', 'PROPN', 14, 'compound', 12]]\n",
      "parent node subtree str cape fear ne\n",
      "candidate 1=Pender County\n",
      "anchor NE candidates = \n",
      "testing NE spring_lakes, txt:Boiling Spring Lakes, NC #CarolinaStrong #HurricaneFlorence #GiveBack @EdPiotrowski @wpdeabc15 @jamiearnoldWMBF @wmbfweather <URL>\n",
      "full parse [[['Boiling', 'VERB', 3, 'amod', 0], ['Spring', 'PROPN', 2, 'compound', 1], ['Lakes', 'PROPN', 3, 'compound', 2], ['NC', 'PROPN', 5, 'compound', 3], ['#CarolinaStrong', 'ADP', 5, 'compound', 4], ['#HurricaneFlorence', 'PROPN', 8, 'compound', 5], ['#GiveBack', 'PROPN', 8, 'compound', 6], ['@EdPiotrowski', 'PROPN', 8, 'compound', 7], ['@wpdeabc15', 'NOUN', 8, 'ROOT', 8], ['@jamiearnoldWMBF', 'X', 10, 'punct', 9], ['@wmbfweather', 'PUNCT', 8, 'punct', 10]]]\n",
      "candidate 0=Spring Lakes\n",
      "anchor NE candidates = NC\n",
      "data NE tree=[['Spring', 'PROPN', 2, 'compound', 1], ['Lakes', 'PROPN', 3, 'compound', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Lakes', 'PROPN', 3, 'compound', 2]\n",
      "NE parent token:\n",
      "['NC', 'PROPN', 5, 'compound', 3]\n",
      "parent node subtree [['Boiling', 'VERB', 3, 'amod', 0], ['Spring', 'PROPN', 2, 'compound', 1], ['Lakes', 'PROPN', 3, 'compound', 2], ['NC', 'PROPN', 5, 'compound', 3]]\n",
      "parent node subtree str boiling spring lakes nc\n",
      "false positive: NE=spring_lakes, type=compound\n",
      "testing NE georgetown_county, txt:Georgetown County will open emergency shelters at 7 a.m. Monday at the following locations: • Georgetown High School, 2500 Anthuan Maybank Drive, Georgetown • Waccamaw Middle School, 247 Wildcat Way, Pawleys Island @SCPublicRadio #HurricaneFlorence @GCEMD\n",
      "full parse [[['Georgetown', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'nsubj', 1], ['will', 'VERB', 3, 'aux', 2], ['open', 'VERB', 3, 'ROOT', 3], ['emergency', 'NOUN', 5, 'compound', 4], ['shelters', 'NOUN', 3, 'dobj', 5], ['at', 'ADP', 3, 'prep', 6], ['7', 'NUM', 6, 'pobj', 7], ['a', 'DET', 7, 'det', 8], ['.', 'PUNCT', 3, 'punct', 9], ['m', 'NOUN', 10, 'ROOT', 10], ['.', 'PUNCT', 10, 'punct', 11], ['Monday', 'PROPN', 12, 'ROOT', 12], ['at', 'ADP', 12, 'prep', 13], ['the', 'DET', 16, 'det', 14], ['following', 'VERB', 16, 'amod', 15], ['locations', 'NOUN', 13, 'pobj', 16], [':', 'PUNCT', 12, 'punct', 17], ['•', 'PROPN', 18, 'ROOT', 18], ['Georgetown', 'PROPN', 21, 'compound', 19], ['High', 'PROPN', 21, 'compound', 20], ['School', 'PROPN', 21, 'ROOT', 21], ['2500', 'NUM', 21, 'nummod', 22], ['Anthuan', 'PROPN', 26, 'compound', 23], ['Maybank', 'PROPN', 26, 'compound', 24], ['Drive', 'PROPN', 26, 'compound', 25], ['Georgetown', 'PROPN', 21, 'appos', 26], ['•', 'PROPN', 27, 'ROOT', 27], ['Waccamaw', 'PROPN', 30, 'compound', 28], ['Middle', 'PROPN', 30, 'compound', 29], ['School', 'PROPN', 35, 'compound', 30], ['247', 'NUM', 33, 'nummod', 31], ['Wildcat', 'PROPN', 33, 'compound', 32], ['Way', 'PROPN', 35, 'compound', 33], ['Pawleys', 'PROPN', 35, 'compound', 34], ['Island', 'PROPN', 35, 'ROOT', 35], ['@SCPublicRadio', 'PROPN', 35, 'punct', 36], ['#HurricaneFlorence', 'PROPN', 38, 'compound', 37], ['@GCEMD', 'X', 38, 'ROOT', 38]]]\n",
      "candidate 0=Georgetown County\n",
      "anchor NE candidates = Georgetown\n",
      "data NE tree=[['Georgetown', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['County', 'PROPN', 3, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['open', 'VERB', 3, 'ROOT', 3]\n",
      "candidate 1=Georgetown\n",
      "anchor NE candidates = \n",
      "candidate 2=Pawleys Island\n",
      "anchor NE candidates = Georgetown County,Georgetown\n",
      "data NE tree=[['Pawleys', 'PROPN', 35, 'compound', 34], ['Island', 'PROPN', 35, 'ROOT', 35]]\n",
      "NE=Pawleys Island subtree=[['Waccamaw', 'PROPN', 30, 'compound', 28], ['Middle', 'PROPN', 30, 'compound', 29], ['School', 'PROPN', 35, 'compound', 30], ['247', 'NUM', 33, 'nummod', 31], ['Wildcat', 'PROPN', 33, 'compound', 32], ['Way', 'PROPN', 35, 'compound', 33], ['@SCPublicRadio', 'PROPN', 35, 'punct', 36]]\n",
      "min node deps ['compound', 'compound']\n",
      "testing NE red_cross, txt:Eat at #beachsidebistro and 10% of your purchase will be donated to the Red Cross of North Carolina to help our fellow #northcarolinians affected by #hurricaneflorence #foodforflo … <URL>\n",
      "full parse [[['Eat', 'VERB', 0, 'ROOT', 0], ['at', 'ADP', 0, 'prep', 1], ['#beachsidebistro', 'PROPN', 1, 'pobj', 2], ['and', 'CCONJ', 0, 'cc', 3], ['10', 'NUM', 5, 'nummod', 4], ['%', 'NOUN', 11, 'nsubjpass', 5], ['of', 'ADP', 5, 'prep', 6], ['your', 'ADJ', 8, 'poss', 7], ['purchase', 'NOUN', 6, 'pobj', 8], ['will', 'VERB', 11, 'aux', 9], ['be', 'VERB', 11, 'auxpass', 10], ['donated', 'VERB', 0, 'conj', 11], ['to', 'ADP', 11, 'prep', 12], ['the', 'DET', 15, 'det', 13], ['Red', 'PROPN', 15, 'compound', 14], ['Cross', 'PROPN', 12, 'pobj', 15], ['of', 'ADP', 15, 'prep', 16], ['North', 'PROPN', 18, 'compound', 17], ['Carolina', 'PROPN', 16, 'pobj', 18], ['to', 'PART', 20, 'aux', 19], ['help', 'VERB', 11, 'advcl', 20], ['our', 'ADJ', 23, 'poss', 21], ['fellow', 'ADJ', 23, 'amod', 22], ['#northcarolinians', 'NOUN', 24, 'nsubj', 23], ['affected', 'VERB', 20, 'ccomp', 24], ['by', 'ADP', 24, 'agent', 25], ['#hurricaneflorence', 'NOUN', 27, 'compound', 26], ['#foodforflo', 'PROPN', 25, 'pobj', 27], ['…', 'PUNCT', 11, 'punct', 28]]]\n",
      "candidate 0=Red Cross\n",
      "anchor NE candidates = North Carolina\n",
      "data NE tree=[['Red', 'PROPN', 15, 'compound', 14], ['Cross', 'PROPN', 12, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Cross', 'PROPN', 12, 'pobj', 15]\n",
      "NE parent token:\n",
      "['to', 'ADP', 11, 'prep', 12]\n",
      "NE=Red Cross subtree=[['the', 'DET', 15, 'det', 13], ['of', 'ADP', 15, 'prep', 16], ['North', 'PROPN', 18, 'compound', 17], ['Carolina', 'PROPN', 16, 'pobj', 18]]\n",
      "min node deps ['det', 'prep']\n",
      "subtree = the of North Carolina\n",
      "testing NE duke, txt:Coal ash flowing like pudding in Neuse River near Duke's Goldsboro power plant <URL>\n",
      "full parse [[['Coal', 'NOUN', 1, 'compound', 0], ['ash', 'NOUN', 2, 'nsubj', 1], ['flowing', 'VERB', 2, 'ROOT', 2], ['like', 'ADP', 2, 'prep', 3], ['pudding', 'NOUN', 3, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['Neuse', 'PROPN', 7, 'compound', 6], ['River', 'PROPN', 5, 'pobj', 7], ['near', 'ADP', 4, 'prep', 8], [\"Duke's\", 'PROPN', 12, 'compound', 9], ['Goldsboro', 'PROPN', 12, 'compound', 10], ['power', 'NOUN', 12, 'compound', 11], ['plant', 'NOUN', 8, 'pobj', 12]]]\n",
      "candidate 0=Duke\n",
      "anchor NE candidates = Duke,Goldsboro\n",
      "candidate 1=Goldsboro\n",
      "anchor NE candidates = Goldsboro\n",
      "data NE tree=[['Goldsboro', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Goldsboro', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['plant', 'NOUN', 8, 'pobj', 12]\n",
      "parent node subtree [[\"Duke's\", 'PROPN', 12, 'compound', 9], ['Goldsboro', 'PROPN', 12, 'compound', 10], ['power', 'NOUN', 12, 'compound', 11], ['plant', 'NOUN', 8, 'pobj', 12]]\n",
      "parent node subtree str duke's goldsboro power plant\n",
      "testing NE corpus_christi, txt:The first Hurricane Watches for this part of #Texas in 3,267 days (9yrs!) like Houston & Corpus Christi #TXwx #Harvey h/t @KathrynProciv <URL>\n",
      "full parse [[['The', 'DET', 3, 'det', 0], ['first', 'ADJ', 3, 'amod', 1], ['Hurricane', 'PROPN', 3, 'compound', 2], ['Watches', 'PROPN', 3, 'ROOT', 3], ['for', 'ADP', 3, 'prep', 4], ['this', 'DET', 6, 'det', 5], ['part', 'NOUN', 4, 'pobj', 6], ['of', 'ADP', 6, 'prep', 7], ['#Texas', 'NOUN', 7, 'pobj', 8], ['in', 'ADP', 3, 'prep', 9], ['3267', 'NUM', 11, 'nummod', 10], ['days', 'NOUN', 9, 'pobj', 11], ['(', 'PUNCT', 3, 'punct', 12], ['9yrs', 'NUM', 3, 'appos', 13], ['!', 'PUNCT', 3, 'punct', 14], [')', 'PUNCT', 3, 'punct', 15]], [['like', 'ADP', 0, 'ROOT', 0], ['Houston', 'PROPN', 0, 'pobj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['Corpus', 'PROPN', 5, 'compound', 3], ['Christi', 'PROPN', 5, 'compound', 4], ['#TXwx', 'PROPN', 1, 'conj', 5], ['#Harvey', 'PROPN', 10, 'nmod', 6], ['h', 'NOUN', 10, 'intj', 7], ['/', 'SYM', 9, 'punct', 8], ['t', 'NOUN', 10, 'compound', 9], ['@KathrynProciv', 'PROPN', 10, 'ROOT', 10]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Corpus Christi\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Corpus', 'PROPN', 5, 'compound', 3], ['Christi', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Christi', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['#TXwx', 'PROPN', 1, 'conj', 5]\n",
      "parent node subtree [['Corpus', 'PROPN', 5, 'compound', 3], ['Christi', 'PROPN', 5, 'compound', 4], ['#TXwx', 'PROPN', 1, 'conj', 5]]\n",
      "parent node subtree str corpus christi #txwx\n",
      "testing NE rockport, txt:As of 10 a.m., the modeling has #Harvey making landfall north of Rockport, which would spare Corpus Christi the worst of the storm.\n",
      "full parse [[['As', 'ADP', 0, 'ROOT', 0], ['of', 'ADP', 0, 'prep', 1], ['10', 'NUM', 1, 'pobj', 2], ['a', 'DET', 2, 'det', 3], ['.', 'PUNCT', 5, 'punct', 4], ['m', 'NOUN', 0, 'pobj', 5], ['.', 'PUNCT', 0, 'punct', 6], ['the', 'DET', 8, 'det', 7], ['modeling', 'NOUN', 9, 'nsubj', 8], ['has', 'VERB', 9, 'ROOT', 9], ['#Harvey', 'PROPN', 9, 'dobj', 10], ['making', 'VERB', 10, 'acl', 11], ['landfall', 'NOUN', 11, 'dobj', 12], ['north', 'ADV', 11, 'advmod', 13], ['of', 'ADP', 13, 'prep', 14], ['Rockport', 'PROPN', 14, 'pobj', 15], ['which', 'ADJ', 18, 'nsubj', 16], ['would', 'VERB', 18, 'aux', 17], ['spare', 'VERB', 12, 'relcl', 18], ['Corpus', 'PROPN', 20, 'compound', 19], ['Christi', 'PROPN', 18, 'dobj', 20], ['the', 'DET', 22, 'det', 21], ['worst', 'ADJ', 18, 'dobj', 22], ['of', 'ADP', 22, 'prep', 23], ['the', 'DET', 25, 'det', 24], ['storm', 'NOUN', 23, 'pobj', 25], ['.', 'PUNCT', 9, 'punct', 26]]]\n",
      "candidate 0=Rockport\n",
      "anchor NE candidates = Corpus Christi\n",
      "data NE tree=[['Rockport', 'PROPN', 14, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Rockport', 'PROPN', 14, 'pobj', 15]\n",
      "NE parent token:\n",
      "['of', 'ADP', 13, 'prep', 14]\n",
      "candidate 1=Corpus Christi\n",
      "anchor NE candidates = \n",
      "testing NE brownsville, txt:The eye of #HurricaneHarvey is now showing on the Brownsville, Texas long range radar. <URL>\n",
      "full parse [[['The', 'DET', 1, 'det', 0], ['eye', 'NOUN', 6, 'nsubj', 1], ['of', 'ADP', 1, 'prep', 2], ['#HurricaneHarvey', 'PROPN', 2, 'pobj', 3], ['is', 'VERB', 6, 'aux', 4], ['now', 'ADV', 6, 'advmod', 5], ['showing', 'VERB', 6, 'ROOT', 6], ['on', 'ADP', 6, 'prep', 7], ['the', 'DET', 13, 'det', 8], ['Brownsville', 'PROPN', 10, 'nmod', 9], ['Texas', 'PROPN', 13, 'nmod', 10], ['long', 'ADJ', 12, 'amod', 11], ['range', 'NOUN', 13, 'compound', 12], ['radar', 'NOUN', 7, 'pobj', 13], ['.', 'PUNCT', 6, 'punct', 14]]]\n",
      "candidate 0=Brownsville\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Brownsville', 'PROPN', 10, 'nmod', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Brownsville', 'PROPN', 10, 'nmod', 9]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 13, 'nmod', 10]\n",
      "parent node subtree [['Brownsville', 'PROPN', 10, 'nmod', 9], ['Texas', 'PROPN', 13, 'nmod', 10]]\n",
      "parent node subtree str brownsville texas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive: NE=brownsville, type=compound\n",
      "testing NE corpus_christi, txt:Praying for Texas, esp my other home Corpus Christi. #HurricaneHarvey\n",
      "full parse [[['Praying', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['Texas', 'PROPN', 1, 'pobj', 2], ['esp', 'VERB', 0, 'advmod', 3], ['my', 'ADJ', 6, 'poss', 4], ['other', 'ADJ', 6, 'amod', 5], ['home', 'NOUN', 0, 'npadvmod', 6], ['Corpus', 'PROPN', 8, 'compound', 7], ['Christi', 'PROPN', 6, 'appos', 8], ['.', 'PUNCT', 0, 'punct', 9]], [['#HurricaneHarvey', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "testing NE matagorda, txt:Heavy squall headed toward Matagorda and Brazoria County coasts. Watch for waterspouts. #txwx #harvey <URL>\n",
      "full parse [[['Heavy', 'ADJ', 1, 'amod', 0], ['squall', 'NOUN', 2, 'nsubj', 1], ['headed', 'VERB', 2, 'ROOT', 2], ['toward', 'ADP', 2, 'prep', 3], ['Matagorda', 'PROPN', 8, 'nmod', 4], ['and', 'CCONJ', 4, 'cc', 5], ['Brazoria', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 4, 'conj', 7], ['coasts', 'NOUN', 3, 'pobj', 8], ['.', 'PUNCT', 2, 'punct', 9]], [['Watch', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['waterspouts', 'NOUN', 1, 'pobj', 2], ['.', 'PUNCT', 0, 'punct', 3]], [['#txwx', 'PROPN', 1, 'compound', 0], ['#harvey', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Matagorda\n",
      "anchor NE candidates = Brazoria County\n",
      "data NE tree=[['Matagorda', 'PROPN', 8, 'nmod', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Matagorda', 'PROPN', 8, 'nmod', 4]\n",
      "NE parent token:\n",
      "['coasts', 'NOUN', 3, 'pobj', 8]\n",
      "parent node subtree [['Matagorda', 'PROPN', 8, 'nmod', 4], ['and', 'CCONJ', 4, 'cc', 5], ['Brazoria', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 4, 'conj', 7], ['coasts', 'NOUN', 3, 'pobj', 8]]\n",
      "parent node subtree str matagorda and brazoria county coasts\n",
      "NE=Matagorda subtree=[['and', 'CCONJ', 4, 'cc', 5], ['Brazoria', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 4, 'conj', 7]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Brazoria County\n",
      "anchor NE candidates = \n",
      "testing NE galveston, txt:#Live . @mikebettes on #Periscope : Streaming cam from Galveston, Texas as Hurricane #Harvey approaches coast. #txwx <URL>\n",
      "full parse [[['#Live', 'ADJ', 0, 'ROOT', 0], ['.', 'PUNCT', 0, 'punct', 1]], [['@mikebettes', 'NOUN', 0, 'ROOT', 0], ['on', 'ADP', 0, 'prep', 1], ['#Periscope', 'PROPN', 1, 'pobj', 2], [':', 'PUNCT', 0, 'punct', 3], ['Streaming', 'VERB', 5, 'compound', 4], ['cam', 'NOUN', 5, 'ROOT', 5], ['from', 'ADP', 5, 'prep', 6], ['Galveston', 'PROPN', 8, 'compound', 7], ['Texas', 'PROPN', 6, 'pobj', 8], ['as', 'ADP', 12, 'mark', 9], ['Hurricane', 'PROPN', 11, 'compound', 10], ['#Harvey', 'PROPN', 12, 'nsubj', 11], ['approaches', 'VERB', 5, 'advcl', 12], ['coast', 'NOUN', 12, 'dobj', 13], ['.', 'PUNCT', 5, 'punct', 14]], [['#txwx', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Galveston\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Galveston', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Galveston', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Galveston', 'PROPN', 8, 'compound', 7], ['Texas', 'PROPN', 6, 'pobj', 8]]\n",
      "parent node subtree str galveston texas\n",
      "false positive: NE=galveston, type=compound\n",
      "testing NE galveston, txt:Headed to Galveston as #Harvey pushes closer to the TX coast. Look for updates here & live reports on @KPRC2 at 10 #HurricaneHarvey #kprc2 <URL>\n",
      "full parse [[['Headed', 'VERB', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['Galveston', 'PROPN', 1, 'pobj', 2], ['as', 'ADP', 5, 'mark', 3], ['#Harvey', 'PROPN', 5, 'nsubj', 4], ['pushes', 'VERB', 0, 'advcl', 5], ['closer', 'ADV', 5, 'advmod', 6], ['to', 'ADP', 6, 'prep', 7], ['the', 'DET', 10, 'det', 8], ['TX', 'PROPN', 10, 'compound', 9], ['coast', 'NOUN', 7, 'pobj', 10], ['.', 'PUNCT', 0, 'punct', 11]], [['Look', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['updates', 'NOUN', 1, 'pobj', 2], ['here', 'ADV', 2, 'advmod', 3], ['&', 'CCONJ', 2, 'cc', 4], ['live', 'VERB', 6, 'amod', 5], ['reports', 'NOUN', 2, 'conj', 6], ['on', 'ADP', 6, 'prep', 7], ['@KPRC2', 'PROPN', 7, 'pobj', 8], ['at', 'ADP', 0, 'prep', 9], ['10', 'NUM', 11, 'nummod', 10], ['#HurricaneHarvey', 'PROPN', 9, 'pobj', 11], ['#kprc2', 'X', 0, 'dep', 12]]]\n",
      "candidate 0=Galveston\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Galveston', 'PROPN', 1, 'pobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Galveston', 'PROPN', 1, 'pobj', 2]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "testing NE rockport, txt:#Harvey up to Cat 4 now. Just hours from landfall near Rockport, TX. Winds sustained at 130 mph. <URL>\n",
      "full parse [[['#Harvey', 'VERB', 0, 'ROOT', 0], ['up', 'PART', 0, 'prt', 1], ['to', 'ADP', 0, 'prep', 2], ['Cat', 'PROPN', 2, 'pobj', 3], ['4', 'NUM', 3, 'nummod', 4], ['now', 'ADV', 0, 'advmod', 5], ['.', 'PUNCT', 0, 'punct', 6]], [['Just', 'ADV', 1, 'advmod', 0], ['hours', 'NOUN', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['landfall', 'NOUN', 2, 'pobj', 3], ['near', 'ADP', 3, 'prep', 4], ['Rockport', 'PROPN', 6, 'compound', 5], ['TX', 'PROPN', 4, 'pobj', 6], ['.', 'PUNCT', 1, 'punct', 7]], [['Winds', 'NOUN', 1, 'nsubj', 0], ['sustained', 'VERB', 1, 'ROOT', 1], ['at', 'ADP', 1, 'prep', 2], ['130', 'NUM', 4, 'nummod', 3], ['mph', 'NOUN', 2, 'pobj', 4], ['.', 'PUNCT', 1, 'punct', 5]]]\n",
      "candidate 0=Rockport\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Rockport', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Rockport', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 4, 'pobj', 6]\n",
      "parent node subtree [['Rockport', 'PROPN', 6, 'compound', 5], ['TX', 'PROPN', 4, 'pobj', 6]]\n",
      "parent node subtree str rockport tx\n",
      "false positive: NE=rockport, type=compound\n",
      "testing NE lubbock, txt:@UnitedAirways I know you will do the right thing and refund my flight from Corpus Christi to Lubbock. #harvey . Thanks\n",
      "full parse [[['@UnitedAirways', 'NOUN', 0, 'ROOT', 0], ['I', 'PRON', 2, 'nsubj', 1], ['know', 'VERB', 2, 'ROOT', 2], ['you', 'PRON', 5, 'nsubj', 3], ['will', 'VERB', 5, 'aux', 4], ['do', 'VERB', 2, 'ccomp', 5], ['the', 'DET', 8, 'det', 6], ['right', 'ADJ', 8, 'amod', 7], ['thing', 'NOUN', 5, 'dobj', 8], ['and', 'CCONJ', 5, 'cc', 9], ['refund', 'VERB', 5, 'conj', 10], ['my', 'ADJ', 12, 'poss', 11], ['flight', 'NOUN', 10, 'dobj', 12], ['from', 'ADP', 12, 'prep', 13], ['Corpus', 'PROPN', 15, 'compound', 14], ['Christi', 'PROPN', 13, 'pobj', 15], ['to', 'ADP', 10, 'prep', 16], ['Lubbock', 'PROPN', 16, 'pobj', 17], ['.', 'PUNCT', 2, 'punct', 18]], [['#harvey', 'PROPN', 0, 'ROOT', 0], ['.', 'PUNCT', 0, 'punct', 1]], [['Thanks', 'NOUN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "candidate 1=Lubbock\n",
      "anchor NE candidates = Corpus Christi\n",
      "data NE tree=[['Lubbock', 'PROPN', 16, 'pobj', 17]]\n",
      "NE parse token at tree=0, token=18:\n",
      "['Lubbock', 'PROPN', 16, 'pobj', 17]\n",
      "NE parent token:\n",
      "['to', 'ADP', 10, 'prep', 16]\n",
      "testing NE san_jose_island, txt:Eyewall of #Harvey moving over San Jose Island north of Port Aransas, TX. #txwx <URL>\n",
      "full parse [[['Eyewall', 'PROPN', 3, 'nsubj', 0], ['of', 'ADP', 0, 'prep', 1], ['#Harvey', 'PROPN', 1, 'pobj', 2], ['moving', 'VERB', 3, 'ROOT', 3], ['over', 'ADP', 3, 'prep', 4], ['San', 'PROPN', 6, 'compound', 5], ['Jose', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 8, 'compound', 7], ['north', 'ADV', 3, 'advmod', 8], ['of', 'ADP', 8, 'prep', 9], ['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11], ['TX', 'PROPN', 9, 'pobj', 12], ['.', 'PUNCT', 3, 'punct', 13]], [['#txwx', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=San Jose Island\n",
      "anchor NE candidates = Port Aransas,TX\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Jose', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Island', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['north', 'ADV', 3, 'advmod', 8]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Jose', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 8, 'compound', 7], ['north', 'ADV', 3, 'advmod', 8], ['of', 'ADP', 8, 'prep', 9], ['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11], ['TX', 'PROPN', 9, 'pobj', 12]]\n",
      "parent node subtree str san jose island north of port aransas tx\n",
      "candidate 1=Port Aransas\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Aransas', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Port', 'PROPN', 11, 'compound', 10], ['Aransas', 'PROPN', 12, 'compound', 11], ['TX', 'PROPN', 9, 'pobj', 12]]\n",
      "parent node subtree str port aransas tx\n",
      "false positive: NE=san_jose_island, type=compound\n",
      "testing NE san_jose_island, txt:#BREAKING #HurricaneHarvey makes landfall on TX coast over the northern end of San Jose Island about 4 miles east of Rockport. #nprnewscast\n",
      "full parse [[['#BREAKING', 'PROPN', 1, 'compound', 0], ['#HurricaneHarvey', 'PROPN', 2, 'nsubj', 1], ['makes', 'VERB', 2, 'ROOT', 2], ['landfall', 'NOUN', 2, 'dobj', 3], ['on', 'ADP', 2, 'prep', 4], ['TX', 'PROPN', 6, 'compound', 5], ['coast', 'NOUN', 4, 'pobj', 6], ['over', 'ADP', 2, 'prep', 7], ['the', 'DET', 10, 'det', 8], ['northern', 'ADJ', 10, 'amod', 9], ['end', 'NOUN', 7, 'pobj', 10], ['of', 'ADP', 10, 'prep', 11], ['San', 'PROPN', 13, 'compound', 12], ['Jose', 'PROPN', 14, 'compound', 13], ['Island', 'PROPN', 11, 'pobj', 14], ['about', 'ADV', 16, 'advmod', 15], ['4', 'NUM', 17, 'nummod', 16], ['miles', 'NOUN', 18, 'npadvmod', 17], ['east', 'ADV', 10, 'advmod', 18], ['of', 'ADP', 18, 'prep', 19], ['Rockport', 'PROPN', 19, 'pobj', 20], ['.', 'PUNCT', 2, 'punct', 21]], [['#nprnewscast', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=San Jose Island\n",
      "anchor NE candidates = \n",
      "candidate 1=Rockport\n",
      "anchor NE candidates = TX,Rockport\n",
      "data NE tree=[['Rockport', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Rockport', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['of', 'ADP', 18, 'prep', 19]\n",
      "testing NE san_jose_island, txt:#HurricaneHarvey makes landfall on San Jose Island, TX near Rockport, TX as a Cat. 4 hurricane. @WCCBCharlotte <URL>\n",
      "full parse [[['#HurricaneHarvey', 'PROPN', 1, 'nsubj', 0], ['makes', 'VERB', 1, 'ROOT', 1], ['landfall', 'NOUN', 1, 'dobj', 2], ['on', 'ADP', 1, 'prep', 3], ['San', 'PROPN', 5, 'compound', 4], ['Jose', 'PROPN', 6, 'compound', 5], ['Island', 'PROPN', 7, 'compound', 6], ['TX', 'PROPN', 3, 'pobj', 7], ['near', 'ADP', 7, 'prep', 8], ['Rockport', 'PROPN', 10, 'compound', 9], ['TX', 'PROPN', 8, 'pobj', 10], ['as', 'ADP', 1, 'prep', 11], ['a', 'DET', 13, 'det', 12], ['Cat', 'PROPN', 11, 'pobj', 13], ['.', 'PUNCT', 1, 'punct', 14]], [['4', 'NUM', 1, 'nummod', 0], ['hurricane', 'NOUN', 1, 'ROOT', 1], ['.', 'PUNCT', 1, 'punct', 2]], [['@WCCBCharlotte', 'X', 0, 'ROOT', 0]]]\n",
      "candidate 0=San Jose Island\n",
      "anchor NE candidates = TX,Rockport,TX\n",
      "data NE tree=[['San', 'PROPN', 5, 'compound', 4], ['Jose', 'PROPN', 6, 'compound', 5], ['Island', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Island', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['San', 'PROPN', 5, 'compound', 4], ['Jose', 'PROPN', 6, 'compound', 5], ['Island', 'PROPN', 7, 'compound', 6], ['TX', 'PROPN', 3, 'pobj', 7], ['near', 'ADP', 7, 'prep', 8], ['Rockport', 'PROPN', 10, 'compound', 9], ['TX', 'PROPN', 8, 'pobj', 10]]\n",
      "parent node subtree str san jose island tx near rockport tx\n",
      "candidate 1=Rockport\n",
      "anchor NE candidates = \n",
      "false positive: NE=san_jose_island, type=compound\n",
      "testing NE port_aransas, txt:The eye of Hurricane #Harvey has made landfall between Port Aransas and Port O'Conner, TX. This is still only the beginning.\n",
      "full parse [[['The', 'DET', 1, 'det', 0], ['eye', 'NOUN', 6, 'nsubj', 1], ['of', 'ADP', 1, 'prep', 2], ['Hurricane', 'PROPN', 4, 'compound', 3], ['#Harvey', 'PROPN', 2, 'pobj', 4], ['has', 'VERB', 6, 'aux', 5], ['made', 'VERB', 6, 'ROOT', 6], ['landfall', 'NOUN', 6, 'dobj', 7], ['between', 'ADP', 7, 'prep', 8], ['Port', 'PROPN', 10, 'compound', 9], ['Aransas', 'PROPN', 8, 'pobj', 10], ['and', 'CCONJ', 10, 'cc', 11], ['Port', 'PROPN', 13, 'compound', 12], [\"O'Conner\", 'PROPN', 14, 'compound', 13], ['TX', 'PROPN', 10, 'conj', 14], ['.', 'PUNCT', 6, 'punct', 15]], [['This', 'DET', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['still', 'ADV', 1, 'advmod', 2], ['only', 'ADV', 5, 'advmod', 3], ['the', 'DET', 5, 'det', 4], ['beginning', 'NOUN', 1, 'attr', 5], ['.', 'PUNCT', 1, 'punct', 6]]]\n",
      "candidate 0=Port Aransas\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Port', 'PROPN', 10, 'compound', 9], ['Aransas', 'PROPN', 8, 'pobj', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Aransas', 'PROPN', 8, 'pobj', 10]\n",
      "NE parent token:\n",
      "['between', 'ADP', 7, 'prep', 8]\n",
      "NE=Port Aransas subtree=[['and', 'CCONJ', 10, 'cc', 11], ['Port', 'PROPN', 13, 'compound', 12], [\"O'Conner\", 'PROPN', 14, 'compound', 13], ['TX', 'PROPN', 10, 'conj', 14]]\n",
      "min node deps ['cc', 'conj']\n",
      "testing NE houston, txt:praying for my family all around texas, especially most of my family that resides in houston. stay safe! #prayfortexas #hurricaneharvey\n",
      "full parse [[['praying', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['my', 'ADJ', 3, 'poss', 2], ['family', 'NOUN', 1, 'pobj', 3], ['all', 'ADV', 5, 'advmod', 4], ['around', 'ADP', 0, 'prep', 5], ['texas', 'NOUN', 5, 'pobj', 6], ['especially', 'ADV', 8, 'advmod', 7], ['most', 'ADJ', 0, 'advmod', 8], ['of', 'ADP', 8, 'prep', 9], ['my', 'ADJ', 11, 'poss', 10], ['family', 'NOUN', 9, 'pobj', 11], ['that', 'ADJ', 13, 'nsubj', 12], ['resides', 'VERB', 8, 'relcl', 13], ['in', 'ADP', 13, 'prep', 14], ['houston', 'NOUN', 14, 'pobj', 15], ['.', 'PUNCT', 0, 'punct', 16]], [['stay', 'VERB', 0, 'ROOT', 0], ['safe', 'ADJ', 0, 'acomp', 1], ['!', 'PUNCT', 0, 'punct', 2]], [['#prayfortexas', 'PROPN', 1, 'compound', 0], ['#hurricaneharvey', 'X', 1, 'ROOT', 1]]]\n",
      "candidate 0=houston\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE houston, txt:My hometown Houston be safe people texting me i'm chill i'm in Dallas we should be gucci #HurricaneHarvey\n",
      "full parse [[['My', 'ADJ', 1, 'poss', 0], ['hometown', 'NOUN', 3, 'nsubj', 1], ['Houston', 'PROPN', 1, 'appos', 2], ['be', 'VERB', 3, 'ROOT', 3], ['safe', 'ADJ', 5, 'amod', 4], ['people', 'NOUN', 3, 'attr', 5], ['texting', 'VERB', 5, 'acl', 6], ['me', 'PRON', 10, 'nmod', 7], [\"i'm\", 'ADV', 10, 'compound', 8], ['chill', 'VERB', 10, 'compound', 9], [\"i'm\", 'PROPN', 6, 'dobj', 10], ['in', 'ADP', 10, 'prep', 11], ['Dallas', 'PROPN', 11, 'pobj', 12], ['we', 'PRON', 15, 'nsubj', 13], ['should', 'VERB', 15, 'aux', 14], ['be', 'VERB', 3, 'conj', 15], ['gucci', 'PROPN', 17, 'compound', 16], ['#HurricaneHarvey', 'PUNCT', 15, 'attr', 17]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Dallas\n",
      "data NE tree=[['Houston', 'PROPN', 1, 'appos', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Houston', 'PROPN', 1, 'appos', 2]\n",
      "NE parent token:\n",
      "['hometown', 'NOUN', 3, 'nsubj', 1]\n",
      "parent node subtree [['My', 'ADJ', 1, 'poss', 0], ['hometown', 'NOUN', 3, 'nsubj', 1], ['Houston', 'PROPN', 1, 'appos', 2]]\n",
      "parent node subtree str my hometown houston\n",
      "candidate 1=Dallas\n",
      "anchor NE candidates = \n",
      "testing NE rockport, txt:CBS NEWS: Reports that portions of high school in Rockport, Texas, where #HurricaneHarvey made landfall, have collapsed <URL>\n",
      "full parse [[['CBS', 'PROPN', 1, 'compound', 0], ['NEWS', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['Reports', 'NOUN', 3, 'ROOT', 3], ['that', 'ADP', 17, 'mark', 4], ['portions', 'NOUN', 17, 'nsubj', 5], ['of', 'ADP', 5, 'prep', 6], ['high', 'ADJ', 8, 'amod', 7], ['school', 'NOUN', 6, 'pobj', 8], ['in', 'ADP', 8, 'prep', 9], ['Rockport', 'PROPN', 11, 'compound', 10], ['Texas', 'PROPN', 9, 'pobj', 11], ['where', 'ADV', 14, 'advmod', 12], ['#HurricaneHarvey', 'PROPN', 14, 'nsubj', 13], ['made', 'VERB', 5, 'relcl', 14], ['landfall', 'NOUN', 14, 'dobj', 15], ['have', 'VERB', 17, 'aux', 16], ['collapsed', 'VERB', 3, 'acl', 17]]]\n",
      "candidate 0=Rockport\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Rockport', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Rockport', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Rockport', 'PROPN', 11, 'compound', 10], ['Texas', 'PROPN', 9, 'pobj', 11]]\n",
      "parent node subtree str rockport texas\n",
      "false positive: NE=rockport, type=compound\n",
      "testing NE corpus_christi, txt:Hurricane #Harvey Makes Landfall Near Corpus Christi, Texas but the danger is not over <URL>\n",
      "full parse [[['Hurricane', 'PROPN', 1, 'compound', 0], ['#Harvey', 'PROPN', 2, 'nsubj', 1], ['Makes', 'VERB', 2, 'ROOT', 2], ['Landfall', 'PROPN', 2, 'dobj', 3], ['Near', 'PROPN', 3, 'prep', 4], ['Corpus', 'PROPN', 6, 'compound', 5], ['Christi', 'PROPN', 4, 'pobj', 6], ['Texas', 'PROPN', 6, 'appos', 7], ['but', 'CCONJ', 2, 'cc', 8], ['the', 'DET', 10, 'det', 9], ['danger', 'NOUN', 11, 'nsubj', 10], ['is', 'VERB', 2, 'conj', 11], ['not', 'ADV', 11, 'neg', 12], ['over', 'ADV', 11, 'advmod', 13]]]\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Corpus', 'PROPN', 6, 'compound', 5], ['Christi', 'PROPN', 4, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Christi', 'PROPN', 4, 'pobj', 6]\n",
      "NE parent token:\n",
      "['Near', 'PROPN', 3, 'prep', 4]\n",
      "NE=Corpus Christi subtree=[['Texas', 'PROPN', 6, 'appos', 7]]\n",
      "min node deps ['appos']\n",
      "subtree = Texas\n",
      "false positive: NE=corpus_christi, type=descriptor\n",
      "testing NE san_marcos, txt:Rain and lots wind in San Marcos,Tx. Checked in with my parentals and everyone is ok with a little damage. Thanks #HurricaneHarvey\n",
      "full parse [[['Rain', 'NOUN', 3, 'nmod', 0], ['and', 'CCONJ', 0, 'cc', 1], ['lots', 'NOUN', 0, 'conj', 2], ['wind', 'NOUN', 3, 'ROOT', 3], ['in', 'ADP', 3, 'prep', 4], ['San', 'PROPN', 6, 'compound', 5], ['MarcosTx', 'PROPN', 4, 'pobj', 6], ['.', 'PUNCT', 3, 'punct', 7]], [['Checked', 'VERB', 0, 'ROOT', 0], ['in', 'PART', 0, 'prt', 1], ['with', 'ADP', 0, 'prep', 2], ['my', 'ADJ', 4, 'poss', 3], ['parentals', 'NOUN', 2, 'pobj', 4], ['and', 'CCONJ', 0, 'cc', 5], ['everyone', 'NOUN', 7, 'nsubj', 6], ['is', 'VERB', 0, 'conj', 7], ['ok', 'ADJ', 7, 'acomp', 8], ['with', 'ADP', 7, 'prep', 9], ['a', 'DET', 12, 'det', 10], ['little', 'ADJ', 12, 'amod', 11], ['damage', 'NOUN', 9, 'pobj', 12], ['.', 'PUNCT', 7, 'punct', 13]], [['Thanks', 'NOUN', 1, 'compound', 0], ['#HurricaneHarvey', 'PUNCT', 1, 'ROOT', 1]]]\n",
      "candidate 0=San Marcos\n",
      "anchor NE candidates = Tx\n",
      "testing NE corpus_christi, txt:The tale of Hurricane #Harvey from two Texas cities: Corpus Christi's peak wind gust was 63 mph while Rockport's... <URL>\n",
      "full parse [[['The', 'DET', 1, 'det', 0], ['tale', 'NOUN', 1, 'ROOT', 1], ['of', 'ADP', 1, 'prep', 2], ['Hurricane', 'PROPN', 4, 'compound', 3], ['#Harvey', 'PROPN', 2, 'pobj', 4], ['from', 'ADP', 1, 'prep', 5], ['two', 'NUM', 8, 'nummod', 6], ['Texas', 'PROPN', 8, 'compound', 7], ['cities', 'NOUN', 5, 'pobj', 8], [':', 'PUNCT', 1, 'punct', 9], ['Corpus', 'PROPN', 11, 'compound', 10], [\"Christi's\", 'PROPN', 13, 'compound', 11], ['peak', 'ADJ', 13, 'compound', 12], ['wind', 'NOUN', 15, 'nsubj', 13], ['gust', 'NOUN', 15, 'nsubj', 14], ['was', 'VERB', 15, 'ROOT', 15], ['63', 'NUM', 17, 'nummod', 16], ['mph', 'NOUN', 15, 'attr', 17], ['while', 'ADP', 19, 'mark', 18], [\"Rockport's\", 'PROPN', 15, 'advcl', 19], ['...', 'PUNCT', 15, 'punct', 20]]]\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "candidate 1=Rockport\n",
      "anchor NE candidates = Texas\n",
      "testing NE sienna_plantation, txt:Tornado damage in Sienna Plantation S of Houston and Katy W of Houston #HurricaneHarvey #Harvey2017 Flooding Mayde Creek - Katy W of Houston\n",
      "full parse [[['Tornado', 'NOUN', 1, 'compound', 0], ['damage', 'NOUN', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['Sienna', 'PROPN', 4, 'compound', 3], ['Plantation', 'PROPN', 5, 'compound', 4], ['S', 'PROPN', 2, 'pobj', 5], ['of', 'ADP', 5, 'prep', 6], ['Houston', 'PROPN', 6, 'pobj', 7], ['and', 'CCONJ', 5, 'cc', 8], ['Katy', 'PROPN', 10, 'compound', 9], ['W', 'PROPN', 5, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Houston', 'PROPN', 13, 'compound', 12], ['#HurricaneHarvey', 'PROPN', 14, 'compound', 13], ['#Harvey2017', 'PUNCT', 11, 'pobj', 14], ['Flooding', 'PROPN', 16, 'compound', 15], ['Mayde', 'PROPN', 19, 'compound', 16], ['Creek', 'PROPN', 19, 'compound', 17], ['Katy', 'PROPN', 19, 'compound', 18], ['W', 'PROPN', 19, 'ROOT', 19], ['of', 'ADP', 19, 'prep', 20], ['Houston', 'PROPN', 20, 'pobj', 21]]]\n",
      "candidate 0=Sienna Plantation\n",
      "anchor NE candidates = Houston,Houston,Houston\n",
      "data NE tree=[['Sienna', 'PROPN', 4, 'compound', 3], ['Plantation', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Plantation', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['S', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Sienna', 'PROPN', 4, 'compound', 3], ['Plantation', 'PROPN', 5, 'compound', 4], ['S', 'PROPN', 2, 'pobj', 5], ['of', 'ADP', 5, 'prep', 6], ['Houston', 'PROPN', 6, 'pobj', 7], ['and', 'CCONJ', 5, 'cc', 8], ['Katy', 'PROPN', 10, 'compound', 9], ['W', 'PROPN', 5, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Houston', 'PROPN', 13, 'compound', 12], ['#HurricaneHarvey', 'PROPN', 14, 'compound', 13], ['#Harvey2017', 'PUNCT', 11, 'pobj', 14]]\n",
      "parent node subtree str sienna plantation s of houston and katy w of houston #hurricaneharvey #harvey2017\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "candidate 2=Houston\n",
      "anchor NE candidates = \n",
      "candidate 3=Houston\n",
      "anchor NE candidates = \n",
      "testing NE austin, txt:I'm at a shelter in Austin, TX, where @govabbott is meeting with evacuated Texans. #harvey #txlege <URL>\n",
      "full parse [[[\"I'm\", 'NUM', 0, 'ROOT', 0], ['at', 'ADP', 0, 'prep', 1], ['a', 'DET', 3, 'det', 2], ['shelter', 'NOUN', 1, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['Austin', 'PROPN', 6, 'compound', 5], ['TX', 'PROPN', 4, 'pobj', 6], ['where', 'ADV', 10, 'advmod', 7], ['@govabbott', 'PROPN', 10, 'nsubj', 8], ['is', 'VERB', 10, 'aux', 9], ['meeting', 'VERB', 6, 'relcl', 10], ['with', 'ADP', 10, 'prep', 11], ['evacuated', 'VERB', 13, 'amod', 12], ['Texans', 'PROPN', 11, 'pobj', 13], ['.', 'PUNCT', 0, 'punct', 14]], [['#harvey', 'PROPN', 1, 'compound', 0], ['#txlege', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Austin\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Austin', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Austin', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 4, 'pobj', 6]\n",
      "parent node subtree [['Austin', 'PROPN', 6, 'compound', 5], ['TX', 'PROPN', 4, 'pobj', 6], ['where', 'ADV', 10, 'advmod', 7], ['@govabbott', 'PROPN', 10, 'nsubj', 8], ['is', 'VERB', 10, 'aux', 9], ['meeting', 'VERB', 6, 'relcl', 10], ['with', 'ADP', 10, 'prep', 11], ['evacuated', 'VERB', 13, 'amod', 12], ['Texans', 'PROPN', 11, 'pobj', 13]]\n",
      "parent node subtree str austin tx where @govabbott is meeting with evacuated texans\n",
      "false positive: NE=austin, type=compound\n",
      "testing NE wharton, txt:Convoy of wildlife agents from Louisiana towing boats leave gas station in Wharton and head toward Houston #harvey <URL>\n",
      "full parse [[['Convoy', 'NOUN', 3, 'nmod', 0], ['of', 'ADP', 0, 'prep', 1], ['wildlife', 'NOUN', 1, 'pobj', 2], ['agents', 'NOUN', 8, 'nsubj', 3], ['from', 'ADP', 3, 'prep', 4], ['Louisiana', 'PROPN', 4, 'pobj', 5], ['towing', 'NOUN', 7, 'amod', 6], ['boats', 'NOUN', 8, 'nsubj', 7], ['leave', 'VERB', 8, 'ROOT', 8], ['gas', 'NOUN', 10, 'compound', 9], ['station', 'NOUN', 8, 'dobj', 10], ['in', 'ADP', 8, 'prep', 11], ['Wharton', 'PROPN', 11, 'pobj', 12], ['and', 'CCONJ', 8, 'cc', 13], ['head', 'NOUN', 8, 'conj', 14], ['toward', 'ADP', 14, 'prep', 15], ['Houston', 'PROPN', 17, 'compound', 16], ['#harvey', 'PROPN', 15, 'pobj', 17]]]\n",
      "candidate 0=Wharton\n",
      "anchor NE candidates = \n",
      "candidate 1=Houston\n",
      "anchor NE candidates = Louisiana,Houston\n",
      "data NE tree=[['Houston', 'PROPN', 17, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Houston', 'PROPN', 17, 'compound', 16]\n",
      "NE parent token:\n",
      "['#harvey', 'PROPN', 15, 'pobj', 17]\n",
      "parent node subtree [['Houston', 'PROPN', 17, 'compound', 16], ['#harvey', 'PROPN', 15, 'pobj', 17]]\n",
      "parent node subtree str houston #harvey\n",
      "testing NE sharpstown, txt:ALL of my District is under siege-Brays Oaks, Med Center, Meyerland, Sharpstown, Southpark, Sunnyside, 3rd Ward, & Westbury. #Harvey #Flood <URL>\n",
      "full parse [[['ALL', 'DET', 4, 'nsubj', 0], ['of', 'ADP', 0, 'prep', 1], ['my', 'ADJ', 3, 'poss', 2], ['District', 'PROPN', 1, 'pobj', 3], ['is', 'VERB', 4, 'ROOT', 4], ['under', 'ADP', 4, 'prep', 5], ['siegeBrays', 'NOUN', 9, 'compound', 6], ['Oaks', 'PROPN', 9, 'compound', 7], ['Med', 'PROPN', 9, 'compound', 8], ['Center', 'PROPN', 15, 'compound', 9], ['Meyerland', 'PROPN', 11, 'compound', 10], ['Sharpstown', 'PROPN', 15, 'compound', 11], ['Southpark', 'PROPN', 15, 'compound', 12], ['Sunnyside', 'PROPN', 15, 'compound', 13], ['3rd', 'PROPN', 15, 'compound', 14], ['Ward', 'PROPN', 5, 'pobj', 15], ['&', 'CCONJ', 15, 'cc', 16], ['Westbury', 'PROPN', 15, 'conj', 17], ['.', 'PUNCT', 4, 'punct', 18]], [['#Harvey', 'PROPN', 1, 'compound', 0], ['#Flood', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Sharpstown\n",
      "anchor NE candidates = Westbury\n",
      "data NE tree=[['Sharpstown', 'PROPN', 15, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Sharpstown', 'PROPN', 15, 'compound', 11]\n",
      "NE parent token:\n",
      "['Ward', 'PROPN', 5, 'pobj', 15]\n",
      "parent node subtree [['siegeBrays', 'NOUN', 9, 'compound', 6], ['Oaks', 'PROPN', 9, 'compound', 7], ['Med', 'PROPN', 9, 'compound', 8], ['Center', 'PROPN', 15, 'compound', 9], ['Meyerland', 'PROPN', 11, 'compound', 10], ['Sharpstown', 'PROPN', 15, 'compound', 11], ['Southpark', 'PROPN', 15, 'compound', 12], ['Sunnyside', 'PROPN', 15, 'compound', 13], ['3rd', 'PROPN', 15, 'compound', 14], ['Ward', 'PROPN', 5, 'pobj', 15], ['&', 'CCONJ', 15, 'cc', 16], ['Westbury', 'PROPN', 15, 'conj', 17]]\n",
      "parent node subtree str siegebrays oaks med center meyerland sharpstown southpark sunnyside 3rd ward & westbury\n",
      "NE=Sharpstown subtree=[['Meyerland', 'PROPN', 11, 'compound', 10]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Southpark\n",
      "anchor NE candidates = Westbury\n",
      "data NE tree=[['Southpark', 'PROPN', 15, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Southpark', 'PROPN', 15, 'compound', 12]\n",
      "NE parent token:\n",
      "['Ward', 'PROPN', 5, 'pobj', 15]\n",
      "parent node subtree [['siegeBrays', 'NOUN', 9, 'compound', 6], ['Oaks', 'PROPN', 9, 'compound', 7], ['Med', 'PROPN', 9, 'compound', 8], ['Center', 'PROPN', 15, 'compound', 9], ['Meyerland', 'PROPN', 11, 'compound', 10], ['Sharpstown', 'PROPN', 15, 'compound', 11], ['Southpark', 'PROPN', 15, 'compound', 12], ['Sunnyside', 'PROPN', 15, 'compound', 13], ['3rd', 'PROPN', 15, 'compound', 14], ['Ward', 'PROPN', 5, 'pobj', 15], ['&', 'CCONJ', 15, 'cc', 16], ['Westbury', 'PROPN', 15, 'conj', 17]]\n",
      "parent node subtree str siegebrays oaks med center meyerland sharpstown southpark sunnyside 3rd ward & westbury\n",
      "candidate 2=Westbury\n",
      "anchor NE candidates = \n",
      "testing NE san_antonio, txt:Wolff said patients from Ben Taub in Houston might be transported to San Antonio area hospitals. Not confirmed yet. #Harvey\n",
      "full parse [[['Wolff', 'PROPN', 1, 'nsubj', 0], ['said', 'VERB', 1, 'ROOT', 1], ['patients', 'NOUN', 10, 'nsubjpass', 2], ['from', 'ADP', 2, 'prep', 3], ['Ben', 'PROPN', 5, 'compound', 4], ['Taub', 'PROPN', 3, 'pobj', 5], ['in', 'ADP', 5, 'prep', 6], ['Houston', 'PROPN', 6, 'pobj', 7], ['might', 'VERB', 10, 'aux', 8], ['be', 'VERB', 10, 'auxpass', 9], ['transported', 'VERB', 1, 'ccomp', 10], ['to', 'ADP', 10, 'prep', 11], ['San', 'PROPN', 13, 'compound', 12], ['Antonio', 'PROPN', 15, 'compound', 13], ['area', 'NOUN', 15, 'compound', 14], ['hospitals', 'NOUN', 11, 'pobj', 15], ['.', 'PUNCT', 1, 'punct', 16]], [['Not', 'ADV', 1, 'neg', 0], ['confirmed', 'VERB', 1, 'ROOT', 1], ['yet', 'ADV', 1, 'advmod', 2], ['.', 'PUNCT', 1, 'punct', 3]], [['#Harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Houston,San Antonio\n",
      "data NE tree=[['Houston', 'PROPN', 6, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Houston', 'PROPN', 6, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 5, 'prep', 6]\n",
      "candidate 1=San Antonio\n",
      "anchor NE candidates = \n",
      "testing NE plano, txt:Plano efforts w/ #HurricaneHarvey (1/2) - Plano Fire-Rescue: 2 members deployed w/ TX Task Force One & 3 (incl K-9) w/ TX Task Force Two. <URL>\n",
      "full parse [[['Plano', 'PROPN', 1, 'compound', 0], ['efforts', 'NOUN', 1, 'ROOT', 1], ['w', 'ADP', 4, 'nmod', 2], ['/', 'SYM', 4, 'punct', 3], ['#HurricaneHarvey', 'PROPN', 4, 'ROOT', 4], ['(', 'PUNCT', 6, 'punct', 5], ['1/2', 'NUM', 4, 'appos', 6], [')', 'PUNCT', 4, 'punct', 7], ['Plano', 'PROPN', 9, 'compound', 8], ['FireRescue', 'PROPN', 9, 'ROOT', 9], [':', 'PUNCT', 9, 'punct', 10], ['2', 'NUM', 12, 'nummod', 11], ['members', 'NOUN', 9, 'appos', 12], ['deployed', 'VERB', 12, 'acl', 13], ['w', 'ADP', 19, 'nmod', 14], ['/', 'SYM', 14, 'punct', 15], ['TX', 'PROPN', 18, 'compound', 16], ['Task', 'PROPN', 18, 'compound', 17], ['Force', 'PROPN', 19, 'compound', 18], ['One', 'PROPN', 13, 'dobj', 19], ['&', 'CCONJ', 19, 'cc', 20], ['3', 'NUM', 19, 'conj', 21], ['(', 'PUNCT', 24, 'punct', 22], ['incl', 'PROPN', 24, 'compound', 23], ['K9', 'PROPN', 19, 'conj', 24], [')', 'PUNCT', 24, 'punct', 25], ['w', 'ADP', 13, 'prep', 26], ['/', 'SYM', 26, 'punct', 27], ['TX', 'PROPN', 30, 'compound', 28], ['Task', 'PROPN', 30, 'compound', 29], ['Force', 'PROPN', 31, 'compound', 30], ['Two', 'PROPN', 26, 'pobj', 31], ['.', 'PUNCT', 9, 'punct', 32]]]\n",
      "candidate 0=Plano\n",
      "anchor NE candidates = TX,TX\n",
      "data NE tree=[['Plano', 'PROPN', 1, 'compound', 0]]\n",
      "NE parse token at tree=0, token=1:\n",
      "['Plano', 'PROPN', 1, 'compound', 0]\n",
      "NE parent token:\n",
      "['efforts', 'NOUN', 1, 'ROOT', 1]\n",
      "parent node subtree [['Plano', 'PROPN', 1, 'compound', 0], ['efforts', 'NOUN', 1, 'ROOT', 1]]\n",
      "parent node subtree str plano efforts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE dayton, txt:The latest rainfall totals (since Thurs) compiled by @NWSWPC are INSANE! 39.2 inches (so far) in Dayton, TX. 30+ in south Houston. #harvey <URL>\n",
      "full parse [[['The', 'DET', 3, 'det', 0], ['latest', 'ADJ', 3, 'amod', 1], ['rainfall', 'NOUN', 3, 'compound', 2], ['totals', 'NOUN', 11, 'nsubj', 3], ['(', 'PUNCT', 3, 'punct', 4], ['since', 'ADP', 3, 'prep', 5], ['Thurs', 'PROPN', 5, 'pobj', 6], [')', 'PUNCT', 3, 'punct', 7], ['compiled', 'VERB', 3, 'acl', 8], ['by', 'ADP', 8, 'agent', 9], ['@NWSWPC', 'PROPN', 9, 'pobj', 10], ['are', 'VERB', 11, 'ROOT', 11], ['INSANE', 'ADJ', 11, 'acomp', 12], ['!', 'PUNCT', 11, 'punct', 13]], [['39.2', 'NUM', 1, 'nummod', 0], ['inches', 'NOUN', 4, 'npadvmod', 1], ['(', 'PUNCT', 4, 'punct', 2], ['so', 'ADV', 4, 'advmod', 3], ['far', 'ADV', 4, 'ROOT', 4], [')', 'PUNCT', 4, 'punct', 5], ['in', 'ADP', 4, 'prep', 6], ['Dayton', 'PROPN', 8, 'compound', 7], ['TX', 'PROPN', 6, 'pobj', 8], ['.', 'PUNCT', 4, 'punct', 9]], [['30', 'NUM', 0, 'ROOT', 0], ['+', 'SYM', 0, 'cc', 1], ['in', 'ADP', 0, 'conj', 2], ['south', 'ADJ', 4, 'amod', 3], ['Houston', 'PROPN', 2, 'pobj', 4], ['.', 'PUNCT', 0, 'punct', 5]], [['#harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Dayton\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Dayton', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Dayton', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Dayton', 'PROPN', 8, 'compound', 7], ['TX', 'PROPN', 6, 'pobj', 8]]\n",
      "parent node subtree str dayton tx\n",
      "candidate 1=south Houston\n",
      "anchor NE candidates = \n",
      "false positive: NE=dayton, type=compound\n",
      "testing NE lindale, txt:CONTACT?!!!!!!!!!!!!! 2 KAYAKS 4 #HELP inner LOOP: LINDALE, IRVINGTON, CAVALCADE area and BEYOND! #HurricaneHarvey #Houston <URL>\n",
      "full parse [[['CONTACT', 'VERB', 0, 'ROOT', 0], ['?', 'PUNCT', 0, 'punct', 1], ['!', 'PUNCT', 0, 'punct', 2], ['!', 'PUNCT', 0, 'punct', 3], ['!', 'PUNCT', 0, 'punct', 4]], [['2', 'PUNCT', 5, 'nummod', 0], ['KAYAKS', 'NOUN', 3, 'nmod', 1], ['4', 'NUM', 1, 'nummod', 2], ['#HELP', 'PROPN', 5, 'nmod', 3], ['inner', 'ADJ', 5, 'amod', 4], ['LOOP', 'NOUN', 5, 'ROOT', 5], [':', 'PUNCT', 5, 'punct', 6], ['LINDALE', 'PROPN', 10, 'compound', 7], ['IRVINGTON', 'PROPN', 9, 'compound', 8], ['CAVALCADE', 'NOUN', 10, 'compound', 9], ['area', 'NOUN', 10, 'ROOT', 10], ['and', 'CCONJ', 10, 'cc', 11], ['BEYOND', 'ADV', 10, 'conj', 12], ['!', 'PUNCT', 10, 'punct', 13]], [['#HurricaneHarvey', 'PUNCT', 1, 'compound', 0], ['#Houston', 'X', 1, 'ROOT', 1]]]\n",
      "candidate 0=LINDALE\n",
      "anchor NE candidates = IRVINGTON\n",
      "data NE tree=[['LINDALE', 'PROPN', 10, 'compound', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['LINDALE', 'PROPN', 10, 'compound', 7]\n",
      "NE parent token:\n",
      "['area', 'NOUN', 10, 'ROOT', 10]\n",
      "parent node subtree [['LINDALE', 'PROPN', 10, 'compound', 7], ['IRVINGTON', 'PROPN', 9, 'compound', 8], ['CAVALCADE', 'NOUN', 10, 'compound', 9], ['area', 'NOUN', 10, 'ROOT', 10], ['and', 'CCONJ', 10, 'cc', 11], ['BEYOND', 'ADV', 10, 'conj', 12], ['!', 'PUNCT', 10, 'punct', 13]]\n",
      "parent node subtree str lindale irvington cavalcade area and beyond !\n",
      "testing NE houston, txt:From New York to Houston- our thoughts are with the safety and well-being of everyone in Texas. #HoustonStong #HurricaneHarvey <URL>\n",
      "full parse [[['From', 'ADP', 7, 'prep', 0], ['New', 'PROPN', 2, 'compound', 1], ['York', 'PROPN', 0, 'pobj', 2], ['to', 'ADP', 0, 'prep', 3], ['Houston', 'PROPN', 3, 'pobj', 4], ['our', 'ADJ', 6, 'poss', 5], ['thoughts', 'NOUN', 7, 'nsubj', 6], ['are', 'VERB', 7, 'ROOT', 7], ['with', 'ADP', 7, 'prep', 8], ['the', 'DET', 10, 'det', 9], ['safety', 'NOUN', 8, 'pobj', 10], ['and', 'CCONJ', 10, 'cc', 11], ['wellbeing', 'NOUN', 10, 'conj', 12], ['of', 'ADP', 10, 'prep', 13], ['everyone', 'NOUN', 13, 'pobj', 14], ['in', 'ADP', 14, 'prep', 15], ['Texas', 'PROPN', 15, 'pobj', 16], ['.', 'PUNCT', 7, 'punct', 17]], [['#HoustonStong', 'ADP', 1, 'compound', 0], ['#HurricaneHarvey', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Houston', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Houston', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 3]\n",
      "testing NE houston, txt:@realDonaldTrump You bypassed Houston? If NYC had a 1,000-year flood wd you visit Albany & Rochester, bypass NYC? #Harvey #HurricaneHarvey\n",
      "full parse [[['@realDonaldTrump', 'PROPN', 0, 'ROOT', 0], ['You', 'PRON', 2, 'nsubj', 1], ['bypassed', 'VERB', 2, 'ROOT', 2], ['Houston', 'PROPN', 2, 'dobj', 3], ['?', 'PUNCT', 2, 'punct', 4]], [['If', 'ADP', 2, 'mark', 0], ['NYC', 'PROPN', 2, 'nsubj', 1], ['had', 'VERB', 8, 'advcl', 2], ['a', 'DET', 6, 'det', 3], ['1000year', 'NUM', 6, 'nummod', 4], ['flood', 'NOUN', 6, 'compound', 5], ['wd', 'NOUN', 2, 'dobj', 6], ['you', 'PRON', 8, 'nsubj', 7], ['visit', 'VERB', 8, 'ROOT', 8], ['Albany', 'PROPN', 8, 'dobj', 9], ['&', 'CCONJ', 9, 'cc', 10], ['Rochester', 'PROPN', 9, 'conj', 11], ['bypass', 'NOUN', 13, 'compound', 12], ['NYC', 'PROPN', 9, 'conj', 13], ['?', 'PUNCT', 8, 'punct', 14]], [['#Harvey', 'PROPN', 1, 'compound', 0], ['#HurricaneHarvey', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Albany\n",
      "data NE tree=[['Houston', 'PROPN', 2, 'dobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Houston', 'PROPN', 2, 'dobj', 3]\n",
      "NE parent token:\n",
      "['bypassed', 'VERB', 2, 'ROOT', 2]\n",
      "candidate 1=Rochester\n",
      "anchor NE candidates = \n",
      "testing NE round_top, txt:Teague's Tavern in Round Top is offering 10 percent of their sales to flood relief efforts in La Grange and Houston. Check them out! #Harvey\n",
      "full parse [[[\"Teague's\", 'PROPN', 1, 'compound', 0], ['Tavern', 'ADJ', 6, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['Round', 'PROPN', 4, 'compound', 3], ['Top', 'PROPN', 2, 'pobj', 4], ['is', 'VERB', 6, 'aux', 5], ['offering', 'VERB', 6, 'ROOT', 6], ['10', 'NUM', 8, 'nummod', 7], ['percent', 'NOUN', 6, 'dobj', 8], ['of', 'ADP', 8, 'prep', 9], ['their', 'ADJ', 11, 'poss', 10], ['sales', 'NOUN', 9, 'pobj', 11], ['to', 'PART', 13, 'aux', 12], ['flood', 'VERB', 6, 'xcomp', 13], ['relief', 'NOUN', 15, 'compound', 14], ['efforts', 'NOUN', 13, 'dobj', 15], ['in', 'ADP', 15, 'prep', 16], ['La', 'PROPN', 18, 'compound', 17], ['Grange', 'PROPN', 16, 'pobj', 18], ['and', 'CCONJ', 18, 'cc', 19], ['Houston', 'PROPN', 18, 'conj', 20], ['.', 'PUNCT', 6, 'punct', 21]], [['Check', 'VERB', 0, 'ROOT', 0], ['them', 'PRON', 0, 'dobj', 1], ['out', 'PART', 0, 'prt', 2], ['!', 'PUNCT', 0, 'punct', 3]], [['#Harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Round Top\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Round', 'PROPN', 4, 'compound', 3], ['Top', 'PROPN', 2, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Top', 'PROPN', 2, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "testing NE harris_county, txt:NOAA: rainfall total from #Harvey for Cedar Bayou in Harris County, Texas, is at 51.88”, a contiguous US record for any tropical system.\n",
      "full parse [[['NOAA', 'PROPN', 13, 'nsubj', 0], [':', 'PUNCT', 0, 'punct', 1], ['rainfall', 'NOUN', 0, 'acl', 2], ['total', 'NOUN', 2, 'dobj', 3], ['from', 'ADP', 3, 'prep', 4], ['#Harvey', 'PROPN', 4, 'pobj', 5], ['for', 'ADP', 3, 'prep', 6], ['Cedar', 'PROPN', 8, 'compound', 7], ['Bayou', 'PROPN', 6, 'pobj', 8], ['in', 'ADP', 8, 'prep', 9], ['Harris', 'PROPN', 11, 'compound', 10], ['County', 'PROPN', 12, 'compound', 11], ['Texas', 'PROPN', 9, 'pobj', 12], ['is', 'VERB', 13, 'ROOT', 13], ['at', 'ADP', 13, 'prep', 14], ['51.88', 'NUM', 16, 'nummod', 15], ['”', 'NOUN', 14, 'pobj', 16], ['a', 'DET', 20, 'det', 17], ['contiguous', 'ADJ', 20, 'amod', 18], ['US', 'PROPN', 20, 'compound', 19], ['record', 'NOUN', 13, 'attr', 20], ['for', 'ADP', 20, 'prep', 21], ['any', 'DET', 24, 'det', 22], ['tropical', 'ADJ', 24, 'amod', 23], ['system', 'NOUN', 21, 'pobj', 24], ['.', 'PUNCT', 13, 'punct', 25]]]\n",
      "candidate 0=Harris County\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Harris', 'PROPN', 11, 'compound', 10], ['County', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['County', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['Texas', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Harris', 'PROPN', 11, 'compound', 10], ['County', 'PROPN', 12, 'compound', 11], ['Texas', 'PROPN', 9, 'pobj', 12]]\n",
      "parent node subtree str harris county texas\n",
      "false positive: NE=harris_county, type=compound\n",
      "testing NE corpus_christi, txt:President Trump and First Lady Melania at Annaville Fire Rescue | Corpus Christi, TX #HurricaneHarvey <URL>\n",
      "full parse [[['President', 'PROPN', 1, 'compound', 0], ['Trump', 'PROPN', 1, 'ROOT', 1], ['and', 'CCONJ', 1, 'cc', 2], ['First', 'PROPN', 5, 'compound', 3], ['Lady', 'PROPN', 5, 'compound', 4], ['Melania', 'PROPN', 1, 'conj', 5], ['at', 'ADP', 5, 'prep', 6], ['Annaville', 'PROPN', 9, 'compound', 7], ['Fire', 'PROPN', 9, 'nmod', 8], ['Rescue', 'PROPN', 6, 'pobj', 9], ['|', 'PROPN', 14, 'punct', 10], ['Corpus', 'PROPN', 12, 'compound', 11], ['Christi', 'PROPN', 14, 'compound', 12], ['TX', 'PROPN', 14, 'compound', 13], ['#HurricaneHarvey', 'PROPN', 9, 'appos', 14]]]\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Corpus', 'PROPN', 12, 'compound', 11], ['Christi', 'PROPN', 14, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Christi', 'PROPN', 14, 'compound', 12]\n",
      "NE parent token:\n",
      "['#HurricaneHarvey', 'PROPN', 9, 'appos', 14]\n",
      "parent node subtree [['|', 'PROPN', 14, 'punct', 10], ['Corpus', 'PROPN', 12, 'compound', 11], ['Christi', 'PROPN', 14, 'compound', 12], ['TX', 'PROPN', 14, 'compound', 13], ['#HurricaneHarvey', 'PROPN', 9, 'appos', 14]]\n",
      "parent node subtree str | corpus christi tx #hurricaneharvey\n",
      "false positive: NE=corpus_christi, type=compound\n",
      "testing NE port_arthur, txt:1927 Freeman Ave. 77642 Port Arthur, Tx elderly lady and her granddaughter stuck #HurricaneHarvey #portarthur\n",
      "full parse [[['1927', 'NUM', 2, 'nummod', 0], ['Freeman', 'PROPN', 2, 'compound', 1], ['Ave', 'PROPN', 2, 'ROOT', 2], ['.', 'PUNCT', 2, 'punct', 3], ['77642', 'NUM', 4, 'ROOT', 4], ['Port', 'PROPN', 7, 'nmod', 5], ['Arthur', 'PROPN', 7, 'nmod', 6], ['Tx', 'PROPN', 9, 'nmod', 7], ['elderly', 'ADJ', 9, 'amod', 8], ['lady', 'NOUN', 13, 'nsubj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['her', 'ADJ', 12, 'poss', 11], ['granddaughter', 'NOUN', 9, 'conj', 12], ['stuck', 'VERB', 13, 'ROOT', 13], ['#HurricaneHarvey', 'PROPN', 15, 'compound', 14], ['#portarthur', 'X', 13, 'dobj', 15]]]\n",
      "candidate 0=Port Arthur\n",
      "anchor NE candidates = Tx\n",
      "data NE tree=[['Port', 'PROPN', 7, 'nmod', 5], ['Arthur', 'PROPN', 7, 'nmod', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Arthur', 'PROPN', 7, 'nmod', 6]\n",
      "NE parent token:\n",
      "['Tx', 'PROPN', 9, 'nmod', 7]\n",
      "parent node subtree [['Port', 'PROPN', 7, 'nmod', 5], ['Arthur', 'PROPN', 7, 'nmod', 6], ['Tx', 'PROPN', 9, 'nmod', 7]]\n",
      "parent node subtree str port arthur tx\n",
      "false positive: NE=port_arthur, type=compound\n",
      "testing NE austin, txt:Has anyone in Houston been successful driving to Austin or are roads still under? #Houston #Harvey\n",
      "full parse [[['Has', 'VERB', 4, 'aux', 0], ['anyone', 'NOUN', 4, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['Houston', 'PROPN', 2, 'pobj', 3], ['been', 'VERB', 4, 'ROOT', 4], ['successful', 'ADJ', 6, 'amod', 5], ['driving', 'NOUN', 4, 'attr', 6], ['to', 'ADP', 6, 'prep', 7], ['Austin', 'PROPN', 7, 'pobj', 8], ['or', 'CCONJ', 4, 'cc', 9], ['are', 'VERB', 4, 'conj', 10], ['roads', 'NOUN', 10, 'attr', 11], ['still', 'ADV', 13, 'advmod', 12], ['under', 'ADP', 10, 'advmod', 13], ['?', 'PUNCT', 4, 'punct', 14]], [['#Houston', 'X', 1, 'compound', 0], ['#Harvey', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Austin\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Austin', 'PROPN', 7, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Austin', 'PROPN', 7, 'pobj', 8]\n",
      "NE parent token:\n",
      "['to', 'ADP', 6, 'prep', 7]\n",
      "testing NE united, txt:#HurricaneHarvey #MumbaiRains Houston Vs Mumbai Divided by oceans, United in Grief <URL>\n",
      "full parse [[['#HurricaneHarvey', 'PROPN', 4, 'compound', 0], ['#MumbaiRains', 'PROPN', 4, 'compound', 1], ['Houston', 'PROPN', 4, 'compound', 2], ['Vs', 'PROPN', 4, 'compound', 3], ['Mumbai', 'PROPN', 4, 'ROOT', 4], ['Divided', 'VERB', 4, 'acl', 5], ['by', 'ADP', 5, 'agent', 6], ['oceans', 'NOUN', 6, 'pobj', 7], ['United', 'PROPN', 7, 'appos', 8], ['in', 'ADP', 7, 'prep', 9], ['Grief', 'PROPN', 9, 'pobj', 10]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=United\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['United', 'PROPN', 7, 'appos', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['United', 'PROPN', 7, 'appos', 8]\n",
      "NE parent token:\n",
      "['oceans', 'NOUN', 6, 'pobj', 7]\n",
      "parent node subtree [['oceans', 'NOUN', 6, 'pobj', 7], ['United', 'PROPN', 7, 'appos', 8], ['in', 'ADP', 7, 'prep', 9], ['Grief', 'PROPN', 9, 'pobj', 10]]\n",
      "parent node subtree str oceans united in grief\n",
      "testing NE bevil_oaks, txt:Coast Guard and Port Arthur officials involved in rescues in the city, Bevil Oaks FD rescuing in that area. #SETXNews #Harvey\n",
      "full parse [[['Coast', 'PROPN', 1, 'compound', 0], ['Guard', 'PROPN', 15, 'nsubj', 1], ['and', 'CCONJ', 1, 'cc', 2], ['Port', 'PROPN', 4, 'compound', 3], ['Arthur', 'PROPN', 5, 'compound', 4], ['officials', 'NOUN', 1, 'conj', 5], ['involved', 'VERB', 5, 'acl', 6], ['in', 'ADP', 6, 'prep', 7], ['rescues', 'NOUN', 7, 'pobj', 8], ['in', 'ADP', 8, 'prep', 9], ['the', 'DET', 11, 'det', 10], ['city', 'NOUN', 9, 'pobj', 11], ['Bevil', 'PROPN', 14, 'compound', 12], ['Oaks', 'PROPN', 14, 'compound', 13], ['FD', 'PROPN', 15, 'nsubj', 14], ['rescuing', 'VERB', 15, 'ROOT', 15], ['in', 'ADP', 15, 'prep', 16], ['that', 'DET', 18, 'det', 17], ['area', 'NOUN', 16, 'pobj', 18], ['.', 'PUNCT', 15, 'punct', 19]], [['#SETXNews', 'PROPN', 1, 'nmod', 0], ['#Harvey', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Port Arthur\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate 1=Bevil Oaks\n",
      "anchor NE candidates = Port Arthur\n",
      "data NE tree=[['Bevil', 'PROPN', 14, 'compound', 12], ['Oaks', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Oaks', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['FD', 'PROPN', 15, 'nsubj', 14]\n",
      "parent node subtree [['Bevil', 'PROPN', 14, 'compound', 12], ['Oaks', 'PROPN', 14, 'compound', 13], ['FD', 'PROPN', 15, 'nsubj', 14]]\n",
      "parent node subtree str bevil oaks fd\n",
      "testing NE harris_county, txt:Sending prayers - More than 1,700 square miles of Harris County in Texas in underwater - more than New York City & Chicago combined. #Harvey <URL>\n",
      "full parse [[['Sending', 'VERB', 0, 'ROOT', 0], ['prayers', 'NOUN', 0, 'dobj', 1], ['More', 'ADJ', 4, 'amod', 2], ['than', 'ADP', 4, 'quantmod', 3], ['1700', 'NUM', 6, 'nummod', 4], ['square', 'ADJ', 6, 'amod', 5], ['miles', 'NOUN', 0, 'dobj', 6], ['of', 'ADP', 6, 'prep', 7], ['Harris', 'PROPN', 9, 'compound', 8], ['County', 'PROPN', 7, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Texas', 'PROPN', 10, 'pobj', 11], ['in', 'ADP', 0, 'prep', 12], ['underwater', 'NOUN', 12, 'pobj', 13], ['more', 'ADJ', 13, 'amod', 14], ['than', 'ADP', 14, 'prep', 15], ['New', 'PROPN', 17, 'compound', 16], ['York', 'PROPN', 18, 'compound', 17], ['City', 'PROPN', 21, 'nsubj', 18], ['&', 'CCONJ', 18, 'cc', 19], ['Chicago', 'PROPN', 18, 'conj', 20], ['combined', 'VERB', 1, 'relcl', 21], ['.', 'PUNCT', 0, 'punct', 22]], [['#Harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Harris County\n",
      "anchor NE candidates = Texas,New York City\n",
      "data NE tree=[['Harris', 'PROPN', 9, 'compound', 8], ['County', 'PROPN', 7, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['County', 'PROPN', 7, 'pobj', 9]\n",
      "NE parent token:\n",
      "['of', 'ADP', 6, 'prep', 7]\n",
      "NE=Harris County subtree=[['in', 'ADP', 9, 'prep', 10], ['Texas', 'PROPN', 10, 'pobj', 11]]\n",
      "min node deps ['prep']\n",
      "subtree = in Texas\n",
      "candidate 1=Chicago\n",
      "anchor NE candidates = \n",
      "testing NE bend, txt:Treviño on #HurricaneHarvey : We are getting ready for refugees. Let's not forget Coastal Bend communities. It is not just Houston.\n",
      "full parse [[['Treviño', 'PROPN', 6, 'npadvmod', 0], ['on', 'ADP', 0, 'prep', 1], ['#HurricaneHarvey', 'PROPN', 1, 'pobj', 2], [':', 'PUNCT', 6, 'punct', 3], ['We', 'PRON', 6, 'nsubj', 4], ['are', 'VERB', 6, 'aux', 5], ['getting', 'VERB', 6, 'ROOT', 6], ['ready', 'ADJ', 6, 'acomp', 7], ['for', 'ADP', 7, 'prep', 8], ['refugees', 'NOUN', 8, 'pobj', 9], ['.', 'PUNCT', 6, 'punct', 10]], [[\"Let's\", 'PROPN', 2, 'advmod', 0], ['not', 'ADV', 2, 'neg', 1], ['forget', 'VERB', 2, 'ROOT', 2], ['Coastal', 'PROPN', 4, 'compound', 3], ['Bend', 'PROPN', 5, 'compound', 4], ['communities', 'NOUN', 2, 'dobj', 5], ['.', 'PUNCT', 2, 'punct', 6]], [['It', 'PRON', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['not', 'ADV', 1, 'neg', 2], ['just', 'ADV', 4, 'advmod', 3], ['Houston', 'PROPN', 1, 'attr', 4], ['.', 'PUNCT', 1, 'punct', 5]]]\n",
      "candidate 0=Bend\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Bend', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Bend', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['communities', 'NOUN', 2, 'dobj', 5]\n",
      "parent node subtree [['Coastal', 'PROPN', 4, 'compound', 3], ['Bend', 'PROPN', 5, 'compound', 4], ['communities', 'NOUN', 2, 'dobj', 5]]\n",
      "parent node subtree str coastal bend communities\n",
      "NE=Bend subtree=[['Coastal', 'PROPN', 4, 'compound', 3]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "testing NE prague, txt:So... #Harvey for (European) scale. Corpus Christi is ~Milan Houston is ~München Beumont ~Salzburg Shreveport ~Prague <URL>\n",
      "full parse [[['So', 'ADV', 2, 'advmod', 0], ['...', 'PUNCT', 2, 'punct', 1], ['#Harvey', 'PROPN', 2, 'ROOT', 2], ['for', 'ADP', 2, 'prep', 3], ['(', 'PUNCT', 7, 'punct', 4], ['European', 'ADJ', 7, 'amod', 5], [')', 'PUNCT', 7, 'punct', 6], ['scale', 'NOUN', 3, 'pobj', 7], ['.', 'PUNCT', 2, 'punct', 8]], [['Corpus', 'PROPN', 1, 'compound', 0], ['Christi', 'PROPN', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['~', 'PUNCT', 6, 'punct', 3], ['Milan', 'PROPN', 5, 'compound', 4], ['Houston', 'PROPN', 6, 'nsubj', 5], ['is', 'VERB', 2, 'ccomp', 6], ['~', 'PUNCT', 6, 'punct', 7], ['München', 'PROPN', 9, 'compound', 8], ['Beumont', 'PROPN', 6, 'attr', 9], ['~', 'PUNCT', 9, 'punct', 10], ['Salzburg', 'PROPN', 12, 'compound', 11], ['Shreveport', 'PROPN', 9, 'appos', 12], ['~', 'SYM', 12, 'punct', 13], ['Prague', 'PROPN', 12, 'appos', 14]]]\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = \n",
      "candidate 1=Prague\n",
      "anchor NE candidates = Corpus Christi,Prague\n",
      "data NE tree=[['Prague', 'PROPN', 12, 'appos', 14]]\n",
      "NE parse token at tree=1, token=0:\n",
      "['Prague', 'PROPN', 12, 'appos', 14]\n",
      "NE parent token:\n",
      "['Shreveport', 'PROPN', 9, 'appos', 12]\n",
      "parent node subtree [['Salzburg', 'PROPN', 12, 'compound', 11], ['Shreveport', 'PROPN', 9, 'appos', 12], ['~', 'SYM', 12, 'punct', 13], ['Prague', 'PROPN', 12, 'appos', 14]]\n",
      "parent node subtree str salzburg shreveport ~ prague\n",
      "testing NE galveston, txt:Because the horror and devastation of #Harvey was in Houston and Galveston not Corpus Cristi. Go to the heart of it all not a safe area <URL>\n",
      "full parse [[['Because', 'ADP', 7, 'mark', 0], ['the', 'DET', 2, 'det', 1], ['horror', 'NOUN', 7, 'nsubj', 2], ['and', 'CCONJ', 2, 'cc', 3], ['devastation', 'NOUN', 2, 'conj', 4], ['of', 'ADP', 2, 'prep', 5], ['#Harvey', 'PROPN', 5, 'pobj', 6], ['was', 'VERB', 7, 'ROOT', 7], ['in', 'ADP', 7, 'prep', 8], ['Houston', 'PROPN', 8, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['Galveston', 'PROPN', 9, 'conj', 11], ['not', 'ADV', 9, 'neg', 12], ['Corpus', 'PROPN', 14, 'compound', 13], ['Cristi', 'PROPN', 9, 'appos', 14], ['.', 'PUNCT', 7, 'punct', 15]], [['Go', 'VERB', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['heart', 'NOUN', 1, 'pobj', 3], ['of', 'ADP', 3, 'prep', 4], ['it', 'PRON', 4, 'pobj', 5], ['all', 'DET', 5, 'appos', 6], ['not', 'ADV', 0, 'neg', 7], ['a', 'DET', 10, 'det', 8], ['safe', 'ADJ', 10, 'amod', 9], ['area', 'NOUN', 0, 'dep', 10]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=Galveston\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Galveston', 'PROPN', 9, 'conj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Galveston', 'PROPN', 9, 'conj', 11]\n",
      "NE parent token:\n",
      "['Houston', 'PROPN', 8, 'pobj', 9]\n",
      "testing NE euless, txt:Another crew from Euless and Haltom City heading out with a N. Texas strike team headed to Southeast Texas #Harvey <URL>\n",
      "full parse [[['Another', 'DET', 1, 'det', 0], ['crew', 'NOUN', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['Euless', 'PROPN', 2, 'pobj', 3], ['and', 'CCONJ', 3, 'cc', 4], ['Haltom', 'PROPN', 6, 'compound', 5], ['City', 'PROPN', 3, 'conj', 6], ['heading', 'VERB', 1, 'acl', 7], ['out', 'PART', 7, 'prt', 8], ['with', 'ADP', 7, 'prep', 9], ['a', 'DET', 11, 'det', 10], ['N', 'NOUN', 9, 'pobj', 11], ['.', 'PUNCT', 1, 'punct', 12], ['Texas', 'PROPN', 15, 'compound', 13], ['strike', 'NOUN', 15, 'compound', 14], ['team', 'NOUN', 16, 'nsubj', 15], ['headed', 'VERB', 16, 'ROOT', 16], ['to', 'ADP', 16, 'prep', 17], ['Southeast', 'PROPN', 20, 'compound', 18], ['Texas', 'PROPN', 20, 'compound', 19], ['#Harvey', 'PROPN', 17, 'pobj', 20]]]\n",
      "candidate 0=Euless\n",
      "anchor NE candidates = Texas\n",
      "data NE tree=[['Euless', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Euless', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['from', 'ADP', 1, 'prep', 2]\n",
      "NE=Euless subtree=[['and', 'CCONJ', 3, 'cc', 4], ['Haltom', 'PROPN', 6, 'compound', 5], ['City', 'PROPN', 3, 'conj', 6]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Haltom City\n",
      "anchor NE candidates = Euless,Texas\n",
      "data NE tree=[['Haltom', 'PROPN', 6, 'compound', 5], ['City', 'PROPN', 3, 'conj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['City', 'PROPN', 3, 'conj', 6]\n",
      "NE parent token:\n",
      "['Euless', 'PROPN', 2, 'pobj', 3]\n",
      "testing NE san_antonio, txt:While airports are resuming service, getting a flight to Houston is not easy; Some folks flying to San Antonio, then driving. #Harvey\n",
      "full parse [[['While', 'ADP', 3, 'mark', 0], ['airports', 'NOUN', 3, 'nsubj', 1], ['are', 'VERB', 3, 'aux', 2], ['resuming', 'VERB', 10, 'csubj', 3], ['service', 'NOUN', 3, 'dobj', 4], ['getting', 'VERB', 4, 'acl', 5], ['a', 'DET', 7, 'det', 6], ['flight', 'NOUN', 5, 'dobj', 7], ['to', 'ADP', 7, 'prep', 8], ['Houston', 'PROPN', 8, 'pobj', 9], ['is', 'VERB', 21, 'ccomp', 10], ['not', 'ADV', 10, 'neg', 11], ['easy', 'ADJ', 10, 'acomp', 12], [';', 'PUNCT', 21, 'punct', 13], ['Some', 'DET', 15, 'det', 14], ['folks', 'NOUN', 21, 'nsubj', 15], ['flying', 'VERB', 15, 'acl', 16], ['to', 'ADP', 16, 'prep', 17], ['San', 'PROPN', 19, 'compound', 18], ['Antonio', 'PROPN', 17, 'pobj', 19], ['then', 'ADV', 21, 'advmod', 20], ['driving', 'VERB', 21, 'ROOT', 21], ['.', 'PUNCT', 21, 'punct', 22]], [['#Harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = \n",
      "candidate 1=San Antonio\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['San', 'PROPN', 19, 'compound', 18], ['Antonio', 'PROPN', 17, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Antonio', 'PROPN', 17, 'pobj', 19]\n",
      "NE parent token:\n",
      "['to', 'ADP', 16, 'prep', 17]\n",
      "testing NE corpus_christi, txt:Our claims adjusters are in Corpus Christi, Victoria & limited areas of Houston. To contact our claims team: <URL>\n",
      "full parse [[['Our', 'ADJ', 2, 'poss', 0], ['claims', 'NOUN', 2, 'compound', 1], ['adjusters', 'NOUN', 3, 'nsubj', 2], ['are', 'VERB', 3, 'ROOT', 3], ['in', 'ADP', 3, 'prep', 4], ['Corpus', 'PROPN', 7, 'compound', 5], ['Christi', 'PROPN', 7, 'compound', 6], ['Victoria', 'PROPN', 4, 'pobj', 7], ['&', 'CCONJ', 7, 'cc', 8], ['limited', 'ADJ', 10, 'amod', 9], ['areas', 'NOUN', 7, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Houston', 'PROPN', 11, 'pobj', 12], ['.', 'PUNCT', 3, 'punct', 13]], [['To', 'PART', 1, 'aux', 0], ['contact', 'VERB', 1, 'ROOT', 1], ['our', 'ADJ', 4, 'poss', 2], ['claims', 'NOUN', 4, 'compound', 3], ['team', 'NOUN', 1, 'dobj', 4], [':', 'PUNCT', 1, 'punct', 5]]]\n",
      "candidate 0=Corpus Christi\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Corpus', 'PROPN', 7, 'compound', 5], ['Christi', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Christi', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['Victoria', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['Corpus', 'PROPN', 7, 'compound', 5], ['Christi', 'PROPN', 7, 'compound', 6], ['Victoria', 'PROPN', 4, 'pobj', 7], ['&', 'CCONJ', 7, 'cc', 8], ['limited', 'ADJ', 10, 'amod', 9], ['areas', 'NOUN', 7, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Houston', 'PROPN', 11, 'pobj', 12]]\n",
      "parent node subtree str corpus christi victoria & limited areas of houston\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "testing NE sandy, txt:Sweet! There's no age limit on kindness. We're taking donations today @KATUNews - ocated at NE 21st & Sandy in PDX. #Harvey #TexasStrong <URL>\n",
      "full parse [[['Sweet', 'ADJ', 0, 'ROOT', 0], ['!', 'PUNCT', 0, 'punct', 1]], [[\"There's\", 'NOUN', 3, 'nsubj', 0], ['no', 'DET', 3, 'det', 1], ['age', 'NOUN', 3, 'compound', 2], ['limit', 'NOUN', 3, 'ROOT', 3], ['on', 'ADP', 3, 'prep', 4], ['kindness', 'NOUN', 4, 'pobj', 5], ['.', 'PUNCT', 3, 'punct', 6]], [[\"We're\", 'PROPN', 1, 'nsubj', 0], ['taking', 'VERB', 1, 'ROOT', 1], ['donations', 'NOUN', 1, 'dobj', 2], ['today', 'NOUN', 1, 'npadvmod', 3], ['@KATUNews', 'NOUN', 1, 'punct', 4], ['ocated', 'VERB', 1, 'advcl', 5], ['at', 'ADP', 5, 'prep', 6], ['NE', 'PROPN', 8, 'compound', 7], ['21st', 'PROPN', 6, 'pobj', 8], ['&', 'CCONJ', 8, 'cc', 9], ['Sandy', 'PROPN', 8, 'conj', 10], ['in', 'ADP', 8, 'prep', 11], ['PDX', 'PROPN', 11, 'pobj', 12], ['.', 'PUNCT', 1, 'punct', 13]], [['#Harvey', 'PROPN', 1, 'compound', 0], ['#TexasStrong', 'X', 1, 'ROOT', 1]]]\n",
      "candidate 0=Sandy\n",
      "anchor NE candidates = \n",
      "testing NE cleveland, txt:Better have a plan for DC, Baltimore, Philly, NYC, CLEVELAND, BUFFALO, TORONTO, OTTOWA, MONTREAL. And all between. GFS Model #harvey correct <URL>\n",
      "full parse [[['Better', 'ADV', 1, 'nsubj', 0], ['have', 'VERB', 1, 'ROOT', 1], ['a', 'DET', 3, 'det', 2], ['plan', 'NOUN', 1, 'dobj', 3], ['for', 'ADP', 3, 'prep', 4], ['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8], ['CLEVELAND', 'PROPN', 13, 'compound', 9], ['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11], ['OTTOWA', 'PROPN', 13, 'compound', 12], ['MONTREAL', 'PROPN', 4, 'pobj', 13], ['.', 'PUNCT', 1, 'punct', 14]], [['And', 'CCONJ', 2, 'cc', 0], ['all', 'DET', 2, 'advmod', 1], ['between', 'ADP', 2, 'ROOT', 2], ['.', 'PUNCT', 2, 'punct', 3]], [['GFS', 'PROPN', 1, 'compound', 0], ['Model', 'PROPN', 2, 'compound', 1], ['#harvey', 'PROPN', 3, 'nsubj', 2], ['correct', 'VERB', 3, 'ROOT', 3]]]\n",
      "candidate 0=CLEVELAND\n",
      "anchor NE candidates = Philly,NYC\n",
      "data NE tree=[['CLEVELAND', 'PROPN', 13, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['CLEVELAND', 'PROPN', 13, 'compound', 9]\n",
      "NE parent token:\n",
      "['MONTREAL', 'PROPN', 4, 'pobj', 13]\n",
      "parent node subtree [['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8], ['CLEVELAND', 'PROPN', 13, 'compound', 9], ['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11], ['OTTOWA', 'PROPN', 13, 'compound', 12], ['MONTREAL', 'PROPN', 4, 'pobj', 13]]\n",
      "parent node subtree str dc baltimore philly nyc cleveland buffalo toronto ottowa montreal\n",
      "NE=CLEVELAND subtree=[['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound', 'compound', 'compound', 'compound']\n",
      "candidate 1=BUFFALO\n",
      "anchor NE candidates = NYC\n",
      "data NE tree=[['BUFFALO', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['BUFFALO', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['TORONTO', 'PROPN', 13, 'compound', 11]\n",
      "parent node subtree [['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11]]\n",
      "parent node subtree str buffalo toronto\n",
      "candidate 2=TORONTO\n",
      "anchor NE candidates = \n",
      "candidate 3=MONTREAL\n",
      "anchor NE candidates = Baltimore,Philly,NYC\n",
      "data NE tree=[['MONTREAL', 'PROPN', 4, 'pobj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['MONTREAL', 'PROPN', 4, 'pobj', 13]\n",
      "NE parent token:\n",
      "['for', 'ADP', 3, 'prep', 4]\n",
      "NE=MONTREAL subtree=[['DC', 'PROPN', 9, 'compound', 5], ['Baltimore', 'PROPN', 9, 'compound', 6], ['Philly', 'PROPN', 9, 'compound', 7], ['NYC', 'PROPN', 9, 'compound', 8], ['CLEVELAND', 'PROPN', 13, 'compound', 9], ['BUFFALO', 'PROPN', 11, 'compound', 10], ['TORONTO', 'PROPN', 13, 'compound', 11], ['OTTOWA', 'PROPN', 13, 'compound', 12]]\n",
      "min node deps ['compound', 'compound', 'compound', 'compound']\n",
      "testing NE woodsboro, txt:We're gonna be headed to Woodsboro, TX pop. 1,512 tomorrow to drop off supplies. #Harvey Amazon Wish List - <URL>\n",
      "full parse [[[\"We're\", 'PROPN', 3, 'nsubjpass', 0], ['gonna', 'VERB', 3, 'aux', 1], ['be', 'VERB', 3, 'auxpass', 2], ['headed', 'VERB', 3, 'ROOT', 3], ['to', 'ADP', 3, 'prep', 4], ['Woodsboro', 'PROPN', 6, 'compound', 5], ['TX', 'PROPN', 7, 'compound', 6], ['pop', 'NOUN', 4, 'pobj', 7], ['.', 'PUNCT', 3, 'punct', 8]], [['1512', 'NUM', 1, 'nummod', 0], ['tomorrow', 'NOUN', 3, 'npadvmod', 1], ['to', 'PART', 3, 'aux', 2], ['drop', 'VERB', 3, 'ROOT', 3], ['off', 'PART', 3, 'prt', 4], ['supplies', 'NOUN', 3, 'dobj', 5], ['.', 'PUNCT', 3, 'punct', 6]], [['#Harvey', 'PROPN', 1, 'compound', 0], ['Amazon', 'PROPN', 3, 'compound', 1], ['Wish', 'PROPN', 3, 'compound', 2], ['List', 'NOUN', 3, 'ROOT', 3]]]\n",
      "candidate 0=Woodsboro\n",
      "anchor NE candidates = TX\n",
      "data NE tree=[['Woodsboro', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Woodsboro', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['TX', 'PROPN', 7, 'compound', 6]\n",
      "parent node subtree [['Woodsboro', 'PROPN', 6, 'compound', 5], ['TX', 'PROPN', 7, 'compound', 6]]\n",
      "parent node subtree str woodsboro tx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive: NE=woodsboro, type=compound\n",
      "testing NE morgantown, txt:@kellycass Good morning from Morgantown,WV. Watching today's rain & that impact on Cheat River watershed before #Irma arrives.\n",
      "full parse [[['@kellycass', 'PUNCT', 2, 'punct', 0], ['Good', 'ADJ', 2, 'amod', 1], ['morning', 'NOUN', 2, 'ROOT', 2], ['from', 'ADP', 2, 'prep', 3], ['MorgantownWV', 'PROPN', 3, 'pobj', 4], ['.', 'PUNCT', 2, 'punct', 5]], [['Watching', 'VERB', 12, 'csubj', 0], [\"today's\", 'NUM', 2, 'compound', 1], ['rain', 'VERB', 0, 'dobj', 2], ['&', 'CCONJ', 2, 'cc', 3], ['that', 'DET', 5, 'det', 4], ['impact', 'NOUN', 2, 'conj', 5], ['on', 'ADP', 5, 'prep', 6], ['Cheat', 'PROPN', 8, 'compound', 7], ['River', 'PROPN', 6, 'pobj', 8], ['watershed', 'NOUN', 0, 'ccomp', 9], ['before', 'ADP', 9, 'prep', 10], ['#Irma', 'PROPN', 10, 'pobj', 11], ['arrives', 'VERB', 12, 'ROOT', 12], ['.', 'PUNCT', 12, 'punct', 13]]]\n",
      "candidate 0=Morgantown\n",
      "anchor NE candidates = WV\n",
      "testing NE london, txt:@ShiriSpear do you think #IRMA will directly hit North Florida / Orlando / WDW area. Flying from London to Orlando Thursday curious to kno?\n",
      "full parse [[['@ShiriSpear', 'PUNCT', 0, 'ROOT', 0], ['do', 'VERB', 3, 'aux', 1], ['you', 'PRON', 3, 'nsubj', 2], ['think', 'VERB', 3, 'ROOT', 3], ['#IRMA', 'PART', 7, 'nsubj', 4], ['will', 'VERB', 7, 'aux', 5], ['directly', 'ADV', 7, 'advmod', 6], ['hit', 'VERB', 3, 'ccomp', 7], ['North', 'PROPN', 9, 'compound', 8], ['Florida', 'PROPN', 14, 'nmod', 9], ['/', 'SYM', 13, 'punct', 10], ['Orlando', 'PROPN', 13, 'nmod', 11], ['/', 'SYM', 13, 'punct', 12], ['WDW', 'PROPN', 14, 'compound', 13], ['area', 'NOUN', 7, 'dobj', 14], ['.', 'PUNCT', 3, 'punct', 15]], [['Flying', 'VERB', 0, 'ROOT', 0], ['from', 'ADP', 0, 'prep', 1], ['London', 'PROPN', 1, 'pobj', 2], ['to', 'ADP', 0, 'prep', 3], ['Orlando', 'PROPN', 3, 'pobj', 4], ['Thursday', 'PROPN', 0, 'npadvmod', 5], ['curious', 'ADJ', 5, 'amod', 6], ['to', 'PART', 8, 'aux', 7], ['kno', 'VERB', 6, 'xcomp', 8], ['?', 'PUNCT', 0, 'punct', 9]]]\n",
      "candidate 0=Orlando\n",
      "anchor NE candidates = Orlando,London,Orlando\n",
      "data NE tree=[['Orlando', 'PROPN', 13, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Orlando', 'PROPN', 13, 'nmod', 11]\n",
      "NE parent token:\n",
      "['WDW', 'PROPN', 14, 'compound', 13]\n",
      "parent node subtree [['/', 'SYM', 13, 'punct', 10], ['Orlando', 'PROPN', 13, 'nmod', 11], ['/', 'SYM', 13, 'punct', 12], ['WDW', 'PROPN', 14, 'compound', 13]]\n",
      "parent node subtree str / orlando / wdw\n",
      "candidate 1=London\n",
      "anchor NE candidates = \n",
      "candidate 2=Orlando\n",
      "anchor NE candidates = Orlando,Orlando\n",
      "data NE tree=[['Orlando', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Orlando', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 3]\n",
      "testing NE miami, txt:If #irma is still on FL track in two days, why not fill up all cruise ships in Miami, Cape canaveral etc with ppl - ship away from storm?\n",
      "full parse [[['If', 'ADP', 2, 'mark', 0], ['#irma', 'PROPN', 2, 'nsubj', 1], ['is', 'VERB', 12, 'advcl', 2], ['still', 'ADV', 2, 'advmod', 3], ['on', 'ADP', 2, 'prep', 4], ['FL', 'PROPN', 6, 'compound', 5], ['track', 'NOUN', 4, 'pobj', 6], ['in', 'ADP', 2, 'prep', 7], ['two', 'NUM', 9, 'nummod', 8], ['days', 'NOUN', 7, 'pobj', 9], ['why', 'ADV', 12, 'advmod', 10], ['not', 'ADV', 12, 'neg', 11], ['fill', 'VERB', 12, 'ROOT', 12], ['up', 'PART', 12, 'prt', 13], ['all', 'DET', 16, 'det', 14], ['cruise', 'NOUN', 16, 'compound', 15], ['ships', 'NOUN', 12, 'dobj', 16], ['in', 'ADP', 16, 'prep', 17], ['Miami', 'PROPN', 19, 'compound', 18], ['Cape', 'PROPN', 21, 'compound', 19], ['canaveral', 'ADJ', 21, 'compound', 20], ['etc', 'X', 17, 'pobj', 21], ['with', 'ADP', 24, 'mark', 22], ['ppl', 'NOUN', 24, 'compound', 23], ['ship', 'VERB', 12, 'advcl', 24], ['away', 'ADV', 24, 'advmod', 25], ['from', 'ADP', 25, 'prep', 26], ['storm', 'NOUN', 26, 'pobj', 27], ['?', 'PUNCT', 12, 'punct', 28]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "candidate 1=Cape canaveral\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Cape', 'PROPN', 21, 'compound', 19], ['canaveral', 'ADJ', 21, 'compound', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['canaveral', 'ADJ', 21, 'compound', 20]\n",
      "NE parent token:\n",
      "['etc', 'X', 17, 'pobj', 21]\n",
      "parent node subtree [['Miami', 'PROPN', 19, 'compound', 18], ['Cape', 'PROPN', 21, 'compound', 19], ['canaveral', 'ADJ', 21, 'compound', 20], ['etc', 'X', 17, 'pobj', 21]]\n",
      "parent node subtree str miami cape canaveral etc\n",
      "NE=Cape canaveral subtree=[['Miami', 'PROPN', 19, 'compound', 18]]\n",
      "min node deps ['compound']\n",
      "testing NE miami, txt:@AmericanAir supposed to fly to the Dominican Republic, connection in Miami. Trying to switch to Mexico & you want to charge me? #Help #Irma\n",
      "full parse [[['@AmericanAir', 'PROPN', 1, 'nsubj', 0], ['supposed', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['fly', 'VERB', 1, 'xcomp', 3], ['to', 'ADP', 3, 'prep', 4], ['the', 'DET', 8, 'det', 5], ['Dominican', 'PROPN', 7, 'compound', 6], ['Republic', 'PROPN', 8, 'compound', 7], ['connection', 'NOUN', 4, 'pobj', 8], ['in', 'ADP', 8, 'prep', 9], ['Miami', 'PROPN', 9, 'pobj', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['Trying', 'VERB', 0, 'ROOT', 0], ['to', 'PART', 2, 'aux', 1], ['switch', 'VERB', 0, 'xcomp', 2], ['to', 'ADP', 2, 'prep', 3], ['Mexico', 'PROPN', 3, 'pobj', 4], ['&', 'CCONJ', 0, 'cc', 5], ['you', 'PRON', 7, 'nsubj', 6], ['want', 'VERB', 0, 'conj', 7], ['to', 'PART', 9, 'aux', 8], ['charge', 'VERB', 7, 'xcomp', 9], ['me', 'PRON', 9, 'dobj', 10], ['?', 'PUNCT', 7, 'punct', 11]], [['#Help', 'INTJ', 1, 'compound', 0], ['#Irma', 'PUNCT', 1, 'ROOT', 1]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Mexico\n",
      "data NE tree=[['Miami', 'PROPN', 9, 'pobj', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Miami', 'PROPN', 9, 'pobj', 10]\n",
      "NE parent token:\n",
      "['in', 'ADP', 8, 'prep', 9]\n",
      "testing NE tampa, txt:Hoping for a safe week for our friends at Hillsborough Area Regional Transit in Tampa, FL as they prepare for #HurricaneIrma .\n",
      "full parse [[['Hoping', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['a', 'DET', 4, 'det', 2], ['safe', 'ADJ', 4, 'amod', 3], ['week', 'NOUN', 1, 'pobj', 4], ['for', 'ADP', 0, 'prep', 5], ['our', 'ADJ', 7, 'poss', 6], ['friends', 'NOUN', 5, 'pobj', 7], ['at', 'ADP', 7, 'prep', 8], ['Hillsborough', 'PROPN', 10, 'compound', 9], ['Area', 'PROPN', 12, 'compound', 10], ['Regional', 'PROPN', 12, 'compound', 11], ['Transit', 'PROPN', 8, 'pobj', 12], ['in', 'ADP', 12, 'prep', 13], ['Tampa', 'PROPN', 15, 'compound', 14], ['FL', 'PROPN', 13, 'pobj', 15], ['as', 'ADP', 18, 'mark', 16], ['they', 'PRON', 18, 'nsubj', 17], ['prepare', 'VERB', 0, 'advcl', 18], ['for', 'ADP', 18, 'prep', 19], ['#HurricaneIrma', 'PROPN', 19, 'pobj', 20], ['.', 'PUNCT', 0, 'punct', 21]]]\n",
      "candidate 0=Tampa\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Tampa', 'PROPN', 15, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Tampa', 'PROPN', 15, 'compound', 14]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 13, 'pobj', 15]\n",
      "parent node subtree [['Tampa', 'PROPN', 15, 'compound', 14], ['FL', 'PROPN', 13, 'pobj', 15]]\n",
      "parent node subtree str tampa fl\n",
      "false positive: NE=tampa, type=compound\n",
      "testing NE anna_maria_island, txt:Anna Maria Island evacuating 9/7/17 at 12:40 PM. Mileage check zero. Destination Clearwater then sweet home Alabama. #Irma please .\n",
      "full parse [[['Anna', 'PROPN', 2, 'compound', 0], ['Maria', 'PROPN', 2, 'compound', 1], ['Island', 'PROPN', 3, 'nsubj', 2], ['evacuating', 'VERB', 3, 'ROOT', 3], ['9/7', 'NUM', 3, 'dobj', 4], ['/', 'SYM', 6, 'punct', 5], ['17', 'NUM', 3, 'npadvmod', 6], ['at', 'ADP', 3, 'prep', 7], ['12:40', 'NUM', 9, 'nummod', 8], ['PM', 'NOUN', 7, 'pobj', 9], ['.', 'PUNCT', 3, 'punct', 10]], [['Mileage', 'NOUN', 1, 'nsubj', 0], ['check', 'NOUN', 1, 'ROOT', 1], ['zero', 'NUM', 1, 'dobj', 2], ['.', 'PUNCT', 1, 'punct', 3]], [['Destination', 'NOUN', 1, 'compound', 0], ['Clearwater', 'PROPN', 1, 'ROOT', 1], ['then', 'ADV', 3, 'advmod', 2], ['sweet', 'ADJ', 4, 'amod', 3], ['home', 'NOUN', 5, 'compound', 4], ['Alabama', 'PROPN', 1, 'appos', 5], ['.', 'PUNCT', 1, 'punct', 6]], [['#Irma', 'PROPN', 1, 'nsubj', 0], ['please', 'INTJ', 1, 'ROOT', 1], ['.', 'PUNCT', 1, 'punct', 2]]]\n",
      "candidate 0=Anna Maria Island\n",
      "anchor NE candidates = Alabama\n",
      "data NE tree=[['Anna', 'PROPN', 2, 'compound', 0], ['Maria', 'PROPN', 2, 'compound', 1], ['Island', 'PROPN', 3, 'nsubj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Island', 'PROPN', 3, 'nsubj', 2]\n",
      "NE parent token:\n",
      "['evacuating', 'VERB', 3, 'ROOT', 3]\n",
      "testing NE miami, txt:My thoughts and prayers are with Miami and the entire State of Florida #HurricaneIrma\n",
      "full parse [[['My', 'ADJ', 1, 'poss', 0], ['thoughts', 'NOUN', 4, 'nsubj', 1], ['and', 'CCONJ', 1, 'cc', 2], ['prayers', 'NOUN', 1, 'conj', 3], ['are', 'VERB', 4, 'ROOT', 4], ['with', 'ADP', 4, 'prep', 5], ['Miami', 'PROPN', 5, 'pobj', 6], ['and', 'CCONJ', 6, 'cc', 7], ['the', 'DET', 10, 'det', 8], ['entire', 'ADJ', 10, 'amod', 9], ['State', 'NOUN', 6, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Florida', 'PROPN', 11, 'pobj', 12], ['#HurricaneIrma', 'PUNCT', 4, 'punct', 13]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Miami', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['with', 'ADP', 4, 'prep', 5]\n",
      "NE=Miami subtree=[['and', 'CCONJ', 6, 'cc', 7], ['the', 'DET', 10, 'det', 8], ['entire', 'ADJ', 10, 'amod', 9], ['State', 'NOUN', 6, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['Florida', 'PROPN', 11, 'pobj', 12]]\n",
      "min node deps ['cc', 'conj']\n",
      "false positive: NE=miami, type=list\n",
      "testing NE white_house, txt:#HurricaneIrma please go hit Washington DC *Specifically White House* Thanks the hole world\n",
      "full parse [[['#HurricaneIrma', 'PUNCT', 3, 'dep', 0], ['please', 'INTJ', 2, 'intj', 1], ['go', 'VERB', 3, 'auxpass', 2], ['hit', 'VERB', 3, 'ROOT', 3], ['Washington', 'PROPN', 5, 'compound', 4], ['DC', 'PROPN', 3, 'dobj', 5], ['*', 'PUNCT', 9, 'punct', 6], ['Specifically', 'ADV', 9, 'advmod', 7], ['White', 'PROPN', 9, 'compound', 8], ['House', 'PROPN', 9, 'ROOT', 9], ['*', 'PUNCT', 9, 'punct', 10], ['Thanks', 'NOUN', 11, 'ROOT', 11], ['the', 'DET', 14, 'det', 12], ['hole', 'NOUN', 14, 'compound', 13], ['world', 'NOUN', 11, 'dobj', 14]]]\n",
      "candidate 0=White House\n",
      "anchor NE candidates = \n",
      "testing NE jacksonville, txt:JUST IN - A MANDATORY EVACUATION has been issued for Jacksonville, Florida. #CNN #Irma\n",
      "full parse [[['JUST', 'ADV', 1, 'advmod', 0], ['IN', 'ADP', 7, 'advmod', 1], ['A', 'DET', 4, 'det', 2], ['MANDATORY', 'PROPN', 4, 'compound', 3], ['EVACUATION', 'PROPN', 7, 'nsubjpass', 4], ['has', 'VERB', 7, 'aux', 5], ['been', 'VERB', 7, 'auxpass', 6], ['issued', 'VERB', 7, 'ROOT', 7], ['for', 'ADP', 7, 'prep', 8], ['Jacksonville', 'PROPN', 10, 'compound', 9], ['Florida', 'PROPN', 8, 'pobj', 10], ['.', 'PUNCT', 7, 'punct', 11]], [['#CNN', 'INTJ', 1, 'compound', 0], ['#Irma', 'PUNCT', 1, 'ROOT', 1]]]\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Jacksonville', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Jacksonville', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 8, 'pobj', 10]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 10, 'compound', 9], ['Florida', 'PROPN', 8, 'pobj', 10]]\n",
      "parent node subtree str jacksonville florida\n",
      "false positive: NE=jacksonville, type=compound\n",
      "testing NE fort_myers, txt:Made it to Tulsa last night from Fort Myers escaping #hurricaneirma . Just home we have a home back in FL when we get back. @jamesaydelott\n",
      "full parse [[['Made', 'VERB', 0, 'ROOT', 0], ['it', 'PRON', 0, 'dobj', 1], ['to', 'ADP', 0, 'prep', 2], ['Tulsa', 'PROPN', 2, 'pobj', 3], ['last', 'ADJ', 5, 'amod', 4], ['night', 'NOUN', 0, 'npadvmod', 5], ['from', 'ADP', 0, 'prep', 6], ['Fort', 'PROPN', 8, 'compound', 7], ['Myers', 'PROPN', 6, 'pobj', 8], ['escaping', 'VERB', 10, 'compound', 9], ['#hurricaneirma', 'PROPN', 8, 'appos', 10], ['.', 'PUNCT', 0, 'punct', 11]], [['Just', 'ADV', 1, 'advmod', 0], ['home', 'ADV', 3, 'advmod', 1], ['we', 'PRON', 3, 'nsubj', 2], ['have', 'VERB', 3, 'ROOT', 3], ['a', 'DET', 5, 'det', 4], ['home', 'NOUN', 3, 'dobj', 5], ['back', 'ADV', 3, 'advmod', 6], ['in', 'ADP', 6, 'prep', 7], ['FL', 'PROPN', 7, 'pobj', 8], ['when', 'ADV', 11, 'advmod', 9], ['we', 'PRON', 11, 'nsubj', 10], ['get', 'VERB', 3, 'advcl', 11], ['back', 'ADV', 11, 'advmod', 12], ['.', 'PUNCT', 3, 'punct', 13]], [['@jamesaydelott', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Fort Myers\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Fort', 'PROPN', 8, 'compound', 7], ['Myers', 'PROPN', 6, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Myers', 'PROPN', 6, 'pobj', 8]\n",
      "NE parent token:\n",
      "['from', 'ADP', 0, 'prep', 6]\n",
      "NE=Fort Myers subtree=[['escaping', 'VERB', 10, 'compound', 9], ['#hurricaneirma', 'PROPN', 8, 'appos', 10]]\n",
      "min node deps ['appos']\n",
      "subtree = escaping #hurricaneirma\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE miami, txt:Friends in Miami and Florida, good luck and be safe! #hurricaneirma #irma #miamibeach <URL>\n",
      "full parse [[['Friends', 'NOUN', 6, 'nmod', 0], ['in', 'ADP', 0, 'prep', 1], ['Miami', 'PROPN', 1, 'pobj', 2], ['and', 'CCONJ', 2, 'cc', 3], ['Florida', 'PROPN', 2, 'conj', 4], ['good', 'ADJ', 6, 'amod', 5], ['luck', 'NOUN', 6, 'ROOT', 6], ['and', 'CCONJ', 6, 'cc', 7], ['be', 'VERB', 6, 'conj', 8], ['safe', 'ADJ', 8, 'acomp', 9], ['!', 'PUNCT', 6, 'punct', 10]], [['#hurricaneirma', 'PROPN', 2, 'nmod', 0], ['#irma', 'PROPN', 2, 'compound', 1], ['#miamibeach', 'PROPN', 2, 'ROOT', 2]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 1, 'pobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Miami', 'PROPN', 1, 'pobj', 2]\n",
      "NE parent token:\n",
      "['in', 'ADP', 0, 'prep', 1]\n",
      "NE=Miami subtree=[['and', 'CCONJ', 2, 'cc', 3], ['Florida', 'PROPN', 2, 'conj', 4]]\n",
      "min node deps ['cc', 'conj']\n",
      "false positive: NE=miami, type=list\n",
      "testing NE houston, txt:Left FL to help in Houston, now the hope is that FL will weather the storm. Let's pray for all those in the path of #hurricaneirma\n",
      "full parse [[['Left', 'ADJ', 9, 'advcl', 0], ['FL', 'PROPN', 0, 'dobj', 1], ['to', 'PART', 3, 'aux', 2], ['help', 'VERB', 0, 'advcl', 3], ['in', 'ADP', 3, 'prep', 4], ['Houston', 'PROPN', 4, 'pobj', 5], ['now', 'ADV', 9, 'advmod', 6], ['the', 'DET', 8, 'det', 7], ['hope', 'NOUN', 9, 'nsubj', 8], ['is', 'VERB', 9, 'ROOT', 9], ['that', 'ADP', 13, 'mark', 10], ['FL', 'PROPN', 13, 'nsubj', 11], ['will', 'VERB', 13, 'aux', 12], ['weather', 'VERB', 9, 'ccomp', 13], ['the', 'DET', 15, 'det', 14], ['storm', 'NOUN', 13, 'dobj', 15], ['.', 'PUNCT', 9, 'punct', 16]], [[\"Let's\", 'PROPN', 1, 'nsubj', 0], ['pray', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['all', 'ADJ', 4, 'predet', 3], ['those', 'DET', 2, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['the', 'DET', 7, 'det', 6], ['path', 'NOUN', 5, 'pobj', 7], ['of', 'ADP', 7, 'prep', 8], ['#hurricaneirma', 'PUNCT', 8, 'pobj', 9]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Houston', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Houston', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 4]\n",
      "testing NE miami, txt:LATEST: Hurricane #Irma is 405 miles southeast of Miami; it's spreading westward over parts of Cuba and the... <URL>\n",
      "full parse [[['LATEST', 'ADJ', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['Hurricane', 'PROPN', 3, 'compound', 2], ['#Irma', 'PROPN', 4, 'nsubj', 3], ['is', 'VERB', 12, 'ccomp', 4], ['405', 'NUM', 6, 'nummod', 5], ['miles', 'NOUN', 7, 'npadvmod', 6], ['southeast', 'ADV', 4, 'acomp', 7], ['of', 'ADP', 7, 'prep', 8], ['Miami', 'PROPN', 8, 'pobj', 9], [';', 'PUNCT', 12, 'punct', 10], [\"it's\", 'ADJ', 12, 'nsubj', 11], ['spreading', 'VERB', 12, 'ROOT', 12], ['westward', 'ADV', 12, 'advmod', 13], ['over', 'ADP', 12, 'prep', 14], ['parts', 'NOUN', 14, 'pobj', 15], ['of', 'ADP', 15, 'prep', 16], ['Cuba', 'PROPN', 16, 'pobj', 17], ['and', 'CCONJ', 15, 'cc', 18], ['the', 'DET', 15, 'conj', 19], ['...', 'PUNCT', 12, 'punct', 20]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Cuba\n",
      "data NE tree=[['Miami', 'PROPN', 8, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Miami', 'PROPN', 8, 'pobj', 9]\n",
      "NE parent token:\n",
      "['of', 'ADP', 7, 'prep', 8]\n",
      "testing NE orlando, txt:I hope everyone staying at the theme parks, Orlando, and throughout the entire state of Florida remains as safe as possible! #Irma\n",
      "full parse [[['I', 'PRON', 1, 'nsubj', 0], ['hope', 'VERB', 1, 'ROOT', 1], ['everyone', 'NOUN', 3, 'nsubj', 2], ['staying', 'VERB', 16, 'csubj', 3], ['at', 'ADP', 3, 'prep', 4], ['the', 'DET', 7, 'det', 5], ['theme', 'NOUN', 7, 'compound', 6], ['parks', 'NOUN', 4, 'pobj', 7], ['Orlando', 'PROPN', 7, 'appos', 8], ['and', 'CCONJ', 4, 'cc', 9], ['throughout', 'ADP', 4, 'conj', 10], ['the', 'DET', 13, 'det', 11], ['entire', 'ADJ', 13, 'amod', 12], ['state', 'NOUN', 10, 'pobj', 13], ['of', 'ADP', 13, 'prep', 14], ['Florida', 'PROPN', 14, 'pobj', 15], ['remains', 'VERB', 1, 'ccomp', 16], ['as', 'ADV', 18, 'advmod', 17], ['safe', 'ADJ', 16, 'acomp', 18], ['as', 'ADP', 18, 'prep', 19], ['possible', 'ADJ', 19, 'amod', 20], ['!', 'PUNCT', 1, 'punct', 21]], [['#Irma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Orlando\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Orlando', 'PROPN', 7, 'appos', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Orlando', 'PROPN', 7, 'appos', 8]\n",
      "NE parent token:\n",
      "['parks', 'NOUN', 4, 'pobj', 7]\n",
      "parent node subtree [['the', 'DET', 7, 'det', 5], ['theme', 'NOUN', 7, 'compound', 6], ['parks', 'NOUN', 4, 'pobj', 7], ['Orlando', 'PROPN', 7, 'appos', 8]]\n",
      "parent node subtree str the theme parks orlando\n",
      "testing NE madrid, txt:No planes over Miami right now. That one you see is Air Europa 787 leaving soon for Madrid tonight. #HurricaneIrma <URL>\n",
      "full parse [[['No', 'DET', 1, 'det', 0], ['planes', 'NOUN', 1, 'ROOT', 1], ['over', 'ADP', 1, 'prep', 2], ['Miami', 'PROPN', 2, 'pobj', 3], ['right', 'ADV', 5, 'advmod', 4], ['now', 'ADV', 1, 'advmod', 5], ['.', 'PUNCT', 1, 'punct', 6]], [['That', 'DET', 1, 'det', 0], ['one', 'NOUN', 4, 'nsubj', 1], ['you', 'PRON', 3, 'nsubj', 2], ['see', 'VERB', 1, 'relcl', 3], ['is', 'VERB', 4, 'ROOT', 4], ['Air', 'PROPN', 6, 'compound', 5], ['Europa', 'PROPN', 4, 'attr', 6], ['787', 'NUM', 6, 'nummod', 7], ['leaving', 'VERB', 4, 'advcl', 8], ['soon', 'ADV', 8, 'advmod', 9], ['for', 'ADP', 8, 'prep', 10], ['Madrid', 'PROPN', 10, 'pobj', 11], ['tonight', 'NOUN', 8, 'npadvmod', 12], ['.', 'PUNCT', 4, 'punct', 13]], [['#HurricaneIrma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "candidate 1=Madrid\n",
      "anchor NE candidates = Miami\n",
      "data NE tree=[['Madrid', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['Madrid', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['for', 'ADP', 8, 'prep', 10]\n",
      "testing NE tampa, txt:My family in Miami evacuated yesterday to Tampa. They aren't out of #Irma 's path completely, but I'm so grateful they were able to leave.\n",
      "full parse [[['My', 'ADJ', 1, 'poss', 0], ['family', 'NOUN', 4, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['Miami', 'PROPN', 2, 'pobj', 3], ['evacuated', 'VERB', 4, 'ROOT', 4], ['yesterday', 'NOUN', 4, 'npadvmod', 5], ['to', 'ADP', 4, 'prep', 6], ['Tampa', 'PROPN', 6, 'pobj', 7], ['.', 'PUNCT', 4, 'punct', 8]], [['They', 'PRON', 1, 'nsubj', 0], [\"aren't\", 'VERB', 7, 'nmod', 1], ['out', 'ADP', 1, 'prep', 2], ['of', 'ADP', 2, 'prep', 3], ['#Irma', 'PROPN', 3, 'pobj', 4], [\"'\", 'PUNCT', 7, 'punct', 5], ['s', 'PRON', 7, 'nmod', 6], ['path', 'NOUN', 7, 'ROOT', 7], ['completely', 'ADV', 7, 'advmod', 8], ['but', 'CCONJ', 7, 'cc', 9], [\"I'm\", 'NUM', 7, 'conj', 10], ['so', 'ADV', 12, 'advmod', 11], ['grateful', 'ADJ', 12, 'ROOT', 12], ['they', 'PRON', 14, 'nsubj', 13], ['were', 'VERB', 12, 'ccomp', 14], ['able', 'ADJ', 14, 'acomp', 15], ['to', 'PART', 17, 'aux', 16], ['leave', 'VERB', 15, 'xcomp', 17], ['.', 'PUNCT', 12, 'punct', 18]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = Miami\n",
      "data NE tree=[['Tampa', 'PROPN', 6, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Tampa', 'PROPN', 6, 'pobj', 7]\n",
      "NE parent token:\n",
      "['to', 'ADP', 4, 'prep', 6]\n",
      "testing NE jacksonville, txt:milfordonmove: Local Statement for Jacksonville, FL #disney #dcl #Irma <URL>\n",
      "full parse [[['milfordonmove', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['Local', 'ADJ', 3, 'compound', 2], ['Statement', 'PROPN', 0, 'appos', 3], ['for', 'ADP', 3, 'prep', 4], ['Jacksonville', 'PROPN', 6, 'compound', 5], ['FL', 'PROPN', 9, 'compound', 6], ['#disney', 'PROPN', 9, 'compound', 7], ['#dcl', 'NOUN', 9, 'compound', 8], ['#Irma', 'X', 4, 'pobj', 9]]]\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Jacksonville', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Jacksonville', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 9, 'compound', 6]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 6, 'compound', 5], ['FL', 'PROPN', 9, 'compound', 6]]\n",
      "parent node subtree str jacksonville fl\n",
      "false positive: NE=jacksonville, type=compound\n",
      "testing NE naples, txt:I expect #Irma to make landfall on MO 8 AM nearby Naples. Will hit Tampa at 2PM.\n",
      "full parse [[['I', 'PRON', 1, 'nsubj', 0], ['expect', 'VERB', 1, 'ROOT', 1], ['#Irma', 'PROPN', 4, 'nsubj', 2], ['to', 'PART', 4, 'aux', 3], ['make', 'VERB', 1, 'ccomp', 4], ['landfall', 'NOUN', 4, 'dobj', 5], ['on', 'ADP', 4, 'prep', 6], ['MO', 'PROPN', 6, 'pobj', 7], ['8', 'NUM', 9, 'nummod', 8], ['AM', 'PROPN', 10, 'npadvmod', 9], ['nearby', 'ADP', 4, 'advmod', 10], ['Naples', 'PROPN', 10, 'pobj', 11], ['.', 'PUNCT', 1, 'punct', 12]], [['Will', 'VERB', 1, 'aux', 0], ['hit', 'VERB', 1, 'ROOT', 1], ['Tampa', 'PROPN', 1, 'dobj', 2], ['at', 'ADP', 1, 'prep', 3], ['2PM', 'NUM', 3, 'pobj', 4], ['.', 'PUNCT', 1, 'punct', 5]]]\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Tampa\n",
      "data NE tree=[['Naples', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Naples', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['nearby', 'ADP', 4, 'advmod', 10]\n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = \n",
      "testing NE naples, txt:#Irma is forecast to make landfall somewhere between Naples & Sarasota sometime Sun night & pass very near or over Tampa early Mon am. #flwx\n",
      "full parse [[['#Irma', 'PROPN', 2, 'nsubjpass', 0], ['is', 'VERB', 2, 'auxpass', 1], ['forecast', 'VERB', 2, 'ROOT', 2], ['to', 'PART', 4, 'aux', 3], ['make', 'VERB', 2, 'advcl', 4], ['landfall', 'NOUN', 4, 'dobj', 5], ['somewhere', 'ADV', 4, 'advmod', 6], ['between', 'ADP', 6, 'prep', 7], ['Naples', 'PROPN', 7, 'pobj', 8], ['&', 'CCONJ', 8, 'cc', 9], ['Sarasota', 'PROPN', 8, 'conj', 10], ['sometime', 'ADV', 13, 'advmod', 11], ['Sun', 'PROPN', 13, 'compound', 12], ['night', 'NOUN', 4, 'npadvmod', 13], ['&', 'CCONJ', 4, 'cc', 14], ['pass', 'VERB', 4, 'conj', 15], ['very', 'ADV', 17, 'advmod', 16], ['near', 'ADV', 15, 'advmod', 17], ['or', 'CCONJ', 17, 'cc', 18], ['over', 'ADP', 17, 'conj', 19], ['Tampa', 'PROPN', 19, 'pobj', 20], ['early', 'ADJ', 22, 'amod', 21], ['Mon', 'PROPN', 20, 'appos', 22], ['am', 'VERB', 2, 'advcl', 23], ['.', 'PUNCT', 2, 'punct', 24]], [['#flwx', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Sarasota,Tampa\n",
      "data NE tree=[['Naples', 'PROPN', 7, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Naples', 'PROPN', 7, 'pobj', 8]\n",
      "NE parent token:\n",
      "['between', 'ADP', 6, 'prep', 7]\n",
      "NE=Naples subtree=[['&', 'CCONJ', 8, 'cc', 9], ['Sarasota', 'PROPN', 8, 'conj', 10]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Sarasota\n",
      "anchor NE candidates = \n",
      "candidate 2=Tampa\n",
      "anchor NE candidates = Sarasota\n",
      "data NE tree=[['Tampa', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Tampa', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['over', 'ADP', 17, 'conj', 19]\n",
      "NE=Tampa subtree=[['early', 'ADJ', 22, 'amod', 21], ['Mon', 'PROPN', 20, 'appos', 22]]\n",
      "min node deps ['appos']\n",
      "subtree = early Mon\n",
      "testing NE charleston, txt:Friends and family in Florida facing Hurricane Irma, know you are in our thoughts and prayers in Charleston #hurricaneirma #charleston <URL>\n",
      "full parse [[['Friends', 'NOUN', 8, 'nsubj', 0], ['and', 'CCONJ', 0, 'cc', 1], ['family', 'NOUN', 0, 'conj', 2], ['in', 'ADP', 0, 'prep', 3], ['Florida', 'PROPN', 3, 'pobj', 4], ['facing', 'VERB', 0, 'acl', 5], ['Hurricane', 'PROPN', 7, 'compound', 6], ['Irma', 'PROPN', 5, 'dobj', 7], ['know', 'VERB', 8, 'ROOT', 8], ['you', 'PRON', 10, 'nsubj', 9], ['are', 'VERB', 8, 'ccomp', 10], ['in', 'ADP', 10, 'prep', 11], ['our', 'ADJ', 13, 'poss', 12], ['thoughts', 'NOUN', 11, 'pobj', 13], ['and', 'CCONJ', 13, 'cc', 14], ['prayers', 'NOUN', 13, 'conj', 15], ['in', 'ADP', 13, 'prep', 16], ['Charleston', 'PROPN', 18, 'compound', 17], ['#hurricaneirma', 'PROPN', 16, 'pobj', 18], ['#charleston', 'PROPN', 8, 'dep', 19]]]\n",
      "candidate 0=Charleston\n",
      "anchor NE candidates = \n",
      "testing NE miami, txt:Curfews in effect during #HurricaneIrma in the cities of Miami, Miami Beach and North Miami Beach. No curfew for unincorporated Dade County. <URL>\n",
      "full parse [[['Curfews', 'NOUN', 0, 'ROOT', 0], ['in', 'ADP', 0, 'prep', 1], ['effect', 'NOUN', 1, 'pobj', 2], ['during', 'ADP', 0, 'prep', 3], ['#HurricaneIrma', 'PROPN', 3, 'pobj', 4], ['in', 'ADP', 0, 'prep', 5], ['the', 'DET', 7, 'det', 6], ['cities', 'NOUN', 5, 'pobj', 7], ['of', 'ADP', 7, 'prep', 8], ['Miami', 'PROPN', 11, 'compound', 9], ['Miami', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 8, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15], ['.', 'PUNCT', 0, 'punct', 16]], [['No', 'DET', 1, 'det', 0], ['curfew', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['unincorporated', 'ADJ', 5, 'amod', 3], ['Dade', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 2, 'pobj', 5], ['.', 'PUNCT', 1, 'punct', 6]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Dade County\n",
      "data NE tree=[['Miami', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Miami', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "parent node subtree [['Miami', 'PROPN', 11, 'compound', 9], ['Miami', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 8, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "parent node subtree str miami miami beach and north miami beach\n",
      "candidate 1=Miami Beach\n",
      "anchor NE candidates = Miami,Dade County\n",
      "data NE tree=[['Miami', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 8, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "NE parent token:\n",
      "['of', 'ADP', 7, 'prep', 8]\n",
      "NE=Miami Beach subtree=[['Miami', 'PROPN', 11, 'compound', 9], ['and', 'CCONJ', 11, 'cc', 12], ['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 2=North Miami Beach\n",
      "anchor NE candidates = Miami,Miami Beach,Dade County\n",
      "data NE tree=[['North', 'PROPN', 14, 'compound', 13], ['Miami', 'PROPN', 15, 'compound', 14], ['Beach', 'PROPN', 11, 'conj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Beach', 'PROPN', 11, 'conj', 15]\n",
      "NE parent token:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "candidate 3=Dade County\n",
      "anchor NE candidates = \n",
      "testing NE miami, txt:Sincerely hope everyone in Florida & Miami is safe and prepared for #Irma (as well as you can be) thoughts and prayers for those affected.\n",
      "full parse [[['Sincerely', 'ADV', 1, 'advmod', 0], ['hope', 'VERB', 1, 'ROOT', 1], ['everyone', 'NOUN', 7, 'nsubj', 2], ['in', 'ADP', 2, 'prep', 3], ['Florida', 'PROPN', 3, 'pobj', 4], ['&', 'CCONJ', 4, 'cc', 5], ['Miami', 'PROPN', 4, 'conj', 6], ['is', 'VERB', 1, 'ccomp', 7], ['safe', 'ADJ', 7, 'acomp', 8], ['and', 'CCONJ', 8, 'cc', 9], ['prepared', 'ADJ', 8, 'conj', 10], ['for', 'ADP', 10, 'prep', 11], ['#Irma', 'PROPN', 11, 'pobj', 12], ['(', 'PUNCT', 7, 'punct', 13], ['as', 'ADV', 16, 'advmod', 14], ['well', 'ADV', 16, 'advmod', 15], ['as', 'ADP', 19, 'mark', 16], ['you', 'PRON', 19, 'nsubj', 17], ['can', 'VERB', 19, 'aux', 18], ['be', 'VERB', 7, 'advcl', 19], [')', 'PUNCT', 19, 'punct', 20], ['thoughts', 'NOUN', 19, 'attr', 21], ['and', 'CCONJ', 21, 'cc', 22], ['prayers', 'NOUN', 21, 'conj', 23], ['for', 'ADP', 21, 'prep', 24], ['those', 'DET', 24, 'pobj', 25], ['affected', 'VERB', 25, 'acl', 26], ['.', 'PUNCT', 1, 'punct', 27]]]\n",
      "candidate 0=Miami\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor NE candidates = \n",
      "testing NE tampa, txt:#JewishTimes #Florida #RickScott #HurricaneIrma Irma closes in with Tampa, not Miami, in the crosshairs <URL>\n",
      "full parse [[['#JewishTimes', 'PROPN', 5, 'meta', 0], ['#Florida', 'PROPN', 4, 'compound', 1], ['#RickScott', 'PROPN', 4, 'compound', 2], ['#HurricaneIrma', 'PROPN', 4, 'compound', 3], ['Irma', 'PROPN', 5, 'nsubj', 4], ['closes', 'VERB', 5, 'ROOT', 5], ['in', 'PART', 5, 'prt', 6], ['with', 'ADP', 5, 'prep', 7], ['Tampa', 'PROPN', 10, 'nmod', 8], ['not', 'ADV', 10, 'neg', 9], ['Miami', 'PROPN', 7, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['the', 'DET', 13, 'det', 12], ['crosshairs', 'NOUN', 11, 'pobj', 13]]]\n",
      "candidate 0=Tampa\n",
      "anchor NE candidates = Miami\n",
      "data NE tree=[['Tampa', 'PROPN', 10, 'nmod', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Tampa', 'PROPN', 10, 'nmod', 8]\n",
      "NE parent token:\n",
      "['Miami', 'PROPN', 7, 'pobj', 10]\n",
      "parent node subtree [['Tampa', 'PROPN', 10, 'nmod', 8], ['not', 'ADV', 10, 'neg', 9], ['Miami', 'PROPN', 7, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['the', 'DET', 13, 'det', 12], ['crosshairs', 'NOUN', 11, 'pobj', 13]]\n",
      "parent node subtree str tampa not miami in the crosshairs\n",
      "candidate 1=Miami\n",
      "anchor NE candidates = \n",
      "testing NE lancaster, txt:High wind watch for Cleveland county and lake wind adv. for Lancaster and Chesterfield due to #Irma . #scwx #ncwx <URL>\n",
      "full parse [[['High', 'ADJ', 1, 'amod', 0], ['wind', 'NOUN', 2, 'compound', 1], ['watch', 'NOUN', 2, 'ROOT', 2], ['for', 'ADP', 2, 'prep', 3], ['Cleveland', 'PROPN', 5, 'nmod', 4], ['county', 'NOUN', 9, 'nmod', 5], ['and', 'CCONJ', 5, 'cc', 6], ['lake', 'NOUN', 9, 'compound', 7], ['wind', 'NOUN', 9, 'compound', 8], ['adv', 'NOUN', 3, 'pobj', 9], ['.', 'PUNCT', 2, 'punct', 10]], [['for', 'ADP', 0, 'ROOT', 0], ['Lancaster', 'PROPN', 0, 'pobj', 1], ['and', 'CCONJ', 1, 'cc', 2], ['Chesterfield', 'PROPN', 1, 'conj', 3], ['due', 'ADP', 1, 'amod', 4], ['to', 'ADP', 4, 'prep', 5], ['#Irma', 'PROPN', 5, 'pobj', 6], ['.', 'PUNCT', 0, 'punct', 7]], [['#scwx', 'PROPN', 1, 'compound', 0], ['#ncwx', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Lancaster\n",
      "anchor NE candidates = \n",
      "candidate 1=Chesterfield\n",
      "anchor NE candidates = Cleveland county\n",
      "data NE tree=[['Chesterfield', 'PROPN', 1, 'conj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Chesterfield', 'PROPN', 1, 'conj', 3]\n",
      "NE parent token:\n",
      "['Lancaster', 'PROPN', 0, 'pobj', 1]\n",
      "testing NE naples, txt:. @CityofMiami mayor tells @MLauer he reached out to mayors of Naples, Ft. Myers, Sarasota & Tampa yesterday to offer help #HurricaneIrma\n",
      "full parse [[['.', 'PUNCT', 0, 'ROOT', 0]], [['@CityofMiami', 'NUM', 1, 'compound', 0], ['mayor', 'NOUN', 2, 'nsubj', 1], ['tells', 'VERB', 2, 'ROOT', 2], ['@MLauer', 'PUNCT', 2, 'dobj', 3], ['he', 'PRON', 5, 'nsubj', 4], ['reached', 'VERB', 5, 'ROOT', 5], ['out', 'PART', 5, 'prt', 6], ['to', 'ADP', 5, 'prep', 7], ['mayors', 'NOUN', 7, 'pobj', 8], ['of', 'ADP', 8, 'prep', 9], ['Naples', 'PROPN', 11, 'compound', 10], ['Ft', 'PROPN', 9, 'pobj', 11], ['.', 'PUNCT', 5, 'punct', 12], ['Myers', 'PROPN', 14, 'compound', 13], ['Sarasota', 'PROPN', 14, 'ROOT', 14], ['&', 'CCONJ', 14, 'cc', 15], ['Tampa', 'PROPN', 14, 'conj', 16], ['yesterday', 'NOUN', 14, 'npadvmod', 17], ['to', 'PART', 19, 'aux', 18], ['offer', 'VERB', 14, 'relcl', 19], ['help', 'NOUN', 19, 'dobj', 20], ['#HurricaneIrma', 'PUNCT', 14, 'punct', 21]]]\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Myers,Sarasota,Tampa\n",
      "data NE tree=[['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['Naples', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Ft', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Naples', 'PROPN', 11, 'compound', 10], ['Ft', 'PROPN', 9, 'pobj', 11]]\n",
      "parent node subtree str naples ft\n",
      "candidate 1=Myers\n",
      "anchor NE candidates = Sarasota,Tampa\n",
      "data NE tree=[['Myers', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['Myers', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['Sarasota', 'PROPN', 14, 'ROOT', 14]\n",
      "parent node subtree [['Myers', 'PROPN', 14, 'compound', 13], ['Sarasota', 'PROPN', 14, 'ROOT', 14], ['&', 'CCONJ', 14, 'cc', 15], ['Tampa', 'PROPN', 14, 'conj', 16], ['yesterday', 'NOUN', 14, 'npadvmod', 17], ['to', 'PART', 19, 'aux', 18], ['offer', 'VERB', 14, 'relcl', 19], ['help', 'NOUN', 19, 'dobj', 20], ['#HurricaneIrma', 'PUNCT', 14, 'punct', 21]]\n",
      "parent node subtree str myers sarasota & tampa yesterday to offer help #hurricaneirma\n",
      "candidate 2=Sarasota\n",
      "anchor NE candidates = \n",
      "candidate 3=Tampa\n",
      "anchor NE candidates = Sarasota\n",
      "data NE tree=[['Tampa', 'PROPN', 14, 'conj', 16]]\n",
      "NE parse token at tree=1, token=17:\n",
      "['Tampa', 'PROPN', 14, 'conj', 16]\n",
      "NE parent token:\n",
      "['Sarasota', 'PROPN', 14, 'ROOT', 14]\n",
      "testing NE greenville, txt:Evacuation! Keep safe everyone! #hurricane #irma — traveling to Greenville, South Carolina\n",
      "full parse [[['Evacuation', 'NOUN', 0, 'ROOT', 0], ['!', 'PUNCT', 0, 'punct', 1]], [['Keep', 'VERB', 0, 'ROOT', 0], ['safe', 'ADJ', 0, 'oprd', 1], ['everyone', 'NOUN', 0, 'dobj', 2], ['!', 'PUNCT', 0, 'punct', 3]], [['#hurricane', 'X', 1, 'compound', 0], ['#irma', 'PROPN', 1, 'ROOT', 1], ['—', 'NUM', 3, 'advmod', 2], ['traveling', 'VERB', 1, 'acl', 3], ['to', 'ADP', 3, 'prep', 4], ['Greenville', 'PROPN', 7, 'compound', 5], ['South', 'PROPN', 7, 'compound', 6], ['Carolina', 'PROPN', 4, 'pobj', 7]]]\n",
      "candidate 0=Greenville\n",
      "anchor NE candidates = South Carolina\n",
      "data NE tree=[['Greenville', 'PROPN', 7, 'compound', 5]]\n",
      "NE parse token at tree=2, token=6:\n",
      "['Greenville', 'PROPN', 7, 'compound', 5]\n",
      "NE parent token:\n",
      "['Carolina', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['Greenville', 'PROPN', 7, 'compound', 5], ['South', 'PROPN', 7, 'compound', 6], ['Carolina', 'PROPN', 4, 'pobj', 7]]\n",
      "parent node subtree str greenville south carolina\n",
      "false positive: NE=greenville, type=compound\n",
      "testing NE miami, txt:@MSNBC Appreciate thoroughness on #Irma but at what point do you cover prep/problems NORTH of Keys/Miami? & how's Houston? Nature itself?!\n",
      "full parse [[['@MSNBC', 'PROPN', 1, 'nsubj', 0], ['Appreciate', 'VERB', 1, 'ROOT', 1], ['thoroughness', 'NOUN', 1, 'dobj', 2], ['on', 'ADP', 2, 'prep', 3], ['#Irma', 'PROPN', 3, 'pobj', 4], ['but', 'CCONJ', 3, 'cc', 5], ['at', 'ADP', 11, 'prep', 6], ['what', 'ADJ', 8, 'det', 7], ['point', 'NOUN', 6, 'pobj', 8], ['do', 'VERB', 11, 'aux', 9], ['you', 'PRON', 11, 'nsubj', 10], ['cover', 'VERB', 11, 'ROOT', 11], ['prep', 'NOUN', 14, 'nmod', 12], ['/', 'SYM', 14, 'punct', 13], ['problems', 'NOUN', 15, 'compound', 14], ['NORTH', 'PROPN', 11, 'dobj', 15], ['of', 'ADP', 15, 'prep', 16], ['Keys', 'PROPN', 19, 'nmod', 17], ['/', 'SYM', 19, 'punct', 18], ['Miami', 'PROPN', 16, 'pobj', 19], ['?', 'PUNCT', 11, 'punct', 20]], [['&', 'CCONJ', 1, 'cc', 0], [\"how's\", 'NOUN', 1, 'ROOT', 1], ['Houston', 'PROPN', 1, 'npadvmod', 2], ['?', 'PUNCT', 1, 'punct', 3]], [['Nature', 'NOUN', 0, 'ROOT', 0], ['itself', 'PRON', 0, 'appos', 1], ['?', 'PUNCT', 0, 'punct', 2]], [['!', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Houston\n",
      "data NE tree=[['Miami', 'PROPN', 16, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['Miami', 'PROPN', 16, 'pobj', 19]\n",
      "NE parent token:\n",
      "['of', 'ADP', 15, 'prep', 16]\n",
      "NE=Miami subtree=[['Keys', 'PROPN', 19, 'nmod', 17], ['/', 'SYM', 19, 'punct', 18]]\n",
      "min node deps ['nmod', 'punct']\n",
      "candidate 1=Houston\n",
      "anchor NE candidates = \n",
      "testing NE miami, txt:Heavy flooding right now on the streets of Downtown Miami in Florida #Irma\n",
      "full parse [[['Heavy', 'ADJ', 1, 'amod', 0], ['flooding', 'NOUN', 1, 'ROOT', 1], ['right', 'ADV', 3, 'advmod', 2], ['now', 'ADV', 1, 'advmod', 3], ['on', 'ADP', 1, 'prep', 4], ['the', 'DET', 6, 'det', 5], ['streets', 'NOUN', 4, 'pobj', 6], ['of', 'ADP', 6, 'prep', 7], ['Downtown', 'PROPN', 9, 'compound', 8], ['Miami', 'PROPN', 7, 'pobj', 9], ['in', 'ADP', 6, 'prep', 10], ['Florida', 'PROPN', 12, 'compound', 11], ['#Irma', 'PUNCT', 10, 'pobj', 12]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Miami', 'PROPN', 7, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Miami', 'PROPN', 7, 'pobj', 9]\n",
      "NE parent token:\n",
      "['of', 'ADP', 6, 'prep', 7]\n",
      "NE=Miami subtree=[['Downtown', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "testing NE naples, txt:Still a long way to go but it is looking like #Irma may make landfall between Naples and Fort Myers.\n",
      "full parse [[['Still', 'ADV', 3, 'advmod', 0], ['a', 'DET', 3, 'det', 1], ['long', 'ADJ', 3, 'amod', 2], ['way', 'NOUN', 13, 'nsubj', 3], ['to', 'PART', 5, 'aux', 4], ['go', 'VERB', 3, 'relcl', 5], ['but', 'CCONJ', 3, 'cc', 6], ['it', 'PRON', 9, 'nsubj', 7], ['is', 'VERB', 9, 'aux', 8], ['looking', 'VERB', 3, 'conj', 9], ['like', 'ADP', 9, 'prep', 10], ['#Irma', 'PROPN', 10, 'pobj', 11], ['may', 'VERB', 13, 'aux', 12], ['make', 'VERB', 13, 'ROOT', 13], ['landfall', 'NOUN', 13, 'dobj', 14], ['between', 'ADP', 14, 'prep', 15], ['Naples', 'PROPN', 15, 'pobj', 16], ['and', 'CCONJ', 16, 'cc', 17], ['Fort', 'PROPN', 19, 'compound', 18], ['Myers', 'PROPN', 16, 'conj', 19], ['.', 'PUNCT', 13, 'punct', 20]]]\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = Fort Myers\n",
      "data NE tree=[['Naples', 'PROPN', 15, 'pobj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Naples', 'PROPN', 15, 'pobj', 16]\n",
      "NE parent token:\n",
      "['between', 'ADP', 14, 'prep', 15]\n",
      "NE=Naples subtree=[['and', 'CCONJ', 16, 'cc', 17], ['Fort', 'PROPN', 19, 'compound', 18], ['Myers', 'PROPN', 16, 'conj', 19]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Fort Myers\n",
      "anchor NE candidates = \n",
      "testing NE miami, txt:Pray for Florida as hurricane Irma impacts Miami. #hurricaneirma <URL>\n",
      "full parse [[['Pray', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['Florida', 'PROPN', 1, 'pobj', 2], ['as', 'ADP', 6, 'mark', 3], ['hurricane', 'NOUN', 5, 'compound', 4], ['Irma', 'PROPN', 6, 'nsubj', 5], ['impacts', 'VERB', 0, 'advcl', 6], ['Miami', 'PROPN', 6, 'dobj', 7], ['.', 'PUNCT', 0, 'punct', 8]], [['#hurricaneirma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = \n",
      "testing NE miami, txt:cnnbrk: #HurricaneIrma ’s intense rain and wind pound JohnBerman in Miami. 75% of Miami-Dade County is now without… <URL>\n",
      "full parse [[['cnnbrk', 'X', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['#HurricaneIrma', 'PROPN', 3, 'compound', 2], ['’', 'PROPN', 10, 'poss', 3], ['s', 'PART', 3, 'case', 4], ['intense', 'ADJ', 9, 'amod', 5], ['rain', 'NOUN', 9, 'nmod', 6], ['and', 'CCONJ', 6, 'cc', 7], ['wind', 'NOUN', 6, 'conj', 8], ['pound', 'NOUN', 10, 'compound', 9], ['JohnBerman', 'PROPN', 10, 'ROOT', 10], ['in', 'ADP', 10, 'prep', 11], ['Miami', 'PROPN', 11, 'pobj', 12], ['.', 'PUNCT', 10, 'punct', 13]], [['75', 'NUM', 1, 'nummod', 0], ['%', 'NOUN', 5, 'nsubj', 1], ['of', 'ADP', 1, 'prep', 2], ['MiamiDade', 'PROPN', 4, 'compound', 3], ['County', 'PROPN', 2, 'pobj', 4], ['is', 'VERB', 5, 'ROOT', 5], ['now', 'ADV', 5, 'advmod', 6], ['without', 'ADP', 5, 'prep', 7], ['…', 'PUNCT', 5, 'punct', 8]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Miami-Dade County\n",
      "data NE tree=[['Miami', 'PROPN', 11, 'pobj', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Miami', 'PROPN', 11, 'pobj', 12]\n",
      "NE parent token:\n",
      "['in', 'ADP', 10, 'prep', 11]\n",
      "candidate 1=Miami-Dade County\n",
      "anchor NE candidates = \n",
      "testing NE marco_island, txt:#Irma just made landfall with FL mainland on Marco Island as a Category 3!! @yohoster @GaryBrennan10 @MichaelDillman @MrJShupp @Skena3 <URL>\n",
      "full parse [[['#Irma', 'PROPN', 2, 'nsubj', 0], ['just', 'ADV', 2, 'advmod', 1], ['made', 'VERB', 2, 'ROOT', 2], ['landfall', 'NOUN', 2, 'dobj', 3], ['with', 'ADP', 2, 'prep', 4], ['FL', 'PROPN', 6, 'compound', 5], ['mainland', 'NOUN', 4, 'pobj', 6], ['on', 'ADP', 6, 'prep', 7], ['Marco', 'PROPN', 9, 'compound', 8], ['Island', 'PROPN', 7, 'pobj', 9], ['as', 'ADP', 2, 'prep', 10], ['a', 'DET', 12, 'det', 11], ['Category', 'NOUN', 10, 'pobj', 12], ['3', 'NUM', 12, 'nummod', 13], ['!', 'PUNCT', 2, 'punct', 14], ['!', 'PUNCT', 2, 'punct', 15]], [['@yohoster', 'X', 2, 'compound', 0], ['@GaryBrennan10', 'ADP', 2, 'compound', 1], ['@MichaelDillman', 'X', 3, 'nsubj', 2], ['@MrJShupp', 'PROPN', 3, 'ROOT', 3], ['@Skena3', 'PUNCT', 3, 'punct', 4]]]\n",
      "candidate 0=Marco Island\n",
      "anchor NE candidates = \n",
      "testing NE sunset_terrace, txt:Indian River Dr and Sunset Terrace, Cocoa. Drivers need to use Highview Dr from the south or Forest Hill Dr from the North #Irma <URL>\n",
      "full parse [[['Indian', 'PROPN', 2, 'compound', 0], ['River', 'PROPN', 2, 'compound', 1], ['Dr', 'PROPN', 2, 'ROOT', 2], ['and', 'CCONJ', 2, 'cc', 3], ['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5], ['Cocoa', 'PROPN', 2, 'conj', 6], ['.', 'PUNCT', 2, 'punct', 7]], [['Drivers', 'NOUN', 1, 'nsubj', 0], ['need', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['use', 'VERB', 1, 'xcomp', 3], ['Highview', 'PROPN', 5, 'compound', 4], ['Dr', 'PROPN', 3, 'dobj', 5], ['from', 'ADP', 3, 'prep', 6], ['the', 'DET', 12, 'det', 7], ['south', 'NOUN', 7, 'preconj', 8], ['or', 'CCONJ', 8, 'cc', 9], ['Forest', 'PROPN', 12, 'compound', 10], ['Hill', 'PROPN', 12, 'compound', 11], ['Dr', 'PROPN', 6, 'pobj', 12], ['from', 'ADP', 3, 'prep', 13], ['the', 'DET', 16, 'det', 14], ['North', 'PROPN', 16, 'compound', 15], ['#Irma', 'PUNCT', 13, 'pobj', 16]]]\n",
      "candidate 0=Sunset Terrace\n",
      "anchor NE candidates = Cocoa,Forest Hill\n",
      "data NE tree=[['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Terrace', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['Cocoa', 'PROPN', 2, 'conj', 6]\n",
      "parent node subtree [['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5], ['Cocoa', 'PROPN', 2, 'conj', 6]]\n",
      "parent node subtree str sunset terrace cocoa\n",
      "candidate 1=Cocoa\n",
      "anchor NE candidates = Indian River,Cocoa,Forest Hill\n",
      "data NE tree=[['Cocoa', 'PROPN', 2, 'conj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Cocoa', 'PROPN', 2, 'conj', 6]\n",
      "NE parent token:\n",
      "['Dr', 'PROPN', 2, 'ROOT', 2]\n",
      "NE=Cocoa subtree=[['Sunset', 'PROPN', 6, 'compound', 4], ['Terrace', 'PROPN', 6, 'compound', 5]]\n",
      "min node deps ['compound', 'compound']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE miami-dade, txt:3.3 million in Florida w/o power, 80% of Miami-Dade w/o power #HurricaneIrma\n",
      "full parse [[['3.3', 'NUM', 1, 'compound', 0], ['million', 'NUM', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['Florida', 'PROPN', 2, 'pobj', 3], ['w', 'ADP', 1, 'prep', 4], ['/', 'SYM', 4, 'punct', 5], ['o', 'NOUN', 7, 'dep', 6], ['power', 'NOUN', 4, 'pobj', 7], ['80', 'NUM', 9, 'nummod', 8], ['%', 'NOUN', 1, 'conj', 9], ['of', 'ADP', 9, 'prep', 10], ['MiamiDade', 'PROPN', 10, 'pobj', 11], ['w', 'ADP', 1, 'prep', 12], ['/', 'SYM', 12, 'punct', 13], ['o', 'NOUN', 12, 'pobj', 14], ['power', 'NOUN', 16, 'compound', 15], ['#HurricaneIrma', 'PUNCT', 1, 'appos', 16]]]\n",
      "candidate 0=Miami-Dade\n",
      "anchor NE candidates = \n",
      "testing NE duval, txt:Flash Flood Warning in effect in Clay, Duval, Nassau and St. Johns Counties until 830 AM #flwx #HurricaneIrma <URL>\n",
      "full parse [[['Flash', 'PROPN', 2, 'compound', 0], ['Flood', 'PROPN', 2, 'compound', 1], ['Warning', 'PROPN', 2, 'ROOT', 2], ['in', 'ADP', 2, 'prep', 3], ['effect', 'NOUN', 3, 'pobj', 4], ['in', 'ADP', 2, 'prep', 5], ['Clay', 'PROPN', 8, 'compound', 6], ['Duval', 'PROPN', 8, 'compound', 7], ['Nassau', 'PROPN', 5, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['St', 'PROPN', 8, 'conj', 10], ['.', 'PUNCT', 2, 'punct', 11], ['Johns', 'PROPN', 13, 'compound', 12], ['Counties', 'PROPN', 13, 'ROOT', 13], ['until', 'ADP', 13, 'prep', 14], ['830', 'NUM', 16, 'nummod', 15], ['AM', 'PROPN', 14, 'pobj', 16], ['#flwx', 'PROPN', 16, 'nummod', 17], ['#HurricaneIrma', 'PUNCT', 13, 'appos', 18]]]\n",
      "candidate 0=Duval\n",
      "anchor NE candidates = Nassau\n",
      "data NE tree=[['Duval', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Duval', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Nassau', 'PROPN', 5, 'pobj', 8]\n",
      "parent node subtree [['Clay', 'PROPN', 8, 'compound', 6], ['Duval', 'PROPN', 8, 'compound', 7], ['Nassau', 'PROPN', 5, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['St', 'PROPN', 8, 'conj', 10]]\n",
      "parent node subtree str clay duval nassau and st\n",
      "candidate 1=Nassau\n",
      "anchor NE candidates = \n",
      "testing NE tallahassee, txt:Power outages from my friends in Miami-dade, to Orlando, and now Tallahassee #HurricaneIrma\n",
      "full parse [[['Power', 'NOUN', 1, 'nsubj', 0], ['outages', 'NOUN', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['my', 'ADJ', 4, 'poss', 3], ['friends', 'NOUN', 2, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['Miamidade', 'PROPN', 5, 'pobj', 6], ['to', 'ADP', 1, 'prep', 7], ['Orlando', 'PROPN', 7, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['now', 'ADV', 11, 'advmod', 10], ['Tallahassee', 'PROPN', 8, 'conj', 11], ['#HurricaneIrma', 'PUNCT', 1, 'punct', 12]]]\n",
      "candidate 0=Orlando\n",
      "anchor NE candidates = \n",
      "candidate 1=Tallahassee\n",
      "anchor NE candidates = Orlando\n",
      "data NE tree=[['Tallahassee', 'PROPN', 8, 'conj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Tallahassee', 'PROPN', 8, 'conj', 11]\n",
      "NE parent token:\n",
      "['Orlando', 'PROPN', 7, 'pobj', 8]\n",
      "NE=Tallahassee subtree=[['now', 'ADV', 11, 'advmod', 10]]\n",
      "min node deps ['advmod']\n",
      "testing NE augusta, txt:Irma has arrived in Augusta, Georgia. The power just went out. #hurricaneirma\n",
      "full parse [[['Irma', 'PROPN', 2, 'nsubj', 0], ['has', 'VERB', 2, 'aux', 1], ['arrived', 'VERB', 2, 'ROOT', 2], ['in', 'ADP', 2, 'prep', 3], ['Augusta', 'PROPN', 5, 'compound', 4], ['Georgia', 'PROPN', 3, 'pobj', 5], ['.', 'PUNCT', 2, 'punct', 6]], [['The', 'DET', 1, 'det', 0], ['power', 'NOUN', 3, 'nsubj', 1], ['just', 'ADV', 3, 'advmod', 2], ['went', 'VERB', 3, 'ROOT', 3], ['out', 'PART', 3, 'prt', 4], ['.', 'PUNCT', 3, 'punct', 5]], [['#hurricaneirma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Augusta\n",
      "anchor NE candidates = Georgia\n",
      "data NE tree=[['Augusta', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Augusta', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Georgia', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Augusta', 'PROPN', 5, 'compound', 4], ['Georgia', 'PROPN', 3, 'pobj', 5]]\n",
      "parent node subtree str augusta georgia\n",
      "false positive: NE=augusta, type=compound\n",
      "testing NE beaufort, txt:New tornado warning for parts of Beaufort, Colleton County #Irma #Chswx <URL>\n",
      "full parse [[['New', 'ADJ', 2, 'amod', 0], ['tornado', 'NOUN', 2, 'compound', 1], ['warning', 'NOUN', 2, 'ROOT', 2], ['for', 'ADP', 2, 'prep', 3], ['parts', 'NOUN', 3, 'pobj', 4], ['of', 'ADP', 4, 'prep', 5], ['Beaufort', 'PROPN', 8, 'compound', 6], ['Colleton', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 10, 'compound', 8], ['#Irma', 'PROPN', 10, 'compound', 9], ['#Chswx', 'PROPN', 5, 'pobj', 10]]]\n",
      "candidate 0=Beaufort\n",
      "anchor NE candidates = Colleton County\n",
      "data NE tree=[['Beaufort', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Beaufort', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 10, 'compound', 8]\n",
      "parent node subtree [['Beaufort', 'PROPN', 8, 'compound', 6], ['Colleton', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 10, 'compound', 8]]\n",
      "parent node subtree str beaufort colleton county\n",
      "candidate 1=Colleton County\n",
      "anchor NE candidates = \n",
      "testing NE charleston, txt:Power outages in GA/ flooding in Charleston, SC and Jacksonville. Just a few of the reports today as #Irma moves North. #GAwx #SCwx <URL>\n",
      "full parse [[['Power', 'NOUN', 1, 'nsubj', 0], ['outages', 'NOUN', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['GA', 'PROPN', 2, 'pobj', 3], ['/', 'SYM', 5, 'punct', 4], ['flooding', 'NOUN', 1, 'advcl', 5], ['in', 'ADP', 5, 'prep', 6], ['Charleston', 'PROPN', 8, 'compound', 7], ['SC', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['Jacksonville', 'PROPN', 8, 'conj', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['Just', 'ADV', 2, 'advmod', 0], ['a', 'DET', 2, 'quantmod', 1], ['few', 'ADJ', 2, 'ROOT', 2], ['of', 'ADP', 2, 'prep', 3], ['the', 'DET', 5, 'det', 4], ['reports', 'NOUN', 3, 'pobj', 5], ['today', 'NOUN', 2, 'npadvmod', 6], ['as', 'ADP', 9, 'mark', 7], ['#Irma', 'PROPN', 9, 'nsubj', 8], ['moves', 'VERB', 2, 'advcl', 9], ['North', 'PROPN', 9, 'dobj', 10], ['.', 'PUNCT', 2, 'punct', 11]], [['#GAwx', 'NOUN', 0, 'ROOT', 0], ['#SCwx', 'X', 0, 'intj', 1]]]\n",
      "candidate 0=Charleston\n",
      "anchor NE candidates = \n",
      "candidate 1=Jacksonville\n",
      "anchor NE candidates = GA,SC,Jacksonville\n",
      "data NE tree=[['Jacksonville', 'PROPN', 8, 'conj', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Jacksonville', 'PROPN', 8, 'conj', 10]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 6, 'pobj', 8]\n",
      "testing NE jacksonville, txt:Told someone I was from Cleveland while covering #HurricaneIrma in Jacksonville, FL. First question: What number are the @indians on #19baby\n",
      "full parse [[['Told', 'VERB', 0, 'ROOT', 0], ['someone', 'NOUN', 0, 'dobj', 1], ['I', 'PRON', 3, 'nsubj', 2], ['was', 'VERB', 1, 'relcl', 3], ['from', 'ADP', 3, 'prep', 4], ['Cleveland', 'PROPN', 4, 'pobj', 5], ['while', 'ADP', 7, 'mark', 6], ['covering', 'VERB', 3, 'advcl', 7], ['#HurricaneIrma', 'PUNCT', 7, 'dobj', 8], ['in', 'ADP', 7, 'prep', 9], ['Jacksonville', 'PROPN', 11, 'compound', 10], ['FL', 'PROPN', 9, 'pobj', 11], ['.', 'PUNCT', 0, 'punct', 12]], [['First', 'ADJ', 1, 'amod', 0], ['question', 'NOUN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['What', 'ADJ', 4, 'det', 3], ['number', 'NOUN', 5, 'attr', 4], ['are', 'VERB', 1, 'acl', 5], ['the', 'DET', 7, 'det', 6], ['@indians', 'NOUN', 5, 'nsubj', 7], ['on', 'ADP', 7, 'prep', 8], ['#19baby', 'X', 8, 'pobj', 9]]]\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Jacksonville', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Jacksonville', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 11, 'compound', 10], ['FL', 'PROPN', 9, 'pobj', 11]]\n",
      "parent node subtree str jacksonville fl\n",
      "false positive: NE=jacksonville, type=compound\n",
      "testing NE ocala, txt:#Irma Seeing pockets of heavy traffic SB I-75 from Gainesville thru Ocala as people return to their homes\n",
      "full parse [[['#Irma', 'PROPN', 0, 'ROOT', 0], ['Seeing', 'VERB', 0, 'acl', 1], ['pockets', 'NOUN', 1, 'dobj', 2], ['of', 'ADP', 2, 'prep', 3], ['heavy', 'ADJ', 5, 'amod', 4], ['traffic', 'NOUN', 3, 'pobj', 5], ['SB', 'PROPN', 7, 'compound', 6], ['I75', 'PROPN', 5, 'appos', 7], ['from', 'ADP', 7, 'prep', 8], ['Gainesville', 'PROPN', 8, 'pobj', 9], ['thru', 'ADP', 5, 'prep', 10], ['Ocala', 'PROPN', 10, 'pobj', 11], ['as', 'ADP', 14, 'mark', 12], ['people', 'NOUN', 14, 'nsubj', 13], ['return', 'VERB', 1, 'advcl', 14], ['to', 'ADP', 14, 'prep', 15], ['their', 'ADJ', 17, 'poss', 16], ['homes', 'NOUN', 15, 'pobj', 17]]]\n",
      "candidate 0=Gainesville\n",
      "anchor NE candidates = \n",
      "candidate 1=Ocala\n",
      "anchor NE candidates = Gainesville\n",
      "data NE tree=[['Ocala', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Ocala', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['thru', 'ADP', 5, 'prep', 10]\n",
      "testing NE miami, txt:Volunteers from @MuslimYouthUSA working with @HFUSA in Miami, Tampa, Naples and Jacksonville doing #HurricaneIrma cleanup work <URL>\n",
      "full parse [[['Volunteers', 'NOUN', 12, 'nsubj', 0], ['from', 'ADP', 0, 'prep', 1], ['@MuslimYouthUSA', 'PROPN', 1, 'pobj', 2], ['working', 'VERB', 0, 'acl', 3], ['with', 'ADP', 3, 'prep', 4], ['@HFUSA', 'PROPN', 4, 'pobj', 5], ['in', 'ADP', 3, 'prep', 6], ['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['Naples', 'PROPN', 6, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11], ['doing', 'VERB', 12, 'ROOT', 12], ['#HurricaneIrma', 'PROPN', 14, 'compound', 13], ['cleanup', 'NOUN', 15, 'compound', 14], ['work', 'NOUN', 12, 'dobj', 15]]]\n",
      "candidate 0=Miami\n",
      "anchor NE candidates = Jacksonville\n",
      "data NE tree=[['Miami', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Miami', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Naples', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['Naples', 'PROPN', 6, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "parent node subtree str miami tampa naples and jacksonville\n",
      "candidate 1=Tampa\n",
      "anchor NE candidates = Miami,Jacksonville\n",
      "data NE tree=[['Tampa', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Tampa', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['Naples', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['Naples', 'PROPN', 6, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "parent node subtree str miami tampa naples and jacksonville\n",
      "candidate 2=Naples\n",
      "anchor NE candidates = Miami,Tampa,Jacksonville\n",
      "data NE tree=[['Naples', 'PROPN', 6, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Naples', 'PROPN', 6, 'pobj', 9]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 6]\n",
      "NE=Naples subtree=[['Miami', 'PROPN', 9, 'compound', 7], ['Tampa', 'PROPN', 9, 'compound', 8], ['and', 'CCONJ', 9, 'cc', 10], ['Jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "min node deps ['compound', 'compound', 'cc', 'conj']\n",
      "candidate 3=Jacksonville\n",
      "anchor NE candidates = \n",
      "testing NE sarasota_county, txt:Sarasota County have been very fortunate, that hurricane #Irma did not impact our area as much as it did to other counties in Florida.\n",
      "full parse [[['Sarasota', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'nsubj', 1], ['have', 'VERB', 3, 'aux', 2], ['been', 'VERB', 3, 'ROOT', 3], ['very', 'ADV', 5, 'advmod', 4], ['fortunate', 'ADJ', 3, 'acomp', 5], ['that', 'ADP', 11, 'mark', 6], ['hurricane', 'NOUN', 8, 'compound', 7], ['#Irma', 'PROPN', 11, 'nsubj', 8], ['did', 'VERB', 11, 'aux', 9], ['not', 'ADV', 11, 'neg', 10], ['impact', 'VERB', 3, 'ccomp', 11], ['our', 'ADJ', 13, 'poss', 12], ['area', 'NOUN', 11, 'dobj', 13], ['as', 'ADV', 15, 'advmod', 14], ['much', 'ADV', 11, 'advmod', 15], ['as', 'ADP', 18, 'mark', 16], ['it', 'PRON', 18, 'nsubj', 17], ['did', 'VERB', 15, 'advcl', 18], ['to', 'ADP', 11, 'prep', 19], ['other', 'ADJ', 21, 'amod', 20], ['counties', 'NOUN', 19, 'pobj', 21], ['in', 'ADP', 21, 'prep', 22], ['Florida', 'PROPN', 22, 'pobj', 23], ['.', 'PUNCT', 3, 'punct', 24]]]\n",
      "candidate 0=Sarasota County\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Sarasota', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['County', 'PROPN', 3, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['been', 'VERB', 3, 'ROOT', 3]\n",
      "testing NE naples, txt:Day 5 no power, limited gas after #hurricaneirma came across us in Naples, FL. Hoping and praying we get power soon. We are safe\n",
      "full parse [[['Day', 'NOUN', 5, 'nmod', 0], ['5', 'NUM', 0, 'nummod', 1], ['no', 'DET', 5, 'det', 2], ['power', 'NOUN', 5, 'nmod', 3], ['limited', 'VERB', 5, 'amod', 4], ['gas', 'NOUN', 8, 'nsubj', 5], ['after', 'ADP', 5, 'prep', 6], ['#hurricaneirma', 'PROPN', 6, 'pobj', 7], ['came', 'VERB', 8, 'ROOT', 8], ['across', 'ADP', 8, 'prep', 9], ['us', 'PRON', 9, 'pobj', 10], ['in', 'ADP', 8, 'prep', 11], ['Naples', 'PROPN', 13, 'compound', 12], ['FL', 'PROPN', 11, 'pobj', 13], ['.', 'PUNCT', 8, 'punct', 14]], [['Hoping', 'VERB', 0, 'ROOT', 0], ['and', 'CCONJ', 0, 'cc', 1], ['praying', 'VERB', 0, 'conj', 2], ['we', 'PRON', 4, 'nsubj', 3], ['get', 'VERB', 2, 'ccomp', 4], ['power', 'NOUN', 4, 'dobj', 5], ['soon', 'ADV', 4, 'advmod', 6], ['.', 'PUNCT', 0, 'punct', 7]], [['We', 'PRON', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['safe', 'ADJ', 1, 'acomp', 2]]]\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Naples', 'PROPN', 13, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Naples', 'PROPN', 13, 'compound', 12]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 11, 'pobj', 13]\n",
      "parent node subtree [['Naples', 'PROPN', 13, 'compound', 12], ['FL', 'PROPN', 11, 'pobj', 13]]\n",
      "parent node subtree str naples fl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive: NE=naples, type=compound\n",
      "testing NE lake, txt:@mitchellreports We have major destruction in Polk County Florida. Including Lakeland, bartow,Lake Whales. No power. #Irma\n",
      "full parse [[['@mitchellreports', 'INTJ', 0, 'ROOT', 0], ['We', 'PRON', 2, 'nsubj', 1], ['have', 'VERB', 2, 'ROOT', 2], ['major', 'ADJ', 4, 'amod', 3], ['destruction', 'NOUN', 2, 'dobj', 4], ['in', 'ADP', 4, 'prep', 5], ['Polk', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 8, 'compound', 7], ['Florida', 'PROPN', 5, 'pobj', 8], ['.', 'PUNCT', 2, 'punct', 9]], [['Including', 'VERB', 0, 'ROOT', 0], ['Lakeland', 'PROPN', 3, 'compound', 1], ['bartowLake', 'PROPN', 3, 'compound', 2], ['Whales', 'PROPN', 0, 'pobj', 3], ['.', 'PUNCT', 0, 'punct', 4]], [['No', 'DET', 1, 'det', 0], ['power', 'NOUN', 1, 'ROOT', 1], ['.', 'PUNCT', 1, 'punct', 2]], [['#Irma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Lakeland\n",
      "anchor NE candidates = \n",
      "candidate 1=Lake\n",
      "anchor NE candidates = Lakeland\n",
      "testing NE pembroke_park, txt:Update on lifting of boil water alert for Hollywood, Pembroke park, Miramar, West Park & Dania Beach. #Irma <URL>\n",
      "full parse [[['Update', 'NOUN', 0, 'ROOT', 0], ['on', 'ADP', 0, 'prep', 1], ['lifting', 'NOUN', 1, 'pobj', 2], ['of', 'ADP', 2, 'prep', 3], ['boil', 'NOUN', 5, 'compound', 4], ['water', 'NOUN', 6, 'compound', 5], ['alert', 'NOUN', 3, 'pobj', 6], ['for', 'ADP', 2, 'prep', 7], ['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['West', 'PROPN', 13, 'compound', 12], ['Park', 'PROPN', 7, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16], ['.', 'PUNCT', 0, 'punct', 17]], [['#Irma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Hollywood\n",
      "anchor NE candidates = \n",
      "candidate 1=Pembroke park\n",
      "anchor NE candidates = Hollywood,Miramar,West Park,Dania Beach\n",
      "data NE tree=[['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['park', 'NOUN', 13, 'compound', 10]\n",
      "NE parent token:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "parent node subtree [['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['West', 'PROPN', 13, 'compound', 12], ['Park', 'PROPN', 7, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "parent node subtree str hollywood pembroke park miramar west park & dania beach\n",
      "NE=Pembroke park subtree=[['Hollywood', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Miramar\n",
      "anchor NE candidates = Hollywood\n",
      "data NE tree=[['Miramar', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Miramar', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "parent node subtree [['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['West', 'PROPN', 13, 'compound', 12], ['Park', 'PROPN', 7, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "parent node subtree str hollywood pembroke park miramar west park & dania beach\n",
      "candidate 3=West Park\n",
      "anchor NE candidates = Hollywood,Miramar,Dania Beach\n",
      "data NE tree=[['West', 'PROPN', 13, 'compound', 12], ['Park', 'PROPN', 7, 'pobj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "NE parent token:\n",
      "['for', 'ADP', 2, 'prep', 7]\n",
      "NE=West Park subtree=[['Hollywood', 'PROPN', 9, 'compound', 8], ['Pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['Miramar', 'PROPN', 13, 'compound', 11], ['&', 'CCONJ', 13, 'cc', 14], ['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "min node deps ['compound']\n",
      "candidate 4=Dania Beach\n",
      "anchor NE candidates = Hollywood,Miramar\n",
      "data NE tree=[['Dania', 'PROPN', 16, 'compound', 15], ['Beach', 'PROPN', 13, 'conj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Beach', 'PROPN', 13, 'conj', 16]\n",
      "NE parent token:\n",
      "['Park', 'PROPN', 7, 'pobj', 13]\n",
      "testing NE clearwater, txt:@andersoncooper #HurricaneIrma Glad to have you in Tampa. I was in Clearwater riding out the storm-I wanted to race to Tampa to meet you.\n",
      "full parse [[['@andersoncooper', 'X', 2, 'meta', 0], ['#HurricaneIrma', 'PUNCT', 2, 'dep', 1], ['Glad', 'PROPN', 2, 'ROOT', 2], ['to', 'PART', 4, 'aux', 3], ['have', 'VERB', 2, 'xcomp', 4], ['you', 'PRON', 4, 'dobj', 5], ['in', 'ADP', 4, 'prep', 6], ['Tampa', 'PROPN', 6, 'pobj', 7], ['.', 'PUNCT', 2, 'punct', 8]], [['I', 'PRON', 1, 'nsubj', 0], ['was', 'VERB', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['Clearwater', 'PROPN', 2, 'pobj', 3], ['riding', 'VERB', 3, 'acl', 4], ['out', 'PART', 4, 'prt', 5], ['the', 'DET', 7, 'det', 6], ['stormI', 'NOUN', 4, 'dobj', 7], ['wanted', 'VERB', 1, 'advcl', 8], ['to', 'PART', 10, 'aux', 9], ['race', 'VERB', 8, 'xcomp', 10], ['to', 'ADP', 10, 'prep', 11], ['Tampa', 'PROPN', 11, 'pobj', 12], ['to', 'PART', 14, 'aux', 13], ['meet', 'VERB', 10, 'advcl', 14], ['you', 'PRON', 14, 'dobj', 15], ['.', 'PUNCT', 1, 'punct', 16]]]\n",
      "candidate 0=Tampa\n",
      "anchor NE candidates = \n",
      "candidate 1=Clearwater\n",
      "anchor NE candidates = Tampa,Tampa\n",
      "data NE tree=[['Clearwater', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Clearwater', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "NE=Clearwater subtree=[['riding', 'VERB', 3, 'acl', 4], ['out', 'PART', 4, 'prt', 5], ['the', 'DET', 7, 'det', 6], ['stormI', 'NOUN', 4, 'dobj', 7]]\n",
      "min node deps ['acl']\n",
      "subtree = riding out the stormI\n",
      "candidate 2=Tampa\n",
      "anchor NE candidates = \n",
      "testing NE houston, txt:Emotional homecoming for our 80-person AZ TaskForce 1. First deployed for search & rescue in Houston for #Harvey then to Florida for #Irma . <URL>\n",
      "full parse [[['Emotional', 'ADJ', 1, 'amod', 0], ['homecoming', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['our', 'ADJ', 6, 'poss', 3], ['80person', 'NUM', 6, 'compound', 4], ['AZ', 'PROPN', 6, 'compound', 5], ['TaskForce', 'PROPN', 2, 'pobj', 6], ['1', 'NUM', 6, 'nummod', 7], ['.', 'PUNCT', 1, 'punct', 8]], [['First', 'ADV', 1, 'advmod', 0], ['deployed', 'VERB', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['search', 'NOUN', 2, 'pobj', 3], ['&', 'CCONJ', 3, 'cc', 4], ['rescue', 'NOUN', 3, 'conj', 5], ['in', 'ADP', 3, 'prep', 6], ['Houston', 'PROPN', 6, 'pobj', 7], ['for', 'ADP', 3, 'prep', 8], ['#Harvey', 'PROPN', 8, 'pobj', 9], ['then', 'ADV', 1, 'advmod', 10], ['to', 'ADP', 1, 'prep', 11], ['Florida', 'PROPN', 11, 'pobj', 12], ['for', 'ADP', 1, 'prep', 13], ['#Irma', 'PROPN', 13, 'pobj', 14], ['.', 'PUNCT', 1, 'punct', 15]]]\n",
      "candidate 0=Houston\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Houston', 'PROPN', 6, 'pobj', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['Houston', 'PROPN', 6, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 6]\n",
      "testing NE naples, txt:The Status of Our Parks - Along the Gulfshore - September 2017 - Naples, FL #HurricaneIrma <URL>\n",
      "full parse [[['The', 'DET', 1, 'det', 0], ['Status', 'PROPN', 1, 'ROOT', 1], ['of', 'ADP', 1, 'prep', 2], ['Our', 'ADJ', 4, 'poss', 3], ['Parks', 'PROPN', 2, 'pobj', 4], ['Along', 'ADP', 1, 'prep', 5], ['the', 'DET', 7, 'det', 6], ['Gulfshore', 'PROPN', 5, 'pobj', 7], ['September', 'PROPN', 1, 'npadvmod', 8], ['2017', 'NUM', 8, 'nummod', 9], ['Naples', 'PROPN', 11, 'compound', 10], ['FL', 'PROPN', 12, 'compound', 11], ['#HurricaneIrma', 'PUNCT', 8, 'appos', 12]]]\n",
      "candidate 0=Naples\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Naples', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Naples', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 12, 'compound', 11]\n",
      "parent node subtree [['Naples', 'PROPN', 11, 'compound', 10], ['FL', 'PROPN', 12, 'compound', 11]]\n",
      "parent node subtree str naples fl\n",
      "false positive: NE=naples, type=compound\n",
      "testing NE vieques, txt:A Hurricane Warning has been issued for Puerto Rico, Culebra, and Vieques. #Maria <URL>\n",
      "full parse [[['A', 'DET', 2, 'det', 0], ['Hurricane', 'PROPN', 2, 'compound', 1], ['Warning', 'PROPN', 5, 'nsubjpass', 2], ['has', 'VERB', 5, 'aux', 3], ['been', 'VERB', 5, 'auxpass', 4], ['issued', 'VERB', 5, 'ROOT', 5], ['for', 'ADP', 5, 'prep', 6], ['Puerto', 'PROPN', 9, 'compound', 7], ['Rico', 'PROPN', 9, 'compound', 8], ['Culebra', 'PROPN', 6, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['Vieques', 'PROPN', 9, 'conj', 11], ['.', 'PUNCT', 5, 'punct', 12]], [['#Maria', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=Vieques\n",
      "anchor NE candidates = \n",
      "testing NE san_juan, txt:first band of #maria in San Juan , Puerto Rico <URL>\n",
      "full parse [[['first', 'ADJ', 1, 'amod', 0], ['band', 'NOUN', 1, 'ROOT', 1], ['of', 'ADP', 1, 'prep', 2], ['#maria', 'NOUN', 2, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6], ['Puerto', 'PROPN', 8, 'compound', 7], ['Rico', 'PROPN', 4, 'pobj', 8]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Juan', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 4, 'pobj', 8]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6], ['Puerto', 'PROPN', 8, 'compound', 7], ['Rico', 'PROPN', 4, 'pobj', 8]]\n",
      "parent node subtree str san juan puerto rico\n",
      "false positive: NE=san_juan, type=compound\n",
      "testing NE culebra, txt:#Hurricane warnings for: U.S. Virgin Islands, British Virgin Islands, Puerto Rico, Culebra, and Vieques #Maria @680NEWS @680NEWS\n",
      "full parse [[['#Hurricane', 'X', 1, 'compound', 0], ['warnings', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], [':', 'PUNCT', 2, 'punct', 3], ['U', 'NOUN', 2, 'pobj', 4], ['.', 'PUNCT', 1, 'punct', 5], ['S', 'NOUN', 6, 'ROOT', 6], ['.', 'PUNCT', 6, 'punct', 7], ['Virgin', 'PROPN', 9, 'compound', 8], ['Islands', 'PROPN', 12, 'compound', 9], ['British', 'ADJ', 12, 'amod', 10], ['Virgin', 'PROPN', 12, 'compound', 11], ['Islands', 'PROPN', 15, 'compound', 12], ['Puerto', 'PROPN', 15, 'compound', 13], ['Rico', 'PROPN', 15, 'compound', 14], ['Culebra', 'PROPN', 15, 'ROOT', 15], ['and', 'CCONJ', 15, 'cc', 16], ['Vieques', 'PROPN', 18, 'compound', 17], ['#Maria', 'X', 15, 'conj', 18], ['@680NEWS', 'PROPN', 19, 'ROOT', 19], ['@680NEWS', 'PROPN', 19, 'punct', 20]]]\n",
      "candidate 0=Culebra\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Culebra', 'PROPN', 15, 'ROOT', 15]]\n",
      "NE=Culebra subtree=[['Virgin', 'PROPN', 9, 'compound', 8], ['Islands', 'PROPN', 12, 'compound', 9], ['British', 'ADJ', 12, 'amod', 10], ['Virgin', 'PROPN', 12, 'compound', 11], ['Islands', 'PROPN', 15, 'compound', 12], ['Puerto', 'PROPN', 15, 'compound', 13], ['Rico', 'PROPN', 15, 'compound', 14], ['and', 'CCONJ', 15, 'cc', 16], ['Vieques', 'PROPN', 18, 'compound', 17], ['#Maria', 'X', 15, 'conj', 18]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Vieques\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Vieques', 'PROPN', 18, 'compound', 17]]\n",
      "NE parse token at tree=0, token=18:\n",
      "['Vieques', 'PROPN', 18, 'compound', 17]\n",
      "NE parent token:\n",
      "['#Maria', 'X', 15, 'conj', 18]\n",
      "parent node subtree [['Vieques', 'PROPN', 18, 'compound', 17], ['#Maria', 'X', 15, 'conj', 18]]\n",
      "parent node subtree str vieques #maria\n",
      "testing NE ponce, txt:This is how Ponce, Puerto Rico looked about 30 mins ago. #Maria <URL>\n",
      "full parse [[['This', 'DET', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['how', 'ADV', 6, 'advmod', 2], ['Ponce', 'PROPN', 5, 'compound', 3], ['Puerto', 'PROPN', 5, 'compound', 4], ['Rico', 'PROPN', 6, 'nsubj', 5], ['looked', 'VERB', 1, 'ccomp', 6], ['about', 'ADV', 8, 'advmod', 7], ['30', 'NUM', 9, 'nummod', 8], ['mins', 'NOUN', 10, 'npadvmod', 9], ['ago', 'ADV', 6, 'advmod', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['#Maria', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=Ponce\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Ponce', 'PROPN', 5, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Ponce', 'PROPN', 5, 'compound', 3]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 6, 'nsubj', 5]\n",
      "parent node subtree [['Ponce', 'PROPN', 5, 'compound', 3], ['Puerto', 'PROPN', 5, 'compound', 4], ['Rico', 'PROPN', 6, 'nsubj', 5]]\n",
      "parent node subtree str ponce puerto rico\n",
      "false positive: NE=ponce, type=compound\n",
      "testing NE yabucoa, txt:RT @hurrtrackerapp: BREAKING: Hurricane #Maria makes landfall near Yabucoa, Puerto Rico as a 155 mph, category 4 storm. <URL>\n",
      "full parse [[['RT', 'PROPN', 1, 'compound', 0], ['@hurrtrackerapp', 'PROPN', 7, 'dep', 1], [':', 'PUNCT', 7, 'punct', 2], ['BREAKING', 'VERB', 7, 'ccomp', 3], [':', 'PUNCT', 7, 'punct', 4], ['Hurricane', 'PROPN', 6, 'compound', 5], ['#Maria', 'PUNCT', 7, 'nsubj', 6], ['makes', 'VERB', 7, 'ROOT', 7], ['landfall', 'NOUN', 7, 'dobj', 8], ['near', 'ADP', 8, 'prep', 9], ['Yabucoa', 'PROPN', 12, 'compound', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 9, 'pobj', 12], ['as', 'ADP', 7, 'prep', 13], ['a', 'DET', 17, 'det', 14], ['155', 'NUM', 16, 'nummod', 15], ['mph', 'NOUN', 17, 'compound', 16], ['category', 'NOUN', 13, 'pobj', 17], ['4', 'NUM', 19, 'nummod', 18], ['storm', 'NOUN', 17, 'appos', 19], ['.', 'PUNCT', 7, 'punct', 20]]]\n",
      "candidate 0=Yabucoa\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Yabucoa', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Yabucoa', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Yabucoa', 'PROPN', 12, 'compound', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 9, 'pobj', 12]]\n",
      "parent node subtree str yabucoa puerto rico\n",
      "false positive: NE=yabucoa, type=compound\n",
      "testing NE yabucoa, txt:Went to Humacao, Yabucoa and Vieques multiple times in the mid-aughts. So scary to watch Maria right now #puertorico\n",
      "full parse [[['Went', 'VERB', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['Humacao', 'PROPN', 3, 'compound', 2], ['Yabucoa', 'PROPN', 1, 'pobj', 3], ['and', 'CCONJ', 3, 'cc', 4], ['Vieques', 'PROPN', 3, 'conj', 5], ['multiple', 'ADJ', 7, 'amod', 6], ['times', 'NOUN', 0, 'npadvmod', 7], ['in', 'ADP', 7, 'prep', 8], ['the', 'DET', 10, 'det', 9], ['midaughts', 'NOUN', 8, 'pobj', 10], ['.', 'PUNCT', 0, 'punct', 11]], [['So', 'ADV', 1, 'advmod', 0], ['scary', 'ADJ', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['watch', 'VERB', 1, 'xcomp', 3], ['Maria', 'PROPN', 3, 'dobj', 4], ['right', 'ADV', 6, 'advmod', 5], ['now', 'ADV', 3, 'advmod', 6], ['#puertorico', 'PUNCT', 7, 'ROOT', 7]]]\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 1, 'pobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Yabucoa', 'PROPN', 1, 'pobj', 3]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "NE=Yabucoa subtree=[['Humacao', 'PROPN', 3, 'compound', 2], ['and', 'CCONJ', 3, 'cc', 4], ['Vieques', 'PROPN', 3, 'conj', 5]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 2=Vieques\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Vieques', 'PROPN', 3, 'conj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Vieques', 'PROPN', 3, 'conj', 5]\n",
      "NE parent token:\n",
      "['Yabucoa', 'PROPN', 1, 'pobj', 3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE yabucoa, txt:Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "full parse [[['Aviso', 'NOUN', 11, 'nsubj', 0], ['de', 'ADP', 2, 'case', 1], ['Inundaciones', 'PROPN', 0, 'nmod', 2], ['Repentinas', 'PROPN', 2, 'flat', 3], ['extendida', 'ADJ', 0, 'amod', 4], ['para', 'ADP', 6, 'case', 5], ['Humacao', 'PROPN', 4, 'obl', 6], ['Arroyo', 'PROPN', 6, 'flat', 7], ['Yabucoa', 'PROPN', 6, 'flat', 8], ['Maunabo', 'PROPN', 6, 'flat', 9], ['Patillas', 'PROPN', 6, 'flat', 10], ['#prwx', 'PROPN', 11, 'ROOT', 11], ['#Maria', 'ADJ', 11, 'obj', 12]]]\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 6, 'flat', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Yabucoa', 'PROPN', 6, 'flat', 8]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 4, 'obl', 6]\n",
      "candidate 2=Maunabo\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Maunabo', 'PROPN', 6, 'flat', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Maunabo', 'PROPN', 6, 'flat', 9]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 4, 'obl', 6]\n",
      "testing NE yabucoa, txt:NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria — NWS San Juan (NWSS…\n",
      "full parse [[['NWSSanJuan', 'NOUN', 13, 'nsubj', 0], [':', 'PUNCT', 2, 'punct', 1], ['Aviso', 'NOUN', 13, 'nsubj', 2], ['de', 'ADP', 4, 'case', 3], ['Inundaciones', 'PROPN', 2, 'nmod', 4], ['Repentinas', 'PROPN', 4, 'flat', 5], ['extendida', 'ADJ', 2, 'amod', 6], ['para', 'ADP', 8, 'case', 7], ['Humacao', 'PROPN', 6, 'obl', 8], ['Arroyo', 'PROPN', 8, 'flat', 9], ['Yabucoa', 'PROPN', 8, 'flat', 10], ['Maunabo', 'PROPN', 8, 'flat', 11], ['Patillas', 'PROPN', 8, 'flat', 12], ['#prwx', 'PROPN', 13, 'ROOT', 13], ['#Maria', 'ADJ', 13, 'obj', 14], ['—', 'PUNCT', 13, 'punct', 15], ['NWS', 'PROPN', 13, 'obj', 16], ['San', 'PROPN', 16, 'flat', 17], ['Juan', 'PROPN', 16, 'flat', 18], ['(', 'PUNCT', 20, 'punct', 19], ['NWSS', 'PROPN', 16, 'flat', 20], ['…', 'PUNCT', 20, 'punct', 21]]]\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 8, 'flat', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Yabucoa', 'PROPN', 8, 'flat', 10]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 6, 'obl', 8]\n",
      "candidate 2=Maunabo\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Maunabo', 'PROPN', 8, 'flat', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Maunabo', 'PROPN', 8, 'flat', 11]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 6, 'obl', 8]\n",
      "testing NE san_juan, txt:Anyone having luck connecting with San Juan, Puerto Rico? Are your texts going through? #PuertoRico #SanJuan #HurricaneMaria\n",
      "full parse [[['Anyone', 'NOUN', 0, 'ROOT', 0], ['having', 'VERB', 0, 'acl', 1], ['luck', 'NOUN', 1, 'dobj', 2], ['connecting', 'VERB', 2, 'acl', 3], ['with', 'ADP', 3, 'prep', 4], ['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6], ['Puerto', 'PROPN', 8, 'compound', 7], ['Rico', 'PROPN', 4, 'pobj', 8], ['?', 'PUNCT', 0, 'punct', 9]], [['Are', 'VERB', 0, 'ROOT', 0], ['your', 'ADJ', 2, 'poss', 1], ['texts', 'NOUN', 0, 'attr', 2], ['going', 'VERB', 2, 'acl', 3], ['through', 'ADV', 3, 'prt', 4], ['?', 'PUNCT', 0, 'punct', 5]], [['#PuertoRico', 'PROPN', 0, 'ROOT', 0], ['#SanJuan', 'PROPN', 2, 'compound', 1], ['#HurricaneMaria', 'PROPN', 0, 'dobj', 2]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Juan', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 4, 'pobj', 8]\n",
      "parent node subtree [['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 8, 'compound', 6], ['Puerto', 'PROPN', 8, 'compound', 7], ['Rico', 'PROPN', 4, 'pobj', 8]]\n",
      "parent node subtree str san juan puerto rico\n",
      "false positive: NE=san_juan, type=compound\n",
      "testing NE guayama, txt:#Maria ... footage from Guayama, Puerto Rico #huracanmaria #hurricanemaria <URL>\n",
      "full parse [[['#Maria', 'PUNCT', 0, 'ROOT', 0], ['...', 'PUNCT', 0, 'punct', 1], ['footage', 'NOUN', 0, 'appos', 2], ['from', 'ADP', 2, 'prep', 3], ['Guayama', 'PROPN', 6, 'compound', 4], ['Puerto', 'PROPN', 6, 'compound', 5], ['Rico', 'PROPN', 3, 'pobj', 6], ['#huracanmaria', 'PROPN', 7, 'ROOT', 7], ['#hurricanemaria', 'PROPN', 8, 'ROOT', 8]]]\n",
      "candidate 0=Guayama\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Guayama', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Guayama', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 3, 'pobj', 6]\n",
      "parent node subtree [['Guayama', 'PROPN', 6, 'compound', 4], ['Puerto', 'PROPN', 6, 'compound', 5], ['Rico', 'PROPN', 3, 'pobj', 6]]\n",
      "parent node subtree str guayama puerto rico\n",
      "false positive: NE=guayama, type=compound\n",
      "testing NE san_juan, txt:UPDATE: Our San Juan office remains closed today as Puerto Rico is in a state of total devastation after #HurricaneMaria @NWSSanJuan\n",
      "full parse [[['UPDATE', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['Our', 'ADJ', 5, 'poss', 2], ['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 5, 'compound', 4], ['office', 'NOUN', 6, 'nsubj', 5], ['remains', 'VERB', 0, 'acl', 6], ['closed', 'VERB', 6, 'acomp', 7], ['today', 'NOUN', 7, 'npadvmod', 8], ['as', 'ADP', 12, 'mark', 9], ['Puerto', 'PROPN', 11, 'compound', 10], ['Rico', 'PROPN', 12, 'nsubj', 11], ['is', 'VERB', 7, 'advcl', 12], ['in', 'ADP', 12, 'prep', 13], ['a', 'DET', 15, 'det', 14], ['state', 'NOUN', 13, 'pobj', 15], ['of', 'ADP', 15, 'prep', 16], ['total', 'ADJ', 18, 'amod', 17], ['devastation', 'NOUN', 16, 'pobj', 18], ['after', 'ADP', 12, 'prep', 19], ['#HurricaneMaria', 'PROPN', 21, 'compound', 20], ['@NWSSanJuan', 'PROPN', 19, 'pobj', 21]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Juan', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['office', 'NOUN', 6, 'nsubj', 5]\n",
      "parent node subtree [['Our', 'ADJ', 5, 'poss', 2], ['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 5, 'compound', 4], ['office', 'NOUN', 6, 'nsubj', 5]]\n",
      "parent node subtree str our san juan office\n",
      "testing NE san_sebastian, txt:My heart & prayers are w/ my family in Puerto Rico. Aguadilla, Moca, San Sebastian, San Lorenzo & Mayaguez. ! #PuertoRicoStrong #PuertoRico\n",
      "full parse [[['My', 'ADJ', 1, 'poss', 0], ['heart', 'NOUN', 4, 'nsubj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['prayers', 'NOUN', 1, 'conj', 3], ['are', 'VERB', 4, 'ROOT', 4], ['w', 'ADP', 4, 'dep', 5], ['/', 'SYM', 5, 'punct', 6], ['my', 'ADJ', 8, 'poss', 7], ['family', 'NOUN', 5, 'pobj', 8], ['in', 'ADP', 8, 'prep', 9], ['Puerto', 'PROPN', 11, 'compound', 10], ['Rico', 'PROPN', 9, 'pobj', 11], ['.', 'PUNCT', 4, 'punct', 12]], [['Aguadilla', 'PROPN', 1, 'compound', 0], ['Moca', 'PROPN', 5, 'compound', 1], ['San', 'PROPN', 3, 'compound', 2], ['Sebastian', 'PROPN', 5, 'compound', 3], ['San', 'PROPN', 5, 'compound', 4], ['Lorenzo', 'PROPN', 5, 'ROOT', 5], ['&', 'CCONJ', 5, 'cc', 6], ['Mayaguez', 'PROPN', 5, 'conj', 7], ['.', 'PUNCT', 5, 'punct', 8]], [['!', 'PUNCT', 0, 'ROOT', 0]], [['#PuertoRicoStrong', 'X', 1, 'advmod', 0], ['#PuertoRico', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=San Sebastian\n",
      "anchor NE candidates = \n",
      "candidate 1=San Lorenzo\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 5, 'compound', 4], ['Lorenzo', 'PROPN', 5, 'ROOT', 5]]\n",
      "NE=San Lorenzo subtree=[['Aguadilla', 'PROPN', 1, 'compound', 0], ['Moca', 'PROPN', 5, 'compound', 1], ['San', 'PROPN', 3, 'compound', 2], ['Sebastian', 'PROPN', 5, 'compound', 3], ['&', 'CCONJ', 5, 'cc', 6], ['Mayaguez', 'PROPN', 5, 'conj', 7], ['.', 'PUNCT', 5, 'punct', 8]]\n",
      "min node deps ['compound']\n",
      "testing NE san_juan, txt:Hurricane #Maria batters San Juan, Puerto Rico, with strong winds as the powerful storm comes ashore. <URL>\n",
      "full parse [[['Hurricane', 'PROPN', 1, 'compound', 0], ['#Maria', 'X', 2, 'nsubj', 1], ['batters', 'NOUN', 2, 'ROOT', 2], ['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 6, 'compound', 4], ['Puerto', 'PROPN', 6, 'compound', 5], ['Rico', 'PROPN', 2, 'dobj', 6], ['with', 'ADP', 2, 'prep', 7], ['strong', 'ADJ', 9, 'amod', 8], ['winds', 'NOUN', 7, 'pobj', 9], ['as', 'ADP', 14, 'mark', 10], ['the', 'DET', 13, 'det', 11], ['powerful', 'ADJ', 13, 'amod', 12], ['storm', 'NOUN', 14, 'nsubj', 13], ['comes', 'VERB', 2, 'advcl', 14], ['ashore', 'ADV', 14, 'advmod', 15], ['.', 'PUNCT', 2, 'punct', 16]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Juan', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 2, 'dobj', 6]\n",
      "parent node subtree [['San', 'PROPN', 4, 'compound', 3], ['Juan', 'PROPN', 6, 'compound', 4], ['Puerto', 'PROPN', 6, 'compound', 5], ['Rico', 'PROPN', 2, 'dobj', 6]]\n",
      "parent node subtree str san juan puerto rico\n",
      "false positive: NE=san_juan, type=compound\n",
      "testing NE san_juan, txt:Incredible video from earlier today of the strong winds and flooded road in San Juan, Puerto Rico. #Maria : @TheHungryCondor <URL>\n",
      "full parse [[['Incredible', 'ADJ', 1, 'amod', 0], ['video', 'NOUN', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['earlier', 'ADJ', 4, 'amod', 3], ['today', 'NOUN', 2, 'pobj', 4], ['of', 'ADP', 2, 'prep', 5], ['the', 'DET', 8, 'det', 6], ['strong', 'ADJ', 8, 'amod', 7], ['winds', 'NOUN', 5, 'pobj', 8], ['and', 'CCONJ', 1, 'cc', 9], ['flooded', 'VERB', 11, 'amod', 10], ['road', 'NOUN', 1, 'conj', 11], ['in', 'ADP', 11, 'prep', 12], ['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15], ['Rico', 'PROPN', 12, 'pobj', 16], ['.', 'PUNCT', 1, 'punct', 17]], [['#Maria', 'PUNCT', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['@TheHungryCondor', 'X', 0, 'appos', 2]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Juan', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 12, 'pobj', 16]\n",
      "parent node subtree [['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15], ['Rico', 'PROPN', 12, 'pobj', 16]]\n",
      "parent node subtree str san juan puerto rico\n",
      "false positive: NE=san_juan, type=compound\n",
      "testing NE yabucoa, txt:RT @NWSSanJuan: Aviso de Inundaciones Repentinas extendida para Humacao, Arroyo, Yabucoa, Maunabo, Patillas #prwx #Maria\n",
      "full parse [[['RT', 'NOUN', 14, 'nsubj', 0], ['@NWSSanJuan', 'PUNCT', 0, 'flat', 1], [':', 'PUNCT', 3, 'punct', 2], ['Aviso', 'NOUN', 14, 'nsubj', 3], ['de', 'ADP', 5, 'case', 4], ['Inundaciones', 'PROPN', 3, 'flat', 5], ['Repentinas', 'PROPN', 5, 'flat', 6], ['extendida', 'ADJ', 3, 'amod', 7], ['para', 'ADP', 9, 'case', 8], ['Humacao', 'PROPN', 7, 'obl', 9], ['Arroyo', 'PROPN', 9, 'flat', 10], ['Yabucoa', 'PROPN', 9, 'flat', 11], ['Maunabo', 'PROPN', 9, 'flat', 12], ['Patillas', 'PROPN', 9, 'flat', 13], ['#prwx', 'PROPN', 14, 'ROOT', 14], ['#Maria', 'ADJ', 14, 'obj', 15]]]\n",
      "candidate 0=Humacao\n",
      "anchor NE candidates = \n",
      "candidate 1=Yabucoa\n",
      "anchor NE candidates = Humacao\n",
      "data NE tree=[['Yabucoa', 'PROPN', 9, 'flat', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Yabucoa', 'PROPN', 9, 'flat', 11]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 7, 'obl', 9]\n",
      "candidate 2=Maunabo\n",
      "anchor NE candidates = Humacao,Yabucoa\n",
      "data NE tree=[['Maunabo', 'PROPN', 9, 'flat', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Maunabo', 'PROPN', 9, 'flat', 12]\n",
      "NE parent token:\n",
      "['Humacao', 'PROPN', 7, 'obl', 9]\n",
      "testing NE san_juan, txt:Our prayers are with the staff and students of UM-related @robinson_school , located in San Juan, Puerto Rico, in the wake of #HurricaneMaria <URL>\n",
      "full parse [[['Our', 'ADJ', 1, 'poss', 0], ['prayers', 'NOUN', 2, 'nsubj', 1], ['are', 'VERB', 2, 'ROOT', 2], ['with', 'ADP', 2, 'prep', 3], ['the', 'DET', 5, 'det', 4], ['staff', 'NOUN', 3, 'pobj', 5], ['and', 'CCONJ', 5, 'cc', 6], ['students', 'NOUN', 5, 'conj', 7], ['of', 'ADP', 5, 'prep', 8], ['UMrelated', 'PROPN', 10, 'compound', 9], ['@robinson_school', 'X', 8, 'pobj', 10], ['located', 'VERB', 10, 'acl', 11], ['in', 'ADP', 11, 'prep', 12], ['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15], ['Rico', 'PROPN', 12, 'pobj', 16], ['in', 'ADP', 11, 'prep', 17], ['the', 'DET', 19, 'det', 18], ['wake', 'NOUN', 17, 'pobj', 19], ['of', 'ADP', 19, 'prep', 20], ['#HurricaneMaria', 'PROPN', 20, 'pobj', 21]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Juan', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 12, 'pobj', 16]\n",
      "parent node subtree [['San', 'PROPN', 14, 'compound', 13], ['Juan', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15], ['Rico', 'PROPN', 12, 'pobj', 16]]\n",
      "parent node subtree str san juan puerto rico\n",
      "false positive: NE=san_juan, type=compound\n",
      "testing NE guaynabo, txt:More destruction photos from Bayamón, Guaynabo and San Juan #Maria <URL>\n",
      "full parse [[['More', 'DET', 3, 'nsubj', 0], ['destruction', 'NOUN', 2, 'amod', 1], ['photos', 'ADJ', 0, 'obj', 2], ['from', 'NOUN', 3, 'ROOT', 3], ['Bayamón', 'PROPN', 3, 'obj', 4], ['Guaynabo', 'PROPN', 4, 'flat', 5], ['and', 'PROPN', 4, 'flat', 6], ['San', 'PROPN', 4, 'flat', 7], ['Juan', 'PROPN', 4, 'flat', 8], ['#Maria', 'PROPN', 3, 'amod', 9]]]\n",
      "candidate 0=Bayamón\n",
      "anchor NE candidates = Bayamón,Guaynabo\n",
      "data NE tree=[['Bayamón', 'PROPN', 3, 'obj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Bayamón', 'PROPN', 3, 'obj', 4]\n",
      "NE parent token:\n",
      "['from', 'NOUN', 3, 'ROOT', 3]\n",
      "NE=Bayamón subtree=[['Guaynabo', 'PROPN', 4, 'flat', 5], ['and', 'PROPN', 4, 'flat', 6], ['San', 'PROPN', 4, 'flat', 7], ['Juan', 'PROPN', 4, 'flat', 8]]\n",
      "min node deps ['flat', 'flat', 'flat', 'flat']\n",
      "candidate 1=Guaynabo\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE humacao, txt:Si usted se dializa con Fresenius. Caguas, Rio Grande y Humacao van a estar ofreciendo servicios desde las 10am #puertorico\n",
      "full parse [[['Si', 'SCONJ', 3, 'mark', 0], ['usted', 'PRON', 3, 'nsubj', 1], ['se', 'PRON', 3, 'obj', 2], ['dializa', 'VERB', 3, 'ROOT', 3], ['con', 'ADP', 5, 'case', 4], ['Fresenius', 'PROPN', 3, 'obl', 5], ['.', 'PUNCT', 3, 'punct', 6]], [['Caguas', 'PROPN', 8, 'nsubj', 0], ['Rio', 'PROPN', 0, 'flat', 1], ['Grande', 'ADJ', 0, 'flat', 2], ['y', 'CONJ', 4, 'cc', 3], ['Humacao', 'PROPN', 0, 'conj', 4], ['van', 'AUX', 8, 'aux', 5], ['a', 'ADP', 8, 'mark', 6], ['estar', 'AUX', 8, 'aux', 7], ['ofreciendo', 'VERB', 8, 'ROOT', 8], ['servicios', 'NOUN', 8, 'obj', 9], ['desde', 'ADP', 12, 'case', 10], ['las', 'DET', 12, 'det', 11], ['10am', 'NUM', 8, 'obl', 12], ['#puertorico', 'ADJ', 12, 'amod', 13]]]\n",
      "candidate 0=Caguas\n",
      "anchor NE candidates = \n",
      "candidate 1=Humacao\n",
      "anchor NE candidates = Caguas\n",
      "data NE tree=[['Humacao', 'PROPN', 0, 'conj', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['Humacao', 'PROPN', 0, 'conj', 4]\n",
      "NE parent token:\n",
      "['Caguas', 'PROPN', 8, 'nsubj', 0]\n",
      "NE=Humacao subtree=[['y', 'CONJ', 4, 'cc', 3]]\n",
      "min node deps ['cc']\n",
      "testing NE altagracia, txt:#HuracanMaria Se deja sentir en Samana, Nagua, Santiago, La Altagracia, Santo Domingo Este y otras localidades. #Maria <URL>\n",
      "full parse [[['#HuracanMaria', 'ADJ', 3, 'nsubj', 0], ['Se', 'PRON', 3, 'obj', 1], ['deja', 'AUX', 3, 'aux', 2], ['sentir', 'VERB', 3, 'ROOT', 3], ['en', 'ADP', 5, 'case', 4], ['Samana', 'PROPN', 3, 'obl', 5], ['Nagua', 'PROPN', 5, 'flat', 6], ['Santiago', 'PROPN', 5, 'flat', 7], ['La', 'DET', 9, 'det', 8], ['Altagracia', 'PROPN', 5, 'flat', 9], ['Santo', 'PROPN', 9, 'flat', 10], ['Domingo', 'PROPN', 9, 'flat', 11], ['Este', 'PROPN', 9, 'flat', 12], ['y', 'CONJ', 15, 'cc', 13], ['otras', 'DET', 15, 'det', 14], ['localidades', 'NOUN', 5, 'conj', 15], ['.', 'PUNCT', 3, 'punct', 16]], [['#Maria', 'ADJ', 0, 'ROOT', 0]]]\n",
      "candidate 0=Santiago\n",
      "anchor NE candidates = \n",
      "candidate 1=Altagracia\n",
      "anchor NE candidates = Santiago\n",
      "data NE tree=[['Altagracia', 'PROPN', 5, 'flat', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Altagracia', 'PROPN', 5, 'flat', 9]\n",
      "NE parent token:\n",
      "['Samana', 'PROPN', 3, 'obl', 5]\n",
      "NE=Altagracia subtree=[['La', 'DET', 9, 'det', 8], ['Santo', 'PROPN', 9, 'flat', 10], ['Domingo', 'PROPN', 9, 'flat', 11], ['Este', 'PROPN', 9, 'flat', 12]]\n",
      "min node deps ['det', 'flat', 'flat', 'flat']\n",
      "testing NE san_juan, txt:@weatherchannel is there any way we can hear of other towns in Puerto Rico? There aren’t only people in San Juan! #PuertoRico\n",
      "full parse [[['@weatherchannel', 'PROPN', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['there', 'ADV', 1, 'expl', 2], ['any', 'DET', 4, 'det', 3], ['way', 'NOUN', 1, 'attr', 4], ['we', 'PRON', 7, 'nsubj', 5], ['can', 'VERB', 7, 'aux', 6], ['hear', 'VERB', 4, 'relcl', 7], ['of', 'ADP', 7, 'prep', 8], ['other', 'ADJ', 10, 'amod', 9], ['towns', 'NOUN', 8, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['Puerto', 'PROPN', 13, 'compound', 12], ['Rico', 'PROPN', 11, 'pobj', 13], ['?', 'PUNCT', 1, 'punct', 14]], [['There', 'ADV', 1, 'expl', 0], ['aren', 'VERB', 1, 'ROOT', 1], ['’', 'X', 3, 'compound', 2], ['t', 'NOUN', 1, 'attr', 3], ['only', 'ADV', 5, 'amod', 4], ['people', 'NOUN', 3, 'dobj', 5], ['in', 'ADP', 5, 'prep', 6], ['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 6, 'pobj', 8], ['!', 'PUNCT', 1, 'punct', 9]], [['#PuertoRico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "testing NE yabucoa, txt:RT UnivisionNews: Exclusive video: The devastating path of Hurricane #Maria across #Puerto Rico, from Yabucoa to San Juan\n",
      "full parse [[['RT', 'PROPN', 1, 'compound', 0], ['UnivisionNews', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['Exclusive', 'ADJ', 4, 'amod', 3], ['video', 'NOUN', 4, 'ROOT', 4], [':', 'PUNCT', 4, 'punct', 5], ['The', 'DET', 8, 'det', 6], ['devastating', 'ADJ', 8, 'amod', 7], ['path', 'NOUN', 4, 'appos', 8], ['of', 'ADP', 8, 'prep', 9], ['Hurricane', 'PROPN', 11, 'compound', 10], ['#Maria', 'X', 9, 'pobj', 11], ['across', 'ADP', 8, 'prep', 12], ['#Puerto', 'PROPN', 14, 'compound', 13], ['Rico', 'PROPN', 12, 'pobj', 14], ['from', 'ADP', 8, 'prep', 15], ['Yabucoa', 'PROPN', 15, 'pobj', 16], ['to', 'ADP', 8, 'prep', 17], ['San', 'PROPN', 19, 'compound', 18], ['Juan', 'PROPN', 17, 'pobj', 19]]]\n",
      "candidate 0=Yabucoa\n",
      "anchor NE candidates = Yabucoa,San Juan\n",
      "data NE tree=[['Yabucoa', 'PROPN', 15, 'pobj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Yabucoa', 'PROPN', 15, 'pobj', 16]\n",
      "NE parent token:\n",
      "['from', 'ADP', 8, 'prep', 15]\n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = San Juan\n",
      "data NE tree=[['San', 'PROPN', 19, 'compound', 18], ['Juan', 'PROPN', 17, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=0:\n",
      "['Juan', 'PROPN', 17, 'pobj', 19]\n",
      "NE parent token:\n",
      "['to', 'ADP', 8, 'prep', 17]\n",
      "testing NE jayuya, txt:Seeking info on my aunt Milly Bodon & Luis in Jayuya, Puerto Rico (Cuabey). Its only accessible by helicopter.No power/phone #HurricaneMaria <URL>\n",
      "full parse [[['Seeking', 'VERB', 0, 'ROOT', 0], ['info', 'NOUN', 0, 'dobj', 1], ['on', 'ADP', 1, 'prep', 2], ['my', 'ADJ', 4, 'poss', 3], ['aunt', 'NOUN', 2, 'pobj', 4], ['Milly', 'PROPN', 6, 'compound', 5], ['Bodon', 'PROPN', 4, 'appos', 6], ['&', 'CCONJ', 6, 'cc', 7], ['Luis', 'PROPN', 6, 'conj', 8], ['in', 'ADP', 4, 'prep', 9], ['Jayuya', 'PROPN', 12, 'compound', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 9, 'pobj', 12], ['(', 'PUNCT', 12, 'punct', 13], ['Cuabey', 'PROPN', 12, 'appos', 14], [')', 'PUNCT', 12, 'punct', 15], ['.', 'PUNCT', 0, 'punct', 16]], [['Its', 'ADJ', 2, 'poss', 0], ['only', 'ADV', 2, 'advmod', 1], ['accessible', 'ADJ', 2, 'ROOT', 2], ['by', 'ADP', 2, 'prep', 3], ['helicopter.No', 'NOUN', 8, 'amod', 4], ['power', 'NOUN', 7, 'nmod', 5], ['/', 'SYM', 7, 'punct', 6], ['phone', 'NOUN', 8, 'compound', 7], ['#HurricaneMaria', 'PROPN', 3, 'pobj', 8]]]\n",
      "candidate 0=Jayuya\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Jayuya', 'PROPN', 12, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Jayuya', 'PROPN', 12, 'compound', 10]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Jayuya', 'PROPN', 12, 'compound', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 9, 'pobj', 12], ['(', 'PUNCT', 12, 'punct', 13], ['Cuabey', 'PROPN', 12, 'appos', 14], [')', 'PUNCT', 12, 'punct', 15]]\n",
      "parent node subtree str jayuya puerto rico ( cuabey )\n",
      "false positive: NE=jayuya, type=compound\n",
      "testing NE san_juan, txt:#SanJuan #PuertoRico Drone footage shows flooded streets in San Juan, Puerto Rico, after Hurricane #Maria . <URL>\n",
      "full parse [[['#SanJuan', 'NOUN', 0, 'ROOT', 0], ['#PuertoRico', 'PROPN', 1, 'ROOT', 1], ['Drone', 'NOUN', 3, 'compound', 2], ['footage', 'NOUN', 4, 'nsubj', 3], ['shows', 'VERB', 4, 'ROOT', 4], ['flooded', 'VERB', 6, 'amod', 5], ['streets', 'NOUN', 4, 'dobj', 6], ['in', 'ADP', 6, 'prep', 7], ['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10], ['Rico', 'PROPN', 7, 'pobj', 11], ['after', 'ADP', 6, 'prep', 12], ['Hurricane', 'PROPN', 14, 'compound', 13], ['#Maria', 'X', 12, 'pobj', 14], ['.', 'PUNCT', 4, 'punct', 15]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Juan', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 7, 'pobj', 11]\n",
      "parent node subtree [['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10], ['Rico', 'PROPN', 7, 'pobj', 11]]\n",
      "parent node subtree str san juan puerto rico\n",
      "false positive: NE=san_juan, type=compound\n",
      "testing NE santurce, txt:Inundación en áreas de Ocean Park y Santurce. #María #PuertoRico <URL>\n",
      "full parse [[['Inundación', 'NOUN', 0, 'ROOT', 0], ['en', 'ADP', 2, 'case', 1], ['áreas', 'NOUN', 0, 'nmod', 2], ['de', 'ADP', 4, 'case', 3], ['Ocean', 'PROPN', 2, 'nmod', 4], ['Park', 'PROPN', 4, 'flat', 5], ['y', 'CONJ', 7, 'cc', 6], ['Santurce', 'PROPN', 4, 'conj', 7], ['.', 'PUNCT', 0, 'punct', 8]], [['#María', 'VERB', 0, 'ROOT', 0], ['#PuertoRico', 'ADJ', 0, 'obj', 1]]]\n",
      "candidate 0=Ocean Park\n",
      "anchor NE candidates = \n",
      "candidate 1=Santurce\n",
      "anchor NE candidates = Ocean Park\n",
      "data NE tree=[['Santurce', 'PROPN', 4, 'conj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Santurce', 'PROPN', 4, 'conj', 7]\n",
      "NE parent token:\n",
      "['Ocean', 'PROPN', 2, 'nmod', 4]\n",
      "NE=Santurce subtree=[['y', 'CONJ', 7, 'cc', 6]]\n",
      "min node deps ['cc']\n",
      "testing NE san_isidro, txt:The current photos of Loíza, San Isidro & Toa baja are heartbreaking! The rebuild needed will be massive #HurricaneMaria #PuertoRico <URL>\n",
      "full parse [[['The', 'DET', 2, 'det', 0], ['current', 'ADJ', 2, 'amod', 1], ['photos', 'NOUN', 11, 'nsubj', 2], ['of', 'ADP', 2, 'prep', 3], ['Loíza', 'PROPN', 6, 'compound', 4], ['San', 'PROPN', 6, 'compound', 5], ['Isidro', 'PROPN', 3, 'pobj', 6], ['&', 'CCONJ', 6, 'cc', 7], ['Toa', 'PROPN', 6, 'conj', 8], ['baja', 'NOUN', 3, 'pobj', 9], ['are', 'VERB', 11, 'aux', 10], ['heartbreaking', 'ADJ', 11, 'ROOT', 11], ['!', 'PUNCT', 11, 'punct', 12]], [['The', 'DET', 1, 'det', 0], ['rebuild', 'NOUN', 4, 'nsubj', 1], ['needed', 'VERB', 1, 'acl', 2], ['will', 'VERB', 4, 'aux', 3], ['be', 'VERB', 4, 'ROOT', 4], ['massive', 'ADJ', 7, 'amod', 5], ['#HurricaneMaria', 'PROPN', 7, 'compound', 6], ['#PuertoRico', 'PROPN', 4, 'attr', 7]]]\n",
      "candidate 0=San Isidro\n",
      "anchor NE candidates = Toa baja\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Isidro', 'PROPN', 3, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Isidro', 'PROPN', 3, 'pobj', 6]\n",
      "NE parent token:\n",
      "['of', 'ADP', 2, 'prep', 3]\n",
      "NE=San Isidro subtree=[['Loíza', 'PROPN', 6, 'compound', 4], ['&', 'CCONJ', 6, 'cc', 7], ['Toa', 'PROPN', 6, 'conj', 8]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 1=Toa baja\n",
      "anchor NE candidates = \n",
      "testing NE las_piedras, txt:9-22-2017 Mabu Las Piedras, Juncos, Garabo, Caguas, southern San Juan Helicopter Video #Maria <URL>\n",
      "full parse [[['9222017', 'NUM', 0, 'ROOT', 0], ['Mabu', 'PROPN', 3, 'compound', 1], ['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3], ['Juncos', 'PROPN', 6, 'nmod', 4], ['Garabo', 'PROPN', 6, 'nmod', 5], ['Caguas', 'PROPN', 6, 'ROOT', 6], ['southern', 'ADJ', 12, 'amod', 7], ['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 12, 'compound', 9], ['Helicopter', 'PROPN', 12, 'compound', 10], ['Video', 'PROPN', 12, 'compound', 11], ['#Maria', 'PUNCT', 6, 'appos', 12]]]\n",
      "candidate 0=Las Piedras\n",
      "anchor NE candidates = Caguas,San Juan\n",
      "data NE tree=[['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Piedras', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['Juncos', 'PROPN', 6, 'nmod', 4]\n",
      "parent node subtree [['Mabu', 'PROPN', 3, 'compound', 1], ['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3], ['Juncos', 'PROPN', 6, 'nmod', 4]]\n",
      "parent node subtree str mabu las piedras juncos\n",
      "NE=Las Piedras subtree=[['Mabu', 'PROPN', 3, 'compound', 1]]\n",
      "min node deps ['compound']\n",
      "candidate 1=Caguas\n",
      "anchor NE candidates = San Juan\n",
      "data NE tree=[['Caguas', 'PROPN', 6, 'ROOT', 6]]\n",
      "NE=Caguas subtree=[['Mabu', 'PROPN', 3, 'compound', 1], ['Las', 'PROPN', 3, 'compound', 2], ['Piedras', 'PROPN', 4, 'compound', 3], ['Juncos', 'PROPN', 6, 'nmod', 4], ['Garabo', 'PROPN', 6, 'nmod', 5], ['southern', 'ADJ', 12, 'amod', 7], ['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 12, 'compound', 9], ['Helicopter', 'PROPN', 12, 'compound', 10], ['Video', 'PROPN', 12, 'compound', 11], ['#Maria', 'PUNCT', 6, 'appos', 12]]\n",
      "min node deps ['compound', 'compound']\n",
      "candidate 2=San Juan\n",
      "anchor NE candidates = \n",
      "testing NE quebradillas, txt:Flash Flood Emergency for Quebradillas and Isabela, PR <URL>\n",
      "full parse [[['Flash', 'PROPN', 2, 'compound', 0], ['Flood', 'PROPN', 2, 'compound', 1], ['Emergency', 'PROPN', 2, 'ROOT', 2], ['for', 'ADP', 2, 'prep', 3], ['Quebradillas', 'PROPN', 3, 'pobj', 4], ['and', 'CCONJ', 4, 'cc', 5], ['Isabela', 'PROPN', 7, 'compound', 6], ['PR', 'PROPN', 4, 'conj', 7]]]\n",
      "candidate 0=Quebradillas\n",
      "anchor NE candidates = Isabela\n",
      "data NE tree=[['Quebradillas', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Quebradillas', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['for', 'ADP', 2, 'prep', 3]\n",
      "NE=Quebradillas subtree=[['and', 'CCONJ', 4, 'cc', 5], ['Isabela', 'PROPN', 7, 'compound', 6], ['PR', 'PROPN', 4, 'conj', 7]]\n",
      "min node deps ['cc', 'conj']\n",
      "testing NE san_juan, txt:Retweeted ABC News ( @ABC ): Streets in San Juan, Puerto Rico remain flooded days after #Maria made landfall as a... <URL>\n",
      "full parse [[['Retweeted', 'VERB', 2, 'compound', 0], ['ABC', 'PROPN', 2, 'compound', 1], ['News', 'PROPN', 2, 'ROOT', 2], ['(', 'PUNCT', 2, 'punct', 3], ['@ABC', 'PROPN', 2, 'npadvmod', 4], ['):', 'PROPN', 2, 'punct', 5], ['Streets', 'PROPN', 12, 'nsubj', 6], ['in', 'ADP', 6, 'prep', 7], ['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10], ['Rico', 'PROPN', 7, 'pobj', 11], ['remain', 'VERB', 12, 'ROOT', 12], ['flooded', 'ADJ', 14, 'amod', 13], ['days', 'NOUN', 12, 'npadvmod', 14], ['after', 'ADP', 17, 'mark', 15], ['#Maria', 'NOUN', 17, 'nsubj', 16], ['made', 'VERB', 12, 'advcl', 17], ['landfall', 'NOUN', 17, 'dobj', 18], ['as', 'ADP', 17, 'prep', 19], ['a', 'DET', 19, 'pobj', 20], ['...', 'PUNCT', 12, 'punct', 21]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Juan', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 7, 'pobj', 11]\n",
      "parent node subtree [['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10], ['Rico', 'PROPN', 7, 'pobj', 11]]\n",
      "parent node subtree str san juan puerto rico\n",
      "false positive: NE=san_juan, type=compound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE ponce, txt:Woohoo, Ponce and adjacent areas, help is coming! This is an update from mi tio in Tampa, who is monitoring faith organizations. #PuertoRico <URL>\n",
      "full parse [[['Woohoo', 'PROPN', 1, 'compound', 0], ['Ponce', 'PROPN', 5, 'nsubj', 1], ['and', 'CCONJ', 1, 'cc', 2], ['adjacent', 'ADJ', 4, 'amod', 3], ['areas', 'NOUN', 1, 'conj', 4], ['help', 'VERB', 7, 'nsubj', 5], ['is', 'VERB', 7, 'aux', 6], ['coming', 'VERB', 7, 'ROOT', 7], ['!', 'PUNCT', 7, 'punct', 8]], [['This', 'DET', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['an', 'DET', 3, 'det', 2], ['update', 'NOUN', 1, 'attr', 3], ['from', 'ADP', 3, 'prep', 4], ['mi', 'INTJ', 6, 'compound', 5], ['tio', 'NOUN', 4, 'pobj', 6], ['in', 'ADP', 6, 'prep', 7], ['Tampa', 'PROPN', 7, 'pobj', 8], ['who', 'NOUN', 11, 'nsubj', 9], ['is', 'VERB', 11, 'aux', 10], ['monitoring', 'VERB', 3, 'relcl', 11], ['faith', 'NOUN', 13, 'compound', 12], ['organizations', 'NOUN', 11, 'dobj', 13], ['.', 'PUNCT', 1, 'punct', 14]], [['#PuertoRico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Ponce\n",
      "anchor NE candidates = Tampa\n",
      "data NE tree=[['Ponce', 'PROPN', 5, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Ponce', 'PROPN', 5, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['help', 'VERB', 7, 'nsubj', 5]\n",
      "NE=Ponce subtree=[['Woohoo', 'PROPN', 1, 'compound', 0], ['and', 'CCONJ', 1, 'cc', 2], ['adjacent', 'ADJ', 4, 'amod', 3], ['areas', 'NOUN', 1, 'conj', 4]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "testing NE barinas, txt:Update on #HurricaneMaria . My cousin drove to #Yauco and said Costa Sur, Barinas, Almácigo, Palomas, La Quinta are ok. Luchetti is destroyed\n",
      "full parse [[['Update', 'NOUN', 0, 'ROOT', 0], ['on', 'ADP', 0, 'prep', 1], ['#HurricaneMaria', 'PROPN', 1, 'pobj', 2], ['.', 'PUNCT', 0, 'punct', 3]], [['My', 'ADJ', 1, 'poss', 0], ['cousin', 'NOUN', 2, 'nsubj', 1], ['drove', 'VERB', 2, 'ROOT', 2], ['to', 'ADP', 2, 'prep', 3], ['#Yauco', 'PROPN', 3, 'pobj', 4], ['and', 'CCONJ', 2, 'cc', 5], ['said', 'VERB', 2, 'conj', 6], ['Costa', 'PROPN', 13, 'compound', 7], ['Sur', 'PROPN', 13, 'compound', 8], ['Barinas', 'PROPN', 13, 'compound', 9], ['Almácigo', 'PROPN', 13, 'compound', 10], ['Palomas', 'PROPN', 13, 'compound', 11], ['La', 'PROPN', 13, 'compound', 12], ['Quinta', 'PROPN', 14, 'nsubj', 13], ['are', 'VERB', 6, 'ccomp', 14], ['ok', 'ADJ', 14, 'acomp', 15], ['.', 'PUNCT', 2, 'punct', 16], ['Luchetti', 'PROPN', 19, 'nsubjpass', 17], ['is', 'VERB', 19, 'auxpass', 18], ['destroyed', 'VERB', 19, 'ROOT', 19]]]\n",
      "candidate 0=Barinas\n",
      "anchor NE candidates = Palomas,La Quinta\n",
      "data NE tree=[['Barinas', 'PROPN', 13, 'compound', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Barinas', 'PROPN', 13, 'compound', 9]\n",
      "NE parent token:\n",
      "['Quinta', 'PROPN', 14, 'nsubj', 13]\n",
      "parent node subtree [['Costa', 'PROPN', 13, 'compound', 7], ['Sur', 'PROPN', 13, 'compound', 8], ['Barinas', 'PROPN', 13, 'compound', 9], ['Almácigo', 'PROPN', 13, 'compound', 10], ['Palomas', 'PROPN', 13, 'compound', 11], ['La', 'PROPN', 13, 'compound', 12], ['Quinta', 'PROPN', 14, 'nsubj', 13]]\n",
      "parent node subtree str costa sur barinas almácigo palomas la quinta\n",
      "candidate 1=Palomas\n",
      "anchor NE candidates = La Quinta\n",
      "data NE tree=[['Palomas', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['Palomas', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['Quinta', 'PROPN', 14, 'nsubj', 13]\n",
      "parent node subtree [['Costa', 'PROPN', 13, 'compound', 7], ['Sur', 'PROPN', 13, 'compound', 8], ['Barinas', 'PROPN', 13, 'compound', 9], ['Almácigo', 'PROPN', 13, 'compound', 10], ['Palomas', 'PROPN', 13, 'compound', 11], ['La', 'PROPN', 13, 'compound', 12], ['Quinta', 'PROPN', 14, 'nsubj', 13]]\n",
      "parent node subtree str costa sur barinas almácigo palomas la quinta\n",
      "candidate 2=La Quinta\n",
      "anchor NE candidates = \n",
      "testing NE vega_alta, txt:Vega Alta, a 40 min drive from San Juan, has not seen aid a week after #Maria . Hospital on verge of shutting down. <URL>\n",
      "full parse [[['Vega', 'PROPN', 1, 'compound', 0], ['Alta', 'PROPN', 11, 'nsubj', 1], ['a', 'DET', 5, 'det', 2], ['40', 'NUM', 4, 'nummod', 3], ['min', 'NOUN', 5, 'compound', 4], ['drive', 'NOUN', 1, 'appos', 5], ['from', 'ADP', 5, 'prep', 6], ['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 6, 'pobj', 8], ['has', 'VERB', 11, 'aux', 9], ['not', 'ADV', 11, 'neg', 10], ['seen', 'VERB', 11, 'ROOT', 11], ['aid', 'NOUN', 11, 'dobj', 12], ['a', 'DET', 14, 'det', 13], ['week', 'NOUN', 11, 'npadvmod', 14], ['after', 'ADP', 11, 'prep', 15], ['#Maria', 'X', 15, 'pobj', 16], ['.', 'PUNCT', 11, 'punct', 17]], [['Hospital', 'NOUN', 0, 'ROOT', 0], ['on', 'ADP', 0, 'prep', 1], ['verge', 'NOUN', 1, 'pobj', 2], ['of', 'ADP', 2, 'prep', 3], ['shutting', 'VERB', 3, 'pcomp', 4], ['down', 'PART', 4, 'prt', 5], ['.', 'PUNCT', 0, 'punct', 6]]]\n",
      "candidate 0=Vega Alta\n",
      "anchor NE candidates = San Juan\n",
      "data NE tree=[['Vega', 'PROPN', 1, 'compound', 0], ['Alta', 'PROPN', 11, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Alta', 'PROPN', 11, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['seen', 'VERB', 11, 'ROOT', 11]\n",
      "NE=Vega Alta subtree=[['a', 'DET', 5, 'det', 2], ['40', 'NUM', 4, 'nummod', 3], ['min', 'NOUN', 5, 'compound', 4], ['drive', 'NOUN', 1, 'appos', 5], ['from', 'ADP', 5, 'prep', 6], ['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 6, 'pobj', 8]]\n",
      "min node deps ['appos']\n",
      "subtree = a 40 min drive from San Juan\n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = \n",
      "testing NE toa_alta, txt:Toa Alta, Puerto Rico: A cyclist rides over a bridge damaged by #HurricaneMaria . Photograph: Ricardo Arduengo/AFP #ClimateChange #Capitalism <URL>\n",
      "full parse [[['Toa', 'PROPN', 3, 'compound', 0], ['Alta', 'PROPN', 3, 'compound', 1], ['Puerto', 'PROPN', 3, 'compound', 2], ['Rico', 'PROPN', 3, 'ROOT', 3], [':', 'PUNCT', 3, 'punct', 4], ['A', 'DET', 6, 'det', 5], ['cyclist', 'NOUN', 7, 'nsubj', 6], ['rides', 'VERB', 7, 'ROOT', 7], ['over', 'ADP', 7, 'prep', 8], ['a', 'DET', 10, 'det', 9], ['bridge', 'NOUN', 8, 'pobj', 10], ['damaged', 'VERB', 10, 'acl', 11], ['by', 'ADP', 11, 'agent', 12], ['#HurricaneMaria', 'PROPN', 12, 'pobj', 13], ['.', 'PUNCT', 7, 'punct', 14]], [['Photograph', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['Ricardo', 'PROPN', 5, 'nmod', 2], ['Arduengo', 'PROPN', 5, 'nmod', 3], ['/', 'SYM', 5, 'punct', 4], ['AFP', 'PROPN', 5, 'ROOT', 5], ['#ClimateChange', 'PROPN', 7, 'compound', 6], ['#Capitalism', 'X', 7, 'ROOT', 7]]]\n",
      "candidate 0=Toa Alta\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Toa', 'PROPN', 3, 'compound', 0], ['Alta', 'PROPN', 3, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['Alta', 'PROPN', 3, 'compound', 1]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 3, 'ROOT', 3]\n",
      "parent node subtree [['Toa', 'PROPN', 3, 'compound', 0], ['Alta', 'PROPN', 3, 'compound', 1], ['Puerto', 'PROPN', 3, 'compound', 2], ['Rico', 'PROPN', 3, 'ROOT', 3], [':', 'PUNCT', 3, 'punct', 4]]\n",
      "parent node subtree str toa alta puerto rico :\n",
      "false positive: NE=toa_alta, type=compound\n",
      "testing NE san_juan, txt:Puerto Rico humanitarian crisis Trump talking about Wall Street + banks San Juan Mayor Carmen Yulin Cruz #Maria <URL>\n",
      "full parse [[['Puerto', 'PROPN', 1, 'nmod', 0], ['Rico', 'PROPN', 3, 'amod', 1], ['humanitarian', 'ADJ', 3, 'amod', 2], ['crisis', 'NOUN', 5, 'nsubj', 3], ['Trump', 'NOUN', 3, 'appos', 4], ['talking', 'VERB', 5, 'ROOT', 5], ['about', 'ADP', 5, 'prep', 6], ['Wall', 'PROPN', 8, 'compound', 7], ['Street', 'PROPN', 6, 'pobj', 8], ['+', 'PUNCT', 8, 'cc', 9], ['banks', 'NOUN', 8, 'conj', 10], ['San', 'PROPN', 12, 'compound', 11], ['Juan', 'PROPN', 13, 'compound', 12], ['Mayor', 'PROPN', 13, 'ROOT', 13], ['Carmen', 'PROPN', 15, 'compound', 14], ['Yulin', 'PROPN', 17, 'compound', 15], ['Cruz', 'PROPN', 17, 'compound', 16], ['#Maria', 'PUNCT', 17, 'ROOT', 17]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "testing NE san_juan, txt:#PuertoRico Some towns in Puerto Rico have been able to set up hotlines to find family: San Juan 787-294-0277... <URL>\n",
      "full parse [[['#PuertoRico', 'PROPN', 7, 'dep', 0], ['Some', 'DET', 2, 'det', 1], ['towns', 'NOUN', 7, 'nsubj', 2], ['in', 'ADP', 2, 'prep', 3], ['Puerto', 'PROPN', 5, 'compound', 4], ['Rico', 'PROPN', 3, 'pobj', 5], ['have', 'VERB', 7, 'aux', 6], ['been', 'VERB', 7, 'ROOT', 7], ['able', 'ADJ', 7, 'acomp', 8], ['to', 'PART', 10, 'aux', 9], ['set', 'VERB', 8, 'xcomp', 10], ['up', 'PART', 10, 'prt', 11], ['hotlines', 'NOUN', 10, 'dobj', 12], ['to', 'PART', 14, 'aux', 13], ['find', 'VERB', 10, 'advcl', 14], ['family', 'NOUN', 14, 'dobj', 15], [':', 'PUNCT', 7, 'punct', 16], ['San', 'PROPN', 18, 'compound', 17], ['Juan', 'PROPN', 18, 'ROOT', 18], ['7872940277', 'NUM', 18, 'nummod', 19], ['...', 'PUNCT', 18, 'punct', 20]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "testing NE san_juan, txt:From the San Juan, Puerto Rico mayor. Heart wrenching. #PuertoRico <URL>\n",
      "full parse [[['From', 'ADP', 0, 'ROOT', 0], ['the', 'DET', 6, 'det', 1], ['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 6, 'compound', 3], ['Puerto', 'PROPN', 5, 'compound', 4], ['Rico', 'PROPN', 6, 'compound', 5], ['mayor', 'NOUN', 0, 'pobj', 6], ['.', 'PUNCT', 0, 'punct', 7]], [['Heart', 'NOUN', 0, 'ROOT', 0], ['wrenching', 'ADJ', 0, 'amod', 1], ['.', 'PUNCT', 0, 'punct', 2]], [['#PuertoRico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 6, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Juan', 'PROPN', 6, 'compound', 3]\n",
      "NE parent token:\n",
      "['mayor', 'NOUN', 0, 'pobj', 6]\n",
      "parent node subtree [['the', 'DET', 6, 'det', 1], ['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 6, 'compound', 3], ['Puerto', 'PROPN', 5, 'compound', 4], ['Rico', 'PROPN', 6, 'compound', 5], ['mayor', 'NOUN', 0, 'pobj', 6]]\n",
      "parent node subtree str the san juan puerto rico mayor\n",
      "false positive: NE=san_juan, type=compound\n",
      "testing NE san_juan, txt:Trump: If the mayor of San Juan doesn't start praising me, I'll pull ALL relief efforts from Puerto Rico. @realdonaldtRump #maga #PuertoRico\n",
      "full parse [[['Trump', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['If', 'ADP', 9, 'mark', 2], ['the', 'DET', 4, 'det', 3], ['mayor', 'NOUN', 9, 'nsubj', 4], ['of', 'ADP', 4, 'prep', 5], ['San', 'PROPN', 7, 'compound', 6], ['Juan', 'PROPN', 5, 'pobj', 7], [\"doesn't\", 'ADV', 9, 'aux', 8], ['start', 'VERB', 9, 'ROOT', 9], ['praising', 'VERB', 9, 'xcomp', 10], ['me', 'PRON', 10, 'dobj', 11], [\"I'll\", 'PROPN', 13, 'nsubj', 12], ['pull', 'VERB', 10, 'ccomp', 13], ['ALL', 'DET', 16, 'compound', 14], ['relief', 'NOUN', 16, 'compound', 15], ['efforts', 'NOUN', 13, 'dobj', 16], ['from', 'ADP', 16, 'prep', 17], ['Puerto', 'PROPN', 19, 'compound', 18], ['Rico', 'PROPN', 17, 'pobj', 19], ['.', 'PUNCT', 9, 'punct', 20]], [['@realdonaldtRump', 'X', 0, 'ROOT', 0], ['#maga', 'PUNCT', 1, 'ROOT', 1], ['#PuertoRico', 'PROPN', 2, 'ROOT', 2]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 7, 'compound', 6], ['Juan', 'PROPN', 5, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Juan', 'PROPN', 5, 'pobj', 7]\n",
      "NE parent token:\n",
      "['of', 'ADP', 4, 'prep', 5]\n",
      "testing NE san_juan, txt:Dodges the draft, attacks John McCain. Plays golf in NJ, attacks mayor of hurricane ravaged San Juan. #puertorico #weakness #trump <URL>\n",
      "full parse [[['Dodges', 'VERB', 0, 'ROOT', 0], ['the', 'DET', 3, 'det', 1], ['draft', 'NOUN', 3, 'compound', 2], ['attacks', 'NOUN', 0, 'dobj', 3], ['John', 'PROPN', 5, 'compound', 4], ['McCain', 'PROPN', 3, 'appos', 5], ['.', 'PUNCT', 0, 'punct', 6]], [['Plays', 'VERB', 8, 'nsubj', 0], ['golf', 'NOUN', 0, 'dobj', 1], ['in', 'ADP', 0, 'prep', 2], ['NJ', 'PROPN', 5, 'compound', 3], ['attacks', 'NOUN', 5, 'compound', 4], ['mayor', 'NOUN', 2, 'pobj', 5], ['of', 'ADP', 5, 'prep', 6], ['hurricane', 'NOUN', 6, 'pobj', 7], ['ravaged', 'VERB', 8, 'ROOT', 8], ['San', 'PROPN', 10, 'compound', 9], ['Juan', 'PROPN', 8, 'dobj', 10], ['.', 'PUNCT', 8, 'punct', 11]], [['#puertorico', 'PROPN', 2, 'compound', 0], ['#weakness', 'PROPN', 2, 'compound', 1], ['#trump', 'PUNCT', 2, 'ROOT', 2]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "testing NE san_juan, txt:Can we please help Puerto Rico? Mayor of San Juan is literally begging for aid! Instead of helping @realDonaldTrump is golfing! #PuertoRico\n",
      "full parse [[['Can', 'VERB', 3, 'aux', 0], ['we', 'PRON', 3, 'nsubj', 1], ['please', 'INTJ', 3, 'intj', 2], ['help', 'VERB', 3, 'ROOT', 3], ['Puerto', 'PROPN', 5, 'compound', 4], ['Rico', 'PROPN', 3, 'dobj', 5], ['?', 'PUNCT', 3, 'punct', 6]], [['Mayor', 'PROPN', 6, 'nsubj', 0], ['of', 'ADP', 0, 'prep', 1], ['San', 'PROPN', 3, 'compound', 2], ['Juan', 'PROPN', 1, 'pobj', 3], ['is', 'VERB', 6, 'aux', 4], ['literally', 'ADV', 6, 'advmod', 5], ['begging', 'VERB', 6, 'ROOT', 6], ['for', 'ADP', 6, 'prep', 7], ['aid', 'NOUN', 7, 'pobj', 8], ['!', 'PUNCT', 6, 'punct', 9]], [['Instead', 'ADV', 1, 'advmod', 0], ['of', 'ADP', 4, 'prep', 1], ['helping', 'VERB', 1, 'pcomp', 2], ['@realDonaldTrump', 'PUNCT', 2, 'dobj', 3], ['is', 'VERB', 4, 'ROOT', 4], ['golfing', 'VERB', 4, 'attr', 5], ['!', 'PUNCT', 4, 'punct', 6]], [['#PuertoRico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "testing NE san_juan, txt:Wow, @potus tries to help Puerto Rico and all the mayor of San Juan can say is how bad he is. Thanks for nothing I guess. #puertorico\n",
      "full parse [[['Wow', 'INTJ', 2, 'intj', 0], ['@potus', 'PROPN', 2, 'nsubj', 1], ['tries', 'VERB', 15, 'ccomp', 2], ['to', 'PART', 4, 'aux', 3], ['help', 'VERB', 2, 'xcomp', 4], ['Puerto', 'PROPN', 6, 'compound', 5], ['Rico', 'PROPN', 4, 'dobj', 6], ['and', 'CCONJ', 6, 'cc', 7], ['all', 'ADJ', 10, 'predet', 8], ['the', 'DET', 10, 'det', 9], ['mayor', 'NOUN', 6, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['San', 'PROPN', 13, 'compound', 12], ['Juan', 'PROPN', 11, 'pobj', 13], ['can', 'VERB', 15, 'aux', 14], ['say', 'VERB', 15, 'ROOT', 15], ['is', 'VERB', 15, 'ccomp', 16], ['how', 'ADV', 18, 'advmod', 17], ['bad', 'ADJ', 20, 'acomp', 18], ['he', 'PRON', 20, 'nsubj', 19], ['is', 'VERB', 16, 'ccomp', 20], ['.', 'PUNCT', 15, 'punct', 21]], [['Thanks', 'NOUN', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['nothing', 'NOUN', 1, 'pobj', 2], ['I', 'PRON', 4, 'nsubj', 3], ['guess', 'VERB', 2, 'relcl', 4], ['.', 'PUNCT', 0, 'punct', 5]], [['#puertorico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = \n",
      "testing NE luquillo, txt:El SNM emite aviso de inundaciones repentinas para los municipios de Fajardo, Naguabo, Luquillo, Ceiba hasta las 5:45 p.m. #HuracanMaria E…\n",
      "full parse [[['El', 'DET', 1, 'det', 0], ['SNM', 'PROPN', 2, 'nsubj', 1], ['emite', 'VERB', 2, 'ROOT', 2], ['aviso', 'NOUN', 2, 'obj', 3], ['de', 'ADP', 5, 'case', 4], ['inundaciones', 'NOUN', 3, 'nmod', 5], ['repentinas', 'ADJ', 5, 'amod', 6], ['para', 'ADP', 9, 'case', 7], ['los', 'DET', 9, 'det', 8], ['municipios', 'NOUN', 6, 'nmod', 9], ['de', 'ADP', 11, 'case', 10], ['Fajardo', 'PROPN', 9, 'nmod', 11], ['Naguabo', 'PROPN', 11, 'flat', 12], ['Luquillo', 'PROPN', 11, 'flat', 13], ['Ceiba', 'PROPN', 11, 'flat', 14], ['hasta', 'ADP', 17, 'case', 15], ['las', 'DET', 17, 'det', 16], ['5', 'NUM', 2, 'advmod', 17], [':', 'PUNCT', 20, 'punct', 18], ['45', 'NUM', 20, 'nummod', 19], ['p.m.', 'VERB', 2, 'obj', 20], ['#HuracanMaria', 'ADJ', 20, 'amod', 21], ['E', 'CONJ', 20, 'appos', 22], ['…', 'PUNCT', 20, 'conj', 23]]]\n",
      "candidate 0=Naguabo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor NE candidates = \n",
      "candidate 1=Luquillo\n",
      "anchor NE candidates = Naguabo\n",
      "data NE tree=[['Luquillo', 'PROPN', 11, 'flat', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['Luquillo', 'PROPN', 11, 'flat', 13]\n",
      "NE parent token:\n",
      "['Fajardo', 'PROPN', 9, 'nmod', 11]\n",
      "testing NE morovis, txt:We are on the ground delivering Food helping our people in #PuertoRico this weekend, Toa Baja, Morovis , Orocovis. @FeedingAmerica <URL>\n",
      "full parse [[['We', 'PRON', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['on', 'ADP', 1, 'prep', 2], ['the', 'DET', 4, 'det', 3], ['ground', 'NOUN', 2, 'pobj', 4], ['delivering', 'VERB', 4, 'acl', 5], ['Food', 'PROPN', 5, 'dobj', 6], ['helping', 'VERB', 1, 'advcl', 7], ['our', 'ADJ', 9, 'poss', 8], ['people', 'NOUN', 7, 'dobj', 9], ['in', 'ADP', 7, 'prep', 10], ['#PuertoRico', 'PROPN', 10, 'pobj', 11], ['this', 'DET', 13, 'det', 12], ['weekend', 'NOUN', 7, 'npadvmod', 13], ['Toa', 'PROPN', 17, 'compound', 14], ['Baja', 'PROPN', 17, 'compound', 15], ['Morovis', 'PROPN', 17, 'compound', 16], ['Orocovis', 'PROPN', 17, 'ROOT', 17], ['.', 'PUNCT', 17, 'punct', 18]], [['@FeedingAmerica', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Toa Baja\n",
      "anchor NE candidates = \n",
      "candidate 1=Morovis\n",
      "anchor NE candidates = Toa Baja\n",
      "data NE tree=[['Morovis', 'PROPN', 17, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Morovis', 'PROPN', 17, 'compound', 16]\n",
      "NE parent token:\n",
      "['Orocovis', 'PROPN', 17, 'ROOT', 17]\n",
      "parent node subtree [['Toa', 'PROPN', 17, 'compound', 14], ['Baja', 'PROPN', 17, 'compound', 15], ['Morovis', 'PROPN', 17, 'compound', 16], ['Orocovis', 'PROPN', 17, 'ROOT', 17], ['.', 'PUNCT', 17, 'punct', 18]]\n",
      "parent node subtree str toa baja morovis orocovis .\n",
      "candidate 2=Orocovis\n",
      "anchor NE candidates = Toa Baja,Morovis\n",
      "data NE tree=[['Orocovis', 'PROPN', 17, 'ROOT', 17]]\n",
      "NE=Orocovis subtree=[['Toa', 'PROPN', 17, 'compound', 14], ['Baja', 'PROPN', 17, 'compound', 15], ['Morovis', 'PROPN', 17, 'compound', 16], ['.', 'PUNCT', 17, 'punct', 18]]\n",
      "min node deps ['compound', 'compound', 'compound', 'punct']\n",
      "testing NE san_juan, txt:President @realDonaldTrump the Mayor of San Juan does not represent the majority in Puerto Rico. Thanks for your support. #PuertoRico\n",
      "full parse [[['President', 'PROPN', 1, 'compound', 0], ['@realDonaldTrump', 'PROPN', 9, 'nsubj', 1], ['the', 'DET', 3, 'det', 2], ['Mayor', 'PROPN', 1, 'appos', 3], ['of', 'ADP', 3, 'prep', 4], ['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 4, 'pobj', 6], ['does', 'VERB', 9, 'aux', 7], ['not', 'ADV', 9, 'neg', 8], ['represent', 'VERB', 9, 'ROOT', 9], ['the', 'DET', 11, 'det', 10], ['majority', 'NOUN', 9, 'dobj', 11], ['in', 'ADP', 11, 'prep', 12], ['Puerto', 'PROPN', 14, 'compound', 13], ['Rico', 'PROPN', 12, 'pobj', 14], ['.', 'PUNCT', 9, 'punct', 15]], [['Thanks', 'NOUN', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['your', 'ADJ', 3, 'poss', 2], ['support', 'NOUN', 1, 'pobj', 3], ['.', 'PUNCT', 0, 'punct', 4]], [['#PuertoRico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 6, 'compound', 5], ['Juan', 'PROPN', 4, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Juan', 'PROPN', 4, 'pobj', 6]\n",
      "NE parent token:\n",
      "['of', 'ADP', 3, 'prep', 4]\n",
      "testing NE vegas, txt:Pres Trump expected to travel to Puerto Rico tom as scheduled to Survey damage from #Maria . Then heads to Vegas on Wed. #VegasShooting\n",
      "full parse [[['Pres', 'PROPN', 1, 'compound', 0], ['Trump', 'PROPN', 2, 'nsubj', 1], ['expected', 'VERB', 2, 'ROOT', 2], ['to', 'PART', 4, 'aux', 3], ['travel', 'VERB', 2, 'xcomp', 4], ['to', 'ADP', 4, 'prep', 5], ['Puerto', 'PROPN', 7, 'compound', 6], ['Rico', 'PROPN', 8, 'compound', 7], ['tom', 'NOUN', 5, 'pobj', 8], ['as', 'ADP', 10, 'mark', 9], ['scheduled', 'VERB', 4, 'advcl', 10], ['to', 'ADP', 12, 'aux', 11], ['Survey', 'PROPN', 10, 'xcomp', 12], ['damage', 'NOUN', 12, 'dobj', 13], ['from', 'ADP', 13, 'prep', 14], ['#Maria', 'NOUN', 14, 'pobj', 15], ['.', 'PUNCT', 2, 'punct', 16]], [['Then', 'ADV', 1, 'advmod', 0], ['heads', 'NOUN', 1, 'ROOT', 1], ['to', 'ADP', 1, 'prep', 2], ['Vegas', 'PROPN', 2, 'pobj', 3], ['on', 'ADP', 1, 'prep', 4], ['Wed', 'PROPN', 4, 'pobj', 5], ['.', 'PUNCT', 1, 'punct', 6], ['#VegasShooting', 'X', 7, 'ROOT', 7]]]\n",
      "candidate 0=Vegas\n",
      "anchor NE candidates = \n",
      "testing NE san_juan, txt:Eye of the Storm: A dispatch from San Juan, Puerto Rico by @sodapopcomics <URL>\n",
      "full parse [[['Eye', 'NOUN', 0, 'ROOT', 0], ['of', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['Storm', 'NOUN', 1, 'pobj', 3], [':', 'PUNCT', 0, 'punct', 4], ['A', 'DET', 6, 'det', 5], ['dispatch', 'NOUN', 0, 'appos', 6], ['from', 'ADP', 6, 'prep', 7], ['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10], ['Rico', 'PROPN', 7, 'pobj', 11], ['by', 'ADP', 6, 'prep', 12], ['@sodapopcomics', 'NOUN', 12, 'pobj', 13]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Juan', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 7, 'pobj', 11]\n",
      "parent node subtree [['San', 'PROPN', 9, 'compound', 8], ['Juan', 'PROPN', 11, 'compound', 9], ['Puerto', 'PROPN', 11, 'compound', 10], ['Rico', 'PROPN', 7, 'pobj', 11]]\n",
      "parent node subtree str san juan puerto rico\n",
      "false positive: NE=san_juan, type=compound\n",
      "testing NE guaynabo, txt:Our potus is in Guaynabo -one of the wealthiest towns in Puerto Rico - does anyone know if he plans to go out of San Juan?? #hurricanemaria\n",
      "full parse [[['Our', 'ADJ', 1, 'poss', 0], ['potus', 'NOUN', 2, 'nsubj', 1], ['is', 'VERB', 15, 'ccomp', 2], ['in', 'ADP', 2, 'prep', 3], ['Guaynabo', 'PROPN', 3, 'pobj', 4], ['one', 'NUM', 4, 'nummod', 5], ['of', 'ADP', 5, 'prep', 6], ['the', 'DET', 9, 'det', 7], ['wealthiest', 'ADJ', 9, 'amod', 8], ['towns', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 10, 'pobj', 12], ['does', 'VERB', 15, 'aux', 13], ['anyone', 'NOUN', 15, 'nsubj', 14], ['know', 'VERB', 15, 'ROOT', 15], ['if', 'ADP', 18, 'mark', 16], ['he', 'PRON', 18, 'nsubj', 17], ['plans', 'VERB', 15, 'advcl', 18], ['to', 'PART', 20, 'aux', 19], ['go', 'VERB', 18, 'xcomp', 20], ['out', 'ADP', 20, 'prep', 21], ['of', 'ADP', 21, 'prep', 22], ['San', 'PROPN', 24, 'compound', 23], ['Juan', 'PROPN', 22, 'pobj', 24], ['?', 'PUNCT', 15, 'punct', 25], ['?', 'PUNCT', 15, 'punct', 26]], [['#hurricanemaria', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Guaynabo\n",
      "anchor NE candidates = Puerto Rico,San Juan\n",
      "data NE tree=[['Guaynabo', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Guaynabo', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "NE=Guaynabo subtree=[['one', 'NUM', 4, 'nummod', 5], ['of', 'ADP', 5, 'prep', 6], ['the', 'DET', 9, 'det', 7], ['wealthiest', 'ADJ', 9, 'amod', 8], ['towns', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 10, 'pobj', 12]]\n",
      "min node deps ['nummod']\n",
      "subtree = one of the wealthiest towns in Puerto Rico\n",
      "candidate 1=San Juan\n",
      "anchor NE candidates = \n",
      "testing NE san_juan, txt:Welcome to PR, Mr. President @Old San Juan, Puerto Rico. @realDonaldTrump #PuertoRico #HuracanMaria #TrumpBully <URL>\n",
      "full parse [[['Welcome', 'VERB', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['PR', 'PROPN', 3, 'compound', 2], ['Mr', 'PROPN', 1, 'pobj', 3], ['.', 'PUNCT', 0, 'punct', 4], ['President', 'PROPN', 6, 'nsubj', 5], ['@Old', 'PROPN', 6, 'ROOT', 6], ['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 10, 'compound', 8], ['Puerto', 'PROPN', 10, 'compound', 9], ['Rico', 'PROPN', 6, 'dobj', 10], ['.', 'PUNCT', 6, 'punct', 11]], [['@realDonaldTrump', 'X', 0, 'ROOT', 0], ['#PuertoRico', 'PROPN', 1, 'ROOT', 1], ['#HuracanMaria', 'PROPN', 3, 'compound', 2], ['#TrumpBully', 'ADV', 3, 'ROOT', 3]]]\n",
      "candidate 0=San Juan\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 10, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Juan', 'PROPN', 10, 'compound', 8]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 6, 'dobj', 10]\n",
      "parent node subtree [['San', 'PROPN', 8, 'compound', 7], ['Juan', 'PROPN', 10, 'compound', 8], ['Puerto', 'PROPN', 10, 'compound', 9], ['Rico', 'PROPN', 6, 'dobj', 10]]\n",
      "parent node subtree str san juan puerto rico\n",
      "false positive: NE=san_juan, type=compound\n",
      "testing NE cidra, txt:Photos of the land in front of my family's house in Cidra, Puerto Rico. My heart continues to ache for my people @PuertoRicoPUR #Maria <URL>\n",
      "full parse [[['Photos', 'NOUN', 0, 'ROOT', 0], ['of', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['land', 'NOUN', 1, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['front', 'NOUN', 4, 'pobj', 5], ['of', 'ADP', 5, 'prep', 6], ['my', 'ADJ', 9, 'poss', 7], [\"family's\", 'ADJ', 9, 'compound', 8], ['house', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Cidra', 'PROPN', 13, 'compound', 11], ['Puerto', 'PROPN', 13, 'compound', 12], ['Rico', 'PROPN', 10, 'pobj', 13], ['.', 'PUNCT', 0, 'punct', 14]], [['My', 'ADJ', 1, 'poss', 0], ['heart', 'NOUN', 2, 'nsubj', 1], ['continues', 'VERB', 2, 'ROOT', 2], ['to', 'PART', 2, 'prep', 3], ['ache', 'VERB', 3, 'pobj', 4], ['for', 'ADP', 4, 'prep', 5], ['my', 'ADJ', 7, 'poss', 6], ['people', 'NOUN', 5, 'pobj', 7], ['@PuertoRicoPUR', 'ADP', 2, 'punct', 8], ['#Maria', 'PUNCT', 9, 'ROOT', 9]]]\n",
      "candidate 0=Cidra\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Cidra', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Cidra', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 10, 'pobj', 13]\n",
      "parent node subtree [['Cidra', 'PROPN', 13, 'compound', 11], ['Puerto', 'PROPN', 13, 'compound', 12], ['Rico', 'PROPN', 10, 'pobj', 13]]\n",
      "parent node subtree str cidra puerto rico\n",
      "false positive: NE=cidra, type=compound\n",
      "testing NE utuado, txt:Watch: A CG aircrew air drops much needed supplies to the residents of Utuado, Puerto Rico after #HurricaneMaria left them stranded <URL>\n",
      "full parse [[['Watch', 'VERB', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['A', 'DET', 5, 'det', 2], ['CG', 'PROPN', 5, 'compound', 3], ['aircrew', 'NOUN', 5, 'compound', 4], ['air', 'NOUN', 6, 'nsubj', 5], ['drops', 'VERB', 0, 'acl', 6], ['much', 'ADV', 8, 'advmod', 7], ['needed', 'VERB', 9, 'amod', 8], ['supplies', 'NOUN', 6, 'dobj', 9], ['to', 'ADP', 6, 'prep', 10], ['the', 'DET', 12, 'det', 11], ['residents', 'NOUN', 10, 'pobj', 12], ['of', 'ADP', 12, 'prep', 13], ['Utuado', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15], ['Rico', 'PROPN', 13, 'pobj', 16], ['after', 'ADP', 19, 'mark', 17], ['#HurricaneMaria', 'PROPN', 19, 'nsubj', 18], ['left', 'VERB', 6, 'advcl', 19], ['them', 'PRON', 19, 'dobj', 20], ['stranded', 'VERB', 0, 'acl', 21]]]\n",
      "candidate 0=Utuado\n",
      "anchor NE candidates = Puerto Rico\n",
      "data NE tree=[['Utuado', 'PROPN', 16, 'compound', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Utuado', 'PROPN', 16, 'compound', 14]\n",
      "NE parent token:\n",
      "['Rico', 'PROPN', 13, 'pobj', 16]\n",
      "parent node subtree [['Utuado', 'PROPN', 16, 'compound', 14], ['Puerto', 'PROPN', 16, 'compound', 15], ['Rico', 'PROPN', 13, 'pobj', 16]]\n",
      "parent node subtree str utuado puerto rico\n",
      "false positive: NE=utuado, type=compound\n",
      "testing NE culebra, txt:St John, St Croix, St Thomas, Water Island, Puerto Rico, Culebra, Vieques are ALL US territories & ALL need help! #hurricanemaria\n",
      "full parse [[['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5], ['Water', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 11, 'compound', 7], ['Puerto', 'PROPN', 9, 'compound', 8], ['Rico', 'PROPN', 11, 'compound', 9], ['Culebra', 'PROPN', 11, 'compound', 10], ['Vieques', 'PROPN', 12, 'nsubj', 11], ['are', 'VERB', 12, 'ROOT', 12], ['ALL', 'DET', 15, 'det', 13], ['US', 'PROPN', 15, 'compound', 14], ['territories', 'NOUN', 12, 'attr', 15], ['&', 'CCONJ', 15, 'cc', 16], ['ALL', 'DET', 15, 'conj', 17], ['need', 'VERB', 12, 'conj', 18], ['help', 'NOUN', 18, 'dobj', 19], ['!', 'PUNCT', 12, 'punct', 20]], [['#hurricanemaria', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Culebra\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Culebra', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Culebra', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Vieques', 'PROPN', 12, 'nsubj', 11]\n",
      "parent node subtree [['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5], ['Water', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 11, 'compound', 7], ['Puerto', 'PROPN', 9, 'compound', 8], ['Rico', 'PROPN', 11, 'compound', 9], ['Culebra', 'PROPN', 11, 'compound', 10], ['Vieques', 'PROPN', 12, 'nsubj', 11]]\n",
      "parent node subtree str st john st croix st thomas water island puerto rico culebra vieques\n",
      "candidate 1=Vieques\n",
      "anchor NE candidates = Puerto Rico,Culebra,Vieques\n",
      "data NE tree=[['Vieques', 'PROPN', 12, 'nsubj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Vieques', 'PROPN', 12, 'nsubj', 11]\n",
      "NE parent token:\n",
      "['are', 'VERB', 12, 'ROOT', 12]\n",
      "NE=Vieques subtree=[['St', 'PROPN', 2, 'compound', 0], ['John', 'PROPN', 2, 'compound', 1], ['St', 'PROPN', 4, 'compound', 2], ['Croix', 'PROPN', 4, 'compound', 3], ['St', 'PROPN', 7, 'compound', 4], ['Thomas', 'PROPN', 7, 'compound', 5], ['Water', 'PROPN', 7, 'compound', 6], ['Island', 'PROPN', 11, 'compound', 7], ['Puerto', 'PROPN', 9, 'compound', 8], ['Rico', 'PROPN', 11, 'compound', 9], ['Culebra', 'PROPN', 11, 'compound', 10]]\n",
      "min node deps ['compound', 'compound']\n",
      "false positive: NE=culebra, type=compound\n",
      "testing NE gadsden, txt:The latest reliable models available (from this morning) ALL keep Hurricane force *sustained* winds out of #Tallahassee from #HurricaneMichael . However Gadsden & Liberty will still per these models get Hurricane force winds so it’s close enough to Tallahassee to worry.\n",
      "full parse [[['The', 'DET', 3, 'det', 0], ['latest', 'ADJ', 3, 'amod', 1], ['reliable', 'ADJ', 3, 'amod', 2], ['models', 'NOUN', 3, 'ROOT', 3], ['available', 'ADJ', 3, 'amod', 4], ['(', 'PUNCT', 3, 'punct', 5], ['from', 'ADP', 3, 'prep', 6], ['this', 'DET', 8, 'det', 7], ['morning', 'NOUN', 6, 'pobj', 8], [')', 'PUNCT', 3, 'punct', 9], ['ALL', 'DET', 11, 'nsubj', 10], ['keep', 'VERB', 11, 'ROOT', 11], ['Hurricane', 'PROPN', 13, 'compound', 12], ['force', 'NOUN', 11, 'dobj', 13], ['*', 'PUNCT', 15, 'punct', 14], ['sustained', 'VERB', 17, 'amod', 15], ['*', 'PUNCT', 17, 'punct', 16], ['winds', 'NOUN', 17, 'ROOT', 17], ['out', 'ADP', 17, 'prep', 18], ['of', 'ADP', 18, 'prep', 19], ['#Tallahassee', 'PROPN', 19, 'pobj', 20], ['from', 'ADP', 17, 'prep', 21], ['#HurricaneMichael', 'PROPN', 21, 'pobj', 22], ['.', 'PUNCT', 17, 'punct', 23]], [['However', 'ADV', 9, 'advmod', 0], ['Gadsden', 'PROPN', 6, 'nsubj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['Liberty', 'PROPN', 1, 'conj', 3], ['will', 'VERB', 6, 'aux', 4], ['still', 'ADV', 6, 'advmod', 5], ['per', 'ADP', 9, 'prep', 6], ['these', 'DET', 8, 'det', 7], ['models', 'NOUN', 6, 'pobj', 8], ['get', 'VERB', 9, 'ROOT', 9], ['Hurricane', 'PROPN', 11, 'compound', 10], ['force', 'NOUN', 12, 'compound', 11], ['winds', 'NOUN', 9, 'ccomp', 12], ['so', 'ADP', 16, 'advmod', 13], ['it', 'PRON', 15, 'nsubj', 14], ['’', 'VERB', 16, 'nsubj', 15], ['s', 'VERB', 9, 'advcl', 16], ['close', 'ADV', 16, 'acomp', 17], ['enough', 'ADV', 17, 'advmod', 18], ['to', 'ADP', 17, 'prep', 19], ['Tallahassee', 'PROPN', 19, 'pobj', 20], ['to', 'PART', 22, 'aux', 21], ['worry', 'VERB', 17, 'advcl', 22], ['.', 'PUNCT', 9, 'punct', 23]]]\n",
      "candidate 0=Gadsden\n",
      "anchor NE candidates = Liberty,Tallahassee\n",
      "data NE tree=[['Gadsden', 'PROPN', 6, 'nsubj', 1]]\n",
      "NE parse token at tree=1, token=2:\n",
      "['Gadsden', 'PROPN', 6, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['per', 'ADP', 9, 'prep', 6]\n",
      "NE=Gadsden subtree=[['&', 'CCONJ', 1, 'cc', 2], ['Liberty', 'PROPN', 1, 'conj', 3]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Liberty\n",
      "anchor NE candidates = Tallahassee\n",
      "data NE tree=[['Liberty', 'PROPN', 1, 'conj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['Liberty', 'PROPN', 1, 'conj', 3]\n",
      "NE parent token:\n",
      "['Gadsden', 'PROPN', 6, 'nsubj', 1]\n",
      "candidate 2=Tallahassee\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE tallahassee, txt:HurriCation Self Portrait 3. Nice work on the backdrop katebackdrops #hurricanemichaelmademedoit #longexposure @ Tallahassee, Florida <URL>\n",
      "full parse [[['HurriCation', 'PROPN', 2, 'compound', 0], ['Self', 'PROPN', 2, 'compound', 1], ['Portrait', 'PROPN', 2, 'ROOT', 2], ['3', 'NUM', 2, 'nummod', 3], ['.', 'PUNCT', 2, 'punct', 4]], [['Nice', 'ADJ', 1, 'amod', 0], ['work', 'NOUN', 1, 'ROOT', 1], ['on', 'ADP', 1, 'prep', 2], ['the', 'DET', 4, 'det', 3], ['backdrop', 'NOUN', 5, 'compound', 4], ['katebackdrops', 'NOUN', 2, 'pobj', 5], ['#hurricanemichaelmademedoit', 'X', 7, 'compound', 6], ['#longexposure', 'PROPN', 7, 'ROOT', 7], ['@', 'ADP', 7, 'punct', 8], ['Tallahassee', 'PROPN', 10, 'compound', 9], ['Florida', 'PROPN', 10, 'ROOT', 10]]]\n",
      "candidate 0=Tallahassee\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Tallahassee', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Tallahassee', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 10, 'ROOT', 10]\n",
      "parent node subtree [['Tallahassee', 'PROPN', 10, 'compound', 9], ['Florida', 'PROPN', 10, 'ROOT', 10]]\n",
      "parent node subtree str tallahassee florida\n",
      "false positive: NE=tallahassee, type=state\n",
      "false positive: NE=tallahassee, type=compound\n",
      "testing NE panhandle, txt:RT @weartv: Massive construction cranes loom over the skyline in Panama City Beach as #HurricaneMichael takes aim at the #Florida Panhandle…\n",
      "full parse [[['RT', 'PROPN', 1, 'compound', 0], ['@weartv', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['Massive', 'ADJ', 5, 'amod', 3], ['construction', 'NOUN', 5, 'compound', 4], ['cranes', 'NOUN', 6, 'nsubj', 5], ['loom', 'VERB', 6, 'ROOT', 6], ['over', 'ADP', 6, 'prep', 7], ['the', 'DET', 9, 'det', 8], ['skyline', 'NOUN', 7, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Panama', 'PROPN', 13, 'compound', 11], ['City', 'PROPN', 13, 'compound', 12], ['Beach', 'PROPN', 10, 'pobj', 13], ['as', 'ADP', 16, 'mark', 14], ['#HurricaneMichael', 'PROPN', 16, 'nsubj', 15], ['takes', 'VERB', 6, 'advcl', 16], ['aim', 'NOUN', 16, 'dobj', 17], ['at', 'ADP', 16, 'prep', 18], ['the', 'DET', 20, 'det', 19], ['#Florida', 'PROPN', 21, 'compound', 20], ['Panhandle', 'PROPN', 18, 'pobj', 21], ['…', 'PUNCT', 6, 'punct', 22]]]\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = \n",
      "candidate 1=Panhandle\n",
      "anchor NE candidates = Panama City Beach\n",
      "data NE tree=[['Panhandle', 'PROPN', 18, 'pobj', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Panhandle', 'PROPN', 18, 'pobj', 21]\n",
      "NE parent token:\n",
      "['at', 'ADP', 16, 'prep', 18]\n",
      "NE=Panhandle subtree=[['the', 'DET', 20, 'det', 19], ['#Florida', 'PROPN', 21, 'compound', 20]]\n",
      "min node deps ['det']\n",
      "testing NE gulf_shores, txt:Please be safe my Florida and Gulf Shores friends!! Praying for you! #HurricaneMichael\n",
      "full parse [[['Please', 'INTJ', 1, 'intj', 0], ['be', 'VERB', 1, 'ROOT', 1], ['safe', 'ADJ', 1, 'acomp', 2], ['my', 'ADJ', 8, 'poss', 3], ['Florida', 'PROPN', 8, 'nmod', 4], ['and', 'CCONJ', 4, 'cc', 5], ['Gulf', 'PROPN', 7, 'compound', 6], ['Shores', 'PROPN', 4, 'conj', 7], ['friends', 'NOUN', 1, 'npadvmod', 8], ['!', 'PUNCT', 1, 'punct', 9], ['!', 'PUNCT', 1, 'punct', 10]], [['Praying', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['you', 'PRON', 1, 'pobj', 2], ['!', 'PUNCT', 0, 'punct', 3]], [['#HurricaneMichael', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Gulf Shores\n",
      "anchor NE candidates = \n",
      "testing NE sarasota, txt:#hurricanemichael, Siesta Key Beach, Sarasota, Florida.Only brits 🇬🇧 left on the beach. Sending love further up the panhandle. <URL>\n",
      "full parse [[['#hurricanemichael', 'PROPN', 9, 'intj', 0], ['Siesta', 'PROPN', 2, 'compound', 1], ['Key', 'PROPN', 3, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3], ['Sarasota', 'PROPN', 6, 'compound', 4], ['Florida.Only', 'ADV', 6, 'compound', 5], ['brits', 'NOUN', 9, 'nsubj', 6], ['🇬', 'PROPN', 9, 'punct', 7], ['🇧', 'PROPN', 9, 'nsubj', 8], ['left', 'VERB', 9, 'ROOT', 9], ['on', 'ADP', 9, 'prep', 10], ['the', 'DET', 12, 'det', 11], ['beach', 'NOUN', 10, 'pobj', 12], ['.', 'PUNCT', 9, 'punct', 13]], [['Sending', 'VERB', 0, 'ROOT', 0], ['love', 'NOUN', 0, 'dobj', 1], ['further', 'ADV', 3, 'advmod', 2], ['up', 'ADP', 0, 'prep', 3], ['the', 'DET', 5, 'det', 4], ['panhandle', 'NOUN', 3, 'pobj', 5], ['.', 'PUNCT', 0, 'punct', 6]]]\n",
      "candidate 0=Sarasota\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Sarasota', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Sarasota', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['brits', 'NOUN', 9, 'nsubj', 6]\n",
      "parent node subtree [['Siesta', 'PROPN', 2, 'compound', 1], ['Key', 'PROPN', 3, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3], ['Sarasota', 'PROPN', 6, 'compound', 4], ['Florida.Only', 'ADV', 6, 'compound', 5], ['brits', 'NOUN', 9, 'nsubj', 6]]\n",
      "parent node subtree str siesta key beach sarasota florida.only brits\n",
      "NE=Sarasota subtree=[['Siesta', 'PROPN', 2, 'compound', 1], ['Key', 'PROPN', 3, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3]]\n",
      "min node deps ['compound']\n",
      "testing NE okaloosa_county, txt:Our first #HurricaneMichael response teams have arrived at a staging area in Okaloosa County, FL, just across the b… <URL>\n",
      "full parse [[['Our', 'ADJ', 4, 'poss', 0], ['first', 'ADJ', 2, 'amod', 1], ['#HurricaneMichael', 'PROPN', 4, 'compound', 2], ['response', 'NOUN', 4, 'compound', 3], ['teams', 'NOUN', 6, 'nsubj', 4], ['have', 'VERB', 6, 'aux', 5], ['arrived', 'VERB', 6, 'ROOT', 6], ['at', 'ADP', 6, 'prep', 7], ['a', 'DET', 10, 'det', 8], ['staging', 'NOUN', 10, 'compound', 9], ['area', 'NOUN', 7, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['Okaloosa', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 14, 'compound', 13], ['FL', 'PROPN', 11, 'pobj', 14], ['just', 'ADV', 16, 'advmod', 15], ['across', 'ADP', 6, 'prep', 16], ['the', 'DET', 18, 'det', 17], ['b', 'NOUN', 16, 'pobj', 18], ['…', 'PUNCT', 6, 'punct', 19]]]\n",
      "candidate 0=Okaloosa County\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Okaloosa', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['County', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 11, 'pobj', 14]\n",
      "parent node subtree [['Okaloosa', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 14, 'compound', 13], ['FL', 'PROPN', 11, 'pobj', 14]]\n",
      "parent node subtree str okaloosa county fl\n",
      "false positive: NE=okaloosa_county, type=compound\n",
      "testing NE lynn_haven, txt:Posting for a friend: “If anyone knows what conditions are like or has pics near Delaware Ave (right outside the Lynn Haven Country Club) or on Lisenby near 390, Lynn Haven, FL north of Panama City Beach, FL. Still can get ahold of my mom or grandparents.” #HurricaneMichael\n",
      "full parse [[['Posting', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['a', 'DET', 3, 'det', 2], ['friend', 'NOUN', 1, 'pobj', 3], [':', 'PUNCT', 0, 'punct', 4], ['“', 'INTJ', 0, 'appos', 5], ['If', 'ADP', 8, 'mark', 6], ['anyone', 'NOUN', 8, 'nsubj', 7], ['knows', 'VERB', 0, 'advcl', 8], ['what', 'ADJ', 10, 'det', 9], ['conditions', 'NOUN', 11, 'nsubj', 10], ['are', 'VERB', 8, 'ccomp', 11], ['like', 'ADP', 11, 'acomp', 12], ['or', 'CCONJ', 11, 'cc', 13], ['has', 'VERB', 11, 'conj', 14], ['pics', 'NOUN', 14, 'dobj', 15], ['near', 'ADP', 15, 'prep', 16], ['Delaware', 'PROPN', 18, 'compound', 17], ['Ave', 'PROPN', 16, 'pobj', 18], ['(', 'PUNCT', 18, 'punct', 19], ['right', 'ADV', 21, 'advmod', 20], ['outside', 'ADP', 14, 'prep', 21], ['the', 'DET', 26, 'det', 22], ['Lynn', 'PROPN', 26, 'compound', 23], ['Haven', 'PROPN', 26, 'compound', 24], ['Country', 'PROPN', 26, 'compound', 25], ['Club', 'PROPN', 21, 'pobj', 26], [')', 'PUNCT', 14, 'punct', 27], ['or', 'CCONJ', 14, 'cc', 28], ['on', 'ADP', 14, 'conj', 29], ['Lisenby', 'PROPN', 29, 'pobj', 30], ['near', 'ADP', 14, 'prep', 31], ['390', 'NUM', 36, 'nummod', 32], ['Lynn', 'PROPN', 34, 'compound', 33], ['Haven', 'PROPN', 36, 'compound', 34], ['FL', 'PROPN', 36, 'compound', 35], ['north', 'NOUN', 31, 'pobj', 36], ['of', 'ADP', 36, 'prep', 37], ['Panama', 'PROPN', 41, 'compound', 38], ['City', 'PROPN', 41, 'compound', 39], ['Beach', 'PROPN', 41, 'compound', 40], ['FL', 'PROPN', 37, 'pobj', 41], ['.', 'PUNCT', 0, 'punct', 42]], [['Still', 'ADV', 2, 'advmod', 0], ['can', 'VERB', 2, 'aux', 1], ['get', 'VERB', 2, 'ROOT', 2], ['ahold', 'ADP', 2, 'acomp', 3], ['of', 'ADP', 3, 'prep', 4], ['my', 'ADJ', 6, 'poss', 5], ['mom', 'NOUN', 4, 'pobj', 6], ['or', 'CCONJ', 6, 'cc', 7], ['grandparents', 'NOUN', 6, 'conj', 8], ['.', 'PUNCT', 2, 'punct', 9], ['”', 'PUNCT', 10, 'ROOT', 10], ['#HurricaneMichael', 'PROPN', 11, 'ROOT', 11]]]\n",
      "candidate 0=Lynn Haven\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Lynn', 'PROPN', 26, 'compound', 23], ['Haven', 'PROPN', 26, 'compound', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Haven', 'PROPN', 26, 'compound', 24]\n",
      "NE parent token:\n",
      "['Club', 'PROPN', 21, 'pobj', 26]\n",
      "parent node subtree [['the', 'DET', 26, 'det', 22], ['Lynn', 'PROPN', 26, 'compound', 23], ['Haven', 'PROPN', 26, 'compound', 24], ['Country', 'PROPN', 26, 'compound', 25], ['Club', 'PROPN', 21, 'pobj', 26]]\n",
      "parent node subtree str the lynn haven country club\n",
      "candidate 1=Panama City Beach\n",
      "anchor NE candidates = Delaware,FL\n",
      "data NE tree=[['Panama', 'PROPN', 41, 'compound', 38], ['City', 'PROPN', 41, 'compound', 39], ['Beach', 'PROPN', 41, 'compound', 40]]\n",
      "NE parse token at tree=0, token=41:\n",
      "['Beach', 'PROPN', 41, 'compound', 40]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 37, 'pobj', 41]\n",
      "parent node subtree [['Panama', 'PROPN', 41, 'compound', 38], ['City', 'PROPN', 41, 'compound', 39], ['Beach', 'PROPN', 41, 'compound', 40], ['FL', 'PROPN', 37, 'pobj', 41]]\n",
      "parent node subtree str panama city beach fl\n",
      "testing NE bay, txt:More than 80% of our customers in Bay, Franklin, Gulf, Jefferson & Wakulla counties lost power as #Michael roared on shore as a cat. 4 hurricane. Damage assessment & repairs to the electric system are underway in areas that crews are able to access. <URL>\n",
      "full parse [[['More', 'ADJ', 2, 'amod', 0], ['than', 'ADP', 2, 'quantmod', 1], ['80', 'NUM', 3, 'nummod', 2], ['%', 'NOUN', 15, 'nsubj', 3], ['of', 'ADP', 3, 'prep', 4], ['our', 'ADJ', 6, 'poss', 5], ['customers', 'NOUN', 4, 'pobj', 6], ['in', 'ADP', 6, 'prep', 7], ['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['Jefferson', 'PROPN', 14, 'nmod', 11], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13], ['counties', 'NOUN', 7, 'pobj', 14], ['lost', 'VERB', 15, 'ROOT', 15], ['power', 'NOUN', 15, 'dobj', 16], ['as', 'ADP', 19, 'mark', 17], ['#Michael', 'PROPN', 19, 'nsubj', 18], ['roared', 'VERB', 15, 'advcl', 19], ['on', 'ADP', 19, 'prep', 20], ['shore', 'NOUN', 20, 'pobj', 21], ['as', 'ADP', 19, 'prep', 22], ['a', 'DET', 24, 'det', 23], ['cat', 'NOUN', 22, 'pobj', 24], ['.', 'PUNCT', 15, 'punct', 25]], [['4', 'NUM', 1, 'nummod', 0], ['hurricane', 'NOUN', 1, 'ROOT', 1], ['.', 'PUNCT', 1, 'punct', 2]], [['Damage', 'NOUN', 1, 'compound', 0], ['assessment', 'NOUN', 8, 'nsubj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['repairs', 'NOUN', 1, 'conj', 3], ['to', 'ADP', 1, 'prep', 4], ['the', 'DET', 7, 'det', 5], ['electric', 'ADJ', 7, 'amod', 6], ['system', 'NOUN', 4, 'pobj', 7], ['are', 'VERB', 8, 'ROOT', 8], ['underway', 'ADJ', 8, 'acomp', 9], ['in', 'ADP', 8, 'prep', 10], ['areas', 'NOUN', 10, 'pobj', 11], ['that', 'ADP', 14, 'mark', 12], ['crews', 'NOUN', 14, 'nsubj', 13], ['are', 'VERB', 11, 'relcl', 14], ['able', 'ADJ', 14, 'acomp', 15], ['to', 'PART', 17, 'aux', 16], ['access', 'VERB', 15, 'xcomp', 17], ['.', 'PUNCT', 8, 'punct', 18]]]\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Franklin,Gulf,Jefferson\n",
      "data NE tree=[['Bay', 'PROPN', 11, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Bay', 'PROPN', 11, 'compound', 8]\n",
      "NE parent token:\n",
      "['Jefferson', 'PROPN', 14, 'nmod', 11]\n",
      "parent node subtree [['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['Jefferson', 'PROPN', 14, 'nmod', 11], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "parent node subtree str bay franklin gulf jefferson & wakulla\n",
      "candidate 1=Franklin\n",
      "anchor NE candidates = \n",
      "candidate 2=Gulf\n",
      "anchor NE candidates = Franklin,Jefferson\n",
      "data NE tree=[['Gulf', 'PROPN', 11, 'nmod', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['Gulf', 'PROPN', 11, 'nmod', 10]\n",
      "NE parent token:\n",
      "['Jefferson', 'PROPN', 14, 'nmod', 11]\n",
      "parent node subtree [['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['Jefferson', 'PROPN', 14, 'nmod', 11], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "parent node subtree str bay franklin gulf jefferson & wakulla\n",
      "candidate 3=Jefferson\n",
      "anchor NE candidates = Franklin\n",
      "data NE tree=[['Jefferson', 'PROPN', 14, 'nmod', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Jefferson', 'PROPN', 14, 'nmod', 11]\n",
      "NE parent token:\n",
      "['counties', 'NOUN', 7, 'pobj', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['Jefferson', 'PROPN', 14, 'nmod', 11], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13], ['counties', 'NOUN', 7, 'pobj', 14]]\n",
      "parent node subtree str bay franklin gulf jefferson & wakulla counties\n",
      "NE=Jefferson subtree=[['Bay', 'PROPN', 11, 'compound', 8], ['Franklin', 'PROPN', 11, 'compound', 9], ['Gulf', 'PROPN', 11, 'nmod', 10], ['&', 'CCONJ', 11, 'cc', 12], ['Wakulla', 'PROPN', 11, 'conj', 13]]\n",
      "min node deps ['compound', 'compound', 'nmod', 'cc', 'conj']\n",
      "testing NE gadsden_county, txt:Sadly, we now have 6 confirmed fatalities due to #Michael , all inland. 4 in Gadsden County, FL (NW of Tallahassee), one in Seminole County in SW Georgia, and one north of Charlotte in Iredell County, NC. Most known to be due to wind knocking down trees or structures onto victims.\n",
      "full parse [[['Sadly', 'ADV', 3, 'advmod', 0], ['we', 'PRON', 3, 'nsubj', 1], ['now', 'ADV', 3, 'advmod', 2], ['have', 'VERB', 3, 'ROOT', 3], ['6', 'NUM', 6, 'nummod', 4], ['confirmed', 'VERB', 6, 'amod', 5], ['fatalities', 'NOUN', 3, 'dobj', 6], ['due', 'ADJ', 6, 'amod', 7], ['to', 'ADP', 7, 'prep', 8], ['#Michael', 'PROPN', 8, 'pobj', 9], ['all', 'DET', 11, 'det', 10], ['inland', 'ADV', 3, 'npadvmod', 11], ['.', 'PUNCT', 3, 'punct', 12]], [['4', 'PUNCT', 0, 'ROOT', 0], ['in', 'ADP', 0, 'prep', 1], ['Gadsden', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 4, 'compound', 3], ['FL', 'PROPN', 1, 'pobj', 4], ['(', 'PUNCT', 4, 'punct', 5], ['NW', 'PROPN', 4, 'appos', 6], ['of', 'ADP', 6, 'prep', 7], ['Tallahassee', 'PROPN', 7, 'pobj', 8], [')', 'PUNCT', 4, 'punct', 9], ['one', 'NUM', 4, 'appos', 10], ['in', 'ADP', 10, 'prep', 11], ['Seminole', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 11, 'pobj', 13], ['in', 'ADP', 13, 'prep', 14], ['SW', 'PROPN', 16, 'compound', 15], ['Georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['Charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24], ['NC', 'PROPN', 22, 'pobj', 25], ['.', 'PUNCT', 0, 'punct', 26]], [['Most', 'ADV', 1, 'advmod', 0], ['known', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['be', 'VERB', 1, 'xcomp', 3], ['due', 'ADJ', 3, 'acomp', 4], ['to', 'ADP', 4, 'pcomp', 5], ['wind', 'NOUN', 4, 'pobj', 6], ['knocking', 'VERB', 6, 'acl', 7], ['down', 'PART', 7, 'prt', 8], ['trees', 'NOUN', 7, 'dobj', 9], ['or', 'CCONJ', 9, 'cc', 10], ['structures', 'NOUN', 9, 'conj', 11], ['onto', 'ADP', 7, 'prep', 12], ['victims', 'NOUN', 12, 'pobj', 13], ['.', 'PUNCT', 1, 'punct', 14]]]\n",
      "candidate 0=Gadsden County\n",
      "anchor NE candidates = FL,Tallahassee,Seminole County,Charlotte,Iredell County,NC\n",
      "data NE tree=[['Gadsden', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['County', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 1, 'pobj', 4]\n",
      "parent node subtree [['Gadsden', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 4, 'compound', 3], ['FL', 'PROPN', 1, 'pobj', 4], ['(', 'PUNCT', 4, 'punct', 5], ['NW', 'PROPN', 4, 'appos', 6], ['of', 'ADP', 6, 'prep', 7], ['Tallahassee', 'PROPN', 7, 'pobj', 8], [')', 'PUNCT', 4, 'punct', 9], ['one', 'NUM', 4, 'appos', 10], ['in', 'ADP', 10, 'prep', 11], ['Seminole', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 11, 'pobj', 13], ['in', 'ADP', 13, 'prep', 14], ['SW', 'PROPN', 16, 'compound', 15], ['Georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['Charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24], ['NC', 'PROPN', 22, 'pobj', 25]]\n",
      "parent node subtree str gadsden county fl ( nw of tallahassee ) one in seminole county in sw georgia and one north of charlotte in iredell county nc\n",
      "candidate 1=Tallahassee\n",
      "anchor NE candidates = \n",
      "candidate 2=Seminole County\n",
      "anchor NE candidates = FL,Seminole County,Charlotte,NC\n",
      "data NE tree=[['Seminole', 'PROPN', 13, 'compound', 12], ['County', 'PROPN', 11, 'pobj', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['County', 'PROPN', 11, 'pobj', 13]\n",
      "NE parent token:\n",
      "['in', 'ADP', 10, 'prep', 11]\n",
      "NE=Seminole County subtree=[['in', 'ADP', 13, 'prep', 14], ['SW', 'PROPN', 16, 'compound', 15], ['Georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['Charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['Iredell', 'PROPN', 24, 'compound', 23], ['County', 'PROPN', 25, 'compound', 24], ['NC', 'PROPN', 22, 'pobj', 25]]\n",
      "min node deps ['prep', 'cc', 'conj']\n",
      "subtree = in SW Georgia and one north of Charlotte in Iredell County NC\n",
      "false positive: NE=gadsden_county, type=compound\n",
      "testing NE miami, txt:But here I am, always watching other places have outside help in a disaster and here we live with police and fire from Jacksonville, Miami, Hillsborough, Tallahassee and other places roll up and down the roads #PanamaCity #HurricaneMichael\n",
      "full parse [[['But', 'CCONJ', 5, 'cc', 0], ['here', 'ADV', 5, 'advmod', 1], ['I', 'PRON', 5, 'nsubj', 2], ['am', 'VERB', 5, 'aux', 3], ['always', 'ADV', 5, 'advmod', 4], ['watching', 'VERB', 5, 'ROOT', 5], ['other', 'ADJ', 7, 'amod', 6], ['places', 'NOUN', 8, 'nsubj', 7], ['have', 'VERB', 5, 'ccomp', 8], ['outside', 'ADJ', 10, 'amod', 9], ['help', 'NOUN', 8, 'dobj', 10], ['in', 'ADP', 10, 'prep', 11], ['a', 'DET', 13, 'det', 12], ['disaster', 'NOUN', 11, 'pobj', 13], ['and', 'CCONJ', 8, 'cc', 14], ['here', 'ADV', 17, 'advmod', 15], ['we', 'PRON', 17, 'nsubj', 16], ['live', 'VERB', 8, 'conj', 17], ['with', 'ADP', 17, 'prep', 18], ['police', 'NOUN', 18, 'pobj', 19], ['and', 'CCONJ', 19, 'cc', 20], ['fire', 'NOUN', 19, 'conj', 21], ['from', 'ADP', 17, 'prep', 22], ['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['Tallahassee', 'PROPN', 22, 'pobj', 26], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29], ['roll', 'VERB', 17, 'conj', 30], ['up', 'PART', 30, 'prt', 31], ['and', 'CCONJ', 31, 'cc', 32], ['down', 'ADP', 31, 'conj', 33], ['the', 'DET', 35, 'det', 34], ['roads', 'NOUN', 33, 'pobj', 35], ['#PanamaCity', 'VERB', 37, 'compound', 36], ['#HurricaneMichael', 'PROPN', 37, 'ROOT', 37]]]\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = \n",
      "candidate 1=Miami\n",
      "anchor NE candidates = Jacksonville\n",
      "data NE tree=[['Miami', 'PROPN', 26, 'compound', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Miami', 'PROPN', 26, 'compound', 24]\n",
      "NE parent token:\n",
      "['Tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['Tallahassee', 'PROPN', 22, 'pobj', 26], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "parent node subtree str jacksonville miami hillsborough tallahassee and other places\n",
      "candidate 2=Hillsborough\n",
      "anchor NE candidates = Jacksonville,Miami,Tallahassee\n",
      "data NE tree=[['Hillsborough', 'PROPN', 26, 'compound', 25]]\n",
      "NE parse token at tree=0, token=26:\n",
      "['Hillsborough', 'PROPN', 26, 'compound', 25]\n",
      "NE parent token:\n",
      "['Tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "parent node subtree [['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['Tallahassee', 'PROPN', 22, 'pobj', 26], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "parent node subtree str jacksonville miami hillsborough tallahassee and other places\n",
      "candidate 3=Tallahassee\n",
      "anchor NE candidates = Jacksonville,Miami\n",
      "data NE tree=[['Tallahassee', 'PROPN', 22, 'pobj', 26]]\n",
      "NE parse token at tree=0, token=27:\n",
      "['Tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "NE parent token:\n",
      "['from', 'ADP', 17, 'prep', 22]\n",
      "NE=Tallahassee subtree=[['Jacksonville', 'PROPN', 26, 'compound', 23], ['Miami', 'PROPN', 26, 'compound', 24], ['Hillsborough', 'PROPN', 26, 'compound', 25], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "min node deps ['compound', 'compound', 'compound', 'cc', 'conj']\n",
      "testing NE jacksonville, txt:IDES is responding to #HurricaneMichael IDES staff is en route to Florida where we will be #partnering with our Anchor Church, Christ's Church of Jacksonville, @ccontheweb to connect with churches in communities affected by #Hurricane Michael. <URL>\n",
      "full parse [[['IDES', 'PROPN', 2, 'nsubj', 0], ['is', 'VERB', 2, 'aux', 1], ['responding', 'VERB', 2, 'ROOT', 2], ['to', 'ADP', 2, 'prep', 3], ['#HurricaneMichael', 'PROPN', 6, 'compound', 4], ['IDES', 'PROPN', 6, 'compound', 5], ['staff', 'NOUN', 3, 'pobj', 6], ['is', 'VERB', 2, 'conj', 7], ['en', 'ADP', 7, 'advmod', 8], ['route', 'NOUN', 8, 'npadvmod', 9], ['to', 'ADP', 9, 'prep', 10], ['Florida', 'PROPN', 10, 'pobj', 11], ['where', 'ADV', 16, 'advmod', 12], ['we', 'PRON', 16, 'nsubj', 13], ['will', 'VERB', 16, 'aux', 14], ['be', 'VERB', 16, 'aux', 15], ['#partnering', 'VERB', 11, 'relcl', 16], ['with', 'ADP', 16, 'prep', 17], ['our', 'ADJ', 22, 'poss', 18], ['Anchor', 'PROPN', 20, 'compound', 19], ['Church', 'PROPN', 22, 'compound', 20], [\"Christ's\", 'PROPN', 22, 'compound', 21], ['Church', 'PROPN', 17, 'pobj', 22], ['of', 'ADP', 22, 'prep', 23], ['Jacksonville', 'PROPN', 25, 'compound', 24], ['@ccontheweb', 'PUNCT', 2, 'dobj', 25], ['to', 'PART', 27, 'aux', 26], ['connect', 'VERB', 2, 'advcl', 27], ['with', 'ADP', 27, 'prep', 28], ['churches', 'NOUN', 28, 'pobj', 29], ['in', 'ADP', 29, 'prep', 30], ['communities', 'NOUN', 30, 'pobj', 31], ['affected', 'VERB', 31, 'acl', 32], ['by', 'ADP', 32, 'agent', 33], ['#Hurricane', 'PROPN', 35, 'compound', 34], ['Michael', 'PROPN', 33, 'pobj', 35], ['.', 'PUNCT', 2, 'punct', 36]]]\n",
      "candidate 0=Jacksonville\n",
      "anchor NE candidates = \n",
      "testing NE darlington, txt:TS #Michael knocked down some trees, left thousands without power, and blocked several roadways in Darlington, SC. <URL>\n",
      "full parse [[['TS', 'PROPN', 1, 'compound', 0], ['#Michael', 'PROPN', 2, 'nsubj', 1], ['knocked', 'VERB', 2, 'ROOT', 2], ['down', 'PART', 2, 'prt', 3], ['some', 'DET', 5, 'det', 4], ['trees', 'NOUN', 2, 'dobj', 5], ['left', 'VERB', 2, 'conj', 6], ['thousands', 'NOUN', 6, 'dobj', 7], ['without', 'ADP', 6, 'prep', 8], ['power', 'NOUN', 8, 'pobj', 9], ['and', 'CCONJ', 6, 'cc', 10], ['blocked', 'VERB', 6, 'conj', 11], ['several', 'ADJ', 13, 'amod', 12], ['roadways', 'NOUN', 11, 'dobj', 13], ['in', 'ADP', 11, 'prep', 14], ['Darlington', 'PROPN', 16, 'compound', 15], ['SC', 'PROPN', 14, 'pobj', 16], ['.', 'PUNCT', 2, 'punct', 17]]]\n",
      "candidate 0=Darlington\n",
      "anchor NE candidates = SC\n",
      "data NE tree=[['Darlington', 'PROPN', 16, 'compound', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Darlington', 'PROPN', 16, 'compound', 15]\n",
      "NE parent token:\n",
      "['SC', 'PROPN', 14, 'pobj', 16]\n",
      "parent node subtree [['Darlington', 'PROPN', 16, 'compound', 15], ['SC', 'PROPN', 14, 'pobj', 16]]\n",
      "parent node subtree str darlington sc\n",
      "false positive: NE=darlington, type=compound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE panama_city_beach, txt:All day we've all seen the horrific landscape in Panama City Beach and Mexico Beach, Florida and other parts of the Panhandle. But every new drone or aerial shot continues to stun. #Michael was swift. In the morning things were there. In the afternoon, they weren't. <URL>\n",
      "full parse [[['All', 'DET', 1, 'det', 0], ['day', 'NOUN', 4, 'npadvmod', 1], [\"we've\", 'VERB', 3, 'nmod', 2], ['all', 'DET', 4, 'nsubj', 3], ['seen', 'VERB', 4, 'ROOT', 4], ['the', 'DET', 7, 'det', 5], ['horrific', 'ADJ', 7, 'amod', 6], ['landscape', 'NOUN', 4, 'dobj', 7], ['in', 'ADP', 7, 'prep', 8], ['Panama', 'PROPN', 11, 'compound', 9], ['City', 'PROPN', 11, 'nmod', 10], ['Beach', 'PROPN', 8, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Mexico', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 11, 'conj', 14], ['Florida', 'PROPN', 11, 'conj', 15], ['and', 'CCONJ', 11, 'cc', 16], ['other', 'ADJ', 18, 'amod', 17], ['parts', 'NOUN', 11, 'conj', 18], ['of', 'ADP', 18, 'prep', 19], ['the', 'DET', 21, 'det', 20], ['Panhandle', 'PROPN', 19, 'pobj', 21], ['.', 'PUNCT', 4, 'punct', 22]], [['But', 'CCONJ', 7, 'cc', 0], ['every', 'DET', 3, 'det', 1], ['new', 'ADJ', 3, 'amod', 2], ['drone', 'NOUN', 7, 'nsubj', 3], ['or', 'CCONJ', 3, 'cc', 4], ['aerial', 'ADJ', 6, 'amod', 5], ['shot', 'NOUN', 3, 'conj', 6], ['continues', 'VERB', 7, 'ROOT', 7], ['to', 'PART', 9, 'aux', 8], ['stun', 'VERB', 7, 'xcomp', 9], ['.', 'PUNCT', 7, 'punct', 10]], [['#Michael', 'PROPN', 1, 'nsubj', 0], ['was', 'VERB', 1, 'ROOT', 1], ['swift', 'ADJ', 1, 'acomp', 2], ['.', 'PUNCT', 1, 'punct', 3]], [['In', 'ADP', 4, 'prep', 0], ['the', 'DET', 2, 'det', 1], ['morning', 'NOUN', 0, 'pobj', 2], ['things', 'NOUN', 4, 'nsubj', 3], ['were', 'VERB', 4, 'ROOT', 4], ['there', 'ADV', 4, 'advmod', 5], ['.', 'PUNCT', 4, 'punct', 6]], [['In', 'ADP', 4, 'prep', 0], ['the', 'DET', 2, 'det', 1], ['afternoon', 'NOUN', 0, 'pobj', 2], ['they', 'PRON', 4, 'nsubj', 3], [\"weren't\", 'VERB', 4, 'ROOT', 4], ['.', 'PUNCT', 4, 'punct', 5]]]\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Panama', 'PROPN', 11, 'compound', 9], ['City', 'PROPN', 11, 'nmod', 10], ['Beach', 'PROPN', 8, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "NE parent token:\n",
      "['in', 'ADP', 7, 'prep', 8]\n",
      "NE=Panama City Beach subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Mexico', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 11, 'conj', 14], ['Florida', 'PROPN', 11, 'conj', 15], ['and', 'CCONJ', 11, 'cc', 16], ['other', 'ADJ', 18, 'amod', 17], ['parts', 'NOUN', 11, 'conj', 18], ['of', 'ADP', 18, 'prep', 19], ['the', 'DET', 21, 'det', 20], ['Panhandle', 'PROPN', 19, 'pobj', 21]]\n",
      "min node deps ['cc', 'conj', 'conj', 'cc', 'conj']\n",
      "candidate 1=Mexico Beach\n",
      "anchor NE candidates = Panama City Beach,Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 14, 'compound', 13], ['Beach', 'PROPN', 11, 'conj', 14]]\n",
      "NE parse token at tree=0, token=15:\n",
      "['Beach', 'PROPN', 11, 'conj', 14]\n",
      "NE parent token:\n",
      "['Beach', 'PROPN', 8, 'pobj', 11]\n",
      "testing NE houston_county, txt:Keep all the cities affected by #HurricaneMichael in your prayers. Jackson County Bay County Washington County Houston County and others. We all need help!\n",
      "full parse [[['Keep', 'VERB', 0, 'ROOT', 0], ['all', 'ADJ', 3, 'predet', 1], ['the', 'DET', 3, 'det', 2], ['cities', 'NOUN', 0, 'dobj', 3], ['affected', 'VERB', 3, 'acl', 4], ['by', 'ADP', 4, 'agent', 5], ['#HurricaneMichael', 'PROPN', 5, 'pobj', 6], ['in', 'ADP', 4, 'prep', 7], ['your', 'ADJ', 9, 'poss', 8], ['prayers', 'NOUN', 7, 'pobj', 9], ['.', 'PUNCT', 0, 'punct', 10]], [['Jackson', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'compound', 1], ['Bay', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['Washington', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 7, 'compound', 5], ['Houston', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 7, 'ROOT', 7], ['and', 'CCONJ', 7, 'cc', 8], ['others', 'NOUN', 7, 'conj', 9], ['.', 'PUNCT', 7, 'punct', 10]], [['We', 'PRON', 2, 'nsubj', 0], ['all', 'DET', 0, 'appos', 1], ['need', 'VERB', 2, 'ROOT', 2], ['help', 'NOUN', 2, 'dobj', 3], ['!', 'PUNCT', 2, 'punct', 4]]]\n",
      "candidate 0=Jackson County\n",
      "anchor NE candidates = \n",
      "candidate 1=Houston County\n",
      "anchor NE candidates = Jackson County\n",
      "data NE tree=[['Houston', 'PROPN', 7, 'compound', 6], ['County', 'PROPN', 7, 'ROOT', 7]]\n",
      "NE=Houston County subtree=[['Jackson', 'PROPN', 1, 'compound', 0], ['County', 'PROPN', 3, 'compound', 1], ['Bay', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['Washington', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 7, 'compound', 5], ['and', 'CCONJ', 7, 'cc', 8], ['others', 'NOUN', 7, 'conj', 9], ['.', 'PUNCT', 7, 'punct', 10]]\n",
      "min node deps ['compound']\n",
      "testing NE mexico_beach, txt:All orders to Mexico Beach, FL will be refunded FOC and sent in due course! Please contact info@wave97.com for more information. #HurricaneMichael\n",
      "full parse [[['All', 'DET', 1, 'det', 0], ['orders', 'NOUN', 8, 'nsubjpass', 1], ['to', 'ADP', 1, 'prep', 2], ['Mexico', 'PROPN', 5, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4], ['FL', 'PROPN', 2, 'pobj', 5], ['will', 'VERB', 8, 'aux', 6], ['be', 'VERB', 8, 'auxpass', 7], ['refunded', 'VERB', 8, 'ROOT', 8], ['FOC', 'PROPN', 8, 'dobj', 9], ['and', 'CCONJ', 8, 'cc', 10], ['sent', 'VERB', 8, 'conj', 11], ['in', 'PART', 11, 'advmod', 12], ['due', 'ADJ', 14, 'amod', 13], ['course', 'NOUN', 11, 'dobj', 14], ['!', 'PUNCT', 8, 'punct', 15]], [['Please', 'INTJ', 1, 'intj', 0], ['contact', 'VERB', 1, 'ROOT', 1], ['info@wave97.com', 'X', 1, 'dobj', 2], ['for', 'ADP', 1, 'prep', 3], ['more', 'ADJ', 5, 'amod', 4], ['information', 'NOUN', 3, 'pobj', 5], ['.', 'PUNCT', 1, 'punct', 6]], [['#HurricaneMichael', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Mexico', 'PROPN', 5, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Beach', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Mexico', 'PROPN', 5, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4], ['FL', 'PROPN', 2, 'pobj', 5]]\n",
      "parent node subtree str mexico beach fl\n",
      "false positive: NE=mexico_beach, type=compound\n",
      "testing NE beach, txt:@Dove it would be the perfect time to send extra dry shampoo to Panama City and Beach. No water for maybe weeks #HurricaneMichael #PanamaCityBeach\n",
      "full parse [[['@Dove', 'X', 3, 'npadvmod', 0], ['it', 'PRON', 3, 'nsubj', 1], ['would', 'VERB', 3, 'aux', 2], ['be', 'VERB', 3, 'ROOT', 3], ['the', 'DET', 6, 'det', 4], ['perfect', 'ADJ', 6, 'amod', 5], ['time', 'NOUN', 3, 'attr', 6], ['to', 'PART', 8, 'aux', 7], ['send', 'VERB', 6, 'relcl', 8], ['extra', 'ADV', 11, 'amod', 9], ['dry', 'ADJ', 11, 'amod', 10], ['shampoo', 'NOUN', 8, 'dobj', 11], ['to', 'ADP', 8, 'prep', 12], ['Panama', 'PROPN', 14, 'compound', 13], ['City', 'PROPN', 12, 'pobj', 14], ['and', 'CCONJ', 14, 'cc', 15], ['Beach', 'PROPN', 14, 'conj', 16], ['.', 'PUNCT', 3, 'punct', 17]], [['No', 'DET', 1, 'det', 0], ['water', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['maybe', 'ADV', 4, 'advmod', 3], ['weeks', 'NOUN', 2, 'pobj', 4], ['#HurricaneMichael', 'PROPN', 6, 'compound', 5], ['#PanamaCityBeach', 'PUNCT', 6, 'ROOT', 6]]]\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = \n",
      "candidate 1=Beach\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Beach', 'PROPN', 14, 'conj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['Beach', 'PROPN', 14, 'conj', 16]\n",
      "NE parent token:\n",
      "['City', 'PROPN', 12, 'pobj', 14]\n",
      "testing NE panama_city, txt:ICYMI: This reporter hunkered down in a Panama City, Florida parking deck as Hurricane Michael roared ashore Wednesday More #HurricaneMichael video: <URL>\n",
      "full parse [[['ICYMI', 'PROPN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['This', 'DET', 3, 'det', 2], ['reporter', 'NOUN', 4, 'nsubj', 3], ['hunkered', 'VERB', 4, 'ROOT', 4], ['down', 'PART', 4, 'prt', 5], ['in', 'ADP', 4, 'prep', 6], ['a', 'DET', 12, 'det', 7], ['Panama', 'PROPN', 10, 'compound', 8], ['City', 'PROPN', 10, 'compound', 9], ['Florida', 'PROPN', 12, 'compound', 10], ['parking', 'NOUN', 12, 'compound', 11], ['deck', 'NOUN', 6, 'pobj', 12], ['as', 'ADP', 16, 'mark', 13], ['Hurricane', 'PROPN', 15, 'compound', 14], ['Michael', 'PROPN', 16, 'nsubj', 15], ['roared', 'VERB', 4, 'advcl', 16], ['ashore', 'ADV', 16, 'advmod', 17], ['Wednesday', 'PROPN', 16, 'npadvmod', 18], ['More', 'ADV', 20, 'amod', 19], ['#HurricaneMichael', 'PROPN', 21, 'nummod', 20], ['video', 'NOUN', 21, 'ROOT', 21], [':', 'PUNCT', 21, 'punct', 22]]]\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Panama', 'PROPN', 10, 'compound', 8], ['City', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['City', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 12, 'compound', 10]\n",
      "parent node subtree [['Panama', 'PROPN', 10, 'compound', 8], ['City', 'PROPN', 10, 'compound', 9], ['Florida', 'PROPN', 12, 'compound', 10]]\n",
      "parent node subtree str panama city florida\n",
      "false positive: NE=panama_city, type=compound\n",
      "testing NE bonifay, txt:#HurricaneRelief #HurricaneMichael #MAGA #AmericaFirst #NationalGuard #FEMA @fema #KAG From Congressman Matt Gaetz, for areas having trouble getting supplies, food, water around Bonifay, Holmes County, Ponce De Leon areas. Disaster relief contact info below. @RepMattGaetz <URL>\n",
      "full parse [[['#HurricaneRelief', 'PROPN', 2, 'nmod', 0], ['#HurricaneMichael', 'PROPN', 2, 'compound', 1], ['#MAGA', 'PROPN', 4, 'compound', 2], ['#AmericaFirst', 'X', 4, 'compound', 3], ['#NationalGuard', 'PROPN', 4, 'ROOT', 4], ['#FEMA', 'X', 5, 'ROOT', 5], ['@fema', 'X', 5, 'punct', 6], ['#KAG', 'PUNCT', 7, 'ROOT', 7], ['From', 'ADP', 7, 'prep', 8], ['Congressman', 'PROPN', 11, 'compound', 9], ['Matt', 'PROPN', 11, 'compound', 10], ['Gaetz', 'PROPN', 8, 'pobj', 11], ['for', 'ADP', 8, 'prep', 12], ['areas', 'NOUN', 12, 'pobj', 13], ['having', 'VERB', 13, 'acl', 14], ['trouble', 'NOUN', 14, 'dobj', 15], ['getting', 'VERB', 15, 'acl', 16], ['supplies', 'NOUN', 16, 'dobj', 17], ['food', 'NOUN', 19, 'compound', 18], ['water', 'NOUN', 17, 'dobj', 19], ['around', 'ADP', 17, 'prep', 20], ['Bonifay', 'PROPN', 23, 'compound', 21], ['Holmes', 'PROPN', 23, 'compound', 22], ['County', 'PROPN', 27, 'compound', 23], ['Ponce', 'PROPN', 26, 'compound', 24], ['De', 'PROPN', 26, 'compound', 25], ['Leon', 'PROPN', 27, 'compound', 26], ['areas', 'NOUN', 20, 'pobj', 27], ['.', 'PUNCT', 7, 'punct', 28]], [['Disaster', 'NOUN', 1, 'compound', 0], ['relief', 'NOUN', 2, 'compound', 1], ['contact', 'NOUN', 3, 'compound', 2], ['info', 'NOUN', 3, 'ROOT', 3], ['below', 'ADV', 3, 'advmod', 4], ['.', 'PUNCT', 3, 'punct', 5]], [['@RepMattGaetz', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Bonifay\n",
      "anchor NE candidates = Holmes County\n",
      "data NE tree=[['Bonifay', 'PROPN', 23, 'compound', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Bonifay', 'PROPN', 23, 'compound', 21]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 27, 'compound', 23]\n",
      "parent node subtree [['Bonifay', 'PROPN', 23, 'compound', 21], ['Holmes', 'PROPN', 23, 'compound', 22], ['County', 'PROPN', 27, 'compound', 23]]\n",
      "parent node subtree str bonifay holmes county\n",
      "candidate 1=Holmes County\n",
      "anchor NE candidates = \n",
      "candidate 2=Ponce De Leon\n",
      "anchor NE candidates = Bonifay,Holmes County\n",
      "data NE tree=[['Ponce', 'PROPN', 26, 'compound', 24], ['De', 'PROPN', 26, 'compound', 25], ['Leon', 'PROPN', 27, 'compound', 26]]\n",
      "NE parse token at tree=0, token=27:\n",
      "['Leon', 'PROPN', 27, 'compound', 26]\n",
      "NE parent token:\n",
      "['areas', 'NOUN', 20, 'pobj', 27]\n",
      "parent node subtree [['Bonifay', 'PROPN', 23, 'compound', 21], ['Holmes', 'PROPN', 23, 'compound', 22], ['County', 'PROPN', 27, 'compound', 23], ['Ponce', 'PROPN', 26, 'compound', 24], ['De', 'PROPN', 26, 'compound', 25], ['Leon', 'PROPN', 27, 'compound', 26], ['areas', 'NOUN', 20, 'pobj', 27]]\n",
      "parent node subtree str bonifay holmes county ponce de leon areas\n",
      "testing NE mexico_beach, txt:New aerial video of the massive destruction at Mexico Beach, Florida. Thanks once again to our exclusive partners at @Livestormsmedia #arwx #Michael <URL>\n",
      "full parse [[['New', 'ADJ', 2, 'amod', 0], ['aerial', 'ADJ', 2, 'amod', 1], ['video', 'NOUN', 2, 'ROOT', 2], ['of', 'ADP', 2, 'prep', 3], ['the', 'DET', 6, 'det', 4], ['massive', 'ADJ', 6, 'amod', 5], ['destruction', 'NOUN', 3, 'pobj', 6], ['at', 'ADP', 6, 'prep', 7], ['Mexico', 'PROPN', 10, 'compound', 8], ['Beach', 'PROPN', 10, 'compound', 9], ['Florida', 'PROPN', 7, 'pobj', 10], ['.', 'PUNCT', 2, 'punct', 11]], [['Thanks', 'NOUN', 0, 'ROOT', 0], ['once', 'ADV', 2, 'advmod', 1], ['again', 'ADV', 0, 'advmod', 2], ['to', 'ADP', 0, 'prep', 3], ['our', 'ADJ', 6, 'poss', 4], ['exclusive', 'ADJ', 6, 'amod', 5], ['partners', 'NOUN', 3, 'pobj', 6], ['at', 'ADP', 6, 'prep', 7], ['@Livestormsmedia', 'PROPN', 7, 'pobj', 8], ['#arwx', 'X', 10, 'compound', 9], ['#Michael', 'PROPN', 7, 'pobj', 10]]]\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 10, 'compound', 8], ['Beach', 'PROPN', 10, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Beach', 'PROPN', 10, 'compound', 9]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 7, 'pobj', 10]\n",
      "parent node subtree [['Mexico', 'PROPN', 10, 'compound', 8], ['Beach', 'PROPN', 10, 'compound', 9], ['Florida', 'PROPN', 7, 'pobj', 10]]\n",
      "parent node subtree str mexico beach florida\n",
      "false positive: NE=mexico_beach, type=compound\n",
      "testing NE mexico_beach, txt:DEVASTATING DAMAGE: This is my 2nd year living in Florida during Hurricane Season and the images don't get easier to watch. This picture shows the devastation left behind by #HurricaneMichael in Mexico Beach. Praying for the victims and their families. #PrayersforthePanhandle <URL>\n",
      "full parse [[['DEVASTATING', 'ADJ', 1, 'amod', 0], ['DAMAGE', 'NOUN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['This', 'DET', 4, 'nsubj', 3], ['is', 'VERB', 4, 'ROOT', 4], ['my', 'ADJ', 7, 'poss', 5], ['2nd', 'ADJ', 7, 'amod', 6], ['year', 'NOUN', 4, 'attr', 7], ['living', 'VERB', 7, 'acl', 8], ['in', 'ADP', 8, 'prep', 9], ['Florida', 'PROPN', 9, 'pobj', 10], ['during', 'ADP', 8, 'prep', 11], ['Hurricane', 'PROPN', 13, 'compound', 12], ['Season', 'PROPN', 11, 'pobj', 13], ['and', 'CCONJ', 7, 'cc', 14], ['the', 'DET', 16, 'det', 15], ['images', 'NOUN', 18, 'nsubj', 16], [\"don't\", 'VERB', 18, 'aux', 17], ['get', 'VERB', 4, 'conj', 18], ['easier', 'ADJ', 18, 'acomp', 19], ['to', 'PART', 21, 'aux', 20], ['watch', 'VERB', 19, 'xcomp', 21], ['.', 'PUNCT', 4, 'punct', 22]], [['This', 'DET', 1, 'det', 0], ['picture', 'NOUN', 2, 'nsubj', 1], ['shows', 'VERB', 2, 'ROOT', 2], ['the', 'DET', 4, 'det', 3], ['devastation', 'NOUN', 2, 'dobj', 4], ['left', 'VERB', 4, 'acl', 5], ['behind', 'ADV', 5, 'prt', 6], ['by', 'ADP', 5, 'agent', 7], ['#HurricaneMichael', 'PROPN', 7, 'pobj', 8], ['in', 'ADP', 5, 'prep', 9], ['Mexico', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 9, 'pobj', 11], ['.', 'PUNCT', 2, 'punct', 12]], [['Praying', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['victims', 'NOUN', 1, 'pobj', 3], ['and', 'CCONJ', 3, 'cc', 4], ['their', 'ADJ', 6, 'poss', 5], ['families', 'NOUN', 3, 'conj', 6], ['.', 'PUNCT', 0, 'punct', 7]], [['#PrayersforthePanhandle', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = \n",
      "testing NE panama_city_beach, txt:Thank you, this Panama City Beach #hurricanemichael survivor appreciates what you are doing for us!! Your store in Santa Rosa Beach helped us today when we drove over from Panama City to purchase food/water/supplies for our friends and coworkers. The employees were so kind! <URL>\n",
      "full parse [[['Thank', 'VERB', 0, 'ROOT', 0], ['you', 'PRON', 0, 'dative', 1], ['this', 'DET', 7, 'det', 2], ['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 7, 'nmod', 5], ['#hurricanemichael', 'PROPN', 7, 'compound', 6], ['survivor', 'NOUN', 8, 'nsubj', 7], ['appreciates', 'VERB', 0, 'ccomp', 8], ['what', 'NOUN', 12, 'dobj', 9], ['you', 'PRON', 12, 'nsubj', 10], ['are', 'VERB', 12, 'aux', 11], ['doing', 'VERB', 8, 'ccomp', 12], ['for', 'ADP', 12, 'dative', 13], ['us', 'PRON', 13, 'pobj', 14], ['!', 'PUNCT', 0, 'punct', 15], ['!', 'PUNCT', 0, 'punct', 16]], [['Your', 'ADJ', 1, 'poss', 0], ['store', 'NOUN', 6, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['Santa', 'PROPN', 4, 'compound', 3], ['Rosa', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5], ['helped', 'VERB', 6, 'ROOT', 6], ['us', 'PRON', 6, 'dobj', 7], ['today', 'NOUN', 6, 'npadvmod', 8], ['when', 'ADV', 11, 'advmod', 9], ['we', 'PRON', 11, 'nsubj', 10], ['drove', 'VERB', 6, 'advcl', 11], ['over', 'PART', 11, 'advmod', 12], ['from', 'ADP', 11, 'prep', 13], ['Panama', 'PROPN', 15, 'compound', 14], ['City', 'PROPN', 13, 'pobj', 15], ['to', 'PART', 17, 'aux', 16], ['purchase', 'VERB', 11, 'advcl', 17], ['food', 'NOUN', 22, 'nmod', 18], ['/', 'SYM', 22, 'punct', 19], ['water', 'NOUN', 22, 'nmod', 20], ['/', 'SYM', 22, 'punct', 21], ['supplies', 'NOUN', 17, 'dobj', 22], ['for', 'ADP', 22, 'prep', 23], ['our', 'ADJ', 25, 'poss', 24], ['friends', 'NOUN', 23, 'pobj', 25], ['and', 'CCONJ', 25, 'cc', 26], ['coworkers', 'NOUN', 25, 'conj', 27], ['.', 'PUNCT', 6, 'punct', 28]], [['The', 'DET', 1, 'det', 0], ['employees', 'NOUN', 2, 'nsubj', 1], ['were', 'VERB', 2, 'ROOT', 2], ['so', 'ADV', 4, 'advmod', 3], ['kind', 'ADJ', 2, 'acomp', 4], ['!', 'PUNCT', 2, 'punct', 5]]]\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 7, 'nmod', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Beach', 'PROPN', 7, 'nmod', 5]\n",
      "NE parent token:\n",
      "['survivor', 'NOUN', 8, 'nsubj', 7]\n",
      "parent node subtree [['this', 'DET', 7, 'det', 2], ['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 7, 'nmod', 5], ['#hurricanemichael', 'PROPN', 7, 'compound', 6], ['survivor', 'NOUN', 8, 'nsubj', 7]]\n",
      "parent node subtree str this panama city beach #hurricanemichael survivor\n",
      "candidate 1=Santa Rosa Beach\n",
      "anchor NE candidates = Panama City Beach,Panama City\n",
      "data NE tree=[['Santa', 'PROPN', 4, 'compound', 3], ['Rosa', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Beach', 'PROPN', 2, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "candidate 2=Panama City\n",
      "anchor NE candidates = \n",
      "testing NE springfield, txt:Rob Golding drove to Springfield, Florida to be with his 89-year-old dad during #HurricaneMichael . His home was spared, but the area suffered damage, so they started taking in neighbors, going out to rescue friends, and organizing food for the community. <URL>\n",
      "full parse [[['Rob', 'PROPN', 1, 'compound', 0], ['Golding', 'PROPN', 2, 'nsubj', 1], ['drove', 'VERB', 2, 'ROOT', 2], ['to', 'ADP', 2, 'prep', 3], ['Springfield', 'PROPN', 5, 'compound', 4], ['Florida', 'PROPN', 3, 'pobj', 5], ['to', 'PART', 7, 'aux', 6], ['be', 'VERB', 2, 'advcl', 7], ['with', 'ADP', 7, 'prep', 8], ['his', 'ADJ', 11, 'poss', 9], ['89yearold', 'NUM', 11, 'nummod', 10], ['dad', 'NOUN', 8, 'pobj', 11], ['during', 'ADP', 7, 'prep', 12], ['#HurricaneMichael', 'PROPN', 12, 'pobj', 13], ['.', 'PUNCT', 2, 'punct', 14]], [['His', 'ADJ', 1, 'poss', 0], ['home', 'NOUN', 3, 'nsubjpass', 1], ['was', 'VERB', 3, 'auxpass', 2], ['spared', 'VERB', 3, 'ROOT', 3], ['but', 'CCONJ', 3, 'cc', 4], ['the', 'DET', 6, 'det', 5], ['area', 'NOUN', 7, 'nsubj', 6], ['suffered', 'VERB', 3, 'conj', 7], ['damage', 'NOUN', 7, 'dobj', 8], ['so', 'ADP', 11, 'mark', 9], ['they', 'PRON', 11, 'nsubj', 10], ['started', 'VERB', 7, 'advcl', 11], ['taking', 'VERB', 11, 'xcomp', 12], ['in', 'PART', 12, 'prt', 13], ['neighbors', 'NOUN', 12, 'dobj', 14], ['going', 'VERB', 14, 'acl', 15], ['out', 'PART', 15, 'prt', 16], ['to', 'PART', 18, 'aux', 17], ['rescue', 'VERB', 15, 'advcl', 18], ['friends', 'NOUN', 18, 'dobj', 19], ['and', 'CCONJ', 18, 'cc', 20], ['organizing', 'VERB', 18, 'conj', 21], ['food', 'NOUN', 21, 'dobj', 22], ['for', 'ADP', 21, 'prep', 23], ['the', 'DET', 25, 'det', 24], ['community', 'NOUN', 23, 'pobj', 25], ['.', 'PUNCT', 7, 'punct', 26]]]\n",
      "candidate 0=Springfield\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Springfield', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Springfield', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 3, 'pobj', 5]\n",
      "parent node subtree [['Springfield', 'PROPN', 5, 'compound', 4], ['Florida', 'PROPN', 3, 'pobj', 5]]\n",
      "parent node subtree str springfield florida\n",
      "false positive: NE=springfield, type=compound\n",
      "testing NE dale, txt:#BREAKING: President Trump approves Emergency Disaster Declaration for  the following Alabama counties: Dale, Geneva, Henry, and Houston #HurricaneMichael\n",
      "full parse [[['#BREAKING', 'PROPN', 4, 'npadvmod', 0], [':', 'PUNCT', 4, 'punct', 1], ['President', 'PROPN', 3, 'compound', 2], ['Trump', 'PROPN', 4, 'nsubj', 3], ['approves', 'VERB', 4, 'ROOT', 4], ['Emergency', 'PROPN', 7, 'compound', 5], ['Disaster', 'PROPN', 7, 'compound', 6], ['Declaration', 'PROPN', 4, 'dobj', 7], ['for', 'ADP', 4, 'prep', 8], ['the', 'DET', 12, 'det', 9], ['following', 'VERB', 12, 'amod', 10], ['Alabama', 'PROPN', 12, 'compound', 11], ['counties', 'NOUN', 8, 'pobj', 12], [':', 'PUNCT', 4, 'punct', 13], ['Dale', 'PROPN', 16, 'compound', 14], ['Geneva', 'PROPN', 16, 'compound', 15], ['Henry', 'PROPN', 4, 'appos', 16], ['and', 'CCONJ', 16, 'cc', 17], ['Houston', 'PROPN', 16, 'conj', 18], ['#HurricaneMichael', 'PROPN', 19, 'ROOT', 19]]]\n",
      "candidate 0=Dale\n",
      "anchor NE candidates = \n",
      "candidate 1=Geneva\n",
      "anchor NE candidates = Alabama,Geneva,Houston\n",
      "data NE tree=[['Geneva', 'PROPN', 16, 'compound', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['Geneva', 'PROPN', 16, 'compound', 15]\n",
      "NE parent token:\n",
      "['Henry', 'PROPN', 4, 'appos', 16]\n",
      "parent node subtree [['Dale', 'PROPN', 16, 'compound', 14], ['Geneva', 'PROPN', 16, 'compound', 15], ['Henry', 'PROPN', 4, 'appos', 16], ['and', 'CCONJ', 16, 'cc', 17], ['Houston', 'PROPN', 16, 'conj', 18]]\n",
      "parent node subtree str dale geneva henry and houston\n",
      "candidate 2=Houston\n",
      "anchor NE candidates = Alabama,Houston\n",
      "data NE tree=[['Houston', 'PROPN', 16, 'conj', 18]]\n",
      "NE parse token at tree=0, token=19:\n",
      "['Houston', 'PROPN', 16, 'conj', 18]\n",
      "NE parent token:\n",
      "['Henry', 'PROPN', 4, 'appos', 16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE panama_city_beach, txt:Heard you guys are bringing prepaid phones and charging stations. Please don’t do this on Panama City Beach. They have electricity and access to Destin. Come into Panama City, Callaway, Lynn Haven @TMobile @TMobileHelp #hurricanemichael\n",
      "full parse [[['Heard', 'ADP', 4, 'mark', 0], ['you', 'PRON', 2, 'nmod', 1], ['guys', 'NOUN', 4, 'nsubj', 2], ['are', 'VERB', 4, 'aux', 3], ['bringing', 'VERB', 4, 'ROOT', 4], ['prepaid', 'ADJ', 6, 'amod', 5], ['phones', 'NOUN', 4, 'dobj', 6], ['and', 'CCONJ', 4, 'cc', 7], ['charging', 'VERB', 4, 'conj', 8], ['stations', 'NOUN', 8, 'dobj', 9], ['.', 'PUNCT', 4, 'punct', 10]], [['Please', 'INTJ', 1, 'intj', 0], ['don', 'VERB', 1, 'ROOT', 1], ['’', 'NOUN', 3, 'compound', 2], ['t', 'NOUN', 1, 'dobj', 3], ['do', 'VERB', 1, 'conj', 4], ['this', 'DET', 4, 'dobj', 5], ['on', 'ADP', 4, 'prep', 6], ['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['Beach', 'PROPN', 6, 'pobj', 9], ['.', 'PUNCT', 1, 'punct', 10]], [['They', 'PRON', 1, 'nsubj', 0], ['have', 'VERB', 1, 'ROOT', 1], ['electricity', 'NOUN', 1, 'dobj', 2], ['and', 'CCONJ', 2, 'cc', 3], ['access', 'NOUN', 2, 'conj', 4], ['to', 'ADP', 2, 'prep', 5], ['Destin', 'PROPN', 5, 'pobj', 6], ['.', 'PUNCT', 1, 'punct', 7]], [['Come', 'VERB', 0, 'ROOT', 0], ['into', 'ADP', 0, 'prep', 1], ['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4], ['Lynn', 'PROPN', 6, 'compound', 5], ['Haven', 'PROPN', 7, 'compound', 6], ['@TMobile', 'PROPN', 1, 'pobj', 7], ['@TMobileHelp', 'NOUN', 0, 'punct', 8], ['#hurricanemichael', 'PUNCT', 9, 'ROOT', 9]]]\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Destin,Panama City,Callaway,Lynn Haven\n",
      "data NE tree=[['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['Beach', 'PROPN', 6, 'pobj', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['Beach', 'PROPN', 6, 'pobj', 9]\n",
      "NE parent token:\n",
      "['on', 'ADP', 4, 'prep', 6]\n",
      "candidate 1=Destin\n",
      "anchor NE candidates = Panama City,Callaway,Lynn Haven\n",
      "data NE tree=[['Destin', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=2, token=7:\n",
      "['Destin', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['to', 'ADP', 2, 'prep', 5]\n",
      "candidate 2=Panama City\n",
      "anchor NE candidates = \n",
      "candidate 3=Callaway\n",
      "anchor NE candidates = Panama City,Lynn Haven\n",
      "data NE tree=[['Callaway', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=3, token=5:\n",
      "['Callaway', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['Haven', 'PROPN', 7, 'compound', 6]\n",
      "parent node subtree [['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4], ['Lynn', 'PROPN', 6, 'compound', 5], ['Haven', 'PROPN', 7, 'compound', 6]]\n",
      "parent node subtree str panama city callaway lynn haven\n",
      "candidate 4=Lynn Haven\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Lynn', 'PROPN', 6, 'compound', 5], ['Haven', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=3, token=7:\n",
      "['Haven', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['@TMobile', 'PROPN', 1, 'pobj', 7]\n",
      "parent node subtree [['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4], ['Lynn', 'PROPN', 6, 'compound', 5], ['Haven', 'PROPN', 7, 'compound', 6], ['@TMobile', 'PROPN', 1, 'pobj', 7]]\n",
      "parent node subtree str panama city callaway lynn haven @tmobile\n",
      "NE=Lynn Haven subtree=[['Panama', 'PROPN', 3, 'compound', 2], ['City', 'PROPN', 6, 'compound', 3], ['Callaway', 'PROPN', 6, 'compound', 4]]\n",
      "min node deps ['compound']\n",
      "testing NE mexico_beach, txt:Devastation in Mexico Beach, Florida from Hurricane #Michael . <URL>\n",
      "full parse [[['Devastation', 'NOUN', 0, 'ROOT', 0], ['in', 'ADP', 0, 'prep', 1], ['Mexico', 'PROPN', 4, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3], ['Florida', 'PROPN', 1, 'pobj', 4], ['from', 'ADP', 0, 'prep', 5], ['Hurricane', 'PROPN', 7, 'compound', 6], ['#Michael', 'PROPN', 5, 'pobj', 7], ['.', 'PUNCT', 0, 'punct', 8]]]\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 4, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['Beach', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 1, 'pobj', 4]\n",
      "parent node subtree [['Mexico', 'PROPN', 4, 'compound', 2], ['Beach', 'PROPN', 4, 'compound', 3], ['Florida', 'PROPN', 1, 'pobj', 4]]\n",
      "parent node subtree str mexico beach florida\n",
      "false positive: NE=mexico_beach, type=compound\n",
      "testing NE panama_city_beach, txt:Vacasa office in Panama City Beach. Not too bad... property assessments are under way looks promising and positive so far #hurricanemichael @vacasarentals @RickyHaskins @ Panama City… <URL>\n",
      "full parse [[['Vacasa', 'PROPN', 1, 'compound', 0], ['office', 'NOUN', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5], ['.', 'PUNCT', 1, 'punct', 6]], [['Not', 'ADV', 2, 'neg', 0], ['too', 'ADV', 2, 'advmod', 1], ['bad', 'ADJ', 2, 'ROOT', 2], ['...', 'PUNCT', 2, 'punct', 3], ['property', 'NOUN', 5, 'compound', 4], ['assessments', 'NOUN', 6, 'nsubj', 5], ['are', 'VERB', 9, 'ccomp', 6], ['under', 'ADP', 6, 'prep', 7], ['way', 'NOUN', 7, 'pobj', 8], ['looks', 'VERB', 9, 'ROOT', 9], ['promising', 'ADJ', 9, 'xcomp', 10], ['and', 'CCONJ', 10, 'cc', 11], ['positive', 'ADJ', 10, 'conj', 12], ['so', 'ADV', 14, 'advmod', 13], ['far', 'ADV', 12, 'advmod', 14], ['#hurricanemichael', 'PROPN', 17, 'meta', 15], ['@vacasarentals', 'NOUN', 17, 'punct', 16], ['@RickyHaskins', 'X', 17, 'ROOT', 17], ['@', 'ADP', 17, 'prep', 18], ['Panama', 'PROPN', 20, 'compound', 19], ['City', 'PROPN', 20, 'ROOT', 20], ['…', 'PUNCT', 20, 'punct', 21]]]\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = Panama City\n",
      "data NE tree=[['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Beach', 'PROPN', 2, 'pobj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Beach', 'PROPN', 2, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "candidate 1=Panama City\n",
      "anchor NE candidates = \n",
      "testing NE bay, txt:#HurricaneMichael , current #SNAP households in Bay, Calhoun, Franklin, Gadsden, Gulf, Holmes, Jackson, Jefferson, Leon, Liberty, Wakulla, and Washington counties will receive replacement benefits at a 40% rate as early as 10/15/18 <URL>\n",
      "full parse [[['#HurricaneMichael', 'PROPN', 20, 'npadvmod', 0], ['current', 'ADJ', 3, 'amod', 1], ['#SNAP', 'ADJ', 3, 'compound', 2], ['households', 'NOUN', 20, 'nsubj', 3], ['in', 'ADP', 3, 'prep', 4], ['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9], ['Holmes', 'PROPN', 14, 'compound', 10], ['Jackson', 'PROPN', 14, 'compound', 11], ['Jefferson', 'PROPN', 14, 'compound', 12], ['Leon', 'PROPN', 14, 'compound', 13], ['Liberty', 'PROPN', 15, 'compound', 14], ['Wakulla', 'PROPN', 4, 'pobj', 15], ['and', 'CCONJ', 15, 'cc', 16], ['Washington', 'PROPN', 18, 'compound', 17], ['counties', 'NOUN', 15, 'conj', 18], ['will', 'VERB', 20, 'aux', 19], ['receive', 'VERB', 20, 'ROOT', 20], ['replacement', 'NOUN', 22, 'compound', 21], ['benefits', 'NOUN', 20, 'dobj', 22], ['at', 'ADP', 20, 'prep', 23], ['a', 'DET', 27, 'det', 24], ['40', 'NUM', 26, 'nummod', 25], ['%', 'NOUN', 27, 'compound', 26], ['rate', 'NOUN', 23, 'pobj', 27], ['as', 'ADV', 29, 'advmod', 28], ['early', 'ADV', 20, 'advmod', 29], ['as', 'ADP', 29, 'prep', 30], ['10/15', 'NUM', 33, 'quantmod', 31], ['/', 'SYM', 33, 'punct', 32], ['18', 'NUM', 30, 'pobj', 33]]]\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Calhoun,Franklin,Gadsden,Gulf,Jefferson,Washington\n",
      "data NE tree=[['Bay', 'PROPN', 6, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Bay', 'PROPN', 6, 'compound', 5]\n",
      "NE parent token:\n",
      "['Calhoun', 'PROPN', 9, 'compound', 6]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6]]\n",
      "parent node subtree str bay calhoun\n",
      "candidate 1=Calhoun\n",
      "anchor NE candidates = Franklin,Gadsden,Jefferson,Washington\n",
      "data NE tree=[['Calhoun', 'PROPN', 9, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Calhoun', 'PROPN', 9, 'compound', 6]\n",
      "NE parent token:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9]]\n",
      "parent node subtree str bay calhoun franklin gadsden gulf\n",
      "NE=Calhoun subtree=[['Bay', 'PROPN', 6, 'compound', 5]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Franklin\n",
      "anchor NE candidates = Washington\n",
      "data NE tree=[['Franklin', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Franklin', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9]]\n",
      "parent node subtree str bay calhoun franklin gadsden gulf\n",
      "candidate 3=Gadsden\n",
      "anchor NE candidates = Franklin,Washington\n",
      "data NE tree=[['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['Gadsden', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9]]\n",
      "parent node subtree str bay calhoun franklin gadsden gulf\n",
      "candidate 4=Gulf\n",
      "anchor NE candidates = Calhoun,Franklin,Gadsden,Jefferson,Washington\n",
      "data NE tree=[['Gulf', 'PROPN', 14, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['Gulf', 'PROPN', 14, 'compound', 9]\n",
      "NE parent token:\n",
      "['Liberty', 'PROPN', 15, 'compound', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9], ['Holmes', 'PROPN', 14, 'compound', 10], ['Jackson', 'PROPN', 14, 'compound', 11], ['Jefferson', 'PROPN', 14, 'compound', 12], ['Leon', 'PROPN', 14, 'compound', 13], ['Liberty', 'PROPN', 15, 'compound', 14]]\n",
      "parent node subtree str bay calhoun franklin gadsden gulf holmes jackson jefferson leon liberty\n",
      "NE=Gulf subtree=[['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 5=Jefferson\n",
      "anchor NE candidates = Franklin,Gadsden,Washington\n",
      "data NE tree=[['Jefferson', 'PROPN', 14, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Jefferson', 'PROPN', 14, 'compound', 12]\n",
      "NE parent token:\n",
      "['Liberty', 'PROPN', 15, 'compound', 14]\n",
      "parent node subtree [['Bay', 'PROPN', 6, 'compound', 5], ['Calhoun', 'PROPN', 9, 'compound', 6], ['Franklin', 'PROPN', 9, 'compound', 7], ['Gadsden', 'PROPN', 9, 'compound', 8], ['Gulf', 'PROPN', 14, 'compound', 9], ['Holmes', 'PROPN', 14, 'compound', 10], ['Jackson', 'PROPN', 14, 'compound', 11], ['Jefferson', 'PROPN', 14, 'compound', 12], ['Leon', 'PROPN', 14, 'compound', 13], ['Liberty', 'PROPN', 15, 'compound', 14]]\n",
      "parent node subtree str bay calhoun franklin gadsden gulf holmes jackson jefferson leon liberty\n",
      "testing NE mexico_beach, txt:At least 46 people remained unaccounted for on Sunday in Mexico Beach, Florida, an area pulverized by #HurricaneMichael 289 people, including 10 children, decided to stay put, despite evacuation orders, and ride out the Category 4 storm <URL>\n",
      "full parse [[['At', 'ADV', 1, 'advmod', 0], ['least', 'ADJ', 2, 'advmod', 1], ['46', 'NUM', 3, 'nummod', 2], ['people', 'NOUN', 4, 'nsubj', 3], ['remained', 'VERB', 4, 'ROOT', 4], ['unaccounted', 'ADJ', 4, 'acomp', 5], ['for', 'ADP', 5, 'prep', 6], ['on', 'ADP', 6, 'prep', 7], ['Sunday', 'PROPN', 7, 'pobj', 8], ['in', 'ADP', 4, 'prep', 9], ['Mexico', 'PROPN', 12, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11], ['Florida', 'PROPN', 9, 'pobj', 12], ['an', 'DET', 14, 'det', 13], ['area', 'NOUN', 23, 'nsubj', 14], ['pulverized', 'VERB', 14, 'acl', 15], ['by', 'ADP', 15, 'agent', 16], ['#HurricaneMichael', 'PROPN', 19, 'nmod', 17], ['289', 'NUM', 19, 'nummod', 18], ['people', 'NOUN', 16, 'pobj', 19], ['including', 'VERB', 19, 'prep', 20], ['10', 'NUM', 22, 'nummod', 21], ['children', 'NOUN', 20, 'pobj', 22], ['decided', 'VERB', 4, 'conj', 23], ['to', 'PART', 25, 'aux', 24], ['stay', 'VERB', 23, 'xcomp', 25], ['put', 'VERB', 25, 'acomp', 26], ['despite', 'ADP', 25, 'prep', 27], ['evacuation', 'NOUN', 29, 'compound', 28], ['orders', 'NOUN', 27, 'pobj', 29], ['and', 'CCONJ', 25, 'cc', 30], ['ride', 'VERB', 25, 'conj', 31], ['out', 'PART', 31, 'prt', 32], ['the', 'DET', 36, 'det', 33], ['Category', 'NOUN', 36, 'nmod', 34], ['4', 'NUM', 34, 'nummod', 35], ['storm', 'NOUN', 31, 'dobj', 36]]]\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 12, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Beach', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 9, 'pobj', 12]\n",
      "parent node subtree [['Mexico', 'PROPN', 12, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11], ['Florida', 'PROPN', 9, 'pobj', 12]]\n",
      "parent node subtree str mexico beach florida\n",
      "false positive: NE=mexico_beach, type=compound\n",
      "testing NE panhandle, txt:President Trump in Florida to tour #HurricaneMichael damage in panhandle: <URL>\n",
      "full parse [[['President', 'PROPN', 1, 'compound', 0], ['Trump', 'PROPN', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['Florida', 'PROPN', 2, 'pobj', 3], ['to', 'PART', 5, 'aux', 4], ['tour', 'VERB', 1, 'relcl', 5], ['#HurricaneMichael', 'PROPN', 5, 'prep', 6], ['damage', 'NOUN', 5, 'dobj', 7], ['in', 'ADP', 7, 'prep', 8], ['panhandle', 'NOUN', 8, 'pobj', 9], [':', 'PUNCT', 1, 'punct', 10]]]\n",
      "candidate 0=panhandle\n",
      "anchor NE candidates = \n",
      "testing NE panama_city_beach, txt:Jackie, a #HurricaneMichael survivor in Panama City Beach, FL, is desperate to contact family and friends as cell service remains down following the storm: \"\"I hope you all are all okay...We're all okay.\"\" <URL>\n",
      "full parse [[['Jackie', 'PROPN', 9, 'nsubj', 0], ['a', 'DET', 3, 'det', 1], ['#HurricaneMichael', 'PROPN', 3, 'compound', 2], ['survivor', 'NOUN', 0, 'appos', 3], ['in', 'ADP', 3, 'prep', 4], ['Panama', 'PROPN', 8, 'compound', 5], ['City', 'PROPN', 8, 'compound', 6], ['Beach', 'PROPN', 8, 'compound', 7], ['FL', 'PROPN', 4, 'pobj', 8], ['is', 'VERB', 28, 'ccomp', 9], ['desperate', 'ADJ', 9, 'acomp', 10], ['to', 'PART', 12, 'aux', 11], ['contact', 'VERB', 10, 'xcomp', 12], ['family', 'NOUN', 12, 'dobj', 13], ['and', 'CCONJ', 13, 'cc', 14], ['friends', 'NOUN', 13, 'conj', 15], ['as', 'ADP', 19, 'mark', 16], ['cell', 'NOUN', 18, 'compound', 17], ['service', 'NOUN', 19, 'nsubj', 18], ['remains', 'VERB', 9, 'advcl', 19], ['down', 'ADV', 19, 'prt', 20], ['following', 'VERB', 19, 'prep', 21], ['the', 'DET', 23, 'det', 22], ['storm', 'NOUN', 21, 'dobj', 23], [':', 'PUNCT', 28, 'punct', 24], ['\"', 'PUNCT', 28, 'punct', 25], ['\"', 'PUNCT', 28, 'punct', 26], ['I', 'PRON', 28, 'nsubj', 27], ['hope', 'VERB', 28, 'ROOT', 28], ['you', 'PRON', 31, 'nsubj', 29], ['all', 'DET', 29, 'appos', 30], ['are', 'VERB', 28, 'ccomp', 31], ['all', 'DET', 31, 'advmod', 32], ['okay', 'ADJ', 31, 'acomp', 33], ['...', 'PUNCT', 28, 'punct', 34], [\"We're\", 'INTJ', 35, 'ROOT', 35], ['all', 'ADV', 35, 'appos', 36], ['okay', 'INTJ', 37, 'ROOT', 37], ['.', 'PUNCT', 37, 'punct', 38], ['\"', 'PUNCT', 37, 'punct', 39], ['\"', 'PUNCT', 37, 'punct', 40]]]\n",
      "candidate 0=Panama City Beach\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Panama', 'PROPN', 8, 'compound', 5], ['City', 'PROPN', 8, 'compound', 6], ['Beach', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Beach', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 4, 'pobj', 8]\n",
      "parent node subtree [['Panama', 'PROPN', 8, 'compound', 5], ['City', 'PROPN', 8, 'compound', 6], ['Beach', 'PROPN', 8, 'compound', 7], ['FL', 'PROPN', 4, 'pobj', 8]]\n",
      "parent node subtree str panama city beach fl\n",
      "false positive: NE=panama_city_beach, type=compound\n",
      "testing NE blountstown, txt:I would like to give a great big thank you to @TMobile for having your emergency management truck here in Blountstown, FL and making it possible for us to have WiFi during the aftermath of #HurricaneMichael\n",
      "full parse [[['I', 'PRON', 2, 'nsubj', 0], ['would', 'VERB', 2, 'aux', 1], ['like', 'VERB', 2, 'ROOT', 2], ['to', 'PART', 4, 'aux', 3], ['give', 'VERB', 2, 'xcomp', 4], ['a', 'DET', 8, 'det', 5], ['great', 'ADJ', 8, 'amod', 6], ['big', 'ADJ', 8, 'amod', 7], ['thank', 'VERB', 4, 'dative', 8], ['you', 'PRON', 8, 'dobj', 9], ['to', 'PART', 11, 'aux', 10], ['@TMobile', 'VERB', 4, 'advcl', 11], ['for', 'ADP', 11, 'prep', 12], ['having', 'VERB', 12, 'pcomp', 13], ['your', 'ADJ', 17, 'poss', 14], ['emergency', 'NOUN', 16, 'compound', 15], ['management', 'NOUN', 17, 'compound', 16], ['truck', 'NOUN', 13, 'dobj', 17], ['here', 'ADV', 17, 'advmod', 18], ['in', 'ADP', 18, 'prep', 19], ['Blountstown', 'PROPN', 21, 'compound', 20], ['FL', 'PROPN', 19, 'pobj', 21], ['and', 'CCONJ', 13, 'cc', 22], ['making', 'VERB', 13, 'conj', 23], ['it', 'PRON', 25, 'nsubj', 24], ['possible', 'ADJ', 23, 'ccomp', 25], ['for', 'ADP', 29, 'mark', 26], ['us', 'PRON', 29, 'nsubj', 27], ['to', 'PART', 29, 'aux', 28], ['have', 'VERB', 25, 'advcl', 29], ['WiFi', 'PROPN', 29, 'dobj', 30], ['during', 'ADP', 29, 'prep', 31], ['the', 'DET', 33, 'det', 32], ['aftermath', 'NOUN', 31, 'pobj', 33], ['of', 'ADP', 33, 'prep', 34], ['#HurricaneMichael', 'PROPN', 34, 'pobj', 35]]]\n",
      "candidate 0=Blountstown\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Blountstown', 'PROPN', 21, 'compound', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Blountstown', 'PROPN', 21, 'compound', 20]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 19, 'pobj', 21]\n",
      "parent node subtree [['Blountstown', 'PROPN', 21, 'compound', 20], ['FL', 'PROPN', 19, 'pobj', 21]]\n",
      "parent node subtree str blountstown fl\n",
      "false positive: NE=blountstown, type=compound\n",
      "testing NE panama_city, txt:#HappyMonday - If you think your Monday's bad... be reminded by the pics from #HurricaneMichael that it can ALWAYS get worse. Listen, we are here in Panama City, FL at groundZero delivering supplies to those impacted... <URL>\n",
      "full parse [[['#HappyMonday', 'PROPN', 9, 'npadvmod', 0], ['If', 'ADP', 3, 'mark', 1], ['you', 'PRON', 3, 'nsubj', 2], ['think', 'VERB', 9, 'advcl', 3], ['your', 'ADJ', 5, 'poss', 4], [\"Monday's\", 'PROPN', 6, 'nsubj', 5], ['bad', 'ADJ', 3, 'ccomp', 6], ['...', 'PUNCT', 9, 'punct', 7], ['be', 'VERB', 9, 'auxpass', 8], ['reminded', 'VERB', 9, 'ROOT', 9], ['by', 'ADP', 9, 'agent', 10], ['the', 'DET', 12, 'det', 11], ['pics', 'NOUN', 10, 'pobj', 12], ['from', 'ADP', 9, 'prep', 13], ['#HurricaneMichael', 'PROPN', 13, 'pobj', 14], ['that', 'ADP', 19, 'mark', 15], ['it', 'PRON', 19, 'nsubj', 16], ['can', 'VERB', 19, 'aux', 17], ['ALWAYS', 'ADV', 19, 'advmod', 18], ['get', 'VERB', 9, 'ccomp', 19], ['worse', 'ADJ', 19, 'acomp', 20], ['.', 'PUNCT', 9, 'punct', 21]], [['Listen', 'VERB', 0, 'ROOT', 0], ['we', 'PRON', 2, 'nsubj', 1], ['are', 'VERB', 0, 'ccomp', 2], ['here', 'ADV', 2, 'advmod', 3], ['in', 'ADP', 3, 'prep', 4], ['Panama', 'PROPN', 7, 'compound', 5], ['City', 'PROPN', 7, 'compound', 6], ['FL', 'PROPN', 4, 'pobj', 7], ['at', 'ADP', 2, 'prep', 8], ['groundZero', 'NOUN', 8, 'pobj', 9], ['delivering', 'VERB', 2, 'advcl', 10], ['supplies', 'NOUN', 10, 'dobj', 11], ['to', 'ADP', 10, 'dative', 12], ['those', 'DET', 12, 'pobj', 13], ['impacted', 'VERB', 13, 'acl', 14], ['...', 'PUNCT', 0, 'punct', 15]]]\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Panama', 'PROPN', 7, 'compound', 5], ['City', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['City', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['Panama', 'PROPN', 7, 'compound', 5], ['City', 'PROPN', 7, 'compound', 6], ['FL', 'PROPN', 4, 'pobj', 7]]\n",
      "parent node subtree str panama city fl\n",
      "false positive: NE=panama_city, type=compound\n",
      "testing NE panama_city, txt:The people ravaged by #HurricaneMichael in Panama City, Florida and Mexico Beach, Florida need our help. Let’s do this by donating to the American Red Cross.\n",
      "full parse [[['The', 'DET', 1, 'det', 0], ['people', 'NOUN', 13, 'nsubj', 1], ['ravaged', 'VERB', 1, 'acl', 2], ['by', 'ADP', 2, 'agent', 3], ['#HurricaneMichael', 'PROPN', 3, 'pobj', 4], ['in', 'ADP', 2, 'prep', 5], ['Panama', 'PROPN', 7, 'compound', 6], ['City', 'PROPN', 8, 'compound', 7], ['Florida', 'PROPN', 5, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['Mexico', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11], ['Florida', 'PROPN', 8, 'conj', 12], ['need', 'VERB', 13, 'ROOT', 13], ['our', 'ADJ', 15, 'poss', 14], ['help', 'NOUN', 13, 'dobj', 15], ['.', 'PUNCT', 13, 'punct', 16]], [['Let', 'VERB', 0, 'ROOT', 0], ['’', 'NOUN', 3, 'nsubj', 1], ['s', 'PRON', 3, 'aux', 2], ['do', 'VERB', 0, 'ccomp', 3], ['this', 'DET', 3, 'dobj', 4], ['by', 'ADP', 3, 'prep', 5], ['donating', 'VERB', 5, 'pcomp', 6], ['to', 'ADP', 6, 'prep', 7], ['the', 'DET', 11, 'det', 8], ['American', 'PROPN', 11, 'compound', 9], ['Red', 'PROPN', 11, 'compound', 10], ['Cross', 'PROPN', 7, 'pobj', 11], ['.', 'PUNCT', 0, 'punct', 12]]]\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Florida,Florida\n",
      "data NE tree=[['Panama', 'PROPN', 7, 'compound', 6], ['City', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['City', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 5, 'pobj', 8]\n",
      "parent node subtree [['Panama', 'PROPN', 7, 'compound', 6], ['City', 'PROPN', 8, 'compound', 7], ['Florida', 'PROPN', 5, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['Mexico', 'PROPN', 11, 'compound', 10], ['Beach', 'PROPN', 12, 'compound', 11], ['Florida', 'PROPN', 8, 'conj', 12]]\n",
      "parent node subtree str panama city florida and mexico beach florida\n",
      "candidate 1=Mexico Beach\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false positive: NE=panama_city, type=compound\n",
      "testing NE youngstown, txt:Day #2 of Hurricane #Michael Damage Surveys - Unbelievable tree damage. We surveyed spots in Southport, Youngstown, & Resota Beach (north of Lynn Haven & Panama City) where all trees were snapped, uprooted, or bent/twisted. Pictures do NOT do the damage justice at all... <URL>\n",
      "full parse [[['Day', 'NOUN', 0, 'ROOT', 0], ['#', 'NOUN', 2, 'nmod', 1], ['2', 'NUM', 0, 'nummod', 2], ['of', 'ADP', 2, 'prep', 3], ['Hurricane', 'PROPN', 5, 'compound', 4], ['#Michael', 'PROPN', 10, 'compound', 5], ['Damage', 'NOUN', 7, 'nmod', 6], ['Surveys', 'NOUN', 10, 'compound', 7], ['Unbelievable', 'ADJ', 9, 'compound', 8], ['tree', 'NOUN', 10, 'compound', 9], ['damage', 'NOUN', 3, 'pobj', 10], ['.', 'PUNCT', 0, 'punct', 11]], [['We', 'PRON', 1, 'nsubj', 0], ['surveyed', 'VERB', 1, 'ROOT', 1], ['spots', 'NOUN', 1, 'dobj', 2], ['in', 'ADP', 2, 'prep', 3], ['Southport', 'PROPN', 5, 'compound', 4], ['Youngstown', 'PROPN', 3, 'pobj', 5], ['&', 'CCONJ', 5, 'cc', 6], ['Resota', 'PROPN', 8, 'compound', 7], ['Beach', 'PROPN', 5, 'conj', 8], ['(', 'PUNCT', 5, 'punct', 9], ['north', 'NOUN', 5, 'advmod', 10], ['of', 'ADP', 10, 'prep', 11], ['Lynn', 'PROPN', 13, 'compound', 12], ['Haven', 'PROPN', 11, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16], [')', 'PUNCT', 5, 'punct', 17], ['where', 'ADV', 22, 'advmod', 18], ['all', 'DET', 20, 'det', 19], ['trees', 'NOUN', 22, 'nsubjpass', 20], ['were', 'VERB', 22, 'auxpass', 21], ['snapped', 'VERB', 5, 'relcl', 22], ['uprooted', 'VERB', 22, 'advcl', 23], ['or', 'CCONJ', 23, 'cc', 24], ['bent', 'ADJ', 27, 'amod', 25], ['/', 'SYM', 27, 'punct', 26], ['twisted', 'ADJ', 23, 'conj', 27], ['.', 'PUNCT', 1, 'punct', 28]], [['Pictures', 'NOUN', 3, 'nsubj', 0], ['do', 'VERB', 3, 'aux', 1], ['NOT', 'ADV', 3, 'neg', 2], ['do', 'VERB', 3, 'ROOT', 3], ['the', 'DET', 6, 'det', 4], ['damage', 'NOUN', 6, 'compound', 5], ['justice', 'NOUN', 3, 'dobj', 6], ['at', 'ADV', 8, 'advmod', 7], ['all', 'ADV', 3, 'advmod', 8], ['...', 'PUNCT', 3, 'punct', 9]]]\n",
      "candidate 0=Southport\n",
      "anchor NE candidates = \n",
      "candidate 1=Youngstown\n",
      "anchor NE candidates = Southport\n",
      "data NE tree=[['Youngstown', 'PROPN', 3, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['Youngstown', 'PROPN', 3, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "NE=Youngstown subtree=[['Southport', 'PROPN', 5, 'compound', 4], ['&', 'CCONJ', 5, 'cc', 6], ['Resota', 'PROPN', 8, 'compound', 7], ['Beach', 'PROPN', 5, 'conj', 8], ['(', 'PUNCT', 5, 'punct', 9], ['north', 'NOUN', 5, 'advmod', 10], ['of', 'ADP', 10, 'prep', 11], ['Lynn', 'PROPN', 13, 'compound', 12], ['Haven', 'PROPN', 11, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16], [')', 'PUNCT', 5, 'punct', 17], ['where', 'ADV', 22, 'advmod', 18], ['all', 'DET', 20, 'det', 19], ['trees', 'NOUN', 22, 'nsubjpass', 20], ['were', 'VERB', 22, 'auxpass', 21], ['snapped', 'VERB', 5, 'relcl', 22], ['uprooted', 'VERB', 22, 'advcl', 23], ['or', 'CCONJ', 23, 'cc', 24], ['bent', 'ADJ', 27, 'amod', 25], ['/', 'SYM', 27, 'punct', 26], ['twisted', 'ADJ', 23, 'conj', 27]]\n",
      "min node deps ['compound', 'cc', 'conj', 'punct', 'advmod', 'punct', 'relcl']\n",
      "candidate 2=Resota Beach\n",
      "anchor NE candidates = Southport,Youngstown,Lynn Haven,Panama City\n",
      "data NE tree=[['Resota', 'PROPN', 8, 'compound', 7], ['Beach', 'PROPN', 5, 'conj', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['Beach', 'PROPN', 5, 'conj', 8]\n",
      "NE parent token:\n",
      "['Youngstown', 'PROPN', 3, 'pobj', 5]\n",
      "candidate 3=Lynn Haven\n",
      "anchor NE candidates = Southport,Youngstown,Panama City\n",
      "data NE tree=[['Lynn', 'PROPN', 13, 'compound', 12], ['Haven', 'PROPN', 11, 'pobj', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['Haven', 'PROPN', 11, 'pobj', 13]\n",
      "NE parent token:\n",
      "['of', 'ADP', 10, 'prep', 11]\n",
      "NE=Lynn Haven subtree=[['&', 'CCONJ', 13, 'cc', 14], ['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 4=Panama City\n",
      "anchor NE candidates = Southport,Youngstown\n",
      "data NE tree=[['Panama', 'PROPN', 16, 'compound', 15], ['City', 'PROPN', 13, 'conj', 16]]\n",
      "NE parse token at tree=1, token=17:\n",
      "['City', 'PROPN', 13, 'conj', 16]\n",
      "NE parent token:\n",
      "['Haven', 'PROPN', 11, 'pobj', 13]\n",
      "testing NE callaway, txt:#HurricaneMichael | Tide Loads of Hope is washing clothes for free from 9am-5pm at Walmart Supercenter (25 N Tyndall Pkwy, Callaway, FL 32404) #PanhandleStrong #PanamaCity <URL>\n",
      "full parse [[['#HurricaneMichael', 'PROPN', 7, 'meta', 0], ['|', 'PUNCT', 7, 'punct', 1], ['Tide', 'NOUN', 3, 'compound', 2], ['Loads', 'NOUN', 7, 'nsubj', 3], ['of', 'ADP', 3, 'prep', 4], ['Hope', 'PROPN', 4, 'pobj', 5], ['is', 'VERB', 7, 'aux', 6], ['washing', 'VERB', 7, 'ROOT', 7], ['clothes', 'NOUN', 7, 'dobj', 8], ['for', 'ADP', 7, 'prep', 9], ['free', 'ADJ', 9, 'amod', 10], ['from', 'ADP', 10, 'prep', 11], ['9am5pm', 'NUM', 11, 'pobj', 12], ['at', 'ADP', 7, 'prep', 13], ['Walmart', 'PROPN', 15, 'compound', 14], ['Supercenter', 'PROPN', 13, 'pobj', 15], ['(', 'PUNCT', 15, 'punct', 16], ['25', 'NUM', 22, 'nummod', 17], ['N', 'NOUN', 22, 'compound', 18], ['Tyndall', 'PROPN', 22, 'compound', 19], ['Pkwy', 'PROPN', 22, 'compound', 20], ['Callaway', 'PROPN', 22, 'compound', 21], ['FL', 'PROPN', 15, 'appos', 22], ['32404', 'NUM', 22, 'nummod', 23], [')', 'PUNCT', 15, 'punct', 24], ['#PanhandleStrong', 'PROPN', 25, 'ROOT', 25], ['#PanamaCity', 'PROPN', 25, 'appos', 26]]]\n",
      "candidate 0=Callaway\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Callaway', 'PROPN', 22, 'compound', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['Callaway', 'PROPN', 22, 'compound', 21]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 15, 'appos', 22]\n",
      "parent node subtree [['25', 'NUM', 22, 'nummod', 17], ['N', 'NOUN', 22, 'compound', 18], ['Tyndall', 'PROPN', 22, 'compound', 19], ['Pkwy', 'PROPN', 22, 'compound', 20], ['Callaway', 'PROPN', 22, 'compound', 21], ['FL', 'PROPN', 15, 'appos', 22], ['32404', 'NUM', 22, 'nummod', 23]]\n",
      "parent node subtree str 25 n tyndall pkwy callaway fl 32404\n",
      "false positive: NE=callaway, type=compound\n",
      "testing NE calhoun, txt:Check out Calhoun (98% out), Gulf (86%), Jackson (83%), Liberty (71%), and Bay (56%). Then donate some money or critical supplies & lend a hand. #FloridaStrong #HurricaneMichael #beagoodneighbor <URL>\n",
      "full parse [[['Check', 'VERB', 0, 'ROOT', 0], ['out', 'PART', 0, 'prt', 1], ['Calhoun', 'PROPN', 0, 'dobj', 2], ['(', 'PUNCT', 2, 'punct', 3], ['98', 'NUM', 5, 'nummod', 4], ['%', 'NOUN', 2, 'appos', 5], ['out', 'PART', 5, 'prt', 6], [')', 'PUNCT', 2, 'punct', 7], ['Gulf', 'PROPN', 8, 'ROOT', 8], ['(8', 'PROPN', 8, 'punct', 9], ['6', 'NUM', 11, 'nummod', 10], ['%', 'NOUN', 8, 'appos', 11], [')', 'PUNCT', 8, 'punct', 12], ['Jackson', 'PROPN', 16, 'nmod', 13], ['(8', 'PROPN', 16, 'punct', 14], ['3', 'NUM', 16, 'nummod', 15], ['%', 'NOUN', 16, 'ROOT', 16], [')', 'PUNCT', 16, 'punct', 17], ['Liberty', 'PROPN', 18, 'ROOT', 18], ['(', 'PUNCT', 18, 'punct', 19], ['71', 'NUM', 21, 'nummod', 20], ['%', 'NOUN', 18, 'appos', 21], [')', 'PUNCT', 18, 'punct', 22], ['and', 'CCONJ', 18, 'cc', 23], ['Bay', 'PROPN', 18, 'conj', 24], ['(', 'PUNCT', 24, 'punct', 25], ['56', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], [')', 'PUNCT', 24, 'punct', 28], ['.', 'PUNCT', 18, 'punct', 29]], [['Then', 'ADV', 1, 'advmod', 0], ['donate', 'VERB', 1, 'ROOT', 1], ['some', 'DET', 3, 'det', 2], ['money', 'NOUN', 1, 'dobj', 3], ['or', 'CCONJ', 3, 'cc', 4], ['critical', 'ADJ', 6, 'amod', 5], ['supplies', 'NOUN', 3, 'conj', 6], ['&', 'CCONJ', 1, 'cc', 7], ['lend', 'VERB', 1, 'conj', 8], ['a', 'DET', 10, 'det', 9], ['hand', 'NOUN', 8, 'dobj', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['#FloridaStrong', 'PROPN', 1, 'compound', 0], ['#HurricaneMichael', 'PROPN', 2, 'nummod', 1], ['#beagoodneighbor', 'PROPN', 2, 'ROOT', 2]]]\n",
      "candidate 0=Calhoun\n",
      "anchor NE candidates = Liberty\n",
      "data NE tree=[['Calhoun', 'PROPN', 0, 'dobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['Calhoun', 'PROPN', 0, 'dobj', 2]\n",
      "NE parent token:\n",
      "['Check', 'VERB', 0, 'ROOT', 0]\n",
      "NE=Calhoun subtree=[['(', 'PUNCT', 2, 'punct', 3], ['98', 'NUM', 5, 'nummod', 4], ['%', 'NOUN', 2, 'appos', 5], ['out', 'PART', 5, 'prt', 6], [')', 'PUNCT', 2, 'punct', 7]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( 98 % out )\n",
      "candidate 1=Gulf\n",
      "anchor NE candidates = Calhoun,Liberty\n",
      "data NE tree=[['Gulf', 'PROPN', 8, 'ROOT', 8]]\n",
      "NE=Gulf subtree=[['(8', 'PROPN', 8, 'punct', 9], ['6', 'NUM', 11, 'nummod', 10], ['%', 'NOUN', 8, 'appos', 11], [')', 'PUNCT', 8, 'punct', 12]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = (8 6 % )\n",
      "candidate 2=Liberty\n",
      "anchor NE candidates = \n",
      "candidate 3=Bay\n",
      "anchor NE candidates = Calhoun,Gulf,Liberty\n",
      "data NE tree=[['Bay', 'PROPN', 18, 'conj', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['Bay', 'PROPN', 18, 'conj', 24]\n",
      "NE parent token:\n",
      "['Liberty', 'PROPN', 18, 'ROOT', 18]\n",
      "NE=Bay subtree=[['(', 'PUNCT', 24, 'punct', 25], ['56', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], [')', 'PUNCT', 24, 'punct', 28]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( 56 % )\n",
      "testing NE bay, txt:Beach Surveys have been completed in Bay, Escambia, Franklin, Okaloosa, Santa Rosa and Gulf counties. #HurricaneMichael\n",
      "full parse [[['Beach', 'PROPN', 1, 'compound', 0], ['Surveys', 'NOUN', 4, 'nsubjpass', 1], ['have', 'VERB', 4, 'aux', 2], ['been', 'VERB', 4, 'auxpass', 3], ['completed', 'VERB', 4, 'ROOT', 4], ['in', 'ADP', 4, 'prep', 5], ['Bay', 'PROPN', 7, 'compound', 6], ['Escambia', 'PROPN', 9, 'compound', 7], ['Franklin', 'PROPN', 9, 'compound', 8], ['Okaloosa', 'PROPN', 5, 'pobj', 9], ['Santa', 'PROPN', 11, 'compound', 10], ['Rosa', 'PROPN', 9, 'appos', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 14, 'compound', 13], ['counties', 'NOUN', 11, 'conj', 14], ['.', 'PUNCT', 4, 'punct', 15]], [['#HurricaneMichael', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Santa Rosa,Gulf\n",
      "data NE tree=[['Bay', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['Bay', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['Escambia', 'PROPN', 9, 'compound', 7]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 6], ['Escambia', 'PROPN', 9, 'compound', 7]]\n",
      "parent node subtree str bay escambia\n",
      "candidate 1=Santa Rosa\n",
      "anchor NE candidates = Bay,Santa Rosa,Gulf\n",
      "data NE tree=[['Santa', 'PROPN', 11, 'compound', 10], ['Rosa', 'PROPN', 9, 'appos', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['Rosa', 'PROPN', 9, 'appos', 11]\n",
      "NE parent token:\n",
      "['Okaloosa', 'PROPN', 5, 'pobj', 9]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 6], ['Escambia', 'PROPN', 9, 'compound', 7], ['Franklin', 'PROPN', 9, 'compound', 8], ['Okaloosa', 'PROPN', 5, 'pobj', 9], ['Santa', 'PROPN', 11, 'compound', 10], ['Rosa', 'PROPN', 9, 'appos', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 14, 'compound', 13], ['counties', 'NOUN', 11, 'conj', 14]]\n",
      "parent node subtree str bay escambia franklin okaloosa santa rosa and gulf counties\n",
      "NE=Santa Rosa subtree=[['and', 'CCONJ', 11, 'cc', 12], ['Gulf', 'PROPN', 14, 'compound', 13], ['counties', 'NOUN', 11, 'conj', 14]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 2=Gulf\n",
      "anchor NE candidates = \n",
      "testing NE panama_city, txt:AMR Leaders were able to visit crews today in Panama City, Florida as the crews were coming and going from missions. Crews are all pretty upbeat and so glad to be able to be in the area to help people! #HurricaneMichael <URL>\n",
      "full parse [[['AMR', 'PROPN', 1, 'compound', 0], ['Leaders', 'NOUN', 2, 'nsubj', 1], ['were', 'VERB', 2, 'ROOT', 2], ['able', 'ADJ', 2, 'acomp', 3], ['to', 'PART', 5, 'aux', 4], ['visit', 'VERB', 3, 'xcomp', 5], ['crews', 'NOUN', 5, 'dobj', 6], ['today', 'NOUN', 5, 'npadvmod', 7], ['in', 'ADP', 5, 'prep', 8], ['Panama', 'PROPN', 10, 'compound', 9], ['City', 'PROPN', 11, 'compound', 10], ['Florida', 'PROPN', 8, 'pobj', 11], ['as', 'ADP', 16, 'mark', 12], ['the', 'DET', 14, 'det', 13], ['crews', 'NOUN', 16, 'nsubj', 14], ['were', 'VERB', 16, 'aux', 15], ['coming', 'VERB', 5, 'advcl', 16], ['and', 'CCONJ', 16, 'cc', 17], ['going', 'VERB', 16, 'conj', 18], ['from', 'ADP', 18, 'prep', 19], ['missions', 'NOUN', 19, 'pobj', 20], ['.', 'PUNCT', 2, 'punct', 21]], [['Crews', 'NOUN', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['all', 'DET', 1, 'dep', 2], ['pretty', 'ADV', 4, 'advmod', 3], ['upbeat', 'ADJ', 1, 'acomp', 4], ['and', 'CCONJ', 4, 'cc', 5], ['so', 'ADV', 7, 'advmod', 6], ['glad', 'ADJ', 4, 'conj', 7], ['to', 'PART', 9, 'aux', 8], ['be', 'VERB', 7, 'xcomp', 9], ['able', 'ADJ', 9, 'acomp', 10], ['to', 'PART', 12, 'aux', 11], ['be', 'VERB', 10, 'xcomp', 12], ['in', 'ADP', 12, 'prep', 13], ['the', 'DET', 15, 'det', 14], ['area', 'NOUN', 13, 'pobj', 15], ['to', 'PART', 17, 'aux', 16], ['help', 'VERB', 12, 'advcl', 17], ['people', 'NOUN', 17, 'dobj', 18], ['!', 'PUNCT', 1, 'punct', 19]], [['#HurricaneMichael', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Panama', 'PROPN', 10, 'compound', 9], ['City', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['City', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 8, 'pobj', 11]\n",
      "parent node subtree [['Panama', 'PROPN', 10, 'compound', 9], ['City', 'PROPN', 11, 'compound', 10], ['Florida', 'PROPN', 8, 'pobj', 11]]\n",
      "parent node subtree str panama city florida\n",
      "false positive: NE=panama_city, type=compound\n",
      "testing NE sneads, txt:Clean Water is on the way to Sneads, Florida! Want to help us deliver more water to victims of #HurricaneMichael ? Visit our website to make a donation! USA: <URL>\n",
      "full parse [[['Clean', 'PROPN', 1, 'compound', 0], ['Water', 'PROPN', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['on', 'ADP', 2, 'prep', 3], ['the', 'DET', 5, 'det', 4], ['way', 'NOUN', 3, 'pobj', 5], ['to', 'ADP', 5, 'prep', 6], ['Sneads', 'PROPN', 8, 'compound', 7], ['Florida', 'PROPN', 6, 'pobj', 8], ['!', 'PUNCT', 2, 'punct', 9]], [['Want', 'VERB', 0, 'ROOT', 0], ['to', 'PART', 2, 'aux', 1], ['help', 'VERB', 0, 'xcomp', 2], ['us', 'PRON', 4, 'nsubj', 3], ['deliver', 'VERB', 2, 'ccomp', 4], ['more', 'ADJ', 6, 'amod', 5], ['water', 'NOUN', 4, 'dobj', 6], ['to', 'ADP', 4, 'prep', 7], ['victims', 'NOUN', 7, 'pobj', 8], ['of', 'ADP', 8, 'prep', 9], ['#HurricaneMichael', 'PROPN', 9, 'pobj', 10], ['?', 'PUNCT', 0, 'punct', 11]], [['Visit', 'VERB', 0, 'ROOT', 0], ['our', 'ADJ', 2, 'poss', 1], ['website', 'NOUN', 0, 'dobj', 2], ['to', 'PART', 4, 'aux', 3], ['make', 'VERB', 0, 'xcomp', 4], ['a', 'DET', 6, 'det', 5], ['donation', 'NOUN', 4, 'dobj', 6], ['!', 'PUNCT', 0, 'punct', 7]], [['USA', 'PROPN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1]]]\n",
      "candidate 0=Sneads\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Sneads', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Sneads', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['Sneads', 'PROPN', 8, 'compound', 7], ['Florida', 'PROPN', 6, 'pobj', 8]]\n",
      "parent node subtree str sneads florida\n",
      "false positive: NE=sneads, type=compound\n",
      "testing NE calhoun, txt:One Week After #Michael County By County #FLwx Power Outage Update: Calhoun: 97% Jackson: 81% Liberty: 67% Gulf: 58% Bay/Gadsden: 52% Washington: 18% Holmes: 17%\n",
      "full parse [[['One', 'NUM', 1, 'nummod', 0], ['Week', 'NOUN', 10, 'npadvmod', 1], ['After', 'ADP', 1, 'prep', 2], ['#Michael', 'PROPN', 4, 'compound', 3], ['County', 'PROPN', 2, 'pobj', 4], ['By', 'ADP', 9, 'prep', 5], ['County', 'PROPN', 5, 'pobj', 6], ['#FLwx', 'PROPN', 8, 'compound', 7], ['Power', 'PROPN', 9, 'compound', 8], ['Outage', 'PROPN', 10, 'nsubj', 9], ['Update', 'PROPN', 10, 'ROOT', 10], [':', 'PUNCT', 10, 'punct', 11], ['Calhoun', 'PROPN', 10, 'appos', 12], [':', 'PUNCT', 12, 'punct', 13], ['97', 'NUM', 15, 'nummod', 14], ['%', 'NOUN', 16, 'compound', 15], ['Jackson', 'PROPN', 12, 'appos', 16], [':', 'PUNCT', 16, 'punct', 17], ['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['Liberty', 'PROPN', 19, 'appos', 20], [':', 'PUNCT', 16, 'punct', 21], ['67', 'NUM', 23, 'nummod', 22], ['%', 'NOUN', 24, 'compound', 23], ['Gulf', 'PROPN', 24, 'ROOT', 24], [':', 'PUNCT', 24, 'punct', 25], ['58', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], ['Bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29], ['Gadsden', 'PROPN', 27, 'appos', 30], [':', 'PUNCT', 27, 'punct', 31], ['52', 'NUM', 33, 'nummod', 32], ['%', 'NOUN', 27, 'appos', 33], ['Washington', 'PROPN', 33, 'appos', 34], [':', 'PUNCT', 27, 'punct', 35], ['18', 'NUM', 37, 'nummod', 36], ['%', 'NOUN', 27, 'appos', 37], ['Holmes', 'PROPN', 37, 'appos', 38], [':', 'PUNCT', 37, 'punct', 39], ['17', 'NUM', 41, 'nummod', 40], ['%', 'NOUN', 37, 'appos', 41]]]\n",
      "candidate 0=Calhoun\n",
      "anchor NE candidates = Jackson,Liberty,Gadsden\n",
      "data NE tree=[['Calhoun', 'PROPN', 10, 'appos', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['Calhoun', 'PROPN', 10, 'appos', 12]\n",
      "NE parent token:\n",
      "['Update', 'PROPN', 10, 'ROOT', 10]\n",
      "parent node subtree [['One', 'NUM', 1, 'nummod', 0], ['Week', 'NOUN', 10, 'npadvmod', 1], ['After', 'ADP', 1, 'prep', 2], ['#Michael', 'PROPN', 4, 'compound', 3], ['County', 'PROPN', 2, 'pobj', 4], ['By', 'ADP', 9, 'prep', 5], ['County', 'PROPN', 5, 'pobj', 6], ['#FLwx', 'PROPN', 8, 'compound', 7], ['Power', 'PROPN', 9, 'compound', 8], ['Outage', 'PROPN', 10, 'nsubj', 9], ['Update', 'PROPN', 10, 'ROOT', 10], [':', 'PUNCT', 10, 'punct', 11], ['Calhoun', 'PROPN', 10, 'appos', 12], [':', 'PUNCT', 12, 'punct', 13], ['97', 'NUM', 15, 'nummod', 14], ['%', 'NOUN', 16, 'compound', 15], ['Jackson', 'PROPN', 12, 'appos', 16], [':', 'PUNCT', 16, 'punct', 17], ['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['Liberty', 'PROPN', 19, 'appos', 20], [':', 'PUNCT', 16, 'punct', 21]]\n",
      "parent node subtree str one week after #michael county by county #flwx power outage update : calhoun : 97 % jackson : 81 % liberty :\n",
      "NE=Calhoun subtree=[[':', 'PUNCT', 12, 'punct', 13], ['97', 'NUM', 15, 'nummod', 14], ['%', 'NOUN', 16, 'compound', 15], ['Jackson', 'PROPN', 12, 'appos', 16], [':', 'PUNCT', 16, 'punct', 17], ['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['Liberty', 'PROPN', 19, 'appos', 20], [':', 'PUNCT', 16, 'punct', 21]]\n",
      "min node deps ['punct', 'appos']\n",
      "subtree = : 97 % Jackson : 81 % Liberty :\n",
      "candidate 1=Jackson\n",
      "anchor NE candidates = \n",
      "candidate 2=Liberty\n",
      "anchor NE candidates = Jackson\n",
      "data NE tree=[['Liberty', 'PROPN', 19, 'appos', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Liberty', 'PROPN', 19, 'appos', 20]\n",
      "NE parent token:\n",
      "['%', 'NOUN', 16, 'appos', 19]\n",
      "parent node subtree [['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['Liberty', 'PROPN', 19, 'appos', 20]]\n",
      "parent node subtree str 81 % liberty\n",
      "candidate 3=Bay\n",
      "anchor NE candidates = Calhoun,Jackson,Liberty,Gadsden\n",
      "data NE tree=[['Bay', 'PROPN', 30, 'nmod', 28]]\n",
      "NE parse token at tree=0, token=29:\n",
      "['Bay', 'PROPN', 30, 'nmod', 28]\n",
      "NE parent token:\n",
      "['Gadsden', 'PROPN', 27, 'appos', 30]\n",
      "parent node subtree [['Bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29], ['Gadsden', 'PROPN', 27, 'appos', 30]]\n",
      "parent node subtree str bay / gadsden\n",
      "candidate 4=Gadsden\n",
      "anchor NE candidates = Jackson,Liberty\n",
      "data NE tree=[['Gadsden', 'PROPN', 27, 'appos', 30]]\n",
      "NE parse token at tree=0, token=31:\n",
      "['Gadsden', 'PROPN', 27, 'appos', 30]\n",
      "NE parent token:\n",
      "['%', 'NOUN', 24, 'appos', 27]\n",
      "parent node subtree [['58', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], ['Bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29], ['Gadsden', 'PROPN', 27, 'appos', 30], [':', 'PUNCT', 27, 'punct', 31], ['52', 'NUM', 33, 'nummod', 32], ['%', 'NOUN', 27, 'appos', 33], ['Washington', 'PROPN', 33, 'appos', 34], [':', 'PUNCT', 27, 'punct', 35], ['18', 'NUM', 37, 'nummod', 36], ['%', 'NOUN', 27, 'appos', 37], ['Holmes', 'PROPN', 37, 'appos', 38], [':', 'PUNCT', 37, 'punct', 39], ['17', 'NUM', 41, 'nummod', 40], ['%', 'NOUN', 37, 'appos', 41]]\n",
      "parent node subtree str 58 % bay / gadsden : 52 % washington : 18 % holmes : 17 %\n",
      "NE=Gadsden subtree=[['Bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29]]\n",
      "min node deps ['nmod', 'punct']\n",
      "false positive: NE=calhoun, type=descriptor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing NE mexico_beach, txt:Want to see the real #AHSApocalypse ? Come down here to Mexico beach or Panama City, FL! #HurricaneMichael #hurricanemichael2018 @CNN @weatherchannel\n",
      "full parse [[['Want', 'VERB', 0, 'ROOT', 0], ['to', 'PART', 2, 'aux', 1], ['see', 'VERB', 0, 'xcomp', 2], ['the', 'DET', 5, 'det', 3], ['real', 'ADJ', 5, 'amod', 4], ['#AHSApocalypse', 'NOUN', 2, 'dobj', 5], ['?', 'PUNCT', 0, 'punct', 6]], [['Come', 'VERB', 0, 'ROOT', 0], ['down', 'PART', 0, 'prt', 1], ['here', 'ADV', 0, 'advmod', 2], ['to', 'ADP', 0, 'prep', 3], ['Mexico', 'PROPN', 5, 'compound', 4], ['beach', 'NOUN', 3, 'pobj', 5], ['or', 'CCONJ', 5, 'cc', 6], ['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['FL', 'PROPN', 5, 'conj', 9], ['!', 'PUNCT', 0, 'punct', 10]], [['#HurricaneMichael', 'PROPN', 2, 'compound', 0], ['#hurricanemichael2018', 'PUNCT', 2, 'nsubj', 1], ['@CNN', 'PROPN', 2, 'ROOT', 2], ['@weatherchannel', 'X', 2, 'punct', 3]]]\n",
      "candidate 0=Mexico beach\n",
      "anchor NE candidates = Panama City,FL\n",
      "data NE tree=[['Mexico', 'PROPN', 5, 'compound', 4], ['beach', 'NOUN', 3, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['beach', 'NOUN', 3, 'pobj', 5]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 3]\n",
      "NE=Mexico beach subtree=[['or', 'CCONJ', 5, 'cc', 6], ['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['FL', 'PROPN', 5, 'conj', 9]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=Panama City\n",
      "anchor NE candidates = FL\n",
      "data NE tree=[['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['City', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['FL', 'PROPN', 5, 'conj', 9]\n",
      "parent node subtree [['Panama', 'PROPN', 9, 'compound', 7], ['City', 'PROPN', 9, 'compound', 8], ['FL', 'PROPN', 5, 'conj', 9]]\n",
      "parent node subtree str panama city fl\n",
      "testing NE tallahassee, txt:Orange County Utilities’ Water Reclamation and Field Services team members are helping restore sewer systems impacted by #HurricaneMichael in Tallahassee and Panama City. We are proud to support our neighbors, just as they did, following past storms that affected Central Florida. <URL>\n",
      "full parse [[['Orange', 'PROPN', 3, 'compound', 0], ['County', 'PROPN', 3, 'compound', 1], ['Utilities', 'PROPN', 3, 'compound', 2], ['’', 'PROPN', 10, 'nmod', 3], ['Water', 'PROPN', 5, 'nmod', 4], ['Reclamation', 'PROPN', 10, 'nmod', 5], ['and', 'CCONJ', 5, 'cc', 6], ['Field', 'PROPN', 8, 'compound', 7], ['Services', 'PROPN', 5, 'conj', 8], ['team', 'NOUN', 10, 'compound', 9], ['members', 'NOUN', 12, 'nsubj', 10], ['are', 'VERB', 12, 'aux', 11], ['helping', 'VERB', 12, 'ROOT', 12], ['restore', 'VERB', 12, 'xcomp', 13], ['sewer', 'NOUN', 15, 'compound', 14], ['systems', 'NOUN', 13, 'dobj', 15], ['impacted', 'VERB', 15, 'acl', 16], ['by', 'ADP', 16, 'agent', 17], ['#HurricaneMichael', 'PROPN', 17, 'pobj', 18], ['in', 'ADP', 16, 'prep', 19], ['Tallahassee', 'PROPN', 19, 'pobj', 20], ['and', 'CCONJ', 20, 'cc', 21], ['Panama', 'PROPN', 23, 'compound', 22], ['City', 'PROPN', 20, 'conj', 23], ['.', 'PUNCT', 12, 'punct', 24]], [['We', 'PRON', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['proud', 'ADJ', 1, 'acomp', 2], ['to', 'PART', 4, 'aux', 3], ['support', 'VERB', 2, 'xcomp', 4], ['our', 'ADJ', 6, 'poss', 5], ['neighbors', 'NOUN', 4, 'dobj', 6], ['just', 'ADV', 11, 'advmod', 7], ['as', 'ADP', 11, 'mark', 8], ['they', 'PRON', 11, 'nsubj', 9], ['did', 'VERB', 11, 'aux', 10], ['following', 'VERB', 1, 'advcl', 11], ['past', 'ADJ', 13, 'amod', 12], ['storms', 'NOUN', 11, 'dobj', 13], ['that', 'ADJ', 15, 'nsubj', 14], ['affected', 'VERB', 13, 'relcl', 15], ['Central', 'PROPN', 17, 'compound', 16], ['Florida', 'PROPN', 15, 'dobj', 17], ['.', 'PUNCT', 1, 'punct', 18]]]\n",
      "candidate 0=Orange County\n",
      "anchor NE candidates = \n",
      "candidate 1=Tallahassee\n",
      "anchor NE candidates = Orange County\n",
      "data NE tree=[['Tallahassee', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['Tallahassee', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['in', 'ADP', 16, 'prep', 19]\n",
      "NE=Tallahassee subtree=[['and', 'CCONJ', 20, 'cc', 21], ['Panama', 'PROPN', 23, 'compound', 22], ['City', 'PROPN', 20, 'conj', 23]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 2=Panama City\n",
      "anchor NE candidates = Orange County,Tallahassee\n",
      "data NE tree=[['Panama', 'PROPN', 23, 'compound', 22], ['City', 'PROPN', 20, 'conj', 23]]\n",
      "NE parse token at tree=0, token=24:\n",
      "['City', 'PROPN', 20, 'conj', 23]\n",
      "NE parent token:\n",
      "['Tallahassee', 'PROPN', 19, 'pobj', 20]\n",
      "testing NE panama_city, txt:Reminders from #hurricanemichael . Posted orignally by \"\"The Most Excellent Way\"\" of Panama City, Fl. \"\"And we know that for those who love God all things work together for good, for those… <URL>\n",
      "full parse [[['Reminders', 'NOUN', 0, 'ROOT', 0], ['from', 'ADP', 0, 'prep', 1], ['#hurricanemichael', 'PROPN', 1, 'pobj', 2], ['.', 'PUNCT', 0, 'punct', 3]], [['Posted', 'VERB', 0, 'ROOT', 0], ['orignally', 'ADV', 0, 'advmod', 1], ['by', 'ADP', 0, 'agent', 2], ['\"', 'PUNCT', 8, 'punct', 3], ['\"', 'PUNCT', 8, 'punct', 4], ['The', 'DET', 8, 'det', 5], ['Most', 'ADV', 8, 'compound', 6], ['Excellent', 'ADJ', 8, 'compound', 7], ['Way', 'NOUN', 2, 'pobj', 8], ['\"', 'PUNCT', 8, 'punct', 9], ['\"', 'PUNCT', 8, 'punct', 10], ['of', 'ADP', 8, 'prep', 11], ['Panama', 'PROPN', 14, 'compound', 12], ['City', 'PROPN', 14, 'compound', 13], ['Fl', 'PROPN', 11, 'pobj', 14], ['.', 'PUNCT', 0, 'punct', 15]], [['\"', 'PUNCT', 4, 'punct', 0], ['\"', 'PUNCT', 4, 'punct', 1], ['And', 'CCONJ', 4, 'cc', 2], ['we', 'PRON', 4, 'nsubj', 3], ['know', 'VERB', 4, 'ROOT', 4], ['that', 'ADP', 13, 'mark', 5], ['for', 'ADP', 13, 'prep', 6], ['those', 'DET', 6, 'pobj', 7], ['who', 'NOUN', 9, 'nsubj', 8], ['love', 'VERB', 7, 'relcl', 9], ['God', 'PROPN', 9, 'dobj', 10], ['all', 'DET', 12, 'det', 11], ['things', 'NOUN', 9, 'dobj', 12], ['work', 'VERB', 4, 'ccomp', 13], ['together', 'ADV', 13, 'advmod', 14], ['for', 'ADP', 13, 'prep', 15], ['good', 'ADJ', 15, 'amod', 16], ['for', 'ADP', 13, 'prep', 17], ['those', 'DET', 17, 'pobj', 18], ['…', 'PUNCT', 4, 'punct', 19]]]\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Fl\n",
      "data NE tree=[['Panama', 'PROPN', 14, 'compound', 12], ['City', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['City', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['Fl', 'PROPN', 11, 'pobj', 14]\n",
      "parent node subtree [['Panama', 'PROPN', 14, 'compound', 12], ['City', 'PROPN', 14, 'compound', 13], ['Fl', 'PROPN', 11, 'pobj', 14]]\n",
      "parent node subtree str panama city fl\n",
      "false positive: NE=panama_city, type=compound\n",
      "testing NE mexico_beach, txt:One home in Mexico Beach, Florida, appeared largely untouched amid the incredible destruction of #HurricaneMichael . And its owners, Lebron Lackey and his uncle, Russell King, say it's no… <URL>\n",
      "full parse [[['One', 'NUM', 1, 'nummod', 0], ['home', 'NOUN', 6, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['Mexico', 'PROPN', 4, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4], ['Florida', 'PROPN', 2, 'pobj', 5], ['appeared', 'VERB', 6, 'ROOT', 6], ['largely', 'ADV', 8, 'advmod', 7], ['untouched', 'ADJ', 6, 'oprd', 8], ['amid', 'ADP', 8, 'prep', 9], ['the', 'DET', 12, 'det', 10], ['incredible', 'ADJ', 12, 'amod', 11], ['destruction', 'NOUN', 9, 'pobj', 12], ['of', 'ADP', 12, 'prep', 13], ['#HurricaneMichael', 'PROPN', 13, 'pobj', 14], ['.', 'PUNCT', 6, 'punct', 15]], [['And', 'CCONJ', 10, 'cc', 0], ['its', 'ADJ', 2, 'poss', 1], ['owners', 'NOUN', 10, 'nsubj', 2], ['Lebron', 'PROPN', 4, 'compound', 3], ['Lackey', 'PROPN', 2, 'appos', 4], ['and', 'CCONJ', 4, 'cc', 5], ['his', 'ADJ', 7, 'poss', 6], ['uncle', 'NOUN', 4, 'conj', 7], ['Russell', 'PROPN', 9, 'compound', 8], ['King', 'PROPN', 7, 'appos', 9], ['say', 'VERB', 10, 'ROOT', 10], [\"it's\", 'PRON', 12, 'nsubj', 11], ['no', 'DET', 10, 'ccomp', 12], ['…', 'PUNCT', 10, 'punct', 13]]]\n",
      "candidate 0=Mexico Beach\n",
      "anchor NE candidates = Florida\n",
      "data NE tree=[['Mexico', 'PROPN', 4, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Beach', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Florida', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Mexico', 'PROPN', 4, 'compound', 3], ['Beach', 'PROPN', 5, 'compound', 4], ['Florida', 'PROPN', 2, 'pobj', 5]]\n",
      "parent node subtree str mexico beach florida\n",
      "false positive: NE=mexico_beach, type=compound\n",
      "testing NE panama_city, txt:Hey guys... PLEASE come to Panama City, Fl. We need some laughs after #HurricaneMichael The beach didn't get hit bad at all. There are many venues. Club La Vila is a huge one. We'd love to see ya'll. Please consider it.\n",
      "full parse [[['Hey', 'INTJ', 1, 'intj', 0], ['guys', 'NOUN', 1, 'ROOT', 1], ['...', 'PUNCT', 1, 'punct', 2]], [['PLEASE', 'PRON', 0, 'ROOT', 0], ['come', 'VERB', 0, 'xcomp', 1], ['to', 'ADP', 1, 'prep', 2], ['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Fl', 'PROPN', 2, 'pobj', 5], ['.', 'PUNCT', 0, 'punct', 6]], [['We', 'PRON', 1, 'nsubj', 0], ['need', 'VERB', 1, 'ROOT', 1], ['some', 'DET', 3, 'det', 2], ['laughs', 'NOUN', 1, 'dobj', 3], ['after', 'ADP', 1, 'prep', 4], ['#HurricaneMichael', 'PROPN', 4, 'pobj', 5], ['The', 'DET', 7, 'det', 6], ['beach', 'NOUN', 10, 'nsubjpass', 7], [\"didn't\", 'VERB', 10, 'aux', 8], ['get', 'VERB', 10, 'auxpass', 9], ['hit', 'VERB', 10, 'ROOT', 10], ['bad', 'ADJ', 10, 'advmod', 11], ['at', 'ADV', 13, 'advmod', 12], ['all', 'ADV', 10, 'advmod', 13], ['.', 'PUNCT', 10, 'punct', 14]], [['There', 'ADV', 1, 'expl', 0], ['are', 'VERB', 1, 'ROOT', 1], ['many', 'ADJ', 3, 'amod', 2], ['venues', 'NOUN', 1, 'attr', 3], ['.', 'PUNCT', 1, 'punct', 4]], [['Club', 'PROPN', 2, 'compound', 0], ['La', 'PROPN', 2, 'compound', 1], ['Vila', 'PROPN', 3, 'nsubj', 2], ['is', 'VERB', 3, 'ROOT', 3], ['a', 'DET', 6, 'det', 4], ['huge', 'ADJ', 6, 'amod', 5], ['one', 'NOUN', 3, 'attr', 6], ['.', 'PUNCT', 3, 'punct', 7]], [[\"We'd\", 'ADJ', 1, 'compound', 0], ['love', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['see', 'VERB', 1, 'xcomp', 3], [\"ya'll\", 'PROPN', 3, 'dobj', 4], ['.', 'PUNCT', 1, 'punct', 5]], [['Please', 'INTJ', 1, 'intj', 0], ['consider', 'VERB', 1, 'ROOT', 1], ['it', 'PRON', 1, 'dobj', 2], ['.', 'PUNCT', 1, 'punct', 3]]]\n",
      "candidate 0=Panama City\n",
      "anchor NE candidates = Fl\n",
      "data NE tree=[['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['City', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['Fl', 'PROPN', 2, 'pobj', 5]\n",
      "parent node subtree [['Panama', 'PROPN', 5, 'compound', 3], ['City', 'PROPN', 5, 'compound', 4], ['Fl', 'PROPN', 2, 'pobj', 5]]\n",
      "parent node subtree str panama city fl\n",
      "false positive: NE=panama_city, type=compound\n",
      "testing NE franklin_county, txt:This afternoon, state and federal partners held a call to coordinate housing solutions in areas impacted by #HurricaneMichael . Thanks to Franklin County, Liberty County and Washington County for joining us on the call. em2franklin LibertyCoFLEM <URL>\n",
      "full parse [[['This', 'DET', 5, 'det', 0], ['afternoon', 'NOUN', 5, 'nmod', 1], ['state', 'NOUN', 5, 'nmod', 2], ['and', 'CCONJ', 2, 'cc', 3], ['federal', 'ADJ', 2, 'conj', 4], ['partners', 'NOUN', 6, 'nsubj', 5], ['held', 'VERB', 6, 'ROOT', 6], ['a', 'DET', 8, 'det', 7], ['call', 'NOUN', 6, 'dobj', 8], ['to', 'PART', 10, 'aux', 9], ['coordinate', 'VERB', 8, 'acl', 10], ['housing', 'NOUN', 12, 'compound', 11], ['solutions', 'NOUN', 10, 'dobj', 12], ['in', 'ADP', 12, 'prep', 13], ['areas', 'NOUN', 13, 'pobj', 14], ['impacted', 'VERB', 14, 'acl', 15], ['by', 'ADP', 15, 'agent', 16], ['#HurricaneMichael', 'PROPN', 16, 'pobj', 17], ['.', 'PUNCT', 6, 'punct', 18]], [['Thanks', 'NOUN', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['Liberty', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 1, 'pobj', 5], ['and', 'CCONJ', 5, 'cc', 6], ['Washington', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 5, 'conj', 8], ['for', 'ADP', 0, 'prep', 9], ['joining', 'VERB', 9, 'pcomp', 10], ['us', 'PRON', 10, 'dobj', 11], ['on', 'ADP', 10, 'prep', 12], ['the', 'DET', 14, 'det', 13], ['call', 'NOUN', 12, 'pobj', 14], ['.', 'PUNCT', 0, 'punct', 15]], [['em2franklin', 'PROPN', 1, 'compound', 0], ['LibertyCoFLEM', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=Franklin County\n",
      "anchor NE candidates = Washington County\n",
      "data NE tree=[['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['County', 'PROPN', 5, 'compound', 3]\n",
      "NE parent token:\n",
      "['County', 'PROPN', 1, 'pobj', 5]\n",
      "parent node subtree [['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['Liberty', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 1, 'pobj', 5], ['and', 'CCONJ', 5, 'cc', 6], ['Washington', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 5, 'conj', 8]]\n",
      "parent node subtree str franklin county liberty county and washington county\n",
      "candidate 1=Liberty County\n",
      "anchor NE candidates = Franklin County,Washington County\n",
      "data NE tree=[['Liberty', 'PROPN', 5, 'compound', 4], ['County', 'PROPN', 1, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['County', 'PROPN', 1, 'pobj', 5]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "NE=Liberty County subtree=[['Franklin', 'PROPN', 3, 'compound', 2], ['County', 'PROPN', 5, 'compound', 3], ['and', 'CCONJ', 5, 'cc', 6], ['Washington', 'PROPN', 8, 'compound', 7], ['County', 'PROPN', 5, 'conj', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 2=Washington County\n",
      "anchor NE candidates = \n",
      "testing NE bay, txt:Unless you live in Bay, Gulf, Jackson, Calhoun and Gadsden counties. #850Strong #FloridaStrong #HurricaneMichael\n",
      "full parse [[['Unless', 'ADP', 2, 'mark', 0], ['you', 'PRON', 2, 'nsubj', 1], ['live', 'VERB', 2, 'ROOT', 2], ['in', 'ADP', 2, 'prep', 3], ['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['Calhoun', 'PROPN', 3, 'pobj', 7], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10], ['.', 'PUNCT', 2, 'punct', 11]], [['#850Strong', 'X', 1, 'intj', 0], ['#FloridaStrong', 'PROPN', 2, 'compound', 1], ['#HurricaneMichael', 'PROPN', 2, 'ROOT', 2]]]\n",
      "candidate 0=Bay\n",
      "anchor NE candidates = Gulf,Calhoun,Gadsden\n",
      "data NE tree=[['Bay', 'PROPN', 7, 'compound', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['Bay', 'PROPN', 7, 'compound', 4]\n",
      "NE parent token:\n",
      "['Calhoun', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['Calhoun', 'PROPN', 3, 'pobj', 7], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "parent node subtree str bay gulf jackson calhoun and gadsden counties\n",
      "candidate 1=Gulf\n",
      "anchor NE candidates = Calhoun,Gadsden\n",
      "data NE tree=[['Gulf', 'PROPN', 7, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['Gulf', 'PROPN', 7, 'compound', 5]\n",
      "NE parent token:\n",
      "['Calhoun', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['Calhoun', 'PROPN', 3, 'pobj', 7], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "parent node subtree str bay gulf jackson calhoun and gadsden counties\n",
      "candidate 2=Calhoun\n",
      "anchor NE candidates = Gadsden\n",
      "data NE tree=[['Calhoun', 'PROPN', 3, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['Calhoun', 'PROPN', 3, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "NE=Calhoun subtree=[['Bay', 'PROPN', 7, 'compound', 4], ['Gulf', 'PROPN', 7, 'compound', 5], ['Jackson', 'PROPN', 7, 'compound', 6], ['and', 'CCONJ', 7, 'cc', 8], ['Gadsden', 'PROPN', 10, 'compound', 9], ['counties', 'NOUN', 7, 'conj', 10]]\n",
      "min node deps ['compound', 'compound', 'compound', 'cc', 'conj']\n",
      "candidate 3=Gadsden\n",
      "anchor NE candidates = \n",
      "testing subclause type=state\n",
      "80/84 contexts detected\n",
      "recall=0.952\n",
      "prec=0.976\n",
      "testing subclause type=descriptor\n",
      "5/13 contexts detected\n",
      "recall=0.385\n",
      "prec=0.778\n",
      "testing subclause type=compound\n",
      "3/4 contexts detected\n",
      "recall=0.750\n",
      "prec=0.963\n",
      "testing subclause type=list\n",
      "4/4 contexts detected\n",
      "recall=1.000\n",
      "prec=0.667\n"
     ]
    }
   ],
   "source": [
    "## load annotated\n",
    "annotated_anchor_data = pd.read_csv('../../data/mined_tweets/combined_tweet_tag_data_NE_flat_anchor_examples.tsv', sep='\\t', index_col=False)\n",
    "annotated_anchor_data_any_context = annotated_anchor_data[annotated_anchor_data.loc[:, 'context_subclause_any']==1]\n",
    "## track all types of anchors\n",
    "subclause_state = []\n",
    "subclause_descriptor = []\n",
    "# subclause_compound = []\n",
    "# subclause_list = []\n",
    "subclause_state_gold = []\n",
    "subclause_descriptor_gold = []\n",
    "# subclause_compound_gold = []\n",
    "# subclause_list_gold = []\n",
    "subclause_gold_any = []\n",
    "# subclause_preds = [subclause_state, subclause_descriptor, subclause_compound, subclause_list]\n",
    "# subclause_gold = [subclause_state_gold, subclause_descriptor_gold, subclause_compound_gold, subclause_list_gold]\n",
    "subclause_preds = [subclause_state, subclause_descriptor]\n",
    "subclause_gold = [subclause_state_gold, subclause_descriptor_gold]\n",
    "subclause_types = ['state', 'descriptor']\n",
    "for idx_i, annotated_data_i in annotated_anchor_data.iterrows():\n",
    "    txt_i = annotated_data_i.loc['txt']\n",
    "    data_i = anchor_data[anchor_data.loc[:, 'txt']==txt_i]\n",
    "    NE_i = annotated_data_i.loc['NE']\n",
    "    # restrict to data where NE only occurs once per status\n",
    "    if(len([x for x in data_i.loc[:, 'NE'] if x.replace(' ', '_').lower()==NE_i]) == 1):\n",
    "        print('testing NE %s, txt:%s'%(NE_i, txt_i))\n",
    "        subclause_i = detect_subclause_anchor_by_type(data_i, verbose=True)\n",
    "        subclause_gold_any_i = 0\n",
    "        for subclause_j, subclause_type_j, subclause_pred_j, subclause_gold_j in zip(subclause_i, subclause_types, subclause_preds, subclause_gold):\n",
    "            subclause_j.index = [x.replace(' ', '_').lower() for x in subclause_j.index]\n",
    "            subclause_pred_j.append(subclause_j.loc[NE_i])\n",
    "            subclause_gold_j.append(annotated_data_i.loc['context_subclause_%s'%(subclause_type_j)])\n",
    "            subclause_gold_any_i = max(subclause_gold_any_i, annotated_data_i.loc['context_subclause_%s'%(subclause_type_j)])\n",
    "            ## debugging: false negatives hurt recall\n",
    "#             if(annotated_data_i.loc['context_subclause_%s'%(subclause_type_j)] - subclause_j.loc[NE_i] == 1.):\n",
    "#                 print('false negative: NE=%s, type=%s'%(NE_i, subclause_type_j))\n",
    "            ## debugging: false positives hurt precision\n",
    "            if(subclause_j.loc[NE_i] - annotated_data_i.loc['context_subclause_%s'%(subclause_type_j)] == 1.):\n",
    "                print('false positive: NE=%s, type=%s'%(NE_i, subclause_type_j))\n",
    "        subclause_gold_any.append(subclause_gold_any_i)\n",
    "\n",
    "## compute precision/recall\n",
    "## use context_any for gold label in precision! because we don't care if there's overlap between categories\n",
    "subclause_gold_any = np.array(subclause_gold_any)\n",
    "for subclause_type, subclause_pred, subclause_gold in zip(subclause_types, subclause_preds, subclause_gold):\n",
    "    print('testing subclause type=%s'%(subclause_type))\n",
    "    subclause_gold = np.array(subclause_gold)\n",
    "    subclause_pred = np.array(subclause_pred)\n",
    "    # recall\n",
    "    gold_idx = np.where(subclause_gold == 1.)\n",
    "    gold_pred_diff = subclause_gold[gold_idx] - subclause_pred[gold_idx]\n",
    "    recall = len(gold_pred_diff[gold_pred_diff == 0.]) / len(gold_pred_diff[gold_pred_diff >= 0.])\n",
    "    print('%d/%d contexts detected'%(sum(subclause_pred[gold_idx]), sum(subclause_gold[gold_idx])))\n",
    "    print('recall=%.3f'%(recall))\n",
    "    # precision\n",
    "    pred_idx = np.where(subclause_pred == 1.)\n",
    "    all_pred_diff = subclause_pred[pred_idx] - subclause_gold_any[pred_idx]\n",
    "    prec = len(all_pred_diff[all_pred_diff == 0.]) / len(all_pred_diff[all_pred_diff >= 0.])\n",
    "    print('prec=%.3f'%(prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(subclause_estimate[estimate_idx])\n",
    "print(subclause_gold_any[estimate_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test precision on full data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's label all the data with the high-precision anchors, get a random sample, and re-label to ensure that the precision doesn't take a big hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'txt', 'data_name_fixed', 'username', 'date', 'lang', 'NE',\n",
       "       'NE_type', 'NE_LOC', 'valid_loc', 'NE_fixed', 'has_descriptor',\n",
       "       'NE_fixed_clean', 'max_population', 'max_alternate_name_count',\n",
       "       'max_population_anchor', 'max_population_diff',\n",
       "       'max_alternate_name_count_anchor', 'max_alternate_name_count_diff',\n",
       "       'parse'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_parsed_flat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subclause_anchor_data_combined = []\n",
    "id_var = 'id'\n",
    "id_var_unique = combined_data_parsed_flat.loc[:, id_var].nunique()\n",
    "subclause_anchor_var = 'subclause_anchor'\n",
    "subclause_types = ['state', 'descriptor', 'compound', 'list']\n",
    "parse_data_cols = ['txt', 'parse', 'data_name_fixed', 'valid_loc', 'has_descriptor']\n",
    "NE_var = 'NE_fixed'\n",
    "for i, (id_i, data_i) in enumerate(combined_data_parsed_flat.groupby(id_var)):\n",
    "    subclause_i = detect_subclause_anchor_by_type(data_i, verbose=False)\n",
    "    if(len(subclause_i[0]) > 0):\n",
    "        data_i = data_i[data_i.loc[:, 'valid_loc']==1]\n",
    "    #     for subclause_j in subclause_i:\n",
    "    #         subclause_j.index = [x.replace(' ', '_').lower() for x in subclause_j.index]\n",
    "        anchor_data_i = pd.concat(subclause_i, axis=1)\n",
    "        anchor_data_i.columns = subclause_types\n",
    "        anchor_data_i = anchor_data_i.reset_index(inplace=False).rename(columns={'index' : NE_var})\n",
    "        anchor_data_i = anchor_data_i.assign(**{subclause_anchor_var : anchor_data_i.loc[:, subclause_types].max(axis=1)})\n",
    "#         print('anchor data N=%d, data N=%d'%(anchor_data_i.shape[0], data_i.shape[0]))\n",
    "        anchor_data_i.index = data_i.index\n",
    "        anchor_data_i = pd.concat([anchor_data_i, data_i.loc[:, parse_data_cols]], axis=1)\n",
    "        subclause_anchor_data_combined.append(anchor_data_i)\n",
    "    if(i % 1000 == 0):\n",
    "        print('processed %d/%d ID groups'%(i, id_var_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclause_anchor_data_combined = pd.concat(subclause_anchor_data_combined, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158863 samples\n"
     ]
    }
   ],
   "source": [
    "print('%d samples'%(subclause_anchor_data_combined.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['NE_fixed', 'state', 'descriptor', 'compound', 'list',\n",
      "       'subclause_anchor', 'txt', 'parse', 'data_name_fixed', 'valid_loc',\n",
      "       'has_descriptor'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "state               16950\n",
       "descriptor           1103\n",
       "compound            13906\n",
       "list                  532\n",
       "subclause_anchor    19193\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(subclause_anchor_data_combined.columns)\n",
    "display(subclause_anchor_data_combined.loc[:, subclause_types + [subclause_anchor_var]].sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a random sample of each type and annotate for precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 state  descriptor  compound  list\n",
      "data_name_fixed                                   \n",
      "florence            21          10        23    11\n",
      "harvey              21          10        19    10\n",
      "irma                20          11        16    10\n",
      "maria               22          10        14    10\n",
      "michael             22          10        18    10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NE_fixed</th>\n",
       "      <th>txt</th>\n",
       "      <th>data_name_fixed</th>\n",
       "      <th>state</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>compound</th>\n",
       "      <th>list</th>\n",
       "      <th>state_gold</th>\n",
       "      <th>descriptor_gold</th>\n",
       "      <th>compound_gold</th>\n",
       "      <th>list_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460913</th>\n",
       "      <td>Lumberton</td>\n",
       "      <td>Leaving Lumberton... Trailers found a low wate...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454417</th>\n",
       "      <td>New Bern</td>\n",
       "      <td>The scene at the waterfront park in New Bern, ...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461879</th>\n",
       "      <td>Aurora</td>\n",
       "      <td>Update from Capt. Stephan Wildish who is servi...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454282</th>\n",
       "      <td>Wilmington</td>\n",
       "      <td>RT @WFLALeigh: WOW! The potential rainfall tot...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459450</th>\n",
       "      <td>Greensboro</td>\n",
       "      <td>My version of the #Poblanos Chicken Soup! #hom...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NE_fixed                                                txt  \\\n",
       "460913   Lumberton  Leaving Lumberton... Trailers found a low wate...   \n",
       "454417    New Bern  The scene at the waterfront park in New Bern, ...   \n",
       "461879      Aurora  Update from Capt. Stephan Wildish who is servi...   \n",
       "454282  Wilmington  RT @WFLALeigh: WOW! The potential rainfall tot...   \n",
       "459450  Greensboro  My version of the #Poblanos Chicken Soup! #hom...   \n",
       "\n",
       "       data_name_fixed  state  descriptor  compound  list  state_gold  \\\n",
       "460913        florence      1           0         0     0           0   \n",
       "454417        florence      1           0         1     0           0   \n",
       "461879        florence      1           0         1     0           0   \n",
       "454282        florence      1           0         1     0           0   \n",
       "459450        florence      1           0         1     0           0   \n",
       "\n",
       "        descriptor_gold  compound_gold  list_gold  \n",
       "460913                0              0          0  \n",
       "454417                0              0          0  \n",
       "461879                0              0          0  \n",
       "454282                0              0          0  \n",
       "459450                0              0          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_size = 10\n",
    "group_var = 'data_name_fixed'\n",
    "subclause_anchor_data_combined_samples = []\n",
    "sample_usecols = ['NE_fixed', 'txt', group_var] + subclause_types\n",
    "for i, data_i in subclause_anchor_data_combined.groupby(group_var):\n",
    "    samples_i = [data_i[data_i.loc[:, x]==1].assign(**{x : 1}) for x in subclause_types]\n",
    "    samples_i = [x.loc[np.random.choice(x.index, min(sample_size, x.shape[0]), replace=False)] for x in samples_i]\n",
    "    subclause_anchor_data_combined_samples += samples_i\n",
    "subclause_anchor_data_combined_samples = pd.concat(subclause_anchor_data_combined_samples, axis=0)\n",
    "subclause_anchor_data_combined_samples = subclause_anchor_data_combined_samples.loc[:, sample_usecols]\n",
    "## add gold cols for annotation\n",
    "subclause_anchor_data_combined_samples = subclause_anchor_data_combined_samples.assign(**{'%s_gold'%(x) : 0 for x in subclause_types})\n",
    "print(subclause_anchor_data_combined_samples.groupby(group_var).apply(lambda x: x.loc[:, subclause_types].sum(axis=0)))\n",
    "display(subclause_anchor_data_combined_samples.head())\n",
    "## write to file to annotate! so exciting!!\n",
    "sample_out_file = '../../data/mined_tweets/combined_tweet_tag_data_NE_flat_anchor_examples_by_type.tsv'\n",
    "subclause_anchor_data_combined_samples.to_csv(sample_out_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After annotating...let's evaluate the precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NE_fixed</th>\n",
       "      <th>txt</th>\n",
       "      <th>data_name_fixed</th>\n",
       "      <th>state</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>compound</th>\n",
       "      <th>list</th>\n",
       "      <th>state_gold</th>\n",
       "      <th>descriptor_gold</th>\n",
       "      <th>compound_gold</th>\n",
       "      <th>list_gold</th>\n",
       "      <th>any_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lumberton</td>\n",
       "      <td>Leaving Lumberton... Trailers found a low wate...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Bern</td>\n",
       "      <td>The scene at the waterfront park in New Bern, ...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aurora</td>\n",
       "      <td>Update from Capt. Stephan Wildish who is servi...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wilmington</td>\n",
       "      <td>RT @WFLALeigh: WOW! The potential rainfall tot...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greensboro</td>\n",
       "      <td>My version of the #Poblanos Chicken Soup! #hom...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NE_fixed                                                txt  \\\n",
       "0   Lumberton  Leaving Lumberton... Trailers found a low wate...   \n",
       "1    New Bern  The scene at the waterfront park in New Bern, ...   \n",
       "2      Aurora  Update from Capt. Stephan Wildish who is servi...   \n",
       "3  Wilmington  RT @WFLALeigh: WOW! The potential rainfall tot...   \n",
       "4  Greensboro  My version of the #Poblanos Chicken Soup! #hom...   \n",
       "\n",
       "  data_name_fixed  state  descriptor  compound  list  state_gold  \\\n",
       "0        florence      1           0         0     0           1   \n",
       "1        florence      1           0         1     0           1   \n",
       "2        florence      1           0         1     0           1   \n",
       "3        florence      1           0         1     0           1   \n",
       "4        florence      1           0         1     0           1   \n",
       "\n",
       "   descriptor_gold  compound_gold  list_gold  any_gold  \n",
       "0                0              0          0         1  \n",
       "1                0              0          0         1  \n",
       "2                0              0          0         1  \n",
       "3                0              0          0         1  \n",
       "4                0              0          0         1  "
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclause_anchor_data_combined_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NE_fixed</th>\n",
       "      <th>txt</th>\n",
       "      <th>data_name_fixed</th>\n",
       "      <th>state</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>compound</th>\n",
       "      <th>list</th>\n",
       "      <th>state_gold</th>\n",
       "      <th>descriptor_gold</th>\n",
       "      <th>compound_gold</th>\n",
       "      <th>list_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lumberton</td>\n",
       "      <td>Leaving Lumberton... Trailers found a low wate...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Bern</td>\n",
       "      <td>The scene at the waterfront park in New Bern, ...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aurora</td>\n",
       "      <td>Update from Capt. Stephan Wildish who is servi...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wilmington</td>\n",
       "      <td>RT @WFLALeigh: WOW! The potential rainfall tot...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greensboro</td>\n",
       "      <td>My version of the #Poblanos Chicken Soup! #hom...</td>\n",
       "      <td>florence</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NE_fixed                                                txt  \\\n",
       "0   Lumberton  Leaving Lumberton... Trailers found a low wate...   \n",
       "1    New Bern  The scene at the waterfront park in New Bern, ...   \n",
       "2      Aurora  Update from Capt. Stephan Wildish who is servi...   \n",
       "3  Wilmington  RT @WFLALeigh: WOW! The potential rainfall tot...   \n",
       "4  Greensboro  My version of the #Poblanos Chicken Soup! #hom...   \n",
       "\n",
       "  data_name_fixed  state  descriptor  compound  list  state_gold  \\\n",
       "0        florence      1           0         0     0           1   \n",
       "1        florence      1           0         1     0           1   \n",
       "2        florence      1           0         1     0           1   \n",
       "3        florence      1           0         1     0           1   \n",
       "4        florence      1           0         1     0           1   \n",
       "\n",
       "   descriptor_gold  compound_gold  list_gold  \n",
       "0                0              0          0  \n",
       "1                0              0          0  \n",
       "2                0              0          0  \n",
       "3                0              0          0  \n",
       "4                0              0          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>compound</th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_name_fixed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>florence</th>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harvey</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irma</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maria</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>michael</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    state  descriptor  compound      list\n",
       "data_name_fixed                                          \n",
       "florence         0.965517    0.733333  0.896552  0.666667\n",
       "harvey           0.947368    0.550000  0.944444  0.550000\n",
       "irma             0.942857    0.666667  0.968750  0.650000\n",
       "maria            1.000000    0.722222  1.000000  0.466667\n",
       "michael          0.958333    0.916667  1.000000  0.916667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "state         0.962733\n",
       "descriptor    0.697674\n",
       "compound      0.958621\n",
       "list          0.634146\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_precision_for_subclause_types(data, subclause_types, gold_col='any_gold'):\n",
    "    prec_by_type = []\n",
    "#     data_gold = data[data.loc[:, gold_col]==1.]\n",
    "    for x in subclause_types:\n",
    "        diff_x = data.loc[:, x] - data.loc[:, gold_col]\n",
    "        prec_x = len(diff_x[diff_x == 0.]) / len(diff_x[diff_x >= 0.])\n",
    "        prec_by_type.append(prec_x)\n",
    "    prec_by_type = pd.Series(prec_by_type, index=subclause_types)\n",
    "    return prec_by_type\n",
    "subclause_anchor_data_combined_samples = pd.read_csv(sample_out_file, sep='\\t', index_col=False)\n",
    "display(subclause_anchor_data_combined_samples.head())\n",
    "# compute any_gold\n",
    "gold_col = 'any_gold'\n",
    "if(gold_col not in subclause_anchor_data_combined_samples.columns):\n",
    "    subclause_anchor_data_combined_samples = subclause_anchor_data_combined_samples.assign(**{'any_gold' : subclause_anchor_data_combined_samples.loc[:, ['%s_gold'%(x) for x in subclause_types]].max(axis=1)})\n",
    "# per-group\n",
    "group_var = 'data_name_fixed'\n",
    "group_sample_prec = subclause_anchor_data_combined_samples.groupby(group_var).apply(lambda x: compute_precision_for_subclause_types(x, subclause_types))\n",
    "display(group_sample_prec)\n",
    "# overall\n",
    "data_sample_prec = compute_precision_for_subclause_types(subclause_anchor_data_combined_samples, subclause_types)\n",
    "display(data_sample_prec)\n",
    "## we want: data_name | anchor_type | precision\n",
    "## overall | anchor_type | precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn to classify information status\n",
    "Let's get gold labels from LOC, DESCRIPTOR pairs and train a classifier using ELMO embeddings to predict descriptor, then apply that to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6bd0be9cd828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_helpers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_helpers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_elmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0melmo_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_elmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__spec__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkgpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;31m# The module may have replaced itself in sys.modules!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_exec\u001b[0;34m(spec, module)\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/crisis_language/scripts/models/model_helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mranking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch_to_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mElmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# from mpl_toolkits.basemap import Basemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/site-packages/allennlp/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditional_random_field\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConditionalRandomField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedforward\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeedForward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/site-packages/allennlp/modules/conditional_random_field.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/site-packages/allennlp/common/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistrable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegistrable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtee_logger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTeeLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJsonDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/site-packages/allennlp/common/params.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/site-packages/allennlp/common/checks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cuda'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if('..' not in sys.path):\n",
    "    sys.path.append('..')\n",
    "from importlib import reload\n",
    "import models.model_helpers\n",
    "reload(models.model_helpers)\n",
    "from models.model_helpers import load_elmo\n",
    "elmo_model = load_elmo()\n",
    "# dir(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
