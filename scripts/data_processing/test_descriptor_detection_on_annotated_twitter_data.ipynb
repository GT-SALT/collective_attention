{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test anchor detection on annotated data\n",
    "We've annotated a set of tweets (generated [here](determine_anchor_role.ipynb#Annotate-anchors), annotated [here](https://docs.google.com/spreadsheets/d/1_1vwu_UgVlSgIZ09pvKkqK-wGBaK1zhb-9k-k7T5dyA/edit?usp=sharing)) with two English speakers. Let's try to detect anchoring using the following strategies:\n",
    "\n",
    "- state descriptor (LOC, STATE)\n",
    "- description phrase (LOC + DESCRIPTOR)\n",
    "\n",
    "We will test the overall precision and recall.\n",
    "\n",
    "We will also test the effect of adding the following two detecetion strategies:\n",
    "\n",
    "- compound descriptor (LOC + NOUN + DESCRIPTOR)\n",
    "- conjunction descriptor (LOC + LOC + DESCRIPTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load importance data for anchors\n",
    "import pickle\n",
    "## add importance vars\n",
    "geonames_data = pickle.load(open('/hg190/corpora/GeoNames/allCountriesSimplified_lookup_US.pickle', 'rb'))\n",
    "geonames_max_pop = {k : v.loc[:, 'population'].max() for k,v in geonames_data.items()}\n",
    "geonames_max_alt_names = {k : v.loc[:, 'alternate_name_count'].max() for k,v in geonames_data.items()}\n",
    "# test\n",
    "print(geonames_max_pop['san juan'])\n",
    "print(geonames_max_alt_names['san juan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_name</th>\n",
       "      <th>NE</th>\n",
       "      <th>txt</th>\n",
       "      <th>state_gold_1</th>\n",
       "      <th>descriptor_gold_1</th>\n",
       "      <th>state_gold_2</th>\n",
       "      <th>descriptor_gold_2</th>\n",
       "      <th>state_gold_agreement</th>\n",
       "      <th>descriptor_gold_agreement</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>florence</td>\n",
       "      <td>mayfair</td>\n",
       "      <td>Homes in the Mayfair neighborhood of Lumberton...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1041724904327061504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harvey</td>\n",
       "      <td>yale</td>\n",
       "      <td>VIDEO: I-10 at Yale, The Heights, Houston (res...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>901931817862758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>florence</td>\n",
       "      <td>new_bern</td>\n",
       "      <td>RT @EdValleeWx: Our models specifically used f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1039450960312102912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>florence</td>\n",
       "      <td>wilmington</td>\n",
       "      <td>RT @WMO: Hurricane #Florence is likely to make...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1039621551052791808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>florence</td>\n",
       "      <td>cape_fear</td>\n",
       "      <td>RT @ABC: LATEST: Hurricane #Florence a Categor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1039714656217128960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_name          NE                                                txt  \\\n",
       "0  florence     mayfair  Homes in the Mayfair neighborhood of Lumberton...   \n",
       "1    harvey        yale  VIDEO: I-10 at Yale, The Heights, Houston (res...   \n",
       "2  florence    new_bern  RT @EdValleeWx: Our models specifically used f...   \n",
       "3  florence  wilmington  RT @WMO: Hurricane #Florence is likely to make...   \n",
       "4  florence   cape_fear  RT @ABC: LATEST: Hurricane #Florence a Categor...   \n",
       "\n",
       "   state_gold_1  descriptor_gold_1  state_gold_2  descriptor_gold_2  \\\n",
       "0             0                  1             0                  1   \n",
       "1             0                  1             0                  1   \n",
       "2             1                  0             1                  0   \n",
       "3             1                  0             1                  0   \n",
       "4             1                  0             1                  0   \n",
       "\n",
       "   state_gold_agreement  descriptor_gold_agreement                   id  \n",
       "0                     1                          1  1041724904327061504  \n",
       "1                     1                          1   901931817862758400  \n",
       "2                     1                          1  1039450960312102912  \n",
       "3                     1                          1  1039621551052791808  \n",
       "4                     1                          1  1039714656217128960  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/226 agreement\n",
      "state_gold_agreement         218\n",
      "descriptor_gold_agreement    206\n",
      "dtype: int64\n",
      "199/226 agree\n"
     ]
    }
   ],
   "source": [
    "## TODO: fix NEs in annotations => capital and spaced to fit parse matching...UGH!!\n",
    "# load data\n",
    "annotated_data = pd.read_csv('../../data/mined_tweets/NE_twitter_anchor_sample_annotated.tsv', sep='\\t', index_col=False)\n",
    "display(annotated_data.head())\n",
    "agree_cols = ['state_gold_agreement', 'descriptor_gold_agreement']\n",
    "annotated_data = annotated_data.assign(**{'all_gold_agreement' : annotated_data.loc[:, agree_cols].min(axis=1)})\n",
    "print('%d/%d agreement'%(annotated_data.loc[:, 'all_gold_agreement'].sum(), annotated_data.shape[0]))\n",
    "print(annotated_data.loc[:, ['state_gold_agreement', 'descriptor_gold_agreement']].sum(axis=0))\n",
    "annotated_data_agree = annotated_data[annotated_data.loc[:, 'all_gold_agreement']==1]\n",
    "print('%d/%d agree'%(annotated_data_agree.shape[0], annotated_data.shape[0]))\n",
    "# add gold markers\n",
    "annotated_data_agree = annotated_data_agree.assign(**{\n",
    "    'state_gold' : annotated_data_agree.loc[:, ['state_gold_1', 'state_gold_2']].min(axis=1),\n",
    "    'descriptor_gold' : annotated_data_agree.loc[:, ['descriptor_gold_1', 'descriptor_gold_2']].min(axis=1),  \n",
    "})\n",
    "\n",
    "annotated_data_agree = annotated_data_agree.assign(**{\n",
    "    'all_gold' : annotated_data_agree.loc[:, gold_cols].max(axis=1)\n",
    "})\n",
    "# need valid loc marker for later\n",
    "annotated_data_agree = annotated_data_agree.assign(**{'valid_loc':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load text data because we need complete list of valid NEs for each status!! Ugh!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>txt</th>\n",
       "      <th>data_name</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>NE</th>\n",
       "      <th>NE_type</th>\n",
       "      <th>NE_LOC</th>\n",
       "      <th>valid_loc</th>\n",
       "      <th>NE_fixed</th>\n",
       "      <th>has_descriptor</th>\n",
       "      <th>NE_fixed_clean</th>\n",
       "      <th>max_population</th>\n",
       "      <th>max_alternate_name_count</th>\n",
       "      <th>max_population_anchor</th>\n",
       "      <th>max_population_diff</th>\n",
       "      <th>max_alternate_name_count_anchor</th>\n",
       "      <th>max_alternate_name_count_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>899098735367647232</td>\n",
       "      <td>Tropical Depression #Harvey is 1543 miles SSE ...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...</td>\n",
       "      <td>2017-08-19 22:40:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>raleigh</td>\n",
       "      <td>False</td>\n",
       "      <td>raleigh</td>\n",
       "      <td>451066.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>899258634223353856</td>\n",
       "      <td>#Harvey , #Illinois #firefighters ' #pension o...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...</td>\n",
       "      <td>2017-08-20 09:15:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>chicago</td>\n",
       "      <td>False</td>\n",
       "      <td>chicago</td>\n",
       "      <td>2720546.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>899272853954101249</td>\n",
       "      <td>Harvey's. 2380 Wyandotte Street West, Windsor,...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...</td>\n",
       "      <td>2017-08-20 10:12:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Windsor</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>windsor</td>\n",
       "      <td>False</td>\n",
       "      <td>windsor</td>\n",
       "      <td>28778.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>899425632215588864</td>\n",
       "      <td>NHC_Atlantic: #Harvey 's remnants are likely t...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...</td>\n",
       "      <td>2017-08-20 20:19:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Bay</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>bay</td>\n",
       "      <td>False</td>\n",
       "      <td>bay</td>\n",
       "      <td>15402.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>899443698693529601</td>\n",
       "      <td>@NHC_Atlantic #Harvey 's remnants are likely t...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>#Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...</td>\n",
       "      <td>2017-08-20 21:31:00</td>\n",
       "      <td>en</td>\n",
       "      <td>Bay</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>bay</td>\n",
       "      <td>False</td>\n",
       "      <td>bay</td>\n",
       "      <td>15402.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                                txt  \\\n",
       "17  899098735367647232  Tropical Depression #Harvey is 1543 miles SSE ...   \n",
       "31  899258634223353856  #Harvey , #Illinois #firefighters ' #pension o...   \n",
       "33  899272853954101249  Harvey's. 2380 Wyandotte Street West, Windsor,...   \n",
       "49  899425632215588864  NHC_Atlantic: #Harvey 's remnants are likely t...   \n",
       "55  899443698693529601  @NHC_Atlantic #Harvey 's remnants are likely t...   \n",
       "\n",
       "   data_name                                           username  \\\n",
       "17    harvey  #Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...   \n",
       "31    harvey  #Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...   \n",
       "33    harvey  #Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...   \n",
       "49    harvey  #Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...   \n",
       "55    harvey  #Irma,#HurricaneIrma,#Harvey,#HurricaneHarvey_...   \n",
       "\n",
       "                   date lang       NE   NE_type  NE_LOC  valid_loc NE_fixed  \\\n",
       "17  2017-08-19 22:40:00   en  Raleigh  LOCATION    True       True  raleigh   \n",
       "31  2017-08-20 09:15:00   en  Chicago  LOCATION    True       True  chicago   \n",
       "33  2017-08-20 10:12:00   en  Windsor  LOCATION    True       True  windsor   \n",
       "49  2017-08-20 20:19:00   en      Bay  LOCATION    True       True      bay   \n",
       "55  2017-08-20 21:31:00   en      Bay  LOCATION    True       True      bay   \n",
       "\n",
       "    has_descriptor NE_fixed_clean  max_population  max_alternate_name_count  \\\n",
       "17           False        raleigh        451066.0                      43.0   \n",
       "31           False        chicago       2720546.0                      70.0   \n",
       "33           False        windsor         28778.0                      16.0   \n",
       "49           False            bay         15402.0                      15.0   \n",
       "55           False            bay         15402.0                      15.0   \n",
       "\n",
       "    max_population_anchor  max_population_diff  \\\n",
       "17                  False                  0.0   \n",
       "31                  False                  0.0   \n",
       "33                  False                  0.0   \n",
       "49                  False                  0.0   \n",
       "55                  False                  0.0   \n",
       "\n",
       "    max_alternate_name_count_anchor  max_alternate_name_count_diff  \n",
       "17                            False                            0.0  \n",
       "31                            False                            0.0  \n",
       "33                            False                            0.0  \n",
       "49                            False                            0.0  \n",
       "55                            False                            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from ast import literal_eval\n",
    "txt_data = pd.read_csv('../../data/mined_tweets/combined_tweet_tag_data_NE_flat.gz', sep='\\t', index_col=False, compression='gzip')\n",
    "# remove NAN NEs\n",
    "txt_data = txt_data[~txt_data.loc[:, 'NE'].apply(lambda x: np.isnan(x) if type(x) is float else False)]\n",
    "# keep valid NEs\n",
    "txt_data = txt_data[txt_data.loc[:, 'valid_loc']==1]\n",
    "txt_data.rename(columns={'data_name_fixed':'data_name'}, inplace=True)\n",
    "# parsed_data = pd.read_csv('../../data/mined_tweets/combined_tweet_NE_flat_data_parsed.gz', sep='\\t', index_col=False, compression='gzip', converters={'parse' : lambda x: literal_eval(x), 'id' : np.int64})\n",
    "# # combine parse data!! one row per id\n",
    "# parsed_data = pd.concat([pd.Series([i, list(x.loc[:, 'parse'].values)], index=['id', 'parse']) for i,x in parsed_data.groupby('id')], axis=1).transpose()\n",
    "display(txt_data.head())\n",
    "# display(parsed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hg190/istewart6/miniconda3/envs/crisis_language/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_name</th>\n",
       "      <th>NE</th>\n",
       "      <th>txt</th>\n",
       "      <th>state_gold_1</th>\n",
       "      <th>descriptor_gold_1</th>\n",
       "      <th>state_gold_2</th>\n",
       "      <th>descriptor_gold_2</th>\n",
       "      <th>state_gold_agreement</th>\n",
       "      <th>descriptor_gold_agreement</th>\n",
       "      <th>id</th>\n",
       "      <th>all_gold_agreement</th>\n",
       "      <th>state_gold</th>\n",
       "      <th>descriptor_gold</th>\n",
       "      <th>all_gold</th>\n",
       "      <th>valid_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>harvey</td>\n",
       "      <td>corpus_christi</td>\n",
       "      <td>The first Hurricane Watches for this part of #...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900454330544926720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>harvey</td>\n",
       "      <td>houston</td>\n",
       "      <td>The first Hurricane Watches for this part of #...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900454330544926720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>harvey</td>\n",
       "      <td>rockport</td>\n",
       "      <td>As of 10 a.m., the modeling has #Harvey making...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900765014142976000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>harvey</td>\n",
       "      <td>corpus_christi</td>\n",
       "      <td>As of 10 a.m., the modeling has #Harvey making...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900765014142976000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>harvey</td>\n",
       "      <td>brownsville</td>\n",
       "      <td>The eye of #HurricaneHarvey is now showing on ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900894782763012096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data_name              NE  \\\n",
       "49      harvey  corpus_christi   \n",
       "1542    harvey         houston   \n",
       "50      harvey        rockport   \n",
       "4309    harvey  corpus_christi   \n",
       "51      harvey     brownsville   \n",
       "\n",
       "                                                    txt  state_gold_1  \\\n",
       "49    The first Hurricane Watches for this part of #...           0.0   \n",
       "1542  The first Hurricane Watches for this part of #...           0.0   \n",
       "50    As of 10 a.m., the modeling has #Harvey making...           0.0   \n",
       "4309  As of 10 a.m., the modeling has #Harvey making...           0.0   \n",
       "51    The eye of #HurricaneHarvey is now showing on ...           1.0   \n",
       "\n",
       "      descriptor_gold_1  state_gold_2  descriptor_gold_2  \\\n",
       "49                  0.0           0.0                0.0   \n",
       "1542                0.0           0.0                0.0   \n",
       "50                  0.0           0.0                0.0   \n",
       "4309                0.0           0.0                0.0   \n",
       "51                  0.0           1.0                0.0   \n",
       "\n",
       "      state_gold_agreement  descriptor_gold_agreement                  id  \\\n",
       "49                     1.0                        1.0  900454330544926720   \n",
       "1542                   0.0                        0.0  900454330544926720   \n",
       "50                     1.0                        1.0  900765014142976000   \n",
       "4309                   0.0                        0.0  900765014142976000   \n",
       "51                     1.0                        1.0  900894782763012096   \n",
       "\n",
       "      all_gold_agreement  state_gold  descriptor_gold  all_gold  valid_loc  \n",
       "49                   1.0         0.0              0.0       0.0          1  \n",
       "1542                 0.0         0.0              0.0       0.0          1  \n",
       "50                   1.0         0.0              0.0       0.0          1  \n",
       "4309                 0.0         0.0              0.0       0.0          1  \n",
       "51                   1.0         1.0              0.0       1.0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt_data_relevant = txt_data[txt_data.loc[:, 'id'].isin(annotated_data.loc[:, 'id'].unique())]\n",
    "annotated_data_full = []\n",
    "# iteratively build full data to avoid copying\n",
    "# annotated NEs from txt data\n",
    "for id_i, data_i in annotated_data_agree.groupby('id'):\n",
    "    txt_data_i = txt_data_relevant[txt_data_relevant.loc[:, 'id']==id_i]\n",
    "    txt_data_i = txt_data_i.drop('NE', axis=1, inplace=False).rename(columns={'NE_fixed' : 'NE'}, inplace=False)\n",
    "    txt_data_i = txt_data_i[~txt_data_i.loc[:, 'NE'].isin(data_i.loc[:, 'NE'].values)]\n",
    "    data_i = pd.concat([data_i, txt_data_i], axis=0)\n",
    "    data_i.fillna(0, inplace=True)\n",
    "    data_i = data_i.loc[:, annotated_data_agree.columns]\n",
    "    annotated_data_full.append(data_i)\n",
    "annotated_data_full = pd.concat(annotated_data_full, axis=0)\n",
    "display(annotated_data_full.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse the data ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parse</th>\n",
       "      <th>data_name</th>\n",
       "      <th>NE</th>\n",
       "      <th>txt</th>\n",
       "      <th>state_gold_1</th>\n",
       "      <th>descriptor_gold_1</th>\n",
       "      <th>state_gold_2</th>\n",
       "      <th>descriptor_gold_2</th>\n",
       "      <th>state_gold_agreement</th>\n",
       "      <th>descriptor_gold_agreement</th>\n",
       "      <th>all_gold_agreement</th>\n",
       "      <th>state_gold</th>\n",
       "      <th>descriptor_gold</th>\n",
       "      <th>all_gold</th>\n",
       "      <th>valid_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900454330544926720</td>\n",
       "      <td>[[[The, DET, 3, det, 0], [first, ADJ, 3, amod,...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>corpus_christi</td>\n",
       "      <td>The first Hurricane Watches for this part of #...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900454330544926720</td>\n",
       "      <td>[[[The, DET, 3, det, 0], [first, ADJ, 3, amod,...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>houston</td>\n",
       "      <td>The first Hurricane Watches for this part of #...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900765014142976000</td>\n",
       "      <td>[[[As, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>rockport</td>\n",
       "      <td>As of 10 a.m., the modeling has #Harvey making...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>900765014142976000</td>\n",
       "      <td>[[[As, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>corpus_christi</td>\n",
       "      <td>As of 10 a.m., the modeling has #Harvey making...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900894782763012096</td>\n",
       "      <td>[[[The, DET, 1, det, 0], [eye, NOUN, 6, nsubj,...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>brownsville</td>\n",
       "      <td>The eye of #HurricaneHarvey is now showing on ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              parse  \\\n",
       "0  900454330544926720  [[[The, DET, 3, det, 0], [first, ADJ, 3, amod,...   \n",
       "1  900454330544926720  [[[The, DET, 3, det, 0], [first, ADJ, 3, amod,...   \n",
       "2  900765014142976000  [[[As, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...   \n",
       "3  900765014142976000  [[[As, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...   \n",
       "4  900894782763012096  [[[The, DET, 1, det, 0], [eye, NOUN, 6, nsubj,...   \n",
       "\n",
       "  data_name              NE  \\\n",
       "0    harvey  corpus_christi   \n",
       "1    harvey         houston   \n",
       "2    harvey        rockport   \n",
       "3    harvey  corpus_christi   \n",
       "4    harvey     brownsville   \n",
       "\n",
       "                                                 txt  state_gold_1  \\\n",
       "0  The first Hurricane Watches for this part of #...           0.0   \n",
       "1  The first Hurricane Watches for this part of #...           0.0   \n",
       "2  As of 10 a.m., the modeling has #Harvey making...           0.0   \n",
       "3  As of 10 a.m., the modeling has #Harvey making...           0.0   \n",
       "4  The eye of #HurricaneHarvey is now showing on ...           1.0   \n",
       "\n",
       "   descriptor_gold_1  state_gold_2  descriptor_gold_2  state_gold_agreement  \\\n",
       "0                0.0           0.0                0.0                   1.0   \n",
       "1                0.0           0.0                0.0                   0.0   \n",
       "2                0.0           0.0                0.0                   1.0   \n",
       "3                0.0           0.0                0.0                   0.0   \n",
       "4                0.0           1.0                0.0                   1.0   \n",
       "\n",
       "   descriptor_gold_agreement  all_gold_agreement  state_gold  descriptor_gold  \\\n",
       "0                        1.0                 1.0         0.0              0.0   \n",
       "1                        0.0                 0.0         0.0              0.0   \n",
       "2                        1.0                 1.0         0.0              0.0   \n",
       "3                        0.0                 0.0         0.0              0.0   \n",
       "4                        1.0                 1.0         1.0              0.0   \n",
       "\n",
       "   all_gold  valid_loc  \n",
       "0       0.0          1  \n",
       "1       0.0          1  \n",
       "2       0.0          1  \n",
       "3       0.0          1  \n",
       "4       1.0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import parse_twitter_data\n",
    "reload(parse_twitter_data)\n",
    "from parse_twitter_data import parse_data\n",
    "annotated_data_parsed = parse_data(annotated_data_full.drop_duplicates('id').loc[:, ['id', 'txt']])\n",
    "annotated_data_parsed = pd.DataFrame([[i, list(x.loc[:, 'parse'].values)] for i,x in annotated_data_parsed.groupby('id')])\n",
    "annotated_data_parsed.columns = ['id', 'parse']\n",
    "# combine parses\n",
    "annotated_data_parsed = pd.merge(annotated_data_parsed, annotated_data_full, on='id')\n",
    "display(annotated_data_parsed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data_parsed = annotated_data_parsed.drop('NE', axis=1, inplace=False).assign(**{\n",
    "    'NE' : annotated_data_parsed.loc[:, 'NE'].apply(lambda x: x.replace('_', ' '))\n",
    "})\n",
    "annotated_data_parsed = annotated_data_parsed.assign(**{\n",
    "    'max_population' : annotated_data_parsed.loc[:, 'NE'].apply(lambda x: geonames_max_pop[x] if x in geonames_max_pop else 0.),\n",
    "    'max_alternate_names' : annotated_data_parsed.loc[:, 'NE'].apply(lambda x: geonames_max_alt_names[x] if x in geonames_max_alt_names else 0.),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "if('parse_clean' not in annotated_data_parsed.columns):\n",
    "    annotated_data_parsed = annotated_data_parsed.assign(**{\n",
    "        'parse_clean' : annotated_data_parsed.loc[:, 'parse'].apply(lambda x: [[[z[0].lower(), z[1], z[2], z[3], z[4]] for z in y] for y in x])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parse</th>\n",
       "      <th>data_name</th>\n",
       "      <th>txt</th>\n",
       "      <th>state_gold_1</th>\n",
       "      <th>descriptor_gold_1</th>\n",
       "      <th>state_gold_2</th>\n",
       "      <th>descriptor_gold_2</th>\n",
       "      <th>state_gold_agreement</th>\n",
       "      <th>descriptor_gold_agreement</th>\n",
       "      <th>all_gold_agreement</th>\n",
       "      <th>state_gold</th>\n",
       "      <th>descriptor_gold</th>\n",
       "      <th>all_gold</th>\n",
       "      <th>valid_loc</th>\n",
       "      <th>max_population</th>\n",
       "      <th>max_alternate_names</th>\n",
       "      <th>parse_clean</th>\n",
       "      <th>NE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900454330544926720</td>\n",
       "      <td>[[[The, DET, 3, det, 0], [first, ADJ, 3, amod,...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>The first Hurricane Watches for this part of #...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>324074</td>\n",
       "      <td>31</td>\n",
       "      <td>[[[the, DET, 3, det, 0], [first, ADJ, 3, amod,...</td>\n",
       "      <td>corpus christi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900454330544926720</td>\n",
       "      <td>[[[The, DET, 3, det, 0], [first, ADJ, 3, amod,...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>The first Hurricane Watches for this part of #...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2296224</td>\n",
       "      <td>60</td>\n",
       "      <td>[[[the, DET, 3, det, 0], [first, ADJ, 3, amod,...</td>\n",
       "      <td>houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900765014142976000</td>\n",
       "      <td>[[[As, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>As of 10 a.m., the modeling has #Harvey making...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10490</td>\n",
       "      <td>10</td>\n",
       "      <td>[[[as, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...</td>\n",
       "      <td>rockport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>900765014142976000</td>\n",
       "      <td>[[[As, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>As of 10 a.m., the modeling has #Harvey making...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>324074</td>\n",
       "      <td>31</td>\n",
       "      <td>[[[as, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...</td>\n",
       "      <td>corpus christi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900894782763012096</td>\n",
       "      <td>[[[The, DET, 1, det, 0], [eye, NOUN, 6, nsubj,...</td>\n",
       "      <td>harvey</td>\n",
       "      <td>The eye of #HurricaneHarvey is now showing on ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>183887</td>\n",
       "      <td>24</td>\n",
       "      <td>[[[the, DET, 1, det, 0], [eye, NOUN, 6, nsubj,...</td>\n",
       "      <td>brownsville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              parse  \\\n",
       "0  900454330544926720  [[[The, DET, 3, det, 0], [first, ADJ, 3, amod,...   \n",
       "1  900454330544926720  [[[The, DET, 3, det, 0], [first, ADJ, 3, amod,...   \n",
       "2  900765014142976000  [[[As, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...   \n",
       "3  900765014142976000  [[[As, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...   \n",
       "4  900894782763012096  [[[The, DET, 1, det, 0], [eye, NOUN, 6, nsubj,...   \n",
       "\n",
       "  data_name                                                txt  state_gold_1  \\\n",
       "0    harvey  The first Hurricane Watches for this part of #...           0.0   \n",
       "1    harvey  The first Hurricane Watches for this part of #...           0.0   \n",
       "2    harvey  As of 10 a.m., the modeling has #Harvey making...           0.0   \n",
       "3    harvey  As of 10 a.m., the modeling has #Harvey making...           0.0   \n",
       "4    harvey  The eye of #HurricaneHarvey is now showing on ...           1.0   \n",
       "\n",
       "   descriptor_gold_1  state_gold_2  descriptor_gold_2  state_gold_agreement  \\\n",
       "0                0.0           0.0                0.0                   1.0   \n",
       "1                0.0           0.0                0.0                   0.0   \n",
       "2                0.0           0.0                0.0                   1.0   \n",
       "3                0.0           0.0                0.0                   0.0   \n",
       "4                0.0           1.0                0.0                   1.0   \n",
       "\n",
       "   descriptor_gold_agreement  all_gold_agreement  state_gold  descriptor_gold  \\\n",
       "0                        1.0                 1.0         0.0              0.0   \n",
       "1                        0.0                 0.0         0.0              0.0   \n",
       "2                        1.0                 1.0         0.0              0.0   \n",
       "3                        0.0                 0.0         0.0              0.0   \n",
       "4                        1.0                 1.0         1.0              0.0   \n",
       "\n",
       "   all_gold  valid_loc  max_population  max_alternate_names  \\\n",
       "0       0.0          1          324074                   31   \n",
       "1       0.0          1         2296224                   60   \n",
       "2       0.0          1           10490                   10   \n",
       "3       0.0          1          324074                   31   \n",
       "4       1.0          1          183887                   24   \n",
       "\n",
       "                                         parse_clean              NE  \n",
       "0  [[[the, DET, 3, det, 0], [first, ADJ, 3, amod,...  corpus christi  \n",
       "1  [[[the, DET, 3, det, 0], [first, ADJ, 3, amod,...         houston  \n",
       "2  [[[as, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...        rockport  \n",
       "3  [[[as, ADP, 0, ROOT, 0], [of, ADP, 0, prep, 1]...  corpus christi  \n",
       "4  [[[the, DET, 1, det, 0], [eye, NOUN, 6, nsubj,...     brownsville  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(annotated_data_parsed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect anchors\n",
    "Now we try to detect anchors using the parse trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import data_helpers\n",
    "reload(data_helpers)\n",
    "from data_helpers import detect_anchor_by_type\n",
    "def detect_anchor_prec_recall(data, anchor_types_to_use=['descriptor', 'state'], gold_var='all_gold', anchor_var='max_population', data_var='data_name'):\n",
    "    \"\"\"\n",
    "    Compute precision and recall for anchor detection.\n",
    "    \"\"\"\n",
    "    gold_vals = []\n",
    "    pred_vals = []\n",
    "    all_anchor_types = ['state', 'descriptor',  'compound', 'list']\n",
    "    agree_col = 'all_gold_agreement'\n",
    "    NE_col = 'NE'\n",
    "    parse_col = 'parse_clean'\n",
    "    anchor_col = 'anchor'\n",
    "    all_pred_data = []\n",
    "    for id_i, data_i in data.groupby('id'):\n",
    "        anchor_state, anchor_descriptor, anchor_compound, anchor_list = detect_anchor_by_type(data_i, parse_var=parse_col, anchor_var=anchor_var, data_name_var=data_var, verbose=True)\n",
    "        pred_i = pd.concat([anchor_state, anchor_descriptor, anchor_compound, anchor_list], axis=1)\n",
    "        pred_i.columns = all_anchor_types\n",
    "        # restrict to annotated NEs\n",
    "        data_i_annotated = data_i[data_i.loc[:, agree_col]==1]\n",
    "        NE_i_annotated = data_i_annotated.loc[:, NE_col]\n",
    "#         print(pred_i)\n",
    "        pred_i = pred_i.loc[NE_i_annotated, :]\n",
    "#         if(any(pred_i.loc[:, ['compound', 'list']].max(axis=1).values)):\n",
    "#             print('compound/list detected\\n%s'%(pred_i))\n",
    "#         print('pred = \\n%s'%(pred_i))\n",
    "        pred_i = pred_i.loc[:, anchor_types_to_use].max(axis=1)\n",
    "        pred_i_data = pd.DataFrame(pred_i.copy(), columns=[anchor_col])\n",
    "        pred_vals += list(pred_i_data.loc[:, anchor_col].values)\n",
    "        gold_vals += list(data_i_annotated.loc[:, gold_var].values)\n",
    "#         print('pred data =\\n%s'%(pred_i_data))\n",
    "#         print('idx = %d'%(len(pred_i_data.index)))\n",
    "        # save rest of data for debugging\n",
    "        N = pred_i_data.shape[0]\n",
    "        pred_i_data = pred_i_data.assign(**{\n",
    "            'NE' : pred_i_data.index,\n",
    "            'txt' : [data_i.loc[:, 'txt'].iloc[0],]*N,\n",
    "            'parse' : [data_i.loc[:, 'parse'].iloc[0],]*N,\n",
    "            'id' : [id_i,]*N,\n",
    "        })\n",
    "        all_pred_data.append(pred_i_data)\n",
    "    gold_vals = np.array(gold_vals)\n",
    "    pred_vals = np.array(pred_vals)\n",
    "    gold_anchor_idx = np.where(gold_vals == 1)[0]\n",
    "    prec = pred_vals[gold_anchor_idx].sum() / (pred_vals.sum())\n",
    "    rec = pred_vals[gold_anchor_idx].sum() / len(gold_anchor_idx)\n",
    "    all_pred_data = pd.concat(all_pred_data, axis=0)\n",
    "#     print('TP = %d'%(pred_vals[gold_anchor_idx].sum()))\n",
    "#     print('gold idx = %d'%(len(gold_anchor_idx)))\n",
    "    # find false negatives => improve recall!\n",
    "    FN_idx = np.where((gold_vals == 1) & (pred_vals == 0))[0]\n",
    "    print('%d/%d FN'%(len(FN_idx), len(gold_vals)))\n",
    "    display(all_pred_data.iloc[FN_idx, :].head(10).loc[:, ['NE', 'txt', 'parse']].values)\n",
    "    return prec, rec, all_pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['the', 'DET', 3, 'det', 0], ['first', 'ADJ', 3, 'amod', 1], ['hurricane', 'PROPN', 3, 'compound', 2], ['watches', 'PROPN', 3, 'ROOT', 3], ['for', 'ADP', 3, 'prep', 4], ['this', 'DET', 6, 'det', 5], ['part', 'NOUN', 4, 'pobj', 6], ['of', 'ADP', 6, 'prep', 7], ['#texas', 'NOUN', 7, 'pobj', 8], ['in', 'ADP', 3, 'prep', 9], ['3', 'NUM', 11, 'compound', 10], ['267', 'NUM', 12, 'nummod', 11], ['days', 'NOUN', 9, 'pobj', 12], ['(', 'PUNCT', 3, 'punct', 13], ['9yrs', 'NUM', 3, 'appos', 14], ['!', 'PUNCT', 3, 'punct', 15], [')', 'PUNCT', 3, 'punct', 16]], [['like', 'ADP', 0, 'ROOT', 0], ['houston', 'PROPN', 0, 'pobj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['corpus', 'PROPN', 5, 'compound', 3], ['christi', 'PROPN', 5, 'compound', 4], ['#txwx', 'PROPN', 1, 'conj', 5], ['#harvey', 'PROPN', 10, 'nmod', 6], ['h', 'NOUN', 10, 'intj', 7], ['/', 'SYM', 9, 'punct', 8], ['t', 'NOUN', 10, 'compound', 9], ['@kathrynprociv', 'PROPN', 10, 'ROOT', 10]]]\n",
      "candidate 0=corpus christi\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['corpus', 'PROPN', 5, 'compound', 3], ['christi', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['christi', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['#txwx', 'PROPN', 1, 'conj', 5]\n",
      "parent node subtree [['corpus', 'PROPN', 5, 'compound', 3], ['christi', 'PROPN', 5, 'compound', 4], ['#txwx', 'PROPN', 1, 'conj', 5]]\n",
      "parent node subtree str \"corpus christi #txwx\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['as', 'ADP', 0, 'ROOT', 0], ['of', 'ADP', 0, 'prep', 1], ['10', 'NUM', 1, 'pobj', 2], ['a', 'DET', 2, 'det', 3], ['.', 'PUNCT', 5, 'punct', 4], ['m', 'NOUN', 0, 'pobj', 5], ['.', 'PUNCT', 0, 'punct', 6], ['the', 'DET', 8, 'det', 7], ['modeling', 'NOUN', 9, 'nsubj', 8], ['has', 'VERB', 9, 'ROOT', 9], ['#harvey', 'PROPN', 9, 'dobj', 10], ['making', 'VERB', 10, 'acl', 11], ['landfall', 'NOUN', 11, 'dobj', 12], ['north', 'ADV', 11, 'advmod', 13], ['of', 'ADP', 13, 'prep', 14], ['rockport', 'PROPN', 14, 'pobj', 15], ['which', 'ADJ', 18, 'nsubj', 16], ['would', 'VERB', 18, 'aux', 17], ['spare', 'VERB', 12, 'relcl', 18], ['corpus', 'PROPN', 20, 'compound', 19], ['christi', 'PROPN', 18, 'dobj', 20], ['the', 'DET', 22, 'det', 21], ['worst', 'ADJ', 18, 'dobj', 22], ['of', 'ADP', 22, 'prep', 23], ['the', 'DET', 25, 'det', 24], ['storm', 'NOUN', 23, 'pobj', 25], ['.', 'PUNCT', 9, 'punct', 26]]]\n",
      "candidate 0=rockport\n",
      "anchor NE candidates = corpus christi\n",
      "data NE tree=[['rockport', 'PROPN', 14, 'pobj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['rockport', 'PROPN', 14, 'pobj', 15]\n",
      "NE parent token:\n",
      "['of', 'ADP', 13, 'prep', 14]\n",
      "candidate 1=corpus christi\n",
      "anchor NE candidates = \n",
      "full parse [[['the', 'DET', 1, 'det', 0], ['eye', 'NOUN', 6, 'nsubj', 1], ['of', 'ADP', 1, 'prep', 2], ['#hurricaneharvey', 'PROPN', 2, 'pobj', 3], ['is', 'VERB', 6, 'aux', 4], ['now', 'ADV', 6, 'advmod', 5], ['showing', 'VERB', 6, 'ROOT', 6], ['on', 'ADP', 6, 'prep', 7], ['the', 'DET', 13, 'det', 8], ['brownsville', 'PROPN', 10, 'nmod', 9], ['texas', 'PROPN', 13, 'nmod', 10], ['long', 'ADJ', 12, 'amod', 11], ['range', 'NOUN', 13, 'compound', 12], ['radar', 'NOUN', 7, 'pobj', 13], ['.', 'PUNCT', 6, 'punct', 14]]]\n",
      "candidate 0=brownsville\n",
      "anchor NE candidates = \n",
      "full parse [[['praying', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['texas', 'PROPN', 1, 'pobj', 2], ['esp', 'VERB', 0, 'advmod', 3], ['my', 'ADJ', 6, 'poss', 4], ['other', 'ADJ', 6, 'amod', 5], ['home', 'NOUN', 0, 'npadvmod', 6], ['corpus', 'PROPN', 8, 'compound', 7], ['christi', 'PROPN', 6, 'appos', 8], ['.', 'PUNCT', 0, 'punct', 9]], [['#hurricaneharvey', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=corpus christi\n",
      "anchor NE candidates = \n",
      "full parse [[['heavy', 'ADJ', 1, 'amod', 0], ['squall', 'NOUN', 2, 'nsubj', 1], ['headed', 'VERB', 2, 'ROOT', 2], ['toward', 'ADP', 2, 'prep', 3], ['matagorda', 'PROPN', 8, 'nmod', 4], ['and', 'CCONJ', 4, 'cc', 5], ['brazoria', 'PROPN', 7, 'compound', 6], ['county', 'PROPN', 4, 'conj', 7], ['coasts', 'NOUN', 3, 'pobj', 8], ['.', 'PUNCT', 2, 'punct', 9]], [['watch', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['waterspouts', 'NOUN', 1, 'pobj', 2], ['.', 'PUNCT', 0, 'punct', 3]], [['#txwx', 'PROPN', 1, 'compound', 0], ['#harvey', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=matagorda\n",
      "anchor NE candidates = brazoria county\n",
      "data NE tree=[['matagorda', 'PROPN', 8, 'nmod', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['matagorda', 'PROPN', 8, 'nmod', 4]\n",
      "NE parent token:\n",
      "['coasts', 'NOUN', 3, 'pobj', 8]\n",
      "parent node subtree [['matagorda', 'PROPN', 8, 'nmod', 4], ['and', 'CCONJ', 4, 'cc', 5], ['brazoria', 'PROPN', 7, 'compound', 6], ['county', 'PROPN', 4, 'conj', 7], ['coasts', 'NOUN', 3, 'pobj', 8]]\n",
      "parent node subtree str \"matagorda and brazoria county coasts\"\n",
      "NE=matagorda subtree=[['and', 'CCONJ', 4, 'cc', 5], ['brazoria', 'PROPN', 7, 'compound', 6], ['county', 'PROPN', 4, 'conj', 7]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=brazoria county\n",
      "anchor NE candidates = \n",
      "full parse [[['#live', 'ADJ', 0, 'ROOT', 0], ['.', 'PUNCT', 0, 'punct', 1]], [['@mikebettes', 'NOUN', 0, 'ROOT', 0], ['on', 'ADP', 0, 'prep', 1], ['#periscope', 'PROPN', 1, 'pobj', 2], [':', 'PUNCT', 0, 'punct', 3], ['streaming', 'VERB', 5, 'compound', 4], ['cam', 'NOUN', 5, 'ROOT', 5], ['from', 'ADP', 5, 'prep', 6], ['galveston', 'PROPN', 8, 'compound', 7], ['texas', 'PROPN', 6, 'pobj', 8], ['as', 'ADP', 12, 'mark', 9], ['hurricane', 'PROPN', 11, 'compound', 10], ['#harvey', 'PROPN', 12, 'nsubj', 11], ['approaches', 'VERB', 5, 'advcl', 12], ['coast', 'NOUN', 12, 'dobj', 13], ['.', 'PUNCT', 5, 'punct', 14]], [['#txwx', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=galveston\n",
      "anchor NE candidates = \n",
      "full parse [[['headed', 'VERB', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['galveston', 'PROPN', 1, 'pobj', 2], ['as', 'ADP', 5, 'mark', 3], ['#harvey', 'PROPN', 5, 'nsubj', 4], ['pushes', 'VERB', 0, 'advcl', 5], ['closer', 'ADV', 5, 'advmod', 6], ['to', 'ADP', 6, 'prep', 7], ['the', 'DET', 10, 'det', 8], ['tx', 'PROPN', 10, 'compound', 9], ['coast', 'NOUN', 7, 'pobj', 10], ['.', 'PUNCT', 0, 'punct', 11]], [['look', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['updates', 'NOUN', 1, 'pobj', 2], ['here', 'ADV', 2, 'advmod', 3], ['&', 'CCONJ', 2, 'cc', 4], ['live', 'VERB', 6, 'amod', 5], ['reports', 'NOUN', 2, 'conj', 6], ['on', 'ADP', 6, 'prep', 7], ['@kprc2', 'PROPN', 7, 'pobj', 8], ['at', 'ADP', 0, 'prep', 9], ['10', 'NUM', 11, 'nummod', 10], ['#hurricaneharvey', 'PROPN', 9, 'pobj', 11], ['#kprc2', 'X', 0, 'dep', 12]]]\n",
      "candidate 0=galveston\n",
      "anchor NE candidates = \n",
      "full parse [[['#harvey', 'VERB', 0, 'ROOT', 0], ['up', 'PART', 0, 'prt', 1], ['to', 'ADP', 0, 'prep', 2], ['cat', 'PROPN', 2, 'pobj', 3], ['4', 'NUM', 3, 'nummod', 4], ['now', 'ADV', 0, 'advmod', 5], ['.', 'PUNCT', 0, 'punct', 6]], [['just', 'ADV', 1, 'advmod', 0], ['hours', 'NOUN', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['landfall', 'NOUN', 2, 'pobj', 3], ['near', 'ADP', 3, 'prep', 4], ['rockport', 'PROPN', 6, 'compound', 5], ['tx', 'PROPN', 4, 'pobj', 6], ['.', 'PUNCT', 1, 'punct', 7]], [['winds', 'NOUN', 1, 'nsubj', 0], ['sustained', 'VERB', 1, 'ROOT', 1], ['at', 'ADP', 1, 'prep', 2], ['130', 'NUM', 4, 'nummod', 3], ['mph', 'NOUN', 2, 'pobj', 4], ['.', 'PUNCT', 1, 'punct', 5]]]\n",
      "candidate 0=rockport\n",
      "anchor NE candidates = \n",
      "full parse [[['@unitedairways', 'NOUN', 0, 'ROOT', 0], ['i', 'PRON', 2, 'nsubj', 1], ['know', 'VERB', 2, 'ROOT', 2], ['you', 'PRON', 5, 'nsubj', 3], ['will', 'VERB', 5, 'aux', 4], ['do', 'VERB', 2, 'ccomp', 5], ['the', 'DET', 8, 'det', 6], ['right', 'ADJ', 8, 'amod', 7], ['thing', 'NOUN', 5, 'dobj', 8], ['and', 'CCONJ', 5, 'cc', 9], ['refund', 'VERB', 5, 'conj', 10], ['my', 'ADJ', 12, 'poss', 11], ['flight', 'NOUN', 10, 'dobj', 12], ['from', 'ADP', 12, 'prep', 13], ['corpus', 'PROPN', 15, 'compound', 14], ['christi', 'PROPN', 13, 'pobj', 15], ['to', 'ADP', 10, 'prep', 16], ['lubbock', 'PROPN', 16, 'pobj', 17], ['.', 'PUNCT', 2, 'punct', 18]], [['#harvey', 'PROPN', 0, 'ROOT', 0], ['.', 'PUNCT', 0, 'punct', 1]], [['thanks', 'NOUN', 0, 'ROOT', 0]]]\n",
      "candidate 0=lubbock\n",
      "anchor NE candidates = corpus christi\n",
      "data NE tree=[['lubbock', 'PROPN', 16, 'pobj', 17]]\n",
      "NE parse token at tree=0, token=18:\n",
      "['lubbock', 'PROPN', 16, 'pobj', 17]\n",
      "NE parent token:\n",
      "['to', 'ADP', 10, 'prep', 16]\n",
      "candidate 1=corpus christi\n",
      "anchor NE candidates = \n",
      "full parse [[['#hurricaneharvey', 'PROPN', 1, 'nsubj', 0], ['makes', 'VERB', 1, 'ROOT', 1], ['landfall', 'NOUN', 1, 'dobj', 2], ['on', 'ADP', 1, 'prep', 3], ['san', 'PROPN', 5, 'compound', 4], ['jose', 'PROPN', 6, 'compound', 5], ['island', 'PROPN', 7, 'compound', 6], ['tx', 'PROPN', 3, 'pobj', 7], ['near', 'ADP', 7, 'prep', 8], ['rockport', 'PROPN', 10, 'compound', 9], ['tx', 'PROPN', 8, 'pobj', 10], ['as', 'ADP', 1, 'prep', 11], ['a', 'DET', 13, 'det', 12], ['cat', 'PROPN', 11, 'pobj', 13], ['.', 'PUNCT', 1, 'punct', 14]], [['4', 'NUM', 1, 'nummod', 0], ['hurricane', 'NOUN', 1, 'ROOT', 1], ['.', 'PUNCT', 1, 'punct', 2]], [['@wccbcharlotte', 'X', 0, 'ROOT', 0]]]\n",
      "candidate 0=san jose island\n",
      "anchor NE candidates = rockport\n",
      "data NE tree=[['san', 'PROPN', 5, 'compound', 4], ['jose', 'PROPN', 6, 'compound', 5], ['island', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['island', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['tx', 'PROPN', 3, 'pobj', 7]\n",
      "parent node subtree [['san', 'PROPN', 5, 'compound', 4], ['jose', 'PROPN', 6, 'compound', 5], ['island', 'PROPN', 7, 'compound', 6], ['tx', 'PROPN', 3, 'pobj', 7], ['near', 'ADP', 7, 'prep', 8], ['rockport', 'PROPN', 10, 'compound', 9], ['tx', 'PROPN', 8, 'pobj', 10]]\n",
      "parent node subtree str \"san jose island tx near rockport tx\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=rockport\n",
      "anchor NE candidates = \n",
      "full parse [[['my', 'ADJ', 1, 'poss', 0], ['hometown', 'NOUN', 3, 'nsubj', 1], ['houston', 'PROPN', 1, 'appos', 2], ['be', 'VERB', 3, 'ROOT', 3], ['safe', 'ADJ', 5, 'amod', 4], ['people', 'NOUN', 3, 'attr', 5], ['texting', 'VERB', 5, 'acl', 6], ['me', 'PRON', 10, 'nmod', 7], [\"i'm\", 'ADV', 10, 'compound', 8], ['chill', 'VERB', 10, 'compound', 9], [\"i'm\", 'PROPN', 6, 'dobj', 10], ['in', 'ADP', 10, 'prep', 11], ['dallas', 'PROPN', 11, 'pobj', 12], ['we', 'PRON', 15, 'nsubj', 13], ['should', 'VERB', 15, 'aux', 14], ['be', 'VERB', 3, 'conj', 15], ['gucci', 'PROPN', 17, 'compound', 16], ['#hurricaneharvey', 'PUNCT', 15, 'attr', 17]]]\n",
      "candidate 0=houston\n",
      "anchor NE candidates = dallas\n",
      "data NE tree=[['houston', 'PROPN', 1, 'appos', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['houston', 'PROPN', 1, 'appos', 2]\n",
      "NE parent token:\n",
      "['hometown', 'NOUN', 3, 'nsubj', 1]\n",
      "parent node subtree [['my', 'ADJ', 1, 'poss', 0], ['hometown', 'NOUN', 3, 'nsubj', 1], ['houston', 'PROPN', 1, 'appos', 2]]\n",
      "parent node subtree str \"my hometown houston\"\n",
      "candidate 1=dallas\n",
      "anchor NE candidates = \n",
      "full parse [[['cbs', 'PROPN', 1, 'compound', 0], ['news', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['reports', 'NOUN', 3, 'ROOT', 3], ['that', 'ADP', 17, 'mark', 4], ['portions', 'NOUN', 17, 'nsubj', 5], ['of', 'ADP', 5, 'prep', 6], ['high', 'ADJ', 8, 'amod', 7], ['school', 'NOUN', 6, 'pobj', 8], ['in', 'ADP', 8, 'prep', 9], ['rockport', 'PROPN', 11, 'compound', 10], ['texas', 'PROPN', 9, 'pobj', 11], ['where', 'ADV', 14, 'advmod', 12], ['#hurricaneharvey', 'PROPN', 14, 'nsubj', 13], ['made', 'VERB', 5, 'relcl', 14], ['landfall', 'NOUN', 14, 'dobj', 15], ['have', 'VERB', 17, 'aux', 16], ['collapsed', 'VERB', 3, 'acl', 17]]]\n",
      "candidate 0=rockport\n",
      "anchor NE candidates = \n",
      "full parse [[['hurricane', 'PROPN', 1, 'compound', 0], ['#harvey', 'PROPN', 2, 'nsubj', 1], ['makes', 'VERB', 2, 'ROOT', 2], ['landfall', 'PROPN', 2, 'dobj', 3], ['near', 'PROPN', 3, 'prep', 4], ['corpus', 'PROPN', 6, 'compound', 5], ['christi', 'PROPN', 4, 'pobj', 6], ['texas', 'PROPN', 6, 'appos', 7], ['but', 'CCONJ', 2, 'cc', 8], ['the', 'DET', 10, 'det', 9], ['danger', 'NOUN', 11, 'nsubj', 10], ['is', 'VERB', 2, 'conj', 11], ['not', 'ADV', 11, 'neg', 12], ['over', 'ADV', 11, 'advmod', 13]]]\n",
      "candidate 0=corpus christi\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['rain', 'NOUN', 3, 'nmod', 0], ['and', 'CCONJ', 0, 'cc', 1], ['lots', 'NOUN', 0, 'conj', 2], ['wind', 'NOUN', 3, 'ROOT', 3], ['in', 'ADP', 3, 'prep', 4], ['san', 'PROPN', 6, 'compound', 5], ['marcos', 'PROPN', 7, 'compound', 6], ['tx', 'PROPN', 4, 'pobj', 7], ['.', 'PUNCT', 3, 'punct', 8]], [['checked', 'VERB', 0, 'ROOT', 0], ['in', 'PART', 0, 'prt', 1], ['with', 'ADP', 0, 'prep', 2], ['my', 'ADJ', 4, 'poss', 3], ['parentals', 'NOUN', 2, 'pobj', 4], ['and', 'CCONJ', 0, 'cc', 5], ['everyone', 'NOUN', 7, 'nsubj', 6], ['is', 'VERB', 0, 'conj', 7], ['ok', 'ADJ', 7, 'acomp', 8], ['with', 'ADP', 7, 'prep', 9], ['a', 'DET', 12, 'det', 10], ['little', 'ADJ', 12, 'amod', 11], ['damage', 'NOUN', 9, 'pobj', 12], ['.', 'PUNCT', 7, 'punct', 13]], [['thanks', 'NOUN', 1, 'compound', 0], ['#hurricaneharvey', 'PUNCT', 1, 'ROOT', 1]]]\n",
      "candidate 0=san marcos\n",
      "anchor NE candidates = \n",
      "full parse [[[\"i'm\", 'NUM', 0, 'ROOT', 0], ['at', 'ADP', 0, 'prep', 1], ['a', 'DET', 3, 'det', 2], ['shelter', 'NOUN', 1, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['austin', 'PROPN', 6, 'compound', 5], ['tx', 'PROPN', 4, 'pobj', 6], ['where', 'ADV', 10, 'advmod', 7], ['@govabbott', 'PROPN', 10, 'nsubj', 8], ['is', 'VERB', 10, 'aux', 9], ['meeting', 'VERB', 6, 'relcl', 10], ['with', 'ADP', 10, 'prep', 11], ['evacuated', 'VERB', 13, 'amod', 12], ['texans', 'PROPN', 11, 'pobj', 13], ['.', 'PUNCT', 0, 'punct', 14]], [['#harvey', 'PROPN', 1, 'compound', 0], ['#txlege', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=austin\n",
      "anchor NE candidates = \n",
      "full parse [[['convoy', 'NOUN', 3, 'nmod', 0], ['of', 'ADP', 0, 'prep', 1], ['wildlife', 'NOUN', 1, 'pobj', 2], ['agents', 'NOUN', 8, 'nsubj', 3], ['from', 'ADP', 3, 'prep', 4], ['louisiana', 'PROPN', 4, 'pobj', 5], ['towing', 'NOUN', 7, 'amod', 6], ['boats', 'NOUN', 8, 'nsubj', 7], ['leave', 'VERB', 8, 'ROOT', 8], ['gas', 'NOUN', 10, 'compound', 9], ['station', 'NOUN', 8, 'dobj', 10], ['in', 'ADP', 8, 'prep', 11], ['wharton', 'PROPN', 11, 'pobj', 12], ['and', 'CCONJ', 8, 'cc', 13], ['head', 'NOUN', 8, 'conj', 14], ['toward', 'ADP', 14, 'prep', 15], ['houston', 'PROPN', 17, 'compound', 16], ['#harvey', 'PROPN', 15, 'pobj', 17]]]\n",
      "candidate 0=wharton\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['wharton', 'PROPN', 11, 'pobj', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['wharton', 'PROPN', 11, 'pobj', 12]\n",
      "NE parent token:\n",
      "['in', 'ADP', 8, 'prep', 11]\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['all', 'DET', 4, 'nsubj', 0], ['of', 'ADP', 0, 'prep', 1], ['my', 'ADJ', 3, 'poss', 2], ['district', 'PROPN', 1, 'pobj', 3], ['is', 'VERB', 4, 'ROOT', 4], ['under', 'ADP', 4, 'prep', 5], ['siege', 'NOUN', 7, 'compound', 6], ['brays', 'PROPN', 10, 'compound', 7], ['oaks', 'PROPN', 10, 'compound', 8], ['med', 'PROPN', 10, 'compound', 9], ['center', 'PROPN', 16, 'compound', 10], ['meyerland', 'PROPN', 12, 'compound', 11], ['sharpstown', 'PROPN', 16, 'compound', 12], ['southpark', 'PROPN', 16, 'compound', 13], ['sunnyside', 'PROPN', 16, 'compound', 14], ['3rd', 'PROPN', 16, 'compound', 15], ['ward', 'PROPN', 5, 'pobj', 16], ['&', 'CCONJ', 16, 'cc', 17], ['westbury', 'PROPN', 16, 'conj', 18], ['.', 'PUNCT', 4, 'punct', 19]], [['#harvey', 'PROPN', 1, 'compound', 0], ['#flood', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=sharpstown\n",
      "anchor NE candidates = westbury\n",
      "data NE tree=[['sharpstown', 'PROPN', 16, 'compound', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['sharpstown', 'PROPN', 16, 'compound', 12]\n",
      "NE parent token:\n",
      "['ward', 'PROPN', 5, 'pobj', 16]\n",
      "parent node subtree [['siege', 'NOUN', 7, 'compound', 6], ['brays', 'PROPN', 10, 'compound', 7], ['oaks', 'PROPN', 10, 'compound', 8], ['med', 'PROPN', 10, 'compound', 9], ['center', 'PROPN', 16, 'compound', 10], ['meyerland', 'PROPN', 12, 'compound', 11], ['sharpstown', 'PROPN', 16, 'compound', 12], ['southpark', 'PROPN', 16, 'compound', 13], ['sunnyside', 'PROPN', 16, 'compound', 14], ['3rd', 'PROPN', 16, 'compound', 15], ['ward', 'PROPN', 5, 'pobj', 16], ['&', 'CCONJ', 16, 'cc', 17], ['westbury', 'PROPN', 16, 'conj', 18]]\n",
      "parent node subtree str \"siege brays oaks med center meyerland sharpstown southpark sunnyside 3rd ward & westbury\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "NE=sharpstown subtree=[['meyerland', 'PROPN', 12, 'compound', 11]]\n",
      "min node deps ['compound']\n",
      "candidate 1=southpark\n",
      "anchor NE candidates = westbury\n",
      "data NE tree=[['southpark', 'PROPN', 16, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['southpark', 'PROPN', 16, 'compound', 13]\n",
      "NE parent token:\n",
      "['ward', 'PROPN', 5, 'pobj', 16]\n",
      "parent node subtree [['siege', 'NOUN', 7, 'compound', 6], ['brays', 'PROPN', 10, 'compound', 7], ['oaks', 'PROPN', 10, 'compound', 8], ['med', 'PROPN', 10, 'compound', 9], ['center', 'PROPN', 16, 'compound', 10], ['meyerland', 'PROPN', 12, 'compound', 11], ['sharpstown', 'PROPN', 16, 'compound', 12], ['southpark', 'PROPN', 16, 'compound', 13], ['sunnyside', 'PROPN', 16, 'compound', 14], ['3rd', 'PROPN', 16, 'compound', 15], ['ward', 'PROPN', 5, 'pobj', 16], ['&', 'CCONJ', 16, 'cc', 17], ['westbury', 'PROPN', 16, 'conj', 18]]\n",
      "parent node subtree str \"siege brays oaks med center meyerland sharpstown southpark sunnyside 3rd ward & westbury\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 2=westbury\n",
      "anchor NE candidates = \n",
      "full parse [[['wolff', 'PROPN', 1, 'nsubj', 0], ['said', 'VERB', 1, 'ROOT', 1], ['patients', 'NOUN', 10, 'nsubjpass', 2], ['from', 'ADP', 2, 'prep', 3], ['ben', 'PROPN', 5, 'compound', 4], ['taub', 'PROPN', 3, 'pobj', 5], ['in', 'ADP', 5, 'prep', 6], ['houston', 'PROPN', 6, 'pobj', 7], ['might', 'VERB', 10, 'aux', 8], ['be', 'VERB', 10, 'auxpass', 9], ['transported', 'VERB', 1, 'ccomp', 10], ['to', 'ADP', 10, 'prep', 11], ['san', 'PROPN', 13, 'compound', 12], ['antonio', 'PROPN', 15, 'compound', 13], ['area', 'NOUN', 15, 'compound', 14], ['hospitals', 'NOUN', 11, 'pobj', 15], ['.', 'PUNCT', 1, 'punct', 16]], [['not', 'ADV', 1, 'neg', 0], ['confirmed', 'VERB', 1, 'ROOT', 1], ['yet', 'ADV', 1, 'advmod', 2], ['.', 'PUNCT', 1, 'punct', 3]], [['#harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=san antonio\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['san', 'PROPN', 13, 'compound', 12], ['antonio', 'PROPN', 15, 'compound', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['antonio', 'PROPN', 15, 'compound', 13]\n",
      "NE parent token:\n",
      "['hospitals', 'NOUN', 11, 'pobj', 15]\n",
      "parent node subtree [['san', 'PROPN', 13, 'compound', 12], ['antonio', 'PROPN', 15, 'compound', 13], ['area', 'NOUN', 15, 'compound', 14], ['hospitals', 'NOUN', 11, 'pobj', 15]]\n",
      "parent node subtree str \"san antonio area hospitals\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['plano', 'PROPN', 1, 'compound', 0], ['efforts', 'NOUN', 1, 'ROOT', 1], ['w', 'ADP', 4, 'nmod', 2], ['/', 'SYM', 4, 'punct', 3], ['#hurricaneharvey', 'PROPN', 4, 'ROOT', 4], ['(', 'PUNCT', 4, 'punct', 5], ['1/2', 'NUM', 4, 'appos', 6], [')', 'PUNCT', 10, 'punct', 7], ['plano', 'PROPN', 10, 'compound', 8], ['fire', 'PROPN', 10, 'compound', 9], ['rescue', 'PROPN', 4, 'appos', 10], [':', 'PUNCT', 10, 'punct', 11], ['2', 'NUM', 13, 'nummod', 12], ['members', 'NOUN', 14, 'nsubj', 13], ['deployed', 'VERB', 14, 'ROOT', 14], ['w', 'ADP', 20, 'quantmod', 15], ['/', 'SYM', 15, 'punct', 16], ['tx', 'PROPN', 19, 'compound', 17], ['task', 'PROPN', 19, 'compound', 18], ['force', 'PROPN', 20, 'compound', 19], ['one', 'PROPN', 14, 'dobj', 20], ['&', 'CCONJ', 20, 'cc', 21], ['3', 'NUM', 20, 'conj', 22], ['(', 'PUNCT', 20, 'punct', 23], ['incl', 'PROPN', 20, 'appos', 24], ['k', 'PROPN', 24, 'appos', 25], ['9', 'NUM', 25, 'nummod', 26], [')', 'PUNCT', 20, 'punct', 27], ['w', 'ADP', 33, 'quantmod', 28], ['/', 'SYM', 28, 'punct', 29], ['tx', 'PROPN', 32, 'compound', 30], ['task', 'PROPN', 32, 'compound', 31], ['force', 'PROPN', 33, 'compound', 32], ['two', 'PROPN', 20, 'appos', 33], ['.', 'PUNCT', 14, 'punct', 34]]]\n",
      "candidate 0=plano\n",
      "anchor NE candidates = \n",
      "full parse [[['video', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['i', 'PRON', 0, 'appos', 2], ['10', 'NUM', 2, 'appos', 3], ['at', 'ADP', 2, 'prep', 4], ['yale', 'PROPN', 11, 'compound', 5], ['the', 'DET', 11, 'det', 6], ['heights', 'PROPN', 8, 'nmod', 7], ['houston', 'PROPN', 11, 'nmod', 8], ['(', 'PUNCT', 11, 'punct', 9], ['residential', 'ADJ', 11, 'amod', 10], ['area', 'NOUN', 4, 'pobj', 11], ['on', 'ADP', 11, 'prep', 12], ['the', 'DET', 15, 'det', 13], ['north', 'NOUN', 15, 'compound', 14], ['side', 'NOUN', 12, 'pobj', 15], ['of', 'ADP', 15, 'prep', 16], ['downtown', 'NOUN', 16, 'pobj', 17], ['.', 'PUNCT', 0, 'punct', 18], [')', 'PUNCT', 0, 'punct', 19]], [['(', 'PUNCT', 3, 'punct', 0], ['@euzkera', 'PROPN', 3, 'nmod', 1], [')', 'PUNCT', 3, 'punct', 2], ['#harvey', 'PROPN', 3, 'ROOT', 3]]]\n",
      "candidate 0=yale\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['yale', 'PROPN', 11, 'compound', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['yale', 'PROPN', 11, 'compound', 5]\n",
      "NE parent token:\n",
      "['area', 'NOUN', 4, 'pobj', 11]\n",
      "parent node subtree [['yale', 'PROPN', 11, 'compound', 5], ['the', 'DET', 11, 'det', 6], ['heights', 'PROPN', 8, 'nmod', 7], ['houston', 'PROPN', 11, 'nmod', 8], ['(', 'PUNCT', 11, 'punct', 9], ['residential', 'ADJ', 11, 'amod', 10], ['area', 'NOUN', 4, 'pobj', 11], ['on', 'ADP', 11, 'prep', 12], ['the', 'DET', 15, 'det', 13], ['north', 'NOUN', 15, 'compound', 14], ['side', 'NOUN', 12, 'pobj', 15], ['of', 'ADP', 15, 'prep', 16], ['downtown', 'NOUN', 16, 'pobj', 17]]\n",
      "parent node subtree str \"yale the heights houston ( residential area on the north side of downtown\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['the', 'DET', 3, 'det', 0], ['latest', 'ADJ', 3, 'amod', 1], ['rainfall', 'NOUN', 3, 'compound', 2], ['totals', 'NOUN', 11, 'nsubj', 3], ['(', 'PUNCT', 3, 'punct', 4], ['since', 'ADP', 3, 'prep', 5], ['thurs', 'PROPN', 5, 'pobj', 6], [')', 'PUNCT', 3, 'punct', 7], ['compiled', 'VERB', 3, 'acl', 8], ['by', 'ADP', 8, 'agent', 9], ['@nwswpc', 'PROPN', 9, 'pobj', 10], ['are', 'VERB', 11, 'ROOT', 11], ['insane', 'ADJ', 11, 'acomp', 12], ['!', 'PUNCT', 11, 'punct', 13]], [['39.2', 'NUM', 1, 'nummod', 0], ['inches', 'NOUN', 4, 'npadvmod', 1], ['(', 'PUNCT', 4, 'punct', 2], ['so', 'ADV', 4, 'advmod', 3], ['far', 'ADV', 4, 'ROOT', 4], [')', 'PUNCT', 4, 'punct', 5], ['in', 'ADP', 4, 'prep', 6], ['dayton', 'PROPN', 8, 'compound', 7], ['tx', 'PROPN', 6, 'pobj', 8], ['.', 'PUNCT', 4, 'punct', 9]], [['30', 'NUM', 0, 'ROOT', 0], ['+', 'SYM', 0, 'cc', 1], ['in', 'ADP', 0, 'conj', 2], ['south', 'ADJ', 4, 'amod', 3], ['houston', 'PROPN', 2, 'pobj', 4], ['.', 'PUNCT', 0, 'punct', 5]], [['#harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=dayton\n",
      "anchor NE candidates = \n",
      "candidate 1=south houston\n",
      "anchor NE candidates = dayton\n",
      "data NE tree=[['south', 'ADJ', 4, 'amod', 3], ['houston', 'PROPN', 2, 'pobj', 4]]\n",
      "NE parse token at tree=2, token=5:\n",
      "['houston', 'PROPN', 2, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 0, 'conj', 2]\n",
      "full parse [[['contact', 'VERB', 0, 'ROOT', 0], ['?', 'PUNCT', 0, 'punct', 1], ['!', 'PUNCT', 0, 'punct', 2], ['!', 'PUNCT', 0, 'punct', 3], ['!', 'PUNCT', 0, 'punct', 4]], [['2', 'PUNCT', 5, 'nummod', 0], ['kayaks', 'NOUN', 3, 'nmod', 1], ['4', 'NUM', 1, 'nummod', 2], ['#help', 'PROPN', 5, 'nmod', 3], ['inner', 'ADJ', 5, 'amod', 4], ['loop', 'NOUN', 5, 'ROOT', 5], [':', 'PUNCT', 5, 'punct', 6], ['lindale', 'PROPN', 10, 'compound', 7], ['irvington', 'PROPN', 9, 'compound', 8], ['cavalcade', 'NOUN', 10, 'compound', 9], ['area', 'NOUN', 10, 'ROOT', 10], ['and', 'CCONJ', 10, 'cc', 11], ['beyond', 'ADV', 10, 'conj', 12], ['!', 'PUNCT', 10, 'punct', 13]], [['#hurricaneharvey', 'PUNCT', 1, 'compound', 0], ['#houston', 'X', 1, 'ROOT', 1]]]\n",
      "candidate 0=lindale\n",
      "anchor NE candidates = \n",
      "full parse [[['from', 'ADP', 7, 'prep', 0], ['new', 'PROPN', 2, 'compound', 1], ['york', 'PROPN', 0, 'pobj', 2], ['to', 'ADP', 0, 'prep', 3], ['houston', 'PROPN', 3, 'pobj', 4], ['our', 'ADJ', 6, 'poss', 5], ['thoughts', 'NOUN', 7, 'nsubj', 6], ['are', 'VERB', 7, 'ROOT', 7], ['with', 'ADP', 7, 'prep', 8], ['the', 'DET', 10, 'det', 9], ['safety', 'NOUN', 8, 'pobj', 10], ['and', 'CCONJ', 10, 'cc', 11], ['well', 'ADV', 13, 'advmod', 12], ['being', 'VERB', 10, 'conj', 13], ['of', 'ADP', 13, 'prep', 14], ['everyone', 'NOUN', 14, 'pobj', 15], ['in', 'ADP', 15, 'prep', 16], ['texas', 'PROPN', 16, 'pobj', 17], ['.', 'PUNCT', 7, 'punct', 18]], [['#houstonstong', 'ADP', 1, 'compound', 0], ['#hurricaneharvey', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['@realdonaldtrump', 'PROPN', 0, 'ROOT', 0], ['you', 'PRON', 2, 'nsubj', 1], ['bypassed', 'VERB', 2, 'ROOT', 2], ['houston', 'PROPN', 2, 'dobj', 3], ['?', 'PUNCT', 2, 'punct', 4]], [['if', 'ADP', 2, 'mark', 0], ['nyc', 'PROPN', 2, 'nsubj', 1], ['had', 'VERB', 2, 'ROOT', 2], ['a', 'DET', 6, 'det', 3], ['1', 'NUM', 5, 'compound', 4], ['000', 'NUM', 6, 'nummod', 5], ['year', 'NOUN', 2, 'dobj', 6], ['flood', 'NOUN', 8, 'compound', 7], ['wd', 'NOUN', 2, 'dobj', 8], ['you', 'PRON', 10, 'nsubj', 9], ['visit', 'VERB', 10, 'ROOT', 10], ['albany', 'PROPN', 10, 'dobj', 11], ['&', 'CCONJ', 11, 'cc', 12], ['rochester', 'PROPN', 11, 'conj', 13], ['bypass', 'NOUN', 15, 'compound', 14], ['nyc', 'PROPN', 11, 'conj', 15], ['?', 'PUNCT', 10, 'punct', 16]], [['#harvey', 'PROPN', 1, 'compound', 0], ['#hurricaneharvey', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=houston\n",
      "anchor NE candidates = \n",
      "candidate 1=rochester\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['rochester', 'PROPN', 11, 'conj', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['rochester', 'PROPN', 11, 'conj', 13]\n",
      "NE parent token:\n",
      "['albany', 'PROPN', 10, 'dobj', 11]\n",
      "full parse [[[\"teague's\", 'PROPN', 1, 'compound', 0], ['tavern', 'ADJ', 6, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['round', 'PROPN', 4, 'compound', 3], ['top', 'PROPN', 2, 'pobj', 4], ['is', 'VERB', 6, 'aux', 5], ['offering', 'VERB', 6, 'ROOT', 6], ['10', 'NUM', 8, 'nummod', 7], ['percent', 'NOUN', 6, 'dobj', 8], ['of', 'ADP', 8, 'prep', 9], ['their', 'ADJ', 11, 'poss', 10], ['sales', 'NOUN', 9, 'pobj', 11], ['to', 'PART', 13, 'aux', 12], ['flood', 'VERB', 6, 'xcomp', 13], ['relief', 'NOUN', 15, 'compound', 14], ['efforts', 'NOUN', 13, 'dobj', 15], ['in', 'ADP', 15, 'prep', 16], ['la', 'PROPN', 18, 'compound', 17], ['grange', 'PROPN', 16, 'pobj', 18], ['and', 'CCONJ', 18, 'cc', 19], ['houston', 'PROPN', 18, 'conj', 20], ['.', 'PUNCT', 6, 'punct', 21]], [['check', 'VERB', 0, 'ROOT', 0], ['them', 'PRON', 0, 'dobj', 1], ['out', 'PART', 0, 'prt', 2], ['!', 'PUNCT', 0, 'punct', 3]], [['#harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=round top\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['round', 'PROPN', 4, 'compound', 3], ['top', 'PROPN', 2, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['top', 'PROPN', 2, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['noaa', 'PROPN', 13, 'nsubj', 0], [':', 'PUNCT', 0, 'punct', 1], ['rainfall', 'NOUN', 0, 'acl', 2], ['total', 'NOUN', 2, 'dobj', 3], ['from', 'ADP', 3, 'prep', 4], ['#harvey', 'PROPN', 4, 'pobj', 5], ['for', 'ADP', 3, 'prep', 6], ['cedar', 'PROPN', 8, 'compound', 7], ['bayou', 'PROPN', 6, 'pobj', 8], ['in', 'ADP', 8, 'prep', 9], ['harris', 'PROPN', 11, 'compound', 10], ['county', 'PROPN', 12, 'compound', 11], ['texas', 'PROPN', 9, 'pobj', 12], ['is', 'VERB', 13, 'ROOT', 13], ['at', 'ADP', 13, 'prep', 14], ['51.88', 'NUM', 16, 'nummod', 15], ['”', 'NOUN', 14, 'pobj', 16], ['a', 'DET', 20, 'det', 17], ['contiguous', 'ADJ', 20, 'amod', 18], ['us', 'PROPN', 20, 'compound', 19], ['record', 'NOUN', 13, 'attr', 20], ['for', 'ADP', 20, 'prep', 21], ['any', 'DET', 24, 'det', 22], ['tropical', 'ADJ', 24, 'amod', 23], ['system', 'NOUN', 21, 'pobj', 24], ['.', 'PUNCT', 13, 'punct', 25]]]\n",
      "candidate 0=harris county\n",
      "anchor NE candidates = \n",
      "full parse [[['president', 'PROPN', 1, 'compound', 0], ['trump', 'PROPN', 1, 'ROOT', 1], ['and', 'CCONJ', 1, 'cc', 2], ['first', 'PROPN', 5, 'compound', 3], ['lady', 'PROPN', 5, 'compound', 4], ['melania', 'PROPN', 1, 'conj', 5], ['at', 'ADP', 5, 'prep', 6], ['annaville', 'PROPN', 9, 'compound', 7], ['fire', 'PROPN', 9, 'nmod', 8], ['rescue', 'PROPN', 6, 'pobj', 9], ['|', 'PROPN', 14, 'punct', 10], ['corpus', 'PROPN', 12, 'compound', 11], ['christi', 'PROPN', 14, 'compound', 12], ['tx', 'PROPN', 14, 'compound', 13], ['#hurricaneharvey', 'PROPN', 9, 'appos', 14]]]\n",
      "candidate 0=corpus christi\n",
      "anchor NE candidates = \n",
      "full parse [[['1927', 'NUM', 2, 'nummod', 0], ['freeman', 'PROPN', 2, 'compound', 1], ['ave', 'PROPN', 2, 'ROOT', 2], ['.', 'PUNCT', 2, 'punct', 3], ['77642', 'NUM', 4, 'ROOT', 4], ['port', 'PROPN', 7, 'nmod', 5], ['arthur', 'PROPN', 7, 'nmod', 6], ['tx', 'PROPN', 9, 'nmod', 7], ['elderly', 'ADJ', 9, 'amod', 8], ['lady', 'NOUN', 13, 'nsubj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['her', 'ADJ', 12, 'poss', 11], ['granddaughter', 'NOUN', 9, 'conj', 12], ['stuck', 'VERB', 13, 'ROOT', 13], ['#hurricaneharvey', 'PROPN', 15, 'compound', 14], ['#portarthur', 'X', 13, 'dobj', 15]]]\n",
      "candidate 0=port arthur\n",
      "anchor NE candidates = \n",
      "full parse [[['sending', 'VERB', 0, 'ROOT', 0], ['prayers', 'NOUN', 0, 'dobj', 1], ['more', 'ADJ', 5, 'amod', 2], ['than', 'ADP', 5, 'quantmod', 3], ['1', 'NUM', 5, 'compound', 4], ['700', 'NUM', 7, 'nummod', 5], ['square', 'ADJ', 7, 'amod', 6], ['miles', 'NOUN', 0, 'dobj', 7], ['of', 'ADP', 7, 'prep', 8], ['harris', 'PROPN', 10, 'compound', 9], ['county', 'PROPN', 8, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['texas', 'PROPN', 11, 'pobj', 12], ['in', 'ADP', 0, 'prep', 13], ['underwater', 'NOUN', 13, 'pobj', 14], ['more', 'ADJ', 14, 'amod', 15], ['than', 'ADP', 15, 'prep', 16], ['new', 'PROPN', 18, 'compound', 17], ['york', 'PROPN', 19, 'compound', 18], ['city', 'PROPN', 22, 'nsubj', 19], ['&', 'CCONJ', 19, 'cc', 20], ['chicago', 'PROPN', 19, 'conj', 21], ['combined', 'VERB', 1, 'relcl', 22], ['.', 'PUNCT', 0, 'punct', 23]], [['#harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=harris county\n",
      "anchor NE candidates = \n",
      "candidate 1=chicago\n",
      "anchor NE candidates = harris county\n",
      "data NE tree=[['chicago', 'PROPN', 19, 'conj', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['chicago', 'PROPN', 19, 'conj', 21]\n",
      "NE parent token:\n",
      "['city', 'PROPN', 22, 'nsubj', 19]\n",
      "full parse [[['treviño', 'PROPN', 6, 'npadvmod', 0], ['on', 'ADP', 0, 'prep', 1], ['#hurricaneharvey', 'PROPN', 1, 'pobj', 2], [':', 'PUNCT', 6, 'punct', 3], ['we', 'PRON', 6, 'nsubj', 4], ['are', 'VERB', 6, 'aux', 5], ['getting', 'VERB', 6, 'ROOT', 6], ['ready', 'ADJ', 6, 'acomp', 7], ['for', 'ADP', 7, 'prep', 8], ['refugees', 'NOUN', 8, 'pobj', 9], ['.', 'PUNCT', 6, 'punct', 10]], [[\"let's\", 'PROPN', 2, 'advmod', 0], ['not', 'ADV', 2, 'neg', 1], ['forget', 'VERB', 2, 'ROOT', 2], ['coastal', 'PROPN', 4, 'compound', 3], ['bend', 'PROPN', 5, 'compound', 4], ['communities', 'NOUN', 2, 'dobj', 5], ['.', 'PUNCT', 2, 'punct', 6]], [['it', 'PRON', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['not', 'ADV', 1, 'neg', 2], ['just', 'ADV', 4, 'advmod', 3], ['houston', 'PROPN', 1, 'attr', 4], ['.', 'PUNCT', 1, 'punct', 5]]]\n",
      "candidate 0=bend\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['bend', 'PROPN', 5, 'compound', 4]]\n",
      "NE parse token at tree=1, token=5:\n",
      "['bend', 'PROPN', 5, 'compound', 4]\n",
      "NE parent token:\n",
      "['communities', 'NOUN', 2, 'dobj', 5]\n",
      "parent node subtree [['coastal', 'PROPN', 4, 'compound', 3], ['bend', 'PROPN', 5, 'compound', 4], ['communities', 'NOUN', 2, 'dobj', 5]]\n",
      "parent node subtree str \"coastal bend communities\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "NE=bend subtree=[['coastal', 'PROPN', 4, 'compound', 3]]\n",
      "min node deps ['compound']\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['so', 'ADV', 2, 'advmod', 0], ['...', 'PUNCT', 2, 'punct', 1], ['#harvey', 'PROPN', 2, 'ROOT', 2], ['for', 'ADP', 2, 'prep', 3], ['(', 'PUNCT', 7, 'punct', 4], ['european', 'ADJ', 7, 'amod', 5], [')', 'PUNCT', 7, 'punct', 6], ['scale', 'NOUN', 3, 'pobj', 7], ['.', 'PUNCT', 2, 'punct', 8]], [['corpus', 'PROPN', 1, 'compound', 0], ['christi', 'PROPN', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['~', 'PUNCT', 6, 'punct', 3], ['milan', 'PROPN', 5, 'compound', 4], ['houston', 'PROPN', 6, 'nsubj', 5], ['is', 'VERB', 2, 'ccomp', 6], ['~', 'PUNCT', 6, 'punct', 7], ['münchen', 'PROPN', 9, 'compound', 8], ['beumont', 'PROPN', 6, 'attr', 9], ['~', 'PUNCT', 9, 'punct', 10], ['salzburg', 'PROPN', 12, 'compound', 11], ['shreveport', 'PROPN', 9, 'appos', 12], ['~', 'SYM', 12, 'punct', 13], ['prague', 'PROPN', 12, 'appos', 14]]]\n",
      "candidate 0=prague\n",
      "anchor NE candidates = corpus christi\n",
      "data NE tree=[['prague', 'PROPN', 12, 'appos', 14]]\n",
      "NE parse token at tree=1, token=0:\n",
      "['prague', 'PROPN', 12, 'appos', 14]\n",
      "NE parent token:\n",
      "['shreveport', 'PROPN', 9, 'appos', 12]\n",
      "parent node subtree [['salzburg', 'PROPN', 12, 'compound', 11], ['shreveport', 'PROPN', 9, 'appos', 12], ['~', 'SYM', 12, 'punct', 13], ['prague', 'PROPN', 12, 'appos', 14]]\n",
      "parent node subtree str \"salzburg shreveport ~ prague\"\n",
      "candidate 1=corpus christi\n",
      "anchor NE candidates = \n",
      "full parse [[['because', 'ADP', 7, 'mark', 0], ['the', 'DET', 2, 'det', 1], ['horror', 'NOUN', 7, 'nsubj', 2], ['and', 'CCONJ', 2, 'cc', 3], ['devastation', 'NOUN', 2, 'conj', 4], ['of', 'ADP', 2, 'prep', 5], ['#harvey', 'PROPN', 5, 'pobj', 6], ['was', 'VERB', 7, 'ROOT', 7], ['in', 'ADP', 7, 'prep', 8], ['houston', 'PROPN', 8, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['galveston', 'PROPN', 9, 'conj', 11], ['not', 'ADV', 9, 'neg', 12], ['corpus', 'PROPN', 14, 'compound', 13], ['cristi', 'PROPN', 9, 'appos', 14], ['.', 'PUNCT', 7, 'punct', 15]], [['go', 'VERB', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['heart', 'NOUN', 1, 'pobj', 3], ['of', 'ADP', 3, 'prep', 4], ['it', 'PRON', 4, 'pobj', 5], ['all', 'DET', 5, 'appos', 6], ['not', 'ADV', 0, 'neg', 7], ['a', 'DET', 10, 'det', 8], ['safe', 'ADJ', 10, 'amod', 9], ['area', 'NOUN', 0, 'dep', 10]]]\n",
      "candidate 0=galveston\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['galveston', 'PROPN', 9, 'conj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['galveston', 'PROPN', 9, 'conj', 11]\n",
      "NE parent token:\n",
      "['houston', 'PROPN', 8, 'pobj', 9]\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['another', 'DET', 1, 'det', 0], ['crew', 'NOUN', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['euless', 'PROPN', 2, 'pobj', 3], ['and', 'CCONJ', 3, 'cc', 4], ['haltom', 'PROPN', 6, 'compound', 5], ['city', 'PROPN', 3, 'conj', 6], ['heading', 'VERB', 1, 'acl', 7], ['out', 'PART', 7, 'prt', 8], ['with', 'ADP', 7, 'prep', 9], ['a', 'DET', 11, 'det', 10], ['n', 'NOUN', 9, 'pobj', 11], ['.', 'PUNCT', 1, 'punct', 12], ['texas', 'PROPN', 15, 'compound', 13], ['strike', 'NOUN', 15, 'compound', 14], ['team', 'NOUN', 16, 'nsubj', 15], ['headed', 'VERB', 16, 'ROOT', 16], ['to', 'ADP', 16, 'prep', 17], ['southeast', 'PROPN', 20, 'compound', 18], ['texas', 'PROPN', 20, 'compound', 19], ['#harvey', 'PROPN', 17, 'pobj', 20]]]\n",
      "candidate 0=euless\n",
      "anchor NE candidates = \n",
      "candidate 1=haltom city\n",
      "anchor NE candidates = euless\n",
      "data NE tree=[['haltom', 'PROPN', 6, 'compound', 5], ['city', 'PROPN', 3, 'conj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['city', 'PROPN', 3, 'conj', 6]\n",
      "NE parent token:\n",
      "['euless', 'PROPN', 2, 'pobj', 3]\n",
      "full parse [[['while', 'ADP', 3, 'mark', 0], ['airports', 'NOUN', 3, 'nsubj', 1], ['are', 'VERB', 3, 'aux', 2], ['resuming', 'VERB', 10, 'csubj', 3], ['service', 'NOUN', 3, 'dobj', 4], ['getting', 'VERB', 4, 'acl', 5], ['a', 'DET', 7, 'det', 6], ['flight', 'NOUN', 5, 'dobj', 7], ['to', 'ADP', 7, 'prep', 8], ['houston', 'PROPN', 8, 'pobj', 9], ['is', 'VERB', 21, 'ccomp', 10], ['not', 'ADV', 10, 'neg', 11], ['easy', 'ADJ', 10, 'acomp', 12], [';', 'PUNCT', 21, 'punct', 13], ['some', 'DET', 15, 'det', 14], ['folks', 'NOUN', 21, 'nsubj', 15], ['flying', 'VERB', 15, 'acl', 16], ['to', 'ADP', 16, 'prep', 17], ['san', 'PROPN', 19, 'compound', 18], ['antonio', 'PROPN', 17, 'pobj', 19], ['then', 'ADV', 21, 'advmod', 20], ['driving', 'VERB', 21, 'ROOT', 21], ['.', 'PUNCT', 21, 'punct', 22]], [['#harvey', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=san antonio\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['san', 'PROPN', 19, 'compound', 18], ['antonio', 'PROPN', 17, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['antonio', 'PROPN', 17, 'pobj', 19]\n",
      "NE parent token:\n",
      "['to', 'ADP', 16, 'prep', 17]\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['our', 'ADJ', 2, 'poss', 0], ['claims', 'NOUN', 2, 'compound', 1], ['adjusters', 'NOUN', 3, 'nsubj', 2], ['are', 'VERB', 3, 'ROOT', 3], ['in', 'ADP', 3, 'prep', 4], ['corpus', 'PROPN', 7, 'compound', 5], ['christi', 'PROPN', 7, 'compound', 6], ['victoria', 'PROPN', 4, 'pobj', 7], ['&', 'CCONJ', 7, 'cc', 8], ['limited', 'ADJ', 10, 'amod', 9], ['areas', 'NOUN', 7, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['houston', 'PROPN', 11, 'pobj', 12], ['.', 'PUNCT', 3, 'punct', 13]], [['to', 'PART', 1, 'aux', 0], ['contact', 'VERB', 1, 'ROOT', 1], ['our', 'ADJ', 4, 'poss', 2], ['claims', 'NOUN', 4, 'compound', 3], ['team', 'NOUN', 1, 'dobj', 4], [':', 'PUNCT', 1, 'punct', 5]]]\n",
      "candidate 0=corpus christi\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['corpus', 'PROPN', 7, 'compound', 5], ['christi', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['christi', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['victoria', 'PROPN', 4, 'pobj', 7]\n",
      "parent node subtree [['corpus', 'PROPN', 7, 'compound', 5], ['christi', 'PROPN', 7, 'compound', 6], ['victoria', 'PROPN', 4, 'pobj', 7], ['&', 'CCONJ', 7, 'cc', 8], ['limited', 'ADJ', 10, 'amod', 9], ['areas', 'NOUN', 7, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['houston', 'PROPN', 11, 'pobj', 12]]\n",
      "parent node subtree str \"corpus christi victoria & limited areas of houston\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['sweet', 'ADJ', 0, 'ROOT', 0], ['!', 'PUNCT', 0, 'punct', 1]], [[\"there's\", 'NOUN', 3, 'nsubj', 0], ['no', 'DET', 3, 'det', 1], ['age', 'NOUN', 3, 'compound', 2], ['limit', 'NOUN', 3, 'ROOT', 3], ['on', 'ADP', 3, 'prep', 4], ['kindness', 'NOUN', 4, 'pobj', 5], ['.', 'PUNCT', 3, 'punct', 6]], [[\"we're\", 'PROPN', 1, 'nsubj', 0], ['taking', 'VERB', 1, 'ROOT', 1], ['donations', 'NOUN', 1, 'dobj', 2], ['today', 'NOUN', 1, 'npadvmod', 3], ['@katunews', 'NOUN', 1, 'punct', 4], ['ocated', 'VERB', 1, 'advcl', 5], ['at', 'ADP', 5, 'prep', 6], ['ne', 'PROPN', 8, 'compound', 7], ['21st', 'PROPN', 6, 'pobj', 8], ['&', 'CCONJ', 8, 'cc', 9], ['sandy', 'PROPN', 8, 'conj', 10], ['in', 'ADP', 8, 'prep', 11], ['pdx', 'PROPN', 11, 'pobj', 12], ['.', 'PUNCT', 1, 'punct', 13]], [['#harvey', 'PROPN', 1, 'compound', 0], ['#texasstrong', 'X', 1, 'ROOT', 1]]]\n",
      "candidate 0=sandy\n",
      "anchor NE candidates = \n",
      "full parse [[['better', 'ADV', 1, 'nsubj', 0], ['have', 'VERB', 1, 'ROOT', 1], ['a', 'DET', 3, 'det', 2], ['plan', 'NOUN', 1, 'dobj', 3], ['for', 'ADP', 3, 'prep', 4], ['dc', 'PROPN', 9, 'compound', 5], ['baltimore', 'PROPN', 9, 'compound', 6], ['philly', 'PROPN', 9, 'compound', 7], ['nyc', 'PROPN', 9, 'compound', 8], ['cleveland', 'PROPN', 13, 'compound', 9], ['buffalo', 'PROPN', 11, 'compound', 10], ['toronto', 'PROPN', 13, 'compound', 11], ['ottowa', 'PROPN', 13, 'compound', 12], ['montreal', 'PROPN', 4, 'pobj', 13], ['.', 'PUNCT', 1, 'punct', 14]], [['and', 'CCONJ', 2, 'cc', 0], ['all', 'DET', 2, 'advmod', 1], ['between', 'ADP', 2, 'ROOT', 2], ['.', 'PUNCT', 2, 'punct', 3]], [['gfs', 'PROPN', 1, 'compound', 0], ['model', 'PROPN', 2, 'compound', 1], ['#harvey', 'PROPN', 3, 'nsubj', 2], ['correct', 'VERB', 3, 'ROOT', 3]]]\n",
      "candidate 0=cleveland\n",
      "anchor NE candidates = \n",
      "candidate 1=buffalo\n",
      "anchor NE candidates = cleveland\n",
      "data NE tree=[['buffalo', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['buffalo', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['toronto', 'PROPN', 13, 'compound', 11]\n",
      "parent node subtree [['buffalo', 'PROPN', 11, 'compound', 10], ['toronto', 'PROPN', 13, 'compound', 11]]\n",
      "parent node subtree str \"buffalo toronto\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 2=toronto\n",
      "anchor NE candidates = cleveland,buffalo\n",
      "data NE tree=[['toronto', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['toronto', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['montreal', 'PROPN', 4, 'pobj', 13]\n",
      "parent node subtree [['dc', 'PROPN', 9, 'compound', 5], ['baltimore', 'PROPN', 9, 'compound', 6], ['philly', 'PROPN', 9, 'compound', 7], ['nyc', 'PROPN', 9, 'compound', 8], ['cleveland', 'PROPN', 13, 'compound', 9], ['buffalo', 'PROPN', 11, 'compound', 10], ['toronto', 'PROPN', 13, 'compound', 11], ['ottowa', 'PROPN', 13, 'compound', 12], ['montreal', 'PROPN', 4, 'pobj', 13]]\n",
      "parent node subtree str \"dc baltimore philly nyc cleveland buffalo toronto ottowa montreal\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "NE=toronto subtree=[['buffalo', 'PROPN', 11, 'compound', 10]]\n",
      "min node deps ['compound']\n",
      "candidate 3=montreal\n",
      "anchor NE candidates = cleveland,buffalo,toronto\n",
      "data NE tree=[['montreal', 'PROPN', 4, 'pobj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['montreal', 'PROPN', 4, 'pobj', 13]\n",
      "NE parent token:\n",
      "['for', 'ADP', 3, 'prep', 4]\n",
      "NE=montreal subtree=[['dc', 'PROPN', 9, 'compound', 5], ['baltimore', 'PROPN', 9, 'compound', 6], ['philly', 'PROPN', 9, 'compound', 7], ['nyc', 'PROPN', 9, 'compound', 8], ['cleveland', 'PROPN', 13, 'compound', 9], ['buffalo', 'PROPN', 11, 'compound', 10], ['toronto', 'PROPN', 13, 'compound', 11], ['ottowa', 'PROPN', 13, 'compound', 12]]\n",
      "min node deps ['compound', 'compound', 'compound', 'compound']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[[\"we're\", 'PROPN', 3, 'nsubjpass', 0], ['gonna', 'VERB', 3, 'aux', 1], ['be', 'VERB', 3, 'auxpass', 2], ['headed', 'VERB', 3, 'ROOT', 3], ['to', 'ADP', 3, 'prep', 4], ['woodsboro', 'PROPN', 6, 'compound', 5], ['tx', 'PROPN', 7, 'compound', 6], ['pop', 'NOUN', 4, 'pobj', 7], ['.', 'PUNCT', 3, 'punct', 8]], [['1', 'NUM', 1, 'nummod', 0], ['512', 'NUM', 1, 'ROOT', 1], ['tomorrow', 'NOUN', 1, 'npadvmod', 2], ['to', 'PART', 4, 'aux', 3], ['drop', 'VERB', 1, 'relcl', 4], ['off', 'PART', 4, 'prt', 5], ['supplies', 'NOUN', 4, 'dobj', 6], ['.', 'PUNCT', 1, 'punct', 7]], [['#harvey', 'PROPN', 1, 'compound', 0], ['amazon', 'PROPN', 3, 'compound', 1], ['wish', 'PROPN', 3, 'compound', 2], ['list', 'NOUN', 3, 'ROOT', 3]]]\n",
      "candidate 0=woodsboro\n",
      "anchor NE candidates = \n",
      "full parse [[['@kellycass', 'PUNCT', 2, 'nmod', 0], ['good', 'ADJ', 2, 'amod', 1], ['morning', 'NOUN', 2, 'ROOT', 2], ['from', 'ADP', 2, 'prep', 3], ['morgantown', 'PROPN', 5, 'compound', 4], ['wv', 'PROPN', 3, 'pobj', 5], ['.', 'PUNCT', 2, 'punct', 6]], [['watching', 'VERB', 12, 'csubj', 0], [\"today's\", 'NUM', 2, 'compound', 1], ['rain', 'VERB', 0, 'dobj', 2], ['&', 'CCONJ', 2, 'cc', 3], ['that', 'DET', 5, 'det', 4], ['impact', 'NOUN', 2, 'conj', 5], ['on', 'ADP', 5, 'prep', 6], ['cheat', 'PROPN', 8, 'compound', 7], ['river', 'PROPN', 6, 'pobj', 8], ['watershed', 'NOUN', 0, 'ccomp', 9], ['before', 'ADP', 9, 'prep', 10], ['#irma', 'PROPN', 10, 'pobj', 11], ['arrives', 'VERB', 12, 'ROOT', 12], ['.', 'PUNCT', 12, 'punct', 13]]]\n",
      "candidate 0=morgantown\n",
      "anchor NE candidates = \n",
      "full parse [[['@shirispear', 'PUNCT', 0, 'ROOT', 0], ['do', 'VERB', 3, 'aux', 1], ['you', 'PRON', 3, 'nsubj', 2], ['think', 'VERB', 3, 'ROOT', 3], ['#irma', 'PART', 7, 'nsubj', 4], ['will', 'VERB', 7, 'aux', 5], ['directly', 'ADV', 7, 'advmod', 6], ['hit', 'VERB', 3, 'ccomp', 7], ['north', 'PROPN', 9, 'compound', 8], ['florida', 'PROPN', 14, 'nmod', 9], ['/', 'SYM', 13, 'punct', 10], ['orlando', 'PROPN', 13, 'nmod', 11], ['/', 'SYM', 13, 'punct', 12], ['wdw', 'PROPN', 14, 'compound', 13], ['area', 'NOUN', 7, 'dobj', 14], ['.', 'PUNCT', 3, 'punct', 15]], [['flying', 'VERB', 0, 'ROOT', 0], ['from', 'ADP', 0, 'prep', 1], ['london', 'PROPN', 1, 'pobj', 2], ['to', 'ADP', 0, 'prep', 3], ['orlando', 'PROPN', 3, 'pobj', 4], ['thursday', 'PROPN', 0, 'npadvmod', 5], ['curious', 'ADJ', 5, 'amod', 6], ['to', 'PART', 8, 'aux', 7], ['kno', 'VERB', 6, 'xcomp', 8], ['?', 'PUNCT', 0, 'punct', 9]]]\n",
      "candidate 0=london\n",
      "anchor NE candidates = orlando,orlando\n",
      "data NE tree=[['london', 'PROPN', 1, 'pobj', 2]]\n",
      "NE parse token at tree=1, token=3:\n",
      "['london', 'PROPN', 1, 'pobj', 2]\n",
      "NE parent token:\n",
      "['from', 'ADP', 0, 'prep', 1]\n",
      "candidate 1=orlando\n",
      "anchor NE candidates = \n",
      "candidate 2=orlando\n",
      "anchor NE candidates = \n",
      "full parse [[['@americanair', 'PROPN', 1, 'nsubj', 0], ['supposed', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['fly', 'VERB', 1, 'xcomp', 3], ['to', 'ADP', 3, 'prep', 4], ['the', 'DET', 8, 'det', 5], ['dominican', 'PROPN', 7, 'compound', 6], ['republic', 'PROPN', 8, 'compound', 7], ['connection', 'NOUN', 4, 'pobj', 8], ['in', 'ADP', 8, 'prep', 9], ['miami', 'PROPN', 9, 'pobj', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['trying', 'VERB', 0, 'ROOT', 0], ['to', 'PART', 2, 'aux', 1], ['switch', 'VERB', 0, 'xcomp', 2], ['to', 'ADP', 2, 'prep', 3], ['mexico', 'PROPN', 3, 'pobj', 4], ['&', 'CCONJ', 0, 'cc', 5], ['you', 'PRON', 7, 'nsubj', 6], ['want', 'VERB', 0, 'conj', 7], ['to', 'PART', 9, 'aux', 8], ['charge', 'VERB', 7, 'xcomp', 9], ['me', 'PRON', 9, 'dobj', 10], ['?', 'PUNCT', 7, 'punct', 11]], [['#help', 'INTJ', 1, 'compound', 0], ['#irma', 'PUNCT', 1, 'ROOT', 1]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = \n",
      "full parse [[['hoping', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['a', 'DET', 4, 'det', 2], ['safe', 'ADJ', 4, 'amod', 3], ['week', 'NOUN', 1, 'pobj', 4], ['for', 'ADP', 0, 'prep', 5], ['our', 'ADJ', 7, 'poss', 6], ['friends', 'NOUN', 5, 'pobj', 7], ['at', 'ADP', 7, 'prep', 8], ['hillsborough', 'PROPN', 10, 'compound', 9], ['area', 'PROPN', 12, 'compound', 10], ['regional', 'PROPN', 12, 'compound', 11], ['transit', 'PROPN', 8, 'pobj', 12], ['in', 'ADP', 12, 'prep', 13], ['tampa', 'PROPN', 15, 'compound', 14], ['fl', 'PROPN', 13, 'pobj', 15], ['as', 'ADP', 18, 'mark', 16], ['they', 'PRON', 18, 'nsubj', 17], ['prepare', 'VERB', 0, 'advcl', 18], ['for', 'ADP', 18, 'prep', 19], ['#hurricaneirma', 'PROPN', 19, 'pobj', 20], ['.', 'PUNCT', 0, 'punct', 21]]]\n",
      "candidate 0=tampa\n",
      "anchor NE candidates = \n",
      "full parse [[['anna', 'PROPN', 2, 'compound', 0], ['maria', 'PROPN', 2, 'compound', 1], ['island', 'PROPN', 3, 'nsubj', 2], ['evacuating', 'VERB', 3, 'ROOT', 3], ['9/7', 'NUM', 3, 'dobj', 4], ['/', 'SYM', 6, 'punct', 5], ['17', 'NUM', 3, 'npadvmod', 6], ['at', 'ADP', 3, 'prep', 7], ['12:40', 'NUM', 9, 'nummod', 8], ['pm', 'NOUN', 7, 'pobj', 9], ['.', 'PUNCT', 3, 'punct', 10]], [['mileage', 'NOUN', 1, 'nsubj', 0], ['check', 'NOUN', 1, 'ROOT', 1], ['zero', 'NUM', 1, 'dobj', 2], ['.', 'PUNCT', 1, 'punct', 3]], [['destination', 'NOUN', 1, 'compound', 0], ['clearwater', 'PROPN', 1, 'ROOT', 1], ['then', 'ADV', 3, 'advmod', 2], ['sweet', 'ADJ', 4, 'amod', 3], ['home', 'NOUN', 5, 'compound', 4], ['alabama', 'PROPN', 1, 'appos', 5], ['.', 'PUNCT', 1, 'punct', 6]], [['#irma', 'PROPN', 1, 'nsubj', 0], ['please', 'INTJ', 1, 'ROOT', 1], ['.', 'PUNCT', 1, 'punct', 2]]]\n",
      "candidate 0=anna maria island\n",
      "anchor NE candidates = \n",
      "full parse [[['just', 'ADV', 1, 'advmod', 0], ['in', 'ADP', 7, 'advmod', 1], ['a', 'DET', 4, 'det', 2], ['mandatory', 'PROPN', 4, 'compound', 3], ['evacuation', 'PROPN', 7, 'nsubjpass', 4], ['has', 'VERB', 7, 'aux', 5], ['been', 'VERB', 7, 'auxpass', 6], ['issued', 'VERB', 7, 'ROOT', 7], ['for', 'ADP', 7, 'prep', 8], ['jacksonville', 'PROPN', 10, 'compound', 9], ['florida', 'PROPN', 8, 'pobj', 10], ['.', 'PUNCT', 7, 'punct', 11]], [['#cnn', 'INTJ', 1, 'compound', 0], ['#irma', 'PUNCT', 1, 'ROOT', 1]]]\n",
      "candidate 0=jacksonville\n",
      "anchor NE candidates = \n",
      "full parse [[['made', 'VERB', 0, 'ROOT', 0], ['it', 'PRON', 0, 'dobj', 1], ['to', 'ADP', 0, 'prep', 2], ['tulsa', 'PROPN', 2, 'pobj', 3], ['last', 'ADJ', 5, 'amod', 4], ['night', 'NOUN', 0, 'npadvmod', 5], ['from', 'ADP', 0, 'prep', 6], ['fort', 'PROPN', 8, 'compound', 7], ['myers', 'PROPN', 6, 'pobj', 8], ['escaping', 'VERB', 10, 'compound', 9], ['#hurricaneirma', 'PROPN', 8, 'appos', 10], ['.', 'PUNCT', 0, 'punct', 11]], [['just', 'ADV', 1, 'advmod', 0], ['home', 'ADV', 3, 'advmod', 1], ['we', 'PRON', 3, 'nsubj', 2], ['have', 'VERB', 3, 'ROOT', 3], ['a', 'DET', 5, 'det', 4], ['home', 'NOUN', 3, 'dobj', 5], ['back', 'ADV', 3, 'advmod', 6], ['in', 'ADP', 6, 'prep', 7], ['fl', 'PROPN', 7, 'pobj', 8], ['when', 'ADV', 11, 'advmod', 9], ['we', 'PRON', 11, 'nsubj', 10], ['get', 'VERB', 3, 'advcl', 11], ['back', 'ADV', 11, 'advmod', 12], ['.', 'PUNCT', 3, 'punct', 13]], [['@jamesaydelott', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=fort myers\n",
      "anchor NE candidates = \n",
      "full parse [[['friends', 'NOUN', 6, 'nmod', 0], ['in', 'ADP', 0, 'prep', 1], ['miami', 'PROPN', 1, 'pobj', 2], ['and', 'CCONJ', 2, 'cc', 3], ['florida', 'PROPN', 2, 'conj', 4], ['good', 'ADJ', 6, 'amod', 5], ['luck', 'NOUN', 6, 'ROOT', 6], ['and', 'CCONJ', 6, 'cc', 7], ['be', 'VERB', 6, 'conj', 8], ['safe', 'ADJ', 8, 'acomp', 9], ['!', 'PUNCT', 6, 'punct', 10]], [['#hurricaneirma', 'PROPN', 2, 'nmod', 0], ['#irma', 'PROPN', 2, 'compound', 1], ['#miamibeach', 'PROPN', 2, 'ROOT', 2]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = \n",
      "full parse [[['left', 'ADJ', 9, 'advcl', 0], ['fl', 'PROPN', 0, 'dobj', 1], ['to', 'PART', 3, 'aux', 2], ['help', 'VERB', 0, 'advcl', 3], ['in', 'ADP', 3, 'prep', 4], ['houston', 'PROPN', 4, 'pobj', 5], ['now', 'ADV', 9, 'advmod', 6], ['the', 'DET', 8, 'det', 7], ['hope', 'NOUN', 9, 'nsubj', 8], ['is', 'VERB', 9, 'ROOT', 9], ['that', 'ADP', 13, 'mark', 10], ['fl', 'PROPN', 13, 'nsubj', 11], ['will', 'VERB', 13, 'aux', 12], ['weather', 'VERB', 9, 'ccomp', 13], ['the', 'DET', 15, 'det', 14], ['storm', 'NOUN', 13, 'dobj', 15], ['.', 'PUNCT', 9, 'punct', 16]], [[\"let's\", 'PROPN', 1, 'nsubj', 0], ['pray', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['all', 'ADJ', 4, 'predet', 3], ['those', 'DET', 2, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['the', 'DET', 7, 'det', 6], ['path', 'NOUN', 5, 'pobj', 7], ['of', 'ADP', 7, 'prep', 8], ['#hurricaneirma', 'PUNCT', 8, 'pobj', 9]]]\n",
      "candidate 0=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['latest', 'ADJ', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['hurricane', 'PROPN', 3, 'compound', 2], ['#irma', 'PROPN', 4, 'nsubj', 3], ['is', 'VERB', 12, 'ccomp', 4], ['405', 'NUM', 6, 'nummod', 5], ['miles', 'NOUN', 7, 'npadvmod', 6], ['southeast', 'ADV', 4, 'acomp', 7], ['of', 'ADP', 7, 'prep', 8], ['miami', 'PROPN', 8, 'pobj', 9], [';', 'PUNCT', 12, 'punct', 10], [\"it's\", 'ADJ', 12, 'nsubj', 11], ['spreading', 'VERB', 12, 'ROOT', 12], ['westward', 'ADV', 12, 'advmod', 13], ['over', 'ADP', 12, 'prep', 14], ['parts', 'NOUN', 14, 'pobj', 15], ['of', 'ADP', 15, 'prep', 16], ['cuba', 'PROPN', 16, 'pobj', 17], ['and', 'CCONJ', 15, 'cc', 18], ['the', 'DET', 15, 'conj', 19], ['...', 'PUNCT', 12, 'punct', 20]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = \n",
      "full parse [[['no', 'DET', 1, 'det', 0], ['planes', 'NOUN', 1, 'ROOT', 1], ['over', 'ADP', 1, 'prep', 2], ['miami', 'PROPN', 2, 'pobj', 3], ['right', 'ADV', 5, 'advmod', 4], ['now', 'ADV', 1, 'advmod', 5], ['.', 'PUNCT', 1, 'punct', 6]], [['that', 'DET', 1, 'det', 0], ['one', 'NOUN', 4, 'nsubj', 1], ['you', 'PRON', 3, 'nsubj', 2], ['see', 'VERB', 1, 'relcl', 3], ['is', 'VERB', 4, 'ROOT', 4], ['air', 'PROPN', 6, 'compound', 5], ['europa', 'PROPN', 4, 'attr', 6], ['787', 'NUM', 6, 'nummod', 7], ['leaving', 'VERB', 4, 'advcl', 8], ['soon', 'ADV', 8, 'advmod', 9], ['for', 'ADP', 8, 'prep', 10], ['madrid', 'PROPN', 10, 'pobj', 11], ['tonight', 'NOUN', 8, 'npadvmod', 12], ['.', 'PUNCT', 4, 'punct', 13]], [['#hurricaneirma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=madrid\n",
      "anchor NE candidates = miami\n",
      "data NE tree=[['madrid', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['madrid', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['for', 'ADP', 8, 'prep', 10]\n",
      "candidate 1=miami\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['my', 'ADJ', 1, 'poss', 0], ['family', 'NOUN', 4, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['miami', 'PROPN', 2, 'pobj', 3], ['evacuated', 'VERB', 4, 'ROOT', 4], ['yesterday', 'NOUN', 4, 'npadvmod', 5], ['to', 'ADP', 4, 'prep', 6], ['tampa', 'PROPN', 6, 'pobj', 7], ['.', 'PUNCT', 4, 'punct', 8]], [['they', 'PRON', 1, 'nsubj', 0], [\"aren't\", 'VERB', 7, 'nmod', 1], ['out', 'ADP', 1, 'prep', 2], ['of', 'ADP', 2, 'prep', 3], ['#irma', 'PROPN', 3, 'pobj', 4], [\"'\", 'PUNCT', 7, 'punct', 5], ['s', 'PRON', 7, 'nmod', 6], ['path', 'NOUN', 7, 'ROOT', 7], ['completely', 'ADV', 7, 'advmod', 8], ['but', 'CCONJ', 7, 'cc', 9], [\"i'm\", 'NUM', 7, 'conj', 10], ['so', 'ADV', 12, 'advmod', 11], ['grateful', 'ADJ', 12, 'ROOT', 12], ['they', 'PRON', 14, 'nsubj', 13], ['were', 'VERB', 12, 'ccomp', 14], ['able', 'ADJ', 14, 'acomp', 15], ['to', 'PART', 17, 'aux', 16], ['leave', 'VERB', 15, 'xcomp', 17], ['.', 'PUNCT', 12, 'punct', 18]]]\n",
      "candidate 0=tampa\n",
      "anchor NE candidates = miami\n",
      "data NE tree=[['tampa', 'PROPN', 6, 'pobj', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['tampa', 'PROPN', 6, 'pobj', 7]\n",
      "NE parent token:\n",
      "['to', 'ADP', 4, 'prep', 6]\n",
      "candidate 1=miami\n",
      "anchor NE candidates = \n",
      "full parse [[['milfordonmove', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['local', 'ADJ', 3, 'compound', 2], ['statement', 'PROPN', 0, 'appos', 3], ['for', 'ADP', 3, 'prep', 4], ['jacksonville', 'PROPN', 6, 'compound', 5], ['fl', 'PROPN', 9, 'compound', 6], ['#disney', 'PROPN', 9, 'compound', 7], ['#dcl', 'NOUN', 9, 'compound', 8], ['#irma', 'X', 4, 'pobj', 9]]]\n",
      "candidate 0=jacksonville\n",
      "anchor NE candidates = \n",
      "full parse [[['i', 'PRON', 1, 'nsubj', 0], ['expect', 'VERB', 1, 'ROOT', 1], ['#irma', 'PROPN', 4, 'nsubj', 2], ['to', 'PART', 4, 'aux', 3], ['make', 'VERB', 1, 'ccomp', 4], ['landfall', 'NOUN', 4, 'dobj', 5], ['on', 'ADP', 4, 'prep', 6], ['mo', 'PROPN', 6, 'pobj', 7], ['8', 'NUM', 9, 'nummod', 8], ['am', 'PROPN', 10, 'npadvmod', 9], ['nearby', 'ADP', 4, 'advmod', 10], ['naples', 'PROPN', 10, 'pobj', 11], ['.', 'PUNCT', 1, 'punct', 12]], [['will', 'VERB', 1, 'aux', 0], ['hit', 'VERB', 1, 'ROOT', 1], ['tampa', 'PROPN', 1, 'dobj', 2], ['at', 'ADP', 1, 'prep', 3], ['2pm', 'NUM', 3, 'pobj', 4], ['.', 'PUNCT', 1, 'punct', 5]]]\n",
      "candidate 0=naples\n",
      "anchor NE candidates = tampa\n",
      "data NE tree=[['naples', 'PROPN', 10, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['naples', 'PROPN', 10, 'pobj', 11]\n",
      "NE parent token:\n",
      "['nearby', 'ADP', 4, 'advmod', 10]\n",
      "candidate 1=tampa\n",
      "anchor NE candidates = \n",
      "full parse [[['#irma', 'PROPN', 2, 'nsubjpass', 0], ['is', 'VERB', 2, 'auxpass', 1], ['forecast', 'VERB', 2, 'ROOT', 2], ['to', 'PART', 4, 'aux', 3], ['make', 'VERB', 2, 'advcl', 4], ['landfall', 'NOUN', 4, 'dobj', 5], ['somewhere', 'ADV', 4, 'advmod', 6], ['between', 'ADP', 6, 'prep', 7], ['naples', 'PROPN', 7, 'pobj', 8], ['&', 'CCONJ', 8, 'cc', 9], ['sarasota', 'PROPN', 8, 'conj', 10], ['sometime', 'ADV', 13, 'advmod', 11], ['sun', 'PROPN', 13, 'compound', 12], ['night', 'NOUN', 4, 'npadvmod', 13], ['&', 'CCONJ', 4, 'cc', 14], ['pass', 'VERB', 4, 'conj', 15], ['very', 'ADV', 17, 'advmod', 16], ['near', 'ADV', 15, 'advmod', 17], ['or', 'CCONJ', 17, 'cc', 18], ['over', 'ADP', 17, 'conj', 19], ['tampa', 'PROPN', 19, 'pobj', 20], ['early', 'ADJ', 22, 'amod', 21], ['mon', 'PROPN', 20, 'appos', 22], ['am', 'VERB', 2, 'advcl', 23], ['.', 'PUNCT', 2, 'punct', 24]], [['#flwx', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=naples\n",
      "anchor NE candidates = sarasota,tampa\n",
      "data NE tree=[['naples', 'PROPN', 7, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['naples', 'PROPN', 7, 'pobj', 8]\n",
      "NE parent token:\n",
      "['between', 'ADP', 6, 'prep', 7]\n",
      "NE=naples subtree=[['&', 'CCONJ', 8, 'cc', 9], ['sarasota', 'PROPN', 8, 'conj', 10]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=sarasota\n",
      "anchor NE candidates = \n",
      "candidate 2=tampa\n",
      "anchor NE candidates = sarasota\n",
      "data NE tree=[['tampa', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['tampa', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['over', 'ADP', 17, 'conj', 19]\n",
      "NE=tampa subtree=[['early', 'ADJ', 22, 'amod', 21], ['mon', 'PROPN', 20, 'appos', 22]]\n",
      "min node deps ['appos']\n",
      "subtree = early mon\n",
      "full parse [[['friends', 'NOUN', 8, 'nsubj', 0], ['and', 'CCONJ', 0, 'cc', 1], ['family', 'NOUN', 0, 'conj', 2], ['in', 'ADP', 0, 'prep', 3], ['florida', 'PROPN', 3, 'pobj', 4], ['facing', 'VERB', 0, 'acl', 5], ['hurricane', 'PROPN', 7, 'compound', 6], ['irma', 'PROPN', 5, 'dobj', 7], ['know', 'VERB', 8, 'ROOT', 8], ['you', 'PRON', 10, 'nsubj', 9], ['are', 'VERB', 8, 'ccomp', 10], ['in', 'ADP', 10, 'prep', 11], ['our', 'ADJ', 13, 'poss', 12], ['thoughts', 'NOUN', 11, 'pobj', 13], ['and', 'CCONJ', 13, 'cc', 14], ['prayers', 'NOUN', 13, 'conj', 15], ['in', 'ADP', 13, 'prep', 16], ['charleston', 'PROPN', 18, 'compound', 17], ['#hurricaneirma', 'PROPN', 16, 'pobj', 18], ['#charleston', 'PROPN', 8, 'dep', 19]]]\n",
      "candidate 0=charleston\n",
      "anchor NE candidates = \n",
      "full parse [[['curfews', 'NOUN', 0, 'ROOT', 0], ['in', 'ADP', 0, 'prep', 1], ['effect', 'NOUN', 1, 'pobj', 2], ['during', 'ADP', 0, 'prep', 3], ['#hurricaneirma', 'PROPN', 3, 'pobj', 4], ['in', 'ADP', 0, 'prep', 5], ['the', 'DET', 7, 'det', 6], ['cities', 'NOUN', 5, 'pobj', 7], ['of', 'ADP', 7, 'prep', 8], ['miami', 'PROPN', 11, 'compound', 9], ['miami', 'PROPN', 11, 'compound', 10], ['beach', 'PROPN', 8, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['north', 'PROPN', 14, 'compound', 13], ['miami', 'PROPN', 15, 'compound', 14], ['beach', 'PROPN', 11, 'conj', 15], ['.', 'PUNCT', 0, 'punct', 16]], [['no', 'DET', 1, 'det', 0], ['curfew', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['unincorporated', 'ADJ', 5, 'amod', 3], ['dade', 'PROPN', 5, 'compound', 4], ['county', 'PROPN', 2, 'pobj', 5], ['.', 'PUNCT', 1, 'punct', 6]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = dade county\n",
      "data NE tree=[['miami', 'PROPN', 11, 'compound', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['miami', 'PROPN', 11, 'compound', 9]\n",
      "NE parent token:\n",
      "['beach', 'PROPN', 8, 'pobj', 11]\n",
      "parent node subtree [['miami', 'PROPN', 11, 'compound', 9], ['miami', 'PROPN', 11, 'compound', 10], ['beach', 'PROPN', 8, 'pobj', 11], ['and', 'CCONJ', 11, 'cc', 12], ['north', 'PROPN', 14, 'compound', 13], ['miami', 'PROPN', 15, 'compound', 14], ['beach', 'PROPN', 11, 'conj', 15]]\n",
      "parent node subtree str \"miami miami beach and north miami beach\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=miami beach\n",
      "anchor NE candidates = miami,dade county\n",
      "data NE tree=[['miami', 'PROPN', 11, 'compound', 10], ['beach', 'PROPN', 8, 'pobj', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['beach', 'PROPN', 8, 'pobj', 11]\n",
      "NE parent token:\n",
      "['of', 'ADP', 7, 'prep', 8]\n",
      "NE=miami beach subtree=[['miami', 'PROPN', 11, 'compound', 9], ['and', 'CCONJ', 11, 'cc', 12], ['north', 'PROPN', 14, 'compound', 13], ['miami', 'PROPN', 15, 'compound', 14], ['beach', 'PROPN', 11, 'conj', 15]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 2=north miami beach\n",
      "anchor NE candidates = miami,miami beach,dade county\n",
      "data NE tree=[['north', 'PROPN', 14, 'compound', 13], ['miami', 'PROPN', 15, 'compound', 14], ['beach', 'PROPN', 11, 'conj', 15]]\n",
      "NE parse token at tree=0, token=16:\n",
      "['beach', 'PROPN', 11, 'conj', 15]\n",
      "NE parent token:\n",
      "['beach', 'PROPN', 8, 'pobj', 11]\n",
      "candidate 3=dade county\n",
      "anchor NE candidates = \n",
      "full parse [[['sincerely', 'ADV', 1, 'advmod', 0], ['hope', 'VERB', 1, 'ROOT', 1], ['everyone', 'NOUN', 7, 'nsubj', 2], ['in', 'ADP', 2, 'prep', 3], ['florida', 'PROPN', 3, 'pobj', 4], ['&', 'CCONJ', 4, 'cc', 5], ['miami', 'PROPN', 4, 'conj', 6], ['is', 'VERB', 1, 'ccomp', 7], ['safe', 'ADJ', 7, 'acomp', 8], ['and', 'CCONJ', 8, 'cc', 9], ['prepared', 'ADJ', 8, 'conj', 10], ['for', 'ADP', 10, 'prep', 11], ['#irma', 'PROPN', 11, 'pobj', 12], ['(', 'PUNCT', 7, 'punct', 13], ['as', 'ADV', 16, 'advmod', 14], ['well', 'ADV', 16, 'advmod', 15], ['as', 'ADP', 19, 'mark', 16], ['you', 'PRON', 19, 'nsubj', 17], ['can', 'VERB', 19, 'aux', 18], ['be', 'VERB', 7, 'advcl', 19], [')', 'PUNCT', 19, 'punct', 20], ['thoughts', 'NOUN', 19, 'attr', 21], ['and', 'CCONJ', 21, 'cc', 22], ['prayers', 'NOUN', 21, 'conj', 23], ['for', 'ADP', 21, 'prep', 24], ['those', 'DET', 24, 'pobj', 25], ['affected', 'VERB', 25, 'acl', 26], ['.', 'PUNCT', 1, 'punct', 27]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = \n",
      "full parse [[['#jewishtimes', 'PROPN', 5, 'meta', 0], ['#florida', 'PROPN', 4, 'compound', 1], ['#rickscott', 'PROPN', 4, 'compound', 2], ['#hurricaneirma', 'PROPN', 4, 'compound', 3], ['irma', 'PROPN', 5, 'nsubj', 4], ['closes', 'VERB', 5, 'ROOT', 5], ['in', 'PART', 5, 'prt', 6], ['with', 'ADP', 5, 'prep', 7], ['tampa', 'PROPN', 10, 'nmod', 8], ['not', 'ADV', 10, 'neg', 9], ['miami', 'PROPN', 7, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['the', 'DET', 13, 'det', 12], ['crosshairs', 'NOUN', 11, 'pobj', 13]]]\n",
      "candidate 0=tampa\n",
      "anchor NE candidates = miami\n",
      "data NE tree=[['tampa', 'PROPN', 10, 'nmod', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['tampa', 'PROPN', 10, 'nmod', 8]\n",
      "NE parent token:\n",
      "['miami', 'PROPN', 7, 'pobj', 10]\n",
      "parent node subtree [['tampa', 'PROPN', 10, 'nmod', 8], ['not', 'ADV', 10, 'neg', 9], ['miami', 'PROPN', 7, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['the', 'DET', 13, 'det', 12], ['crosshairs', 'NOUN', 11, 'pobj', 13]]\n",
      "parent node subtree str \"tampa not miami in the crosshairs\"\n",
      "candidate 1=miami\n",
      "anchor NE candidates = \n",
      "full parse [[['high', 'ADJ', 1, 'amod', 0], ['wind', 'NOUN', 2, 'compound', 1], ['watch', 'NOUN', 2, 'ROOT', 2], ['for', 'ADP', 2, 'prep', 3], ['cleveland', 'PROPN', 5, 'nmod', 4], ['county', 'NOUN', 9, 'nmod', 5], ['and', 'CCONJ', 5, 'cc', 6], ['lake', 'NOUN', 9, 'compound', 7], ['wind', 'NOUN', 9, 'compound', 8], ['adv', 'NOUN', 3, 'pobj', 9], ['.', 'PUNCT', 2, 'punct', 10]], [['for', 'ADP', 0, 'ROOT', 0], ['lancaster', 'PROPN', 0, 'pobj', 1], ['and', 'CCONJ', 1, 'cc', 2], ['chesterfield', 'PROPN', 1, 'conj', 3], ['due', 'ADP', 1, 'amod', 4], ['to', 'ADP', 4, 'prep', 5], ['#irma', 'PROPN', 5, 'pobj', 6], ['.', 'PUNCT', 0, 'punct', 7]], [['#scwx', 'PROPN', 1, 'compound', 0], ['#ncwx', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=lancaster\n",
      "anchor NE candidates = \n",
      "candidate 1=chesterfield\n",
      "anchor NE candidates = lancaster\n",
      "data NE tree=[['chesterfield', 'PROPN', 1, 'conj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['chesterfield', 'PROPN', 1, 'conj', 3]\n",
      "NE parent token:\n",
      "['lancaster', 'PROPN', 0, 'pobj', 1]\n",
      "full parse [[['.', 'PUNCT', 0, 'ROOT', 0]], [['@cityofmiami', 'NUM', 1, 'compound', 0], ['mayor', 'NOUN', 2, 'nsubj', 1], ['tells', 'VERB', 2, 'ROOT', 2], ['@mlauer', 'PUNCT', 2, 'dobj', 3], ['he', 'PRON', 5, 'nsubj', 4], ['reached', 'VERB', 5, 'ROOT', 5], ['out', 'PART', 5, 'prt', 6], ['to', 'ADP', 5, 'prep', 7], ['mayors', 'NOUN', 7, 'pobj', 8], ['of', 'ADP', 8, 'prep', 9], ['naples', 'PROPN', 11, 'compound', 10], ['ft', 'PROPN', 9, 'pobj', 11], ['.', 'PUNCT', 5, 'punct', 12], ['myers', 'PROPN', 14, 'compound', 13], ['sarasota', 'PROPN', 14, 'ROOT', 14], ['&', 'CCONJ', 14, 'cc', 15], ['tampa', 'PROPN', 14, 'conj', 16], ['yesterday', 'NOUN', 14, 'npadvmod', 17], ['to', 'PART', 19, 'aux', 18], ['offer', 'VERB', 14, 'relcl', 19], ['help', 'NOUN', 19, 'dobj', 20], ['#hurricaneirma', 'PUNCT', 14, 'punct', 21]]]\n",
      "candidate 0=naples\n",
      "anchor NE candidates = myers,sarasota,tampa\n",
      "data NE tree=[['naples', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=1, token=11:\n",
      "['naples', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['ft', 'PROPN', 9, 'pobj', 11]\n",
      "parent node subtree [['naples', 'PROPN', 11, 'compound', 10], ['ft', 'PROPN', 9, 'pobj', 11]]\n",
      "parent node subtree str \"naples ft\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=myers\n",
      "anchor NE candidates = sarasota,tampa\n",
      "data NE tree=[['myers', 'PROPN', 14, 'compound', 13]]\n",
      "NE parse token at tree=1, token=14:\n",
      "['myers', 'PROPN', 14, 'compound', 13]\n",
      "NE parent token:\n",
      "['sarasota', 'PROPN', 14, 'ROOT', 14]\n",
      "parent node subtree [['myers', 'PROPN', 14, 'compound', 13], ['sarasota', 'PROPN', 14, 'ROOT', 14], ['&', 'CCONJ', 14, 'cc', 15], ['tampa', 'PROPN', 14, 'conj', 16], ['yesterday', 'NOUN', 14, 'npadvmod', 17], ['to', 'PART', 19, 'aux', 18], ['offer', 'VERB', 14, 'relcl', 19], ['help', 'NOUN', 19, 'dobj', 20], ['#hurricaneirma', 'PUNCT', 14, 'punct', 21]]\n",
      "parent node subtree str \"myers sarasota & tampa yesterday to offer help #hurricaneirma\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 2=sarasota\n",
      "anchor NE candidates = \n",
      "candidate 3=tampa\n",
      "anchor NE candidates = sarasota\n",
      "data NE tree=[['tampa', 'PROPN', 14, 'conj', 16]]\n",
      "NE parse token at tree=1, token=17:\n",
      "['tampa', 'PROPN', 14, 'conj', 16]\n",
      "NE parent token:\n",
      "['sarasota', 'PROPN', 14, 'ROOT', 14]\n",
      "full parse [[['evacuation', 'NOUN', 0, 'ROOT', 0], ['!', 'PUNCT', 0, 'punct', 1]], [['keep', 'VERB', 0, 'ROOT', 0], ['safe', 'ADJ', 0, 'oprd', 1], ['everyone', 'NOUN', 0, 'dobj', 2], ['!', 'PUNCT', 0, 'punct', 3]], [['#hurricane', 'X', 1, 'compound', 0], ['#irma', 'PROPN', 1, 'ROOT', 1], ['—', 'NUM', 3, 'advmod', 2], ['traveling', 'VERB', 1, 'acl', 3], ['to', 'ADP', 3, 'prep', 4], ['greenville', 'PROPN', 7, 'compound', 5], ['south', 'PROPN', 7, 'compound', 6], ['carolina', 'PROPN', 4, 'pobj', 7]]]\n",
      "candidate 0=greenville\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['@msnbc', 'PROPN', 1, 'nsubj', 0], ['appreciate', 'VERB', 1, 'ROOT', 1], ['thoroughness', 'NOUN', 1, 'dobj', 2], ['on', 'ADP', 2, 'prep', 3], ['#irma', 'PROPN', 3, 'pobj', 4], ['but', 'CCONJ', 3, 'cc', 5], ['at', 'ADP', 11, 'prep', 6], ['what', 'ADJ', 8, 'det', 7], ['point', 'NOUN', 6, 'pobj', 8], ['do', 'VERB', 11, 'aux', 9], ['you', 'PRON', 11, 'nsubj', 10], ['cover', 'VERB', 11, 'ROOT', 11], ['prep', 'NOUN', 14, 'nmod', 12], ['/', 'SYM', 14, 'punct', 13], ['problems', 'NOUN', 15, 'compound', 14], ['north', 'PROPN', 11, 'dobj', 15], ['of', 'ADP', 15, 'prep', 16], ['keys', 'PROPN', 19, 'nmod', 17], ['/', 'SYM', 19, 'punct', 18], ['miami', 'PROPN', 16, 'pobj', 19], ['?', 'PUNCT', 11, 'punct', 20]], [['&', 'CCONJ', 1, 'cc', 0], [\"how's\", 'NOUN', 1, 'ROOT', 1], ['houston', 'PROPN', 1, 'npadvmod', 2], ['?', 'PUNCT', 1, 'punct', 3]], [['nature', 'NOUN', 0, 'ROOT', 0], ['itself', 'PRON', 0, 'appos', 1], ['?', 'PUNCT', 0, 'punct', 2]], [['!', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = houston\n",
      "data NE tree=[['miami', 'PROPN', 16, 'pobj', 19]]\n",
      "NE parse token at tree=0, token=20:\n",
      "['miami', 'PROPN', 16, 'pobj', 19]\n",
      "NE parent token:\n",
      "['of', 'ADP', 15, 'prep', 16]\n",
      "NE=miami subtree=[['keys', 'PROPN', 19, 'nmod', 17], ['/', 'SYM', 19, 'punct', 18]]\n",
      "min node deps ['nmod', 'punct']\n",
      "candidate 1=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['heavy', 'ADJ', 1, 'amod', 0], ['flooding', 'NOUN', 1, 'ROOT', 1], ['right', 'ADV', 3, 'advmod', 2], ['now', 'ADV', 1, 'advmod', 3], ['on', 'ADP', 1, 'prep', 4], ['the', 'DET', 6, 'det', 5], ['streets', 'NOUN', 4, 'pobj', 6], ['of', 'ADP', 6, 'prep', 7], ['downtown', 'PROPN', 9, 'compound', 8], ['miami', 'PROPN', 7, 'pobj', 9], ['in', 'ADP', 6, 'prep', 10], ['florida', 'PROPN', 12, 'compound', 11], ['#irma', 'PUNCT', 10, 'pobj', 12]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = \n",
      "full parse [[['still', 'ADV', 3, 'advmod', 0], ['a', 'DET', 3, 'det', 1], ['long', 'ADJ', 3, 'amod', 2], ['way', 'NOUN', 13, 'nsubj', 3], ['to', 'PART', 5, 'aux', 4], ['go', 'VERB', 3, 'relcl', 5], ['but', 'CCONJ', 3, 'cc', 6], ['it', 'PRON', 9, 'nsubj', 7], ['is', 'VERB', 9, 'aux', 8], ['looking', 'VERB', 3, 'conj', 9], ['like', 'ADP', 9, 'prep', 10], ['#irma', 'PROPN', 10, 'pobj', 11], ['may', 'VERB', 13, 'aux', 12], ['make', 'VERB', 13, 'ROOT', 13], ['landfall', 'NOUN', 13, 'dobj', 14], ['between', 'ADP', 14, 'prep', 15], ['naples', 'PROPN', 15, 'pobj', 16], ['and', 'CCONJ', 16, 'cc', 17], ['fort', 'PROPN', 19, 'compound', 18], ['myers', 'PROPN', 16, 'conj', 19], ['.', 'PUNCT', 13, 'punct', 20]]]\n",
      "candidate 0=naples\n",
      "anchor NE candidates = fort myers\n",
      "data NE tree=[['naples', 'PROPN', 15, 'pobj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['naples', 'PROPN', 15, 'pobj', 16]\n",
      "NE parent token:\n",
      "['between', 'ADP', 14, 'prep', 15]\n",
      "NE=naples subtree=[['and', 'CCONJ', 16, 'cc', 17], ['fort', 'PROPN', 19, 'compound', 18], ['myers', 'PROPN', 16, 'conj', 19]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=fort myers\n",
      "anchor NE candidates = \n",
      "full parse [[['pray', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['florida', 'PROPN', 1, 'pobj', 2], ['as', 'ADP', 6, 'mark', 3], ['hurricane', 'NOUN', 5, 'compound', 4], ['irma', 'PROPN', 6, 'nsubj', 5], ['impacts', 'VERB', 0, 'advcl', 6], ['miami', 'PROPN', 6, 'dobj', 7], ['.', 'PUNCT', 0, 'punct', 8]], [['#hurricaneirma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = \n",
      "full parse [[['cnnbrk', 'X', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['#hurricaneirma', 'PROPN', 3, 'compound', 2], ['’', 'PROPN', 10, 'poss', 3], ['s', 'PART', 3, 'case', 4], ['intense', 'ADJ', 9, 'amod', 5], ['rain', 'NOUN', 9, 'nmod', 6], ['and', 'CCONJ', 6, 'cc', 7], ['wind', 'NOUN', 6, 'conj', 8], ['pound', 'NOUN', 10, 'compound', 9], ['johnberman', 'PROPN', 10, 'ROOT', 10], ['in', 'ADP', 10, 'prep', 11], ['miami', 'PROPN', 11, 'pobj', 12], ['.', 'PUNCT', 10, 'punct', 13]], [['75', 'NUM', 1, 'nummod', 0], ['%', 'NOUN', 6, 'nsubj', 1], ['of', 'ADP', 1, 'prep', 2], ['miami', 'PROPN', 5, 'compound', 3], ['dade', 'PROPN', 5, 'compound', 4], ['county', 'PROPN', 2, 'pobj', 5], ['is', 'VERB', 6, 'ROOT', 6], ['now', 'ADV', 6, 'advmod', 7], ['without', 'ADP', 6, 'prep', 8], ['…', 'PUNCT', 6, 'punct', 9]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = miami-dade county\n",
      "data NE tree=[['miami', 'PROPN', 11, 'pobj', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['miami', 'PROPN', 11, 'pobj', 12]\n",
      "NE parent token:\n",
      "['in', 'ADP', 10, 'prep', 11]\n",
      "candidate 1=miami-dade county\n",
      "anchor NE candidates = \n",
      "full parse [[['3.3', 'NUM', 1, 'compound', 0], ['million', 'NUM', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['florida', 'PROPN', 2, 'pobj', 3], ['w', 'ADP', 1, 'prep', 4], ['/', 'SYM', 4, 'punct', 5], ['o', 'NOUN', 7, 'dep', 6], ['power', 'NOUN', 4, 'pobj', 7], ['80', 'NUM', 9, 'nummod', 8], ['%', 'NOUN', 1, 'conj', 9], ['of', 'ADP', 9, 'prep', 10], ['miami', 'PROPN', 12, 'nmod', 11], ['dade', 'PROPN', 10, 'pobj', 12], ['w', 'ADP', 17, 'nmod', 13], ['/', 'SYM', 13, 'punct', 14], ['o', 'NOUN', 13, 'pobj', 15], ['power', 'NOUN', 13, 'pobj', 16], ['#hurricaneirma', 'PUNCT', 9, 'appos', 17]]]\n",
      "candidate 0=miami-dade\n",
      "anchor NE candidates = \n",
      "full parse [[['flash', 'PROPN', 2, 'compound', 0], ['flood', 'PROPN', 2, 'compound', 1], ['warning', 'PROPN', 2, 'ROOT', 2], ['in', 'ADP', 2, 'prep', 3], ['effect', 'NOUN', 3, 'pobj', 4], ['in', 'ADP', 2, 'prep', 5], ['clay', 'PROPN', 8, 'compound', 6], ['duval', 'PROPN', 8, 'compound', 7], ['nassau', 'PROPN', 5, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['st', 'PROPN', 8, 'conj', 10], ['.', 'PUNCT', 2, 'punct', 11], ['johns', 'PROPN', 13, 'compound', 12], ['counties', 'PROPN', 13, 'ROOT', 13], ['until', 'ADP', 13, 'prep', 14], ['830', 'NUM', 16, 'nummod', 15], ['am', 'PROPN', 14, 'pobj', 16], ['#flwx', 'PROPN', 16, 'nummod', 17], ['#hurricaneirma', 'PUNCT', 13, 'appos', 18]]]\n",
      "candidate 0=duval\n",
      "anchor NE candidates = nassau\n",
      "data NE tree=[['duval', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['duval', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['nassau', 'PROPN', 5, 'pobj', 8]\n",
      "parent node subtree [['clay', 'PROPN', 8, 'compound', 6], ['duval', 'PROPN', 8, 'compound', 7], ['nassau', 'PROPN', 5, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['st', 'PROPN', 8, 'conj', 10]]\n",
      "parent node subtree str \"clay duval nassau and st\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=nassau\n",
      "anchor NE candidates = \n",
      "full parse [[['power', 'NOUN', 1, 'nsubj', 0], ['outages', 'NOUN', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['my', 'ADJ', 4, 'poss', 3], ['friends', 'NOUN', 2, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['miami', 'PROPN', 7, 'compound', 6], ['dade', 'NOUN', 5, 'pobj', 7], ['to', 'ADP', 1, 'prep', 8], ['orlando', 'PROPN', 8, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['now', 'ADV', 12, 'advmod', 11], ['tallahassee', 'PROPN', 9, 'conj', 12], ['#hurricaneirma', 'PUNCT', 1, 'punct', 13]]]\n",
      "candidate 0=tallahassee\n",
      "anchor NE candidates = orlando\n",
      "data NE tree=[['tallahassee', 'PROPN', 9, 'conj', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['tallahassee', 'PROPN', 9, 'conj', 12]\n",
      "NE parent token:\n",
      "['orlando', 'PROPN', 8, 'pobj', 9]\n",
      "NE=tallahassee subtree=[['now', 'ADV', 12, 'advmod', 11]]\n",
      "min node deps ['advmod']\n",
      "candidate 1=orlando\n",
      "anchor NE candidates = \n",
      "full parse [[['irma', 'PROPN', 2, 'nsubj', 0], ['has', 'VERB', 2, 'aux', 1], ['arrived', 'VERB', 2, 'ROOT', 2], ['in', 'ADP', 2, 'prep', 3], ['augusta', 'PROPN', 5, 'compound', 4], ['georgia', 'PROPN', 3, 'pobj', 5], ['.', 'PUNCT', 2, 'punct', 6]], [['the', 'DET', 1, 'det', 0], ['power', 'NOUN', 3, 'nsubj', 1], ['just', 'ADV', 3, 'advmod', 2], ['went', 'VERB', 3, 'ROOT', 3], ['out', 'PART', 3, 'prt', 4], ['.', 'PUNCT', 3, 'punct', 5]], [['#hurricaneirma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=augusta\n",
      "anchor NE candidates = \n",
      "full parse [[['new', 'ADJ', 2, 'amod', 0], ['tornado', 'NOUN', 2, 'compound', 1], ['warning', 'NOUN', 2, 'ROOT', 2], ['for', 'ADP', 2, 'prep', 3], ['parts', 'NOUN', 3, 'pobj', 4], ['of', 'ADP', 4, 'prep', 5], ['beaufort', 'PROPN', 8, 'compound', 6], ['colleton', 'PROPN', 8, 'compound', 7], ['county', 'PROPN', 10, 'compound', 8], ['#irma', 'PROPN', 10, 'compound', 9], ['#chswx', 'PROPN', 5, 'pobj', 10]]]\n",
      "candidate 0=beaufort\n",
      "anchor NE candidates = colleton county\n",
      "data NE tree=[['beaufort', 'PROPN', 8, 'compound', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['beaufort', 'PROPN', 8, 'compound', 6]\n",
      "NE parent token:\n",
      "['county', 'PROPN', 10, 'compound', 8]\n",
      "parent node subtree [['beaufort', 'PROPN', 8, 'compound', 6], ['colleton', 'PROPN', 8, 'compound', 7], ['county', 'PROPN', 10, 'compound', 8]]\n",
      "parent node subtree str \"beaufort colleton county\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=colleton county\n",
      "anchor NE candidates = \n",
      "full parse [[['power', 'NOUN', 1, 'nsubj', 0], ['outages', 'NOUN', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['ga', 'PROPN', 2, 'pobj', 3], ['/', 'SYM', 5, 'punct', 4], ['flooding', 'NOUN', 1, 'advcl', 5], ['in', 'ADP', 5, 'prep', 6], ['charleston', 'PROPN', 8, 'compound', 7], ['sc', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['jacksonville', 'PROPN', 8, 'conj', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['just', 'ADV', 2, 'advmod', 0], ['a', 'DET', 2, 'quantmod', 1], ['few', 'ADJ', 2, 'ROOT', 2], ['of', 'ADP', 2, 'prep', 3], ['the', 'DET', 5, 'det', 4], ['reports', 'NOUN', 3, 'pobj', 5], ['today', 'NOUN', 2, 'npadvmod', 6], ['as', 'ADP', 9, 'mark', 7], ['#irma', 'PROPN', 9, 'nsubj', 8], ['moves', 'VERB', 2, 'advcl', 9], ['north', 'PROPN', 9, 'dobj', 10], ['.', 'PUNCT', 2, 'punct', 11]], [['#gawx', 'NOUN', 0, 'ROOT', 0], ['#scwx', 'X', 0, 'intj', 1]]]\n",
      "candidate 0=charleston\n",
      "anchor NE candidates = jacksonville\n",
      "data NE tree=[['charleston', 'PROPN', 8, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['charleston', 'PROPN', 8, 'compound', 7]\n",
      "NE parent token:\n",
      "['sc', 'PROPN', 6, 'pobj', 8]\n",
      "parent node subtree [['charleston', 'PROPN', 8, 'compound', 7], ['sc', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['jacksonville', 'PROPN', 8, 'conj', 10]]\n",
      "parent node subtree str \"charleston sc and jacksonville\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=jacksonville\n",
      "anchor NE candidates = \n",
      "full parse [[['told', 'VERB', 0, 'ROOT', 0], ['someone', 'NOUN', 0, 'dobj', 1], ['i', 'PRON', 3, 'nsubj', 2], ['was', 'VERB', 1, 'relcl', 3], ['from', 'ADP', 3, 'prep', 4], ['cleveland', 'PROPN', 4, 'pobj', 5], ['while', 'ADP', 7, 'mark', 6], ['covering', 'VERB', 3, 'advcl', 7], ['#hurricaneirma', 'PUNCT', 7, 'dobj', 8], ['in', 'ADP', 7, 'prep', 9], ['jacksonville', 'PROPN', 11, 'compound', 10], ['fl', 'PROPN', 9, 'pobj', 11], ['.', 'PUNCT', 0, 'punct', 12]], [['first', 'ADJ', 1, 'amod', 0], ['question', 'NOUN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['what', 'ADJ', 4, 'det', 3], ['number', 'NOUN', 5, 'attr', 4], ['are', 'VERB', 1, 'acl', 5], ['the', 'DET', 7, 'det', 6], ['@indians', 'NOUN', 5, 'nsubj', 7], ['on', 'ADP', 7, 'prep', 8], ['#19baby', 'X', 8, 'pobj', 9]]]\n",
      "candidate 0=jacksonville\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['#irma', 'PROPN', 0, 'ROOT', 0], ['seeing', 'VERB', 0, 'acl', 1], ['pockets', 'NOUN', 1, 'dobj', 2], ['of', 'ADP', 2, 'prep', 3], ['heavy', 'ADJ', 5, 'amod', 4], ['traffic', 'NOUN', 3, 'pobj', 5], ['sb', 'PROPN', 1, 'ccomp', 6], ['i', 'PRON', 8, 'nsubj', 7], ['75', 'NUM', 1, 'ccomp', 8], ['from', 'ADP', 1, 'prep', 9], ['gainesville', 'PROPN', 9, 'pobj', 10], ['thru', 'ADP', 1, 'prep', 11], ['ocala', 'PROPN', 11, 'pobj', 12], ['as', 'ADP', 15, 'mark', 13], ['people', 'NOUN', 15, 'nsubj', 14], ['return', 'VERB', 1, 'advcl', 15], ['to', 'ADP', 15, 'prep', 16], ['their', 'ADJ', 18, 'poss', 17], ['homes', 'NOUN', 16, 'pobj', 18]]]\n",
      "candidate 0=ocala\n",
      "anchor NE candidates = gainesville\n",
      "data NE tree=[['ocala', 'PROPN', 11, 'pobj', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['ocala', 'PROPN', 11, 'pobj', 12]\n",
      "NE parent token:\n",
      "['thru', 'ADP', 1, 'prep', 11]\n",
      "candidate 1=gainesville\n",
      "anchor NE candidates = \n",
      "full parse [[['volunteers', 'NOUN', 12, 'nsubj', 0], ['from', 'ADP', 0, 'prep', 1], ['@muslimyouthusa', 'PROPN', 1, 'pobj', 2], ['working', 'VERB', 0, 'acl', 3], ['with', 'ADP', 3, 'prep', 4], ['@hfusa', 'PROPN', 4, 'pobj', 5], ['in', 'ADP', 3, 'prep', 6], ['miami', 'PROPN', 9, 'compound', 7], ['tampa', 'PROPN', 9, 'compound', 8], ['naples', 'PROPN', 6, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['jacksonville', 'PROPN', 9, 'conj', 11], ['doing', 'VERB', 12, 'ROOT', 12], ['#hurricaneirma', 'PROPN', 14, 'compound', 13], ['cleanup', 'NOUN', 15, 'compound', 14], ['work', 'NOUN', 12, 'dobj', 15]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = jacksonville\n",
      "data NE tree=[['miami', 'PROPN', 9, 'compound', 7]]\n",
      "NE parse token at tree=0, token=8:\n",
      "['miami', 'PROPN', 9, 'compound', 7]\n",
      "NE parent token:\n",
      "['naples', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['miami', 'PROPN', 9, 'compound', 7], ['tampa', 'PROPN', 9, 'compound', 8], ['naples', 'PROPN', 6, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "parent node subtree str \"miami tampa naples and jacksonville\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=tampa\n",
      "anchor NE candidates = miami,jacksonville\n",
      "data NE tree=[['tampa', 'PROPN', 9, 'compound', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['tampa', 'PROPN', 9, 'compound', 8]\n",
      "NE parent token:\n",
      "['naples', 'PROPN', 6, 'pobj', 9]\n",
      "parent node subtree [['miami', 'PROPN', 9, 'compound', 7], ['tampa', 'PROPN', 9, 'compound', 8], ['naples', 'PROPN', 6, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "parent node subtree str \"miami tampa naples and jacksonville\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 2=naples\n",
      "anchor NE candidates = miami,tampa,jacksonville\n",
      "data NE tree=[['naples', 'PROPN', 6, 'pobj', 9]]\n",
      "NE parse token at tree=0, token=10:\n",
      "['naples', 'PROPN', 6, 'pobj', 9]\n",
      "NE parent token:\n",
      "['in', 'ADP', 3, 'prep', 6]\n",
      "NE=naples subtree=[['miami', 'PROPN', 9, 'compound', 7], ['tampa', 'PROPN', 9, 'compound', 8], ['and', 'CCONJ', 9, 'cc', 10], ['jacksonville', 'PROPN', 9, 'conj', 11]]\n",
      "min node deps ['compound', 'compound', 'cc', 'conj']\n",
      "candidate 3=jacksonville\n",
      "anchor NE candidates = \n",
      "full parse [[['sarasota', 'PROPN', 1, 'compound', 0], ['county', 'PROPN', 3, 'nsubj', 1], ['have', 'VERB', 3, 'aux', 2], ['been', 'VERB', 3, 'ROOT', 3], ['very', 'ADV', 5, 'advmod', 4], ['fortunate', 'ADJ', 3, 'acomp', 5], ['that', 'ADP', 11, 'mark', 6], ['hurricane', 'NOUN', 8, 'compound', 7], ['#irma', 'PROPN', 11, 'nsubj', 8], ['did', 'VERB', 11, 'aux', 9], ['not', 'ADV', 11, 'neg', 10], ['impact', 'VERB', 3, 'ccomp', 11], ['our', 'ADJ', 13, 'poss', 12], ['area', 'NOUN', 11, 'dobj', 13], ['as', 'ADV', 15, 'advmod', 14], ['much', 'ADV', 11, 'advmod', 15], ['as', 'ADP', 18, 'mark', 16], ['it', 'PRON', 18, 'nsubj', 17], ['did', 'VERB', 15, 'advcl', 18], ['to', 'ADP', 11, 'prep', 19], ['other', 'ADJ', 21, 'amod', 20], ['counties', 'NOUN', 19, 'pobj', 21], ['in', 'ADP', 21, 'prep', 22], ['florida', 'PROPN', 22, 'pobj', 23], ['.', 'PUNCT', 3, 'punct', 24]]]\n",
      "candidate 0=sarasota county\n",
      "anchor NE candidates = \n",
      "full parse [[['day', 'NOUN', 5, 'nmod', 0], ['5', 'NUM', 0, 'nummod', 1], ['no', 'DET', 5, 'det', 2], ['power', 'NOUN', 5, 'nmod', 3], ['limited', 'VERB', 5, 'amod', 4], ['gas', 'NOUN', 8, 'nsubj', 5], ['after', 'ADP', 5, 'prep', 6], ['#hurricaneirma', 'PROPN', 6, 'pobj', 7], ['came', 'VERB', 8, 'ROOT', 8], ['across', 'ADP', 8, 'prep', 9], ['us', 'PRON', 9, 'pobj', 10], ['in', 'ADP', 8, 'prep', 11], ['naples', 'PROPN', 13, 'compound', 12], ['fl', 'PROPN', 11, 'pobj', 13], ['.', 'PUNCT', 8, 'punct', 14]], [['hoping', 'VERB', 0, 'ROOT', 0], ['and', 'CCONJ', 0, 'cc', 1], ['praying', 'VERB', 0, 'conj', 2], ['we', 'PRON', 4, 'nsubj', 3], ['get', 'VERB', 2, 'ccomp', 4], ['power', 'NOUN', 4, 'dobj', 5], ['soon', 'ADV', 4, 'advmod', 6], ['.', 'PUNCT', 0, 'punct', 7]], [['we', 'PRON', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['safe', 'ADJ', 1, 'acomp', 2]]]\n",
      "candidate 0=naples\n",
      "anchor NE candidates = \n",
      "full parse [[['update', 'NOUN', 0, 'ROOT', 0], ['on', 'ADP', 0, 'prep', 1], ['lifting', 'NOUN', 1, 'pobj', 2], ['of', 'ADP', 2, 'prep', 3], ['boil', 'NOUN', 5, 'compound', 4], ['water', 'NOUN', 6, 'compound', 5], ['alert', 'NOUN', 3, 'pobj', 6], ['for', 'ADP', 2, 'prep', 7], ['hollywood', 'PROPN', 9, 'compound', 8], ['pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['miramar', 'PROPN', 13, 'compound', 11], ['west', 'PROPN', 13, 'compound', 12], ['park', 'PROPN', 7, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['dania', 'PROPN', 16, 'compound', 15], ['beach', 'PROPN', 13, 'conj', 16], ['.', 'PUNCT', 0, 'punct', 17]], [['#irma', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=pembroke park\n",
      "anchor NE candidates = hollywood,miramar,west park,dania beach\n",
      "data NE tree=[['pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['park', 'NOUN', 13, 'compound', 10]\n",
      "NE parent token:\n",
      "['park', 'PROPN', 7, 'pobj', 13]\n",
      "parent node subtree [['hollywood', 'PROPN', 9, 'compound', 8], ['pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['miramar', 'PROPN', 13, 'compound', 11], ['west', 'PROPN', 13, 'compound', 12], ['park', 'PROPN', 7, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['dania', 'PROPN', 16, 'compound', 15], ['beach', 'PROPN', 13, 'conj', 16]]\n",
      "parent node subtree str \"hollywood pembroke park miramar west park & dania beach\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "NE=pembroke park subtree=[['hollywood', 'PROPN', 9, 'compound', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 1=hollywood\n",
      "anchor NE candidates = \n",
      "candidate 2=miramar\n",
      "anchor NE candidates = hollywood\n",
      "data NE tree=[['miramar', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['miramar', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['park', 'PROPN', 7, 'pobj', 13]\n",
      "parent node subtree [['hollywood', 'PROPN', 9, 'compound', 8], ['pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['miramar', 'PROPN', 13, 'compound', 11], ['west', 'PROPN', 13, 'compound', 12], ['park', 'PROPN', 7, 'pobj', 13], ['&', 'CCONJ', 13, 'cc', 14], ['dania', 'PROPN', 16, 'compound', 15], ['beach', 'PROPN', 13, 'conj', 16]]\n",
      "parent node subtree str \"hollywood pembroke park miramar west park & dania beach\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 3=west park\n",
      "anchor NE candidates = hollywood,miramar,dania beach\n",
      "data NE tree=[['west', 'PROPN', 13, 'compound', 12], ['park', 'PROPN', 7, 'pobj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['park', 'PROPN', 7, 'pobj', 13]\n",
      "NE parent token:\n",
      "['for', 'ADP', 2, 'prep', 7]\n",
      "NE=west park subtree=[['hollywood', 'PROPN', 9, 'compound', 8], ['pembroke', 'PROPN', 10, 'compound', 9], ['park', 'NOUN', 13, 'compound', 10], ['miramar', 'PROPN', 13, 'compound', 11], ['&', 'CCONJ', 13, 'cc', 14], ['dania', 'PROPN', 16, 'compound', 15], ['beach', 'PROPN', 13, 'conj', 16]]\n",
      "min node deps ['compound']\n",
      "candidate 4=dania beach\n",
      "anchor NE candidates = hollywood,miramar\n",
      "data NE tree=[['dania', 'PROPN', 16, 'compound', 15], ['beach', 'PROPN', 13, 'conj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['beach', 'PROPN', 13, 'conj', 16]\n",
      "NE parent token:\n",
      "['park', 'PROPN', 7, 'pobj', 13]\n",
      "full parse [[['@andersoncooper', 'X', 2, 'meta', 0], ['#hurricaneirma', 'PUNCT', 2, 'dep', 1], ['glad', 'PROPN', 2, 'ROOT', 2], ['to', 'PART', 4, 'aux', 3], ['have', 'VERB', 2, 'xcomp', 4], ['you', 'PRON', 4, 'dobj', 5], ['in', 'ADP', 4, 'prep', 6], ['tampa', 'PROPN', 6, 'pobj', 7], ['.', 'PUNCT', 2, 'punct', 8]], [['i', 'PRON', 1, 'nsubj', 0], ['was', 'VERB', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['clearwater', 'PROPN', 2, 'pobj', 3], ['riding', 'VERB', 3, 'acl', 4], ['out', 'PART', 4, 'prt', 5], ['the', 'DET', 7, 'det', 6], ['storm', 'NOUN', 4, 'dobj', 7], ['i', 'PRON', 9, 'nsubj', 8], ['wanted', 'VERB', 7, 'relcl', 9], ['to', 'PART', 11, 'aux', 10], ['race', 'VERB', 9, 'xcomp', 11], ['to', 'ADP', 11, 'prep', 12], ['tampa', 'PROPN', 12, 'pobj', 13], ['to', 'PART', 15, 'aux', 14], ['meet', 'VERB', 4, 'advcl', 15], ['you', 'PRON', 15, 'dobj', 16], ['.', 'PUNCT', 1, 'punct', 17]]]\n",
      "candidate 0=clearwater\n",
      "anchor NE candidates = tampa,tampa\n",
      "data NE tree=[['clearwater', 'PROPN', 2, 'pobj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['clearwater', 'PROPN', 2, 'pobj', 3]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "NE=clearwater subtree=[['riding', 'VERB', 3, 'acl', 4], ['out', 'PART', 4, 'prt', 5], ['the', 'DET', 7, 'det', 6], ['storm', 'NOUN', 4, 'dobj', 7], ['i', 'PRON', 9, 'nsubj', 8], ['wanted', 'VERB', 7, 'relcl', 9], ['to', 'PART', 11, 'aux', 10], ['race', 'VERB', 9, 'xcomp', 11], ['to', 'ADP', 11, 'prep', 12], ['tampa', 'PROPN', 12, 'pobj', 13], ['to', 'PART', 15, 'aux', 14], ['meet', 'VERB', 4, 'advcl', 15], ['you', 'PRON', 15, 'dobj', 16]]\n",
      "min node deps ['acl']\n",
      "subtree = riding out the storm i wanted to race to tampa to meet you\n",
      "candidate 1=tampa\n",
      "anchor NE candidates = \n",
      "candidate 2=tampa\n",
      "anchor NE candidates = \n",
      "full parse [[['emotional', 'ADJ', 1, 'amod', 0], ['homecoming', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['our', 'ADJ', 5, 'poss', 3], ['80', 'NUM', 5, 'nummod', 4], ['person', 'NOUN', 2, 'pobj', 5], ['az', 'PROPN', 7, 'compound', 6], ['taskforce', 'PROPN', 5, 'appos', 7], ['1', 'NUM', 7, 'nummod', 8], ['.', 'PUNCT', 1, 'punct', 9]], [['first', 'ADV', 1, 'advmod', 0], ['deployed', 'VERB', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['search', 'NOUN', 2, 'pobj', 3], ['&', 'CCONJ', 3, 'cc', 4], ['rescue', 'NOUN', 3, 'conj', 5], ['in', 'ADP', 3, 'prep', 6], ['houston', 'PROPN', 6, 'pobj', 7], ['for', 'ADP', 3, 'prep', 8], ['#harvey', 'PROPN', 8, 'pobj', 9], ['then', 'ADV', 1, 'advmod', 10], ['to', 'ADP', 1, 'prep', 11], ['florida', 'PROPN', 11, 'pobj', 12], ['for', 'ADP', 1, 'prep', 13], ['#irma', 'PROPN', 13, 'pobj', 14], ['.', 'PUNCT', 1, 'punct', 15]]]\n",
      "candidate 0=houston\n",
      "anchor NE candidates = \n",
      "full parse [[['a', 'DET', 2, 'det', 0], ['hurricane', 'PROPN', 2, 'compound', 1], ['warning', 'PROPN', 5, 'nsubjpass', 2], ['has', 'VERB', 5, 'aux', 3], ['been', 'VERB', 5, 'auxpass', 4], ['issued', 'VERB', 5, 'ROOT', 5], ['for', 'ADP', 5, 'prep', 6], ['puerto', 'PROPN', 9, 'compound', 7], ['rico', 'PROPN', 9, 'compound', 8], ['culebra', 'PROPN', 6, 'pobj', 9], ['and', 'CCONJ', 9, 'cc', 10], ['vieques', 'PROPN', 9, 'conj', 11], ['.', 'PUNCT', 5, 'punct', 12]], [['#maria', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=vieques\n",
      "anchor NE candidates = \n",
      "full parse [[['the', 'DET', 1, 'det', 0], ['status', 'PROPN', 1, 'ROOT', 1], ['of', 'ADP', 1, 'prep', 2], ['our', 'ADJ', 4, 'poss', 3], ['parks', 'PROPN', 2, 'pobj', 4], ['along', 'ADP', 1, 'prep', 5], ['the', 'DET', 7, 'det', 6], ['gulfshore', 'PROPN', 5, 'pobj', 7], ['september', 'PROPN', 1, 'npadvmod', 8], ['2017', 'NUM', 8, 'nummod', 9], ['naples', 'PROPN', 11, 'compound', 10], ['fl', 'PROPN', 12, 'compound', 11], ['#hurricaneirma', 'PUNCT', 8, 'appos', 12]]]\n",
      "candidate 0=naples\n",
      "anchor NE candidates = \n",
      "full parse [[['first', 'ADJ', 1, 'amod', 0], ['band', 'NOUN', 1, 'ROOT', 1], ['of', 'ADP', 1, 'prep', 2], ['#maria', 'NOUN', 2, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['san', 'PROPN', 6, 'compound', 5], ['juan', 'PROPN', 8, 'compound', 6], ['puerto', 'PROPN', 8, 'compound', 7], ['rico', 'PROPN', 4, 'pobj', 8]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['#hurricane', 'X', 1, 'compound', 0], ['warnings', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], [':', 'PUNCT', 2, 'punct', 3], ['u', 'NOUN', 2, 'pobj', 4], ['.', 'PUNCT', 1, 'punct', 5], ['s', 'NOUN', 6, 'ROOT', 6], ['.', 'PUNCT', 6, 'punct', 7], ['virgin', 'PROPN', 9, 'compound', 8], ['islands', 'PROPN', 12, 'compound', 9], ['british', 'ADJ', 12, 'amod', 10], ['virgin', 'PROPN', 12, 'compound', 11], ['islands', 'PROPN', 15, 'compound', 12], ['puerto', 'PROPN', 15, 'compound', 13], ['rico', 'PROPN', 15, 'compound', 14], ['culebra', 'PROPN', 15, 'ROOT', 15], ['and', 'CCONJ', 15, 'cc', 16], ['vieques', 'PROPN', 18, 'compound', 17], ['#maria', 'X', 15, 'conj', 18], ['@680news', 'PROPN', 19, 'ROOT', 19], ['@680news', 'PROPN', 19, 'punct', 20]]]\n",
      "candidate 0=culebra\n",
      "anchor NE candidates = vieques\n",
      "data NE tree=[['culebra', 'PROPN', 15, 'ROOT', 15]]\n",
      "NE=culebra subtree=[['virgin', 'PROPN', 9, 'compound', 8], ['islands', 'PROPN', 12, 'compound', 9], ['british', 'ADJ', 12, 'amod', 10], ['virgin', 'PROPN', 12, 'compound', 11], ['islands', 'PROPN', 15, 'compound', 12], ['puerto', 'PROPN', 15, 'compound', 13], ['rico', 'PROPN', 15, 'compound', 14], ['and', 'CCONJ', 15, 'cc', 16], ['vieques', 'PROPN', 18, 'compound', 17], ['#maria', 'X', 15, 'conj', 18]]\n",
      "min node deps ['compound']\n",
      "candidate 1=vieques\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['this', 'DET', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['how', 'ADV', 6, 'advmod', 2], ['ponce', 'PROPN', 5, 'compound', 3], ['puerto', 'PROPN', 5, 'compound', 4], ['rico', 'PROPN', 6, 'nsubj', 5], ['looked', 'VERB', 1, 'ccomp', 6], ['about', 'ADV', 8, 'advmod', 7], ['30', 'NUM', 9, 'nummod', 8], ['mins', 'NOUN', 10, 'npadvmod', 9], ['ago', 'ADV', 6, 'advmod', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['#maria', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=ponce\n",
      "anchor NE candidates = \n",
      "full parse [[['rt', 'PROPN', 1, 'compound', 0], ['@hurrtrackerapp', 'PROPN', 7, 'dep', 1], [':', 'PUNCT', 7, 'punct', 2], ['breaking', 'VERB', 7, 'ccomp', 3], [':', 'PUNCT', 7, 'punct', 4], ['hurricane', 'PROPN', 6, 'compound', 5], ['#maria', 'PUNCT', 7, 'nsubj', 6], ['makes', 'VERB', 7, 'ROOT', 7], ['landfall', 'NOUN', 7, 'dobj', 8], ['near', 'ADP', 8, 'prep', 9], ['yabucoa', 'PROPN', 12, 'compound', 10], ['puerto', 'PROPN', 12, 'compound', 11], ['rico', 'PROPN', 9, 'pobj', 12], ['as', 'ADP', 7, 'prep', 13], ['a', 'DET', 17, 'det', 14], ['155', 'NUM', 16, 'nummod', 15], ['mph', 'NOUN', 17, 'compound', 16], ['category', 'NOUN', 13, 'pobj', 17], ['4', 'NUM', 19, 'nummod', 18], ['storm', 'NOUN', 17, 'appos', 19], ['.', 'PUNCT', 7, 'punct', 20]]]\n",
      "candidate 0=yabucoa\n",
      "anchor NE candidates = \n",
      "full parse [[['went', 'VERB', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['humacao', 'PROPN', 3, 'compound', 2], ['yabucoa', 'PROPN', 1, 'pobj', 3], ['and', 'CCONJ', 3, 'cc', 4], ['vieques', 'PROPN', 3, 'conj', 5], ['multiple', 'ADJ', 7, 'amod', 6], ['times', 'NOUN', 0, 'npadvmod', 7], ['in', 'ADP', 7, 'prep', 8], ['the', 'DET', 11, 'det', 9], ['mid', 'ADJ', 11, 'amod', 10], ['aughts', 'NOUN', 8, 'pobj', 11], ['.', 'PUNCT', 0, 'punct', 12]], [['so', 'ADV', 1, 'advmod', 0], ['scary', 'ADJ', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['watch', 'VERB', 1, 'xcomp', 3], ['maria', 'PROPN', 3, 'dobj', 4], ['right', 'ADV', 6, 'advmod', 5], ['now', 'ADV', 3, 'advmod', 6], ['#puertorico', 'PUNCT', 7, 'ROOT', 7]]]\n",
      "candidate 0=yabucoa\n",
      "anchor NE candidates = humacao\n",
      "data NE tree=[['yabucoa', 'PROPN', 1, 'pobj', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['yabucoa', 'PROPN', 1, 'pobj', 3]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "NE=yabucoa subtree=[['humacao', 'PROPN', 3, 'compound', 2], ['and', 'CCONJ', 3, 'cc', 4], ['vieques', 'PROPN', 3, 'conj', 5]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 1=humacao\n",
      "anchor NE candidates = \n",
      "candidate 2=vieques\n",
      "anchor NE candidates = yabucoa,humacao\n",
      "data NE tree=[['vieques', 'PROPN', 3, 'conj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['vieques', 'PROPN', 3, 'conj', 5]\n",
      "NE parent token:\n",
      "['yabucoa', 'PROPN', 1, 'pobj', 3]\n",
      "full parse [[['anyone', 'NOUN', 0, 'ROOT', 0], ['having', 'VERB', 0, 'acl', 1], ['luck', 'NOUN', 1, 'dobj', 2], ['connecting', 'VERB', 2, 'acl', 3], ['with', 'ADP', 3, 'prep', 4], ['san', 'PROPN', 6, 'compound', 5], ['juan', 'PROPN', 8, 'compound', 6], ['puerto', 'PROPN', 8, 'compound', 7], ['rico', 'PROPN', 4, 'pobj', 8], ['?', 'PUNCT', 0, 'punct', 9]], [['are', 'VERB', 0, 'ROOT', 0], ['your', 'ADJ', 2, 'poss', 1], ['texts', 'NOUN', 0, 'attr', 2], ['going', 'VERB', 2, 'acl', 3], ['through', 'ADV', 3, 'prt', 4], ['?', 'PUNCT', 0, 'punct', 5]], [['#puertorico', 'PROPN', 0, 'ROOT', 0], ['#sanjuan', 'PROPN', 2, 'compound', 1], ['#hurricanemaria', 'PROPN', 0, 'dobj', 2]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['#maria', 'PUNCT', 0, 'ROOT', 0], ['...', 'PUNCT', 0, 'punct', 1], ['footage', 'NOUN', 0, 'appos', 2], ['from', 'ADP', 2, 'prep', 3], ['guayama', 'PROPN', 6, 'compound', 4], ['puerto', 'PROPN', 6, 'compound', 5], ['rico', 'PROPN', 3, 'pobj', 6], ['#huracanmaria', 'PROPN', 7, 'ROOT', 7], ['#hurricanemaria', 'PROPN', 8, 'ROOT', 8]]]\n",
      "candidate 0=guayama\n",
      "anchor NE candidates = \n",
      "full parse [[['my', 'ADJ', 1, 'poss', 0], ['heart', 'NOUN', 4, 'nsubj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['prayers', 'NOUN', 1, 'conj', 3], ['are', 'VERB', 4, 'ROOT', 4], ['w', 'ADP', 4, 'dep', 5], ['/', 'SYM', 5, 'punct', 6], ['my', 'ADJ', 8, 'poss', 7], ['family', 'NOUN', 5, 'pobj', 8], ['in', 'ADP', 8, 'prep', 9], ['puerto', 'PROPN', 11, 'compound', 10], ['rico', 'PROPN', 9, 'pobj', 11], ['.', 'PUNCT', 4, 'punct', 12]], [['aguadilla', 'PROPN', 1, 'compound', 0], ['moca', 'PROPN', 5, 'compound', 1], ['san', 'PROPN', 3, 'compound', 2], ['sebastian', 'PROPN', 5, 'compound', 3], ['san', 'PROPN', 5, 'compound', 4], ['lorenzo', 'PROPN', 5, 'ROOT', 5], ['&', 'CCONJ', 5, 'cc', 6], ['mayaguez', 'PROPN', 5, 'conj', 7], ['.', 'PUNCT', 5, 'punct', 8]], [['!', 'PUNCT', 0, 'ROOT', 0]], [['#puertoricostrong', 'X', 1, 'advmod', 0], ['#puertorico', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=san sebastian\n",
      "anchor NE candidates = \n",
      "candidate 1=san lorenzo\n",
      "anchor NE candidates = san sebastian\n",
      "data NE tree=[['san', 'PROPN', 5, 'compound', 4], ['lorenzo', 'PROPN', 5, 'ROOT', 5]]\n",
      "NE=san lorenzo subtree=[['aguadilla', 'PROPN', 1, 'compound', 0], ['moca', 'PROPN', 5, 'compound', 1], ['san', 'PROPN', 3, 'compound', 2], ['sebastian', 'PROPN', 5, 'compound', 3], ['&', 'CCONJ', 5, 'cc', 6], ['mayaguez', 'PROPN', 5, 'conj', 7], ['.', 'PUNCT', 5, 'punct', 8]]\n",
      "min node deps ['compound']\n",
      "full parse [[['hurricane', 'PROPN', 1, 'compound', 0], ['#maria', 'X', 2, 'nsubj', 1], ['batters', 'NOUN', 2, 'ROOT', 2], ['san', 'PROPN', 4, 'compound', 3], ['juan', 'PROPN', 6, 'compound', 4], ['puerto', 'PROPN', 6, 'compound', 5], ['rico', 'PROPN', 2, 'dobj', 6], ['with', 'ADP', 2, 'prep', 7], ['strong', 'ADJ', 9, 'amod', 8], ['winds', 'NOUN', 7, 'pobj', 9], ['as', 'ADP', 14, 'mark', 10], ['the', 'DET', 13, 'det', 11], ['powerful', 'ADJ', 13, 'amod', 12], ['storm', 'NOUN', 14, 'nsubj', 13], ['comes', 'VERB', 2, 'advcl', 14], ['ashore', 'ADV', 14, 'advmod', 15], ['.', 'PUNCT', 2, 'punct', 16]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['incredible', 'ADJ', 1, 'amod', 0], ['video', 'NOUN', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['earlier', 'ADJ', 4, 'amod', 3], ['today', 'NOUN', 2, 'pobj', 4], ['of', 'ADP', 2, 'prep', 5], ['the', 'DET', 8, 'det', 6], ['strong', 'ADJ', 8, 'amod', 7], ['winds', 'NOUN', 5, 'pobj', 8], ['and', 'CCONJ', 1, 'cc', 9], ['flooded', 'VERB', 11, 'amod', 10], ['road', 'NOUN', 1, 'conj', 11], ['in', 'ADP', 11, 'prep', 12], ['san', 'PROPN', 14, 'compound', 13], ['juan', 'PROPN', 16, 'compound', 14], ['puerto', 'PROPN', 16, 'compound', 15], ['rico', 'PROPN', 12, 'pobj', 16], ['.', 'PUNCT', 1, 'punct', 17]], [['#maria', 'PUNCT', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['@thehungrycondor', 'X', 0, 'appos', 2]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['our', 'ADJ', 1, 'poss', 0], ['prayers', 'NOUN', 2, 'nsubj', 1], ['are', 'VERB', 2, 'ROOT', 2], ['with', 'ADP', 2, 'prep', 3], ['the', 'DET', 5, 'det', 4], ['staff', 'NOUN', 3, 'pobj', 5], ['and', 'CCONJ', 5, 'cc', 6], ['students', 'NOUN', 5, 'conj', 7], ['of', 'ADP', 7, 'prep', 8], ['um', 'PROPN', 8, 'pobj', 9], ['related', 'VERB', 9, 'acl', 10], ['@robinson_school', 'X', 2, 'punct', 11], ['located', 'VERB', 12, 'ROOT', 12], ['in', 'ADP', 12, 'prep', 13], ['san', 'PROPN', 15, 'compound', 14], ['juan', 'PROPN', 17, 'compound', 15], ['puerto', 'PROPN', 17, 'compound', 16], ['rico', 'PROPN', 13, 'pobj', 17], ['in', 'ADP', 12, 'prep', 18], ['the', 'DET', 20, 'det', 19], ['wake', 'NOUN', 18, 'pobj', 20], ['of', 'ADP', 20, 'prep', 21], ['#hurricanemaria', 'PROPN', 21, 'pobj', 22]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['more', 'DET', 3, 'nsubj', 0], ['destruction', 'NOUN', 2, 'amod', 1], ['photos', 'ADJ', 0, 'obj', 2], ['from', 'NOUN', 3, 'ROOT', 3], ['bayamón', 'PROPN', 3, 'obj', 4], ['guaynabo', 'PROPN', 4, 'flat', 5], ['and', 'PROPN', 4, 'flat', 6], ['san', 'PROPN', 4, 'flat', 7], ['juan', 'PROPN', 4, 'flat', 8], ['#maria', 'PROPN', 3, 'amod', 9]]]\n",
      "candidate 0=guaynabo\n",
      "anchor NE candidates = bayamon\n",
      "data NE tree=[['guaynabo', 'PROPN', 4, 'flat', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['guaynabo', 'PROPN', 4, 'flat', 5]\n",
      "NE parent token:\n",
      "['bayamón', 'PROPN', 3, 'obj', 4]\n",
      "candidate 1=bayamon\n",
      "anchor NE candidates = \n",
      "full parse [[['@weatherchannel', 'PROPN', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['there', 'ADV', 1, 'expl', 2], ['any', 'DET', 4, 'det', 3], ['way', 'NOUN', 1, 'attr', 4], ['we', 'PRON', 7, 'nsubj', 5], ['can', 'VERB', 7, 'aux', 6], ['hear', 'VERB', 4, 'relcl', 7], ['of', 'ADP', 7, 'prep', 8], ['other', 'ADJ', 10, 'amod', 9], ['towns', 'NOUN', 8, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['puerto', 'PROPN', 13, 'compound', 12], ['rico', 'PROPN', 11, 'pobj', 13], ['?', 'PUNCT', 1, 'punct', 14]], [['there', 'ADV', 1, 'expl', 0], ['aren', 'VERB', 1, 'ROOT', 1], ['’', 'X', 3, 'compound', 2], ['t', 'NOUN', 1, 'attr', 3], ['only', 'ADV', 5, 'amod', 4], ['people', 'NOUN', 3, 'dobj', 5], ['in', 'ADP', 5, 'prep', 6], ['san', 'PROPN', 8, 'compound', 7], ['juan', 'PROPN', 6, 'pobj', 8], ['!', 'PUNCT', 1, 'punct', 9]], [['#puertorico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['rt', 'PROPN', 1, 'compound', 0], ['univisionnews', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['exclusive', 'ADJ', 4, 'amod', 3], ['video', 'NOUN', 4, 'ROOT', 4], [':', 'PUNCT', 4, 'punct', 5], ['the', 'DET', 8, 'det', 6], ['devastating', 'ADJ', 8, 'amod', 7], ['path', 'NOUN', 4, 'appos', 8], ['of', 'ADP', 8, 'prep', 9], ['hurricane', 'PROPN', 11, 'compound', 10], ['#maria', 'X', 9, 'pobj', 11], ['across', 'ADP', 8, 'prep', 12], ['#puerto', 'PROPN', 14, 'compound', 13], ['rico', 'PROPN', 12, 'pobj', 14], ['from', 'ADP', 8, 'prep', 15], ['yabucoa', 'PROPN', 15, 'pobj', 16], ['to', 'ADP', 8, 'prep', 17], ['san', 'PROPN', 19, 'compound', 18], ['juan', 'PROPN', 17, 'pobj', 19]]]\n",
      "candidate 0=yabucoa\n",
      "anchor NE candidates = san juan\n",
      "data NE tree=[['yabucoa', 'PROPN', 15, 'pobj', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['yabucoa', 'PROPN', 15, 'pobj', 16]\n",
      "NE parent token:\n",
      "['from', 'ADP', 8, 'prep', 15]\n",
      "candidate 1=san juan\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['seeking', 'VERB', 0, 'ROOT', 0], ['info', 'NOUN', 0, 'dobj', 1], ['on', 'ADP', 1, 'prep', 2], ['my', 'ADJ', 4, 'poss', 3], ['aunt', 'NOUN', 2, 'pobj', 4], ['milly', 'PROPN', 6, 'compound', 5], ['bodon', 'PROPN', 4, 'appos', 6], ['&', 'CCONJ', 6, 'cc', 7], ['luis', 'PROPN', 6, 'conj', 8], ['in', 'ADP', 4, 'prep', 9], ['jayuya', 'PROPN', 12, 'compound', 10], ['puerto', 'PROPN', 12, 'compound', 11], ['rico', 'PROPN', 9, 'pobj', 12], ['(', 'PUNCT', 12, 'punct', 13], ['cuabey', 'PROPN', 12, 'appos', 14], [')', 'PUNCT', 12, 'punct', 15], ['.', 'PUNCT', 0, 'punct', 16]], [['its', 'ADJ', 2, 'poss', 0], ['only', 'ADV', 2, 'advmod', 1], ['accessible', 'ADJ', 2, 'ROOT', 2], ['by', 'ADP', 2, 'prep', 3], ['helicopter.no', 'NOUN', 8, 'amod', 4], ['power', 'NOUN', 7, 'nmod', 5], ['/', 'SYM', 7, 'punct', 6], ['phone', 'NOUN', 8, 'compound', 7], ['#hurricanemaria', 'PROPN', 3, 'pobj', 8]]]\n",
      "candidate 0=jayuya\n",
      "anchor NE candidates = \n",
      "full parse [[['#sanjuan', 'NOUN', 0, 'ROOT', 0], ['#puertorico', 'PROPN', 1, 'ROOT', 1], ['drone', 'NOUN', 3, 'compound', 2], ['footage', 'NOUN', 4, 'nsubj', 3], ['shows', 'VERB', 4, 'ROOT', 4], ['flooded', 'VERB', 6, 'amod', 5], ['streets', 'NOUN', 4, 'dobj', 6], ['in', 'ADP', 6, 'prep', 7], ['san', 'PROPN', 9, 'compound', 8], ['juan', 'PROPN', 11, 'compound', 9], ['puerto', 'PROPN', 11, 'compound', 10], ['rico', 'PROPN', 7, 'pobj', 11], ['after', 'ADP', 6, 'prep', 12], ['hurricane', 'PROPN', 14, 'compound', 13], ['#maria', 'X', 12, 'pobj', 14], ['.', 'PUNCT', 4, 'punct', 15]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['the', 'DET', 2, 'det', 0], ['current', 'ADJ', 2, 'amod', 1], ['photos', 'NOUN', 11, 'nsubj', 2], ['of', 'ADP', 2, 'prep', 3], ['loíza', 'PROPN', 6, 'compound', 4], ['san', 'PROPN', 6, 'compound', 5], ['isidro', 'PROPN', 3, 'pobj', 6], ['&', 'CCONJ', 6, 'cc', 7], ['toa', 'PROPN', 6, 'conj', 8], ['baja', 'NOUN', 3, 'pobj', 9], ['are', 'VERB', 11, 'aux', 10], ['heartbreaking', 'ADJ', 11, 'ROOT', 11], ['!', 'PUNCT', 11, 'punct', 12]], [['the', 'DET', 1, 'det', 0], ['rebuild', 'NOUN', 4, 'nsubj', 1], ['needed', 'VERB', 1, 'acl', 2], ['will', 'VERB', 4, 'aux', 3], ['be', 'VERB', 4, 'ROOT', 4], ['massive', 'ADJ', 7, 'amod', 5], ['#hurricanemaria', 'PROPN', 7, 'compound', 6], ['#puertorico', 'PROPN', 4, 'attr', 7]]]\n",
      "candidate 0=san isidro\n",
      "anchor NE candidates = toa baja\n",
      "data NE tree=[['san', 'PROPN', 6, 'compound', 5], ['isidro', 'PROPN', 3, 'pobj', 6]]\n",
      "NE parse token at tree=0, token=7:\n",
      "['isidro', 'PROPN', 3, 'pobj', 6]\n",
      "NE parent token:\n",
      "['of', 'ADP', 2, 'prep', 3]\n",
      "NE=san isidro subtree=[['loíza', 'PROPN', 6, 'compound', 4], ['&', 'CCONJ', 6, 'cc', 7], ['toa', 'PROPN', 6, 'conj', 8]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 1=toa baja\n",
      "anchor NE candidates = \n",
      "full parse [[['9', 'NUM', 1, 'nummod', 0], ['22', 'NUM', 1, 'ROOT', 1], ['2017', 'NUM', 2, 'ROOT', 2], ['mabu', 'PROPN', 5, 'compound', 3], ['las', 'PROPN', 5, 'compound', 4], ['piedras', 'PROPN', 5, 'ROOT', 5], ['juncos', 'PROPN', 8, 'nmod', 6], ['garabo', 'PROPN', 8, 'nmod', 7], ['caguas', 'PROPN', 5, 'appos', 8], ['southern', 'ADJ', 14, 'amod', 9], ['san', 'PROPN', 11, 'compound', 10], ['juan', 'PROPN', 14, 'compound', 11], ['helicopter', 'PROPN', 14, 'compound', 12], ['video', 'PROPN', 14, 'compound', 13], ['#maria', 'PUNCT', 5, 'appos', 14]]]\n",
      "candidate 0=las piedras\n",
      "anchor NE candidates = caguas,san juan\n",
      "data NE tree=[['las', 'PROPN', 5, 'compound', 4], ['piedras', 'PROPN', 5, 'ROOT', 5]]\n",
      "NE=las piedras subtree=[['mabu', 'PROPN', 5, 'compound', 3], ['juncos', 'PROPN', 8, 'nmod', 6], ['garabo', 'PROPN', 8, 'nmod', 7], ['caguas', 'PROPN', 5, 'appos', 8], ['southern', 'ADJ', 14, 'amod', 9], ['san', 'PROPN', 11, 'compound', 10], ['juan', 'PROPN', 14, 'compound', 11], ['helicopter', 'PROPN', 14, 'compound', 12], ['video', 'PROPN', 14, 'compound', 13], ['#maria', 'PUNCT', 5, 'appos', 14]]\n",
      "min node deps ['compound', 'appos', 'appos']\n",
      "subtree = mabu juncos garabo caguas southern san juan helicopter video #maria\n",
      "candidate 1=caguas\n",
      "anchor NE candidates = san juan\n",
      "data NE tree=[['caguas', 'PROPN', 5, 'appos', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['caguas', 'PROPN', 5, 'appos', 8]\n",
      "NE parent token:\n",
      "['piedras', 'PROPN', 5, 'ROOT', 5]\n",
      "parent node subtree [['mabu', 'PROPN', 5, 'compound', 3], ['las', 'PROPN', 5, 'compound', 4], ['piedras', 'PROPN', 5, 'ROOT', 5], ['juncos', 'PROPN', 8, 'nmod', 6], ['garabo', 'PROPN', 8, 'nmod', 7], ['caguas', 'PROPN', 5, 'appos', 8], ['southern', 'ADJ', 14, 'amod', 9], ['san', 'PROPN', 11, 'compound', 10], ['juan', 'PROPN', 14, 'compound', 11], ['helicopter', 'PROPN', 14, 'compound', 12], ['video', 'PROPN', 14, 'compound', 13], ['#maria', 'PUNCT', 5, 'appos', 14]]\n",
      "parent node subtree str \"mabu las piedras juncos garabo caguas southern san juan helicopter video #maria\"\n",
      "NE=caguas subtree=[['juncos', 'PROPN', 8, 'nmod', 6], ['garabo', 'PROPN', 8, 'nmod', 7]]\n",
      "min node deps ['nmod', 'nmod']\n",
      "candidate 2=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['retweeted', 'VERB', 2, 'compound', 0], ['abc', 'PROPN', 2, 'compound', 1], ['news', 'PROPN', 2, 'ROOT', 2], ['(', 'PUNCT', 2, 'punct', 3], ['@abc', 'PROPN', 2, 'npadvmod', 4], ['):', 'PROPN', 2, 'punct', 5], ['streets', 'PROPN', 12, 'nsubj', 6], ['in', 'ADP', 6, 'prep', 7], ['san', 'PROPN', 9, 'compound', 8], ['juan', 'PROPN', 11, 'compound', 9], ['puerto', 'PROPN', 11, 'compound', 10], ['rico', 'PROPN', 7, 'pobj', 11], ['remain', 'VERB', 12, 'ROOT', 12], ['flooded', 'ADJ', 14, 'amod', 13], ['days', 'NOUN', 12, 'npadvmod', 14], ['after', 'ADP', 17, 'mark', 15], ['#maria', 'NOUN', 17, 'nsubj', 16], ['made', 'VERB', 12, 'advcl', 17], ['landfall', 'NOUN', 17, 'dobj', 18], ['as', 'ADP', 17, 'prep', 19], ['a', 'DET', 19, 'pobj', 20], ['...', 'PUNCT', 12, 'punct', 21]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['update', 'NOUN', 0, 'ROOT', 0], ['on', 'ADP', 0, 'prep', 1], ['#hurricanemaria', 'PROPN', 1, 'pobj', 2], ['.', 'PUNCT', 0, 'punct', 3]], [['my', 'ADJ', 1, 'poss', 0], ['cousin', 'NOUN', 2, 'nsubj', 1], ['drove', 'VERB', 2, 'ROOT', 2], ['to', 'ADP', 2, 'prep', 3], ['#yauco', 'PROPN', 3, 'pobj', 4], ['and', 'CCONJ', 2, 'cc', 5], ['said', 'VERB', 2, 'conj', 6], ['costa', 'PROPN', 13, 'compound', 7], ['sur', 'PROPN', 13, 'compound', 8], ['barinas', 'PROPN', 13, 'compound', 9], ['almácigo', 'PROPN', 13, 'compound', 10], ['palomas', 'PROPN', 13, 'compound', 11], ['la', 'PROPN', 13, 'compound', 12], ['quinta', 'PROPN', 14, 'nsubj', 13], ['are', 'VERB', 6, 'ccomp', 14], ['ok', 'ADJ', 14, 'acomp', 15], ['.', 'PUNCT', 2, 'punct', 16], ['luchetti', 'PROPN', 19, 'nsubjpass', 17], ['is', 'VERB', 19, 'auxpass', 18], ['destroyed', 'VERB', 19, 'ROOT', 19]]]\n",
      "candidate 0=barinas\n",
      "anchor NE candidates = palomas,la quinta\n",
      "data NE tree=[['barinas', 'PROPN', 13, 'compound', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['barinas', 'PROPN', 13, 'compound', 9]\n",
      "NE parent token:\n",
      "['quinta', 'PROPN', 14, 'nsubj', 13]\n",
      "parent node subtree [['costa', 'PROPN', 13, 'compound', 7], ['sur', 'PROPN', 13, 'compound', 8], ['barinas', 'PROPN', 13, 'compound', 9], ['almácigo', 'PROPN', 13, 'compound', 10], ['palomas', 'PROPN', 13, 'compound', 11], ['la', 'PROPN', 13, 'compound', 12], ['quinta', 'PROPN', 14, 'nsubj', 13]]\n",
      "parent node subtree str \"costa sur barinas almácigo palomas la quinta\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=palomas\n",
      "anchor NE candidates = la quinta\n",
      "data NE tree=[['palomas', 'PROPN', 13, 'compound', 11]]\n",
      "NE parse token at tree=1, token=12:\n",
      "['palomas', 'PROPN', 13, 'compound', 11]\n",
      "NE parent token:\n",
      "['quinta', 'PROPN', 14, 'nsubj', 13]\n",
      "parent node subtree [['costa', 'PROPN', 13, 'compound', 7], ['sur', 'PROPN', 13, 'compound', 8], ['barinas', 'PROPN', 13, 'compound', 9], ['almácigo', 'PROPN', 13, 'compound', 10], ['palomas', 'PROPN', 13, 'compound', 11], ['la', 'PROPN', 13, 'compound', 12], ['quinta', 'PROPN', 14, 'nsubj', 13]]\n",
      "parent node subtree str \"costa sur barinas almácigo palomas la quinta\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 2=la quinta\n",
      "anchor NE candidates = \n",
      "full parse [[['vega', 'PROPN', 1, 'compound', 0], ['alta', 'PROPN', 11, 'nsubj', 1], ['a', 'DET', 5, 'det', 2], ['40', 'NUM', 4, 'nummod', 3], ['min', 'NOUN', 5, 'compound', 4], ['drive', 'NOUN', 1, 'appos', 5], ['from', 'ADP', 5, 'prep', 6], ['san', 'PROPN', 8, 'compound', 7], ['juan', 'PROPN', 6, 'pobj', 8], ['has', 'VERB', 11, 'aux', 9], ['not', 'ADV', 11, 'neg', 10], ['seen', 'VERB', 11, 'ROOT', 11], ['aid', 'NOUN', 11, 'dobj', 12], ['a', 'DET', 14, 'det', 13], ['week', 'NOUN', 11, 'npadvmod', 14], ['after', 'ADP', 11, 'prep', 15], ['#maria', 'X', 15, 'pobj', 16], ['.', 'PUNCT', 11, 'punct', 17]], [['hospital', 'NOUN', 0, 'ROOT', 0], ['on', 'ADP', 0, 'prep', 1], ['verge', 'NOUN', 1, 'pobj', 2], ['of', 'ADP', 2, 'prep', 3], ['shutting', 'VERB', 3, 'pcomp', 4], ['down', 'PART', 4, 'prt', 5], ['.', 'PUNCT', 0, 'punct', 6]]]\n",
      "candidate 0=vega alta\n",
      "anchor NE candidates = san juan\n",
      "data NE tree=[['vega', 'PROPN', 1, 'compound', 0], ['alta', 'PROPN', 11, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['alta', 'PROPN', 11, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['seen', 'VERB', 11, 'ROOT', 11]\n",
      "NE=vega alta subtree=[['a', 'DET', 5, 'det', 2], ['40', 'NUM', 4, 'nummod', 3], ['min', 'NOUN', 5, 'compound', 4], ['drive', 'NOUN', 1, 'appos', 5], ['from', 'ADP', 5, 'prep', 6], ['san', 'PROPN', 8, 'compound', 7], ['juan', 'PROPN', 6, 'pobj', 8]]\n",
      "min node deps ['appos']\n",
      "subtree = a 40 min drive from san juan\n",
      "candidate 1=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['toa', 'PROPN', 3, 'compound', 0], ['alta', 'PROPN', 3, 'compound', 1], ['puerto', 'PROPN', 3, 'compound', 2], ['rico', 'PROPN', 3, 'ROOT', 3], [':', 'PUNCT', 3, 'punct', 4], ['a', 'DET', 6, 'det', 5], ['cyclist', 'NOUN', 7, 'nsubj', 6], ['rides', 'VERB', 7, 'ROOT', 7], ['over', 'ADP', 7, 'prep', 8], ['a', 'DET', 10, 'det', 9], ['bridge', 'NOUN', 8, 'pobj', 10], ['damaged', 'VERB', 10, 'acl', 11], ['by', 'ADP', 11, 'agent', 12], ['#hurricanemaria', 'PROPN', 12, 'pobj', 13], ['.', 'PUNCT', 7, 'punct', 14]], [['photograph', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['ricardo', 'PROPN', 5, 'nmod', 2], ['arduengo', 'PROPN', 5, 'nmod', 3], ['/', 'SYM', 5, 'punct', 4], ['afp', 'PROPN', 5, 'ROOT', 5], ['#climatechange', 'PROPN', 7, 'compound', 6], ['#capitalism', 'X', 7, 'ROOT', 7]]]\n",
      "candidate 0=toa alta\n",
      "anchor NE candidates = \n",
      "full parse [[['puerto', 'PROPN', 1, 'nmod', 0], ['rico', 'PROPN', 3, 'amod', 1], ['humanitarian', 'ADJ', 3, 'amod', 2], ['crisis', 'NOUN', 5, 'nsubj', 3], ['trump', 'NOUN', 3, 'appos', 4], ['talking', 'VERB', 5, 'ROOT', 5], ['about', 'ADP', 5, 'prep', 6], ['wall', 'PROPN', 8, 'compound', 7], ['street', 'PROPN', 6, 'pobj', 8], ['+', 'PUNCT', 8, 'cc', 9], ['banks', 'NOUN', 8, 'conj', 10], ['san', 'PROPN', 12, 'compound', 11], ['juan', 'PROPN', 13, 'compound', 12], ['mayor', 'PROPN', 13, 'ROOT', 13], ['carmen', 'PROPN', 15, 'compound', 14], ['yulin', 'PROPN', 17, 'compound', 15], ['cruz', 'PROPN', 17, 'compound', 16], ['#maria', 'PUNCT', 17, 'ROOT', 17]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['#puertorico', 'PROPN', 7, 'dep', 0], ['some', 'DET', 2, 'det', 1], ['towns', 'NOUN', 7, 'nsubj', 2], ['in', 'ADP', 2, 'prep', 3], ['puerto', 'PROPN', 5, 'compound', 4], ['rico', 'PROPN', 3, 'pobj', 5], ['have', 'VERB', 7, 'aux', 6], ['been', 'VERB', 7, 'ROOT', 7], ['able', 'ADJ', 7, 'acomp', 8], ['to', 'PART', 10, 'aux', 9], ['set', 'VERB', 8, 'xcomp', 10], ['up', 'PART', 10, 'prt', 11], ['hotlines', 'NOUN', 10, 'dobj', 12], ['to', 'PART', 14, 'aux', 13], ['find', 'VERB', 10, 'advcl', 14], ['family', 'NOUN', 14, 'dobj', 15], [':', 'PUNCT', 7, 'punct', 16], ['san', 'PROPN', 18, 'compound', 17], ['juan', 'PROPN', 7, 'npadvmod', 18], ['787 294 0277', 'NUM', 18, 'nummod', 19], ['...', 'PUNCT', 7, 'punct', 20]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['from', 'ADP', 0, 'ROOT', 0], ['the', 'DET', 6, 'det', 1], ['san', 'PROPN', 3, 'compound', 2], ['juan', 'PROPN', 6, 'compound', 3], ['puerto', 'PROPN', 5, 'compound', 4], ['rico', 'PROPN', 6, 'compound', 5], ['mayor', 'NOUN', 0, 'pobj', 6], ['.', 'PUNCT', 0, 'punct', 7]], [['heart', 'NOUN', 0, 'ROOT', 0], ['wrenching', 'ADJ', 0, 'amod', 1], ['.', 'PUNCT', 0, 'punct', 2]], [['#puertorico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['trump', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['if', 'ADP', 9, 'mark', 2], ['the', 'DET', 4, 'det', 3], ['mayor', 'NOUN', 9, 'nsubj', 4], ['of', 'ADP', 4, 'prep', 5], ['san', 'PROPN', 7, 'compound', 6], ['juan', 'PROPN', 5, 'pobj', 7], [\"doesn't\", 'ADV', 9, 'aux', 8], ['start', 'VERB', 9, 'ROOT', 9], ['praising', 'VERB', 9, 'xcomp', 10], ['me', 'PRON', 10, 'dobj', 11], [\"i'll\", 'PROPN', 13, 'nsubj', 12], ['pull', 'VERB', 10, 'ccomp', 13], ['all', 'DET', 16, 'compound', 14], ['relief', 'NOUN', 16, 'compound', 15], ['efforts', 'NOUN', 13, 'dobj', 16], ['from', 'ADP', 16, 'prep', 17], ['puerto', 'PROPN', 19, 'compound', 18], ['rico', 'PROPN', 17, 'pobj', 19], ['.', 'PUNCT', 9, 'punct', 20]], [['@realdonaldtrump', 'X', 0, 'ROOT', 0], ['#maga', 'PUNCT', 1, 'ROOT', 1], ['#puertorico', 'PROPN', 2, 'ROOT', 2]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['dodges', 'VERB', 0, 'ROOT', 0], ['the', 'DET', 3, 'det', 1], ['draft', 'NOUN', 3, 'compound', 2], ['attacks', 'NOUN', 0, 'dobj', 3], ['john', 'PROPN', 5, 'compound', 4], ['mccain', 'PROPN', 3, 'appos', 5], ['.', 'PUNCT', 0, 'punct', 6]], [['plays', 'VERB', 8, 'nsubj', 0], ['golf', 'NOUN', 0, 'dobj', 1], ['in', 'ADP', 0, 'prep', 2], ['nj', 'PROPN', 5, 'compound', 3], ['attacks', 'NOUN', 5, 'compound', 4], ['mayor', 'NOUN', 2, 'pobj', 5], ['of', 'ADP', 5, 'prep', 6], ['hurricane', 'NOUN', 6, 'pobj', 7], ['ravaged', 'VERB', 8, 'ROOT', 8], ['san', 'PROPN', 10, 'compound', 9], ['juan', 'PROPN', 8, 'dobj', 10], ['.', 'PUNCT', 8, 'punct', 11]], [['#puertorico', 'PROPN', 2, 'compound', 0], ['#weakness', 'PROPN', 2, 'compound', 1], ['#trump', 'PUNCT', 2, 'ROOT', 2]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['can', 'VERB', 3, 'aux', 0], ['we', 'PRON', 3, 'nsubj', 1], ['please', 'INTJ', 3, 'intj', 2], ['help', 'VERB', 3, 'ROOT', 3], ['puerto', 'PROPN', 5, 'compound', 4], ['rico', 'PROPN', 3, 'dobj', 5], ['?', 'PUNCT', 3, 'punct', 6]], [['mayor', 'PROPN', 6, 'nsubj', 0], ['of', 'ADP', 0, 'prep', 1], ['san', 'PROPN', 3, 'compound', 2], ['juan', 'PROPN', 1, 'pobj', 3], ['is', 'VERB', 6, 'aux', 4], ['literally', 'ADV', 6, 'advmod', 5], ['begging', 'VERB', 6, 'ROOT', 6], ['for', 'ADP', 6, 'prep', 7], ['aid', 'NOUN', 7, 'pobj', 8], ['!', 'PUNCT', 6, 'punct', 9]], [['instead', 'ADV', 1, 'advmod', 0], ['of', 'ADP', 4, 'prep', 1], ['helping', 'VERB', 1, 'pcomp', 2], ['@realdonaldtrump', 'PUNCT', 2, 'dobj', 3], ['is', 'VERB', 4, 'ROOT', 4], ['golfing', 'VERB', 4, 'attr', 5], ['!', 'PUNCT', 4, 'punct', 6]], [['#puertorico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['wow', 'INTJ', 2, 'intj', 0], ['@potus', 'PROPN', 2, 'nsubj', 1], ['tries', 'VERB', 15, 'ccomp', 2], ['to', 'PART', 4, 'aux', 3], ['help', 'VERB', 2, 'xcomp', 4], ['puerto', 'PROPN', 6, 'compound', 5], ['rico', 'PROPN', 4, 'dobj', 6], ['and', 'CCONJ', 6, 'cc', 7], ['all', 'ADJ', 10, 'predet', 8], ['the', 'DET', 10, 'det', 9], ['mayor', 'NOUN', 6, 'conj', 10], ['of', 'ADP', 10, 'prep', 11], ['san', 'PROPN', 13, 'compound', 12], ['juan', 'PROPN', 11, 'pobj', 13], ['can', 'VERB', 15, 'aux', 14], ['say', 'VERB', 15, 'ROOT', 15], ['is', 'VERB', 15, 'ccomp', 16], ['how', 'ADV', 18, 'advmod', 17], ['bad', 'ADJ', 20, 'acomp', 18], ['he', 'PRON', 20, 'nsubj', 19], ['is', 'VERB', 16, 'ccomp', 20], ['.', 'PUNCT', 15, 'punct', 21]], [['thanks', 'NOUN', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['nothing', 'NOUN', 1, 'pobj', 2], ['i', 'PRON', 4, 'nsubj', 3], ['guess', 'VERB', 2, 'relcl', 4], ['.', 'PUNCT', 0, 'punct', 5]], [['#puertorico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['we', 'PRON', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['on', 'ADP', 1, 'prep', 2], ['the', 'DET', 4, 'det', 3], ['ground', 'NOUN', 2, 'pobj', 4], ['delivering', 'VERB', 4, 'acl', 5], ['food', 'PROPN', 5, 'dobj', 6], ['helping', 'VERB', 1, 'advcl', 7], ['our', 'ADJ', 9, 'poss', 8], ['people', 'NOUN', 7, 'dobj', 9], ['in', 'ADP', 7, 'prep', 10], ['#puertorico', 'PROPN', 10, 'pobj', 11], ['this', 'DET', 13, 'det', 12], ['weekend', 'NOUN', 7, 'npadvmod', 13], ['toa', 'PROPN', 17, 'compound', 14], ['baja', 'PROPN', 17, 'compound', 15], ['morovis', 'PROPN', 17, 'compound', 16], ['orocovis', 'PROPN', 17, 'ROOT', 17], ['.', 'PUNCT', 17, 'punct', 18]], [['@feedingamerica', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=morovis\n",
      "anchor NE candidates = toa baja\n",
      "data NE tree=[['morovis', 'PROPN', 17, 'compound', 16]]\n",
      "NE parse token at tree=0, token=17:\n",
      "['morovis', 'PROPN', 17, 'compound', 16]\n",
      "NE parent token:\n",
      "['orocovis', 'PROPN', 17, 'ROOT', 17]\n",
      "parent node subtree [['toa', 'PROPN', 17, 'compound', 14], ['baja', 'PROPN', 17, 'compound', 15], ['morovis', 'PROPN', 17, 'compound', 16], ['orocovis', 'PROPN', 17, 'ROOT', 17], ['.', 'PUNCT', 17, 'punct', 18]]\n",
      "parent node subtree str \"toa baja morovis orocovis .\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=toa baja\n",
      "anchor NE candidates = \n",
      "candidate 2=orocovis\n",
      "anchor NE candidates = morovis,toa baja\n",
      "data NE tree=[['orocovis', 'PROPN', 17, 'ROOT', 17]]\n",
      "NE=orocovis subtree=[['toa', 'PROPN', 17, 'compound', 14], ['baja', 'PROPN', 17, 'compound', 15], ['morovis', 'PROPN', 17, 'compound', 16], ['.', 'PUNCT', 17, 'punct', 18]]\n",
      "min node deps ['compound', 'compound', 'compound', 'punct']\n",
      "full parse [[['president', 'PROPN', 1, 'compound', 0], ['@realdonaldtrump', 'PROPN', 9, 'nsubj', 1], ['the', 'DET', 3, 'det', 2], ['mayor', 'PROPN', 1, 'appos', 3], ['of', 'ADP', 3, 'prep', 4], ['san', 'PROPN', 6, 'compound', 5], ['juan', 'PROPN', 4, 'pobj', 6], ['does', 'VERB', 9, 'aux', 7], ['not', 'ADV', 9, 'neg', 8], ['represent', 'VERB', 9, 'ROOT', 9], ['the', 'DET', 11, 'det', 10], ['majority', 'NOUN', 9, 'dobj', 11], ['in', 'ADP', 11, 'prep', 12], ['puerto', 'PROPN', 14, 'compound', 13], ['rico', 'PROPN', 12, 'pobj', 14], ['.', 'PUNCT', 9, 'punct', 15]], [['thanks', 'NOUN', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['your', 'ADJ', 3, 'poss', 2], ['support', 'NOUN', 1, 'pobj', 3], ['.', 'PUNCT', 0, 'punct', 4]], [['#puertorico', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['pres', 'PROPN', 1, 'compound', 0], ['trump', 'PROPN', 2, 'nsubj', 1], ['expected', 'VERB', 2, 'ROOT', 2], ['to', 'PART', 4, 'aux', 3], ['travel', 'VERB', 2, 'xcomp', 4], ['to', 'ADP', 4, 'prep', 5], ['puerto', 'PROPN', 7, 'compound', 6], ['rico', 'PROPN', 8, 'compound', 7], ['tom', 'NOUN', 5, 'pobj', 8], ['as', 'ADP', 10, 'mark', 9], ['scheduled', 'VERB', 4, 'advcl', 10], ['to', 'ADP', 12, 'aux', 11], ['survey', 'PROPN', 10, 'xcomp', 12], ['damage', 'NOUN', 12, 'dobj', 13], ['from', 'ADP', 13, 'prep', 14], ['#maria', 'NOUN', 14, 'pobj', 15], ['.', 'PUNCT', 2, 'punct', 16]], [['then', 'ADV', 1, 'advmod', 0], ['heads', 'NOUN', 1, 'ROOT', 1], ['to', 'ADP', 1, 'prep', 2], ['vegas', 'PROPN', 2, 'pobj', 3], ['on', 'ADP', 1, 'prep', 4], ['wed', 'PROPN', 4, 'pobj', 5], ['.', 'PUNCT', 1, 'punct', 6], ['#vegasshooting', 'X', 7, 'ROOT', 7]]]\n",
      "candidate 0=vegas\n",
      "anchor NE candidates = \n",
      "full parse [[['eye', 'NOUN', 0, 'ROOT', 0], ['of', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['storm', 'NOUN', 1, 'pobj', 3], [':', 'PUNCT', 0, 'punct', 4], ['a', 'DET', 6, 'det', 5], ['dispatch', 'NOUN', 0, 'appos', 6], ['from', 'ADP', 6, 'prep', 7], ['san', 'PROPN', 9, 'compound', 8], ['juan', 'PROPN', 11, 'compound', 9], ['puerto', 'PROPN', 11, 'compound', 10], ['rico', 'PROPN', 7, 'pobj', 11], ['by', 'ADP', 6, 'prep', 12], ['@sodapopcomics', 'NOUN', 12, 'pobj', 13]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['our', 'ADJ', 1, 'poss', 0], ['potus', 'NOUN', 2, 'nsubj', 1], ['is', 'VERB', 15, 'ccomp', 2], ['in', 'ADP', 2, 'prep', 3], ['guaynabo', 'PROPN', 3, 'pobj', 4], ['one', 'NUM', 4, 'nummod', 5], ['of', 'ADP', 5, 'prep', 6], ['the', 'DET', 9, 'det', 7], ['wealthiest', 'ADJ', 9, 'amod', 8], ['towns', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['puerto', 'PROPN', 12, 'compound', 11], ['rico', 'PROPN', 10, 'pobj', 12], ['does', 'VERB', 15, 'aux', 13], ['anyone', 'NOUN', 15, 'nsubj', 14], ['know', 'VERB', 15, 'ROOT', 15], ['if', 'ADP', 18, 'mark', 16], ['he', 'PRON', 18, 'nsubj', 17], ['plans', 'VERB', 15, 'advcl', 18], ['to', 'PART', 20, 'aux', 19], ['go', 'VERB', 18, 'xcomp', 20], ['out', 'ADP', 20, 'prep', 21], ['of', 'ADP', 21, 'prep', 22], ['san', 'PROPN', 24, 'compound', 23], ['juan', 'PROPN', 22, 'pobj', 24], ['?', 'PUNCT', 15, 'punct', 25], ['?', 'PUNCT', 15, 'punct', 26]], [['#hurricanemaria', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=guaynabo\n",
      "anchor NE candidates = san juan\n",
      "data NE tree=[['guaynabo', 'PROPN', 3, 'pobj', 4]]\n",
      "NE parse token at tree=0, token=5:\n",
      "['guaynabo', 'PROPN', 3, 'pobj', 4]\n",
      "NE parent token:\n",
      "['in', 'ADP', 2, 'prep', 3]\n",
      "NE=guaynabo subtree=[['one', 'NUM', 4, 'nummod', 5], ['of', 'ADP', 5, 'prep', 6], ['the', 'DET', 9, 'det', 7], ['wealthiest', 'ADJ', 9, 'amod', 8], ['towns', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['puerto', 'PROPN', 12, 'compound', 11], ['rico', 'PROPN', 10, 'pobj', 12]]\n",
      "min node deps ['nummod']\n",
      "subtree = one of the wealthiest towns in puerto rico\n",
      "candidate 1=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['welcome', 'VERB', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['pr', 'PROPN', 3, 'compound', 2], ['mr', 'PROPN', 1, 'pobj', 3], ['.', 'PUNCT', 0, 'punct', 4], ['president', 'PROPN', 6, 'nsubj', 5], ['@old', 'PROPN', 6, 'ROOT', 6], ['san', 'PROPN', 8, 'compound', 7], ['juan', 'PROPN', 10, 'compound', 8], ['puerto', 'PROPN', 10, 'compound', 9], ['rico', 'PROPN', 6, 'dobj', 10], ['.', 'PUNCT', 6, 'punct', 11]], [['@realdonaldtrump', 'X', 0, 'ROOT', 0], ['#puertorico', 'PROPN', 1, 'ROOT', 1], ['#huracanmaria', 'PROPN', 3, 'compound', 2], ['#trumpbully', 'ADV', 3, 'ROOT', 3]]]\n",
      "candidate 0=san juan\n",
      "anchor NE candidates = \n",
      "full parse [[['photos', 'NOUN', 0, 'ROOT', 0], ['of', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['land', 'NOUN', 1, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['front', 'NOUN', 4, 'pobj', 5], ['of', 'ADP', 5, 'prep', 6], ['my', 'ADJ', 9, 'poss', 7], [\"family's\", 'ADJ', 9, 'compound', 8], ['house', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['cidra', 'PROPN', 13, 'compound', 11], ['puerto', 'PROPN', 13, 'compound', 12], ['rico', 'PROPN', 10, 'pobj', 13], ['.', 'PUNCT', 0, 'punct', 14]], [['my', 'ADJ', 1, 'poss', 0], ['heart', 'NOUN', 2, 'nsubj', 1], ['continues', 'VERB', 2, 'ROOT', 2], ['to', 'PART', 2, 'prep', 3], ['ache', 'VERB', 3, 'pobj', 4], ['for', 'ADP', 4, 'prep', 5], ['my', 'ADJ', 7, 'poss', 6], ['people', 'NOUN', 5, 'pobj', 7], ['@puertoricopur', 'ADP', 2, 'punct', 8], ['#maria', 'PUNCT', 9, 'ROOT', 9]]]\n",
      "candidate 0=cidra\n",
      "anchor NE candidates = \n",
      "full parse [[['watch', 'VERB', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['a', 'DET', 5, 'det', 2], ['cg', 'PROPN', 5, 'compound', 3], ['aircrew', 'NOUN', 5, 'compound', 4], ['air', 'NOUN', 6, 'nsubj', 5], ['drops', 'VERB', 0, 'acl', 6], ['much', 'ADV', 8, 'advmod', 7], ['needed', 'VERB', 9, 'amod', 8], ['supplies', 'NOUN', 6, 'dobj', 9], ['to', 'ADP', 6, 'prep', 10], ['the', 'DET', 12, 'det', 11], ['residents', 'NOUN', 10, 'pobj', 12], ['of', 'ADP', 12, 'prep', 13], ['utuado', 'PROPN', 16, 'compound', 14], ['puerto', 'PROPN', 16, 'compound', 15], ['rico', 'PROPN', 13, 'pobj', 16], ['after', 'ADP', 19, 'mark', 17], ['#hurricanemaria', 'PROPN', 19, 'nsubj', 18], ['left', 'VERB', 6, 'advcl', 19], ['them', 'PRON', 19, 'dobj', 20], ['stranded', 'VERB', 0, 'acl', 21]]]\n",
      "candidate 0=utuado\n",
      "anchor NE candidates = \n",
      "full parse [[['st', 'PROPN', 2, 'compound', 0], ['john', 'PROPN', 2, 'compound', 1], ['st', 'PROPN', 4, 'compound', 2], ['croix', 'PROPN', 4, 'compound', 3], ['st', 'PROPN', 7, 'compound', 4], ['thomas', 'PROPN', 7, 'compound', 5], ['water', 'PROPN', 7, 'compound', 6], ['island', 'PROPN', 11, 'compound', 7], ['puerto', 'PROPN', 9, 'compound', 8], ['rico', 'PROPN', 11, 'compound', 9], ['culebra', 'PROPN', 11, 'compound', 10], ['vieques', 'PROPN', 12, 'nsubj', 11], ['are', 'VERB', 12, 'ROOT', 12], ['all', 'DET', 15, 'det', 13], ['us', 'PROPN', 15, 'compound', 14], ['territories', 'NOUN', 12, 'attr', 15], ['&', 'CCONJ', 15, 'cc', 16], ['all', 'DET', 15, 'conj', 17], ['need', 'VERB', 12, 'conj', 18], ['help', 'NOUN', 18, 'dobj', 19], ['!', 'PUNCT', 12, 'punct', 20]], [['#hurricanemaria', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=culebra\n",
      "anchor NE candidates = vieques\n",
      "data NE tree=[['culebra', 'PROPN', 11, 'compound', 10]]\n",
      "NE parse token at tree=0, token=11:\n",
      "['culebra', 'PROPN', 11, 'compound', 10]\n",
      "NE parent token:\n",
      "['vieques', 'PROPN', 12, 'nsubj', 11]\n",
      "parent node subtree [['st', 'PROPN', 2, 'compound', 0], ['john', 'PROPN', 2, 'compound', 1], ['st', 'PROPN', 4, 'compound', 2], ['croix', 'PROPN', 4, 'compound', 3], ['st', 'PROPN', 7, 'compound', 4], ['thomas', 'PROPN', 7, 'compound', 5], ['water', 'PROPN', 7, 'compound', 6], ['island', 'PROPN', 11, 'compound', 7], ['puerto', 'PROPN', 9, 'compound', 8], ['rico', 'PROPN', 11, 'compound', 9], ['culebra', 'PROPN', 11, 'compound', 10], ['vieques', 'PROPN', 12, 'nsubj', 11]]\n",
      "parent node subtree str \"st john st croix st thomas water island puerto rico culebra vieques\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=vieques\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['rt', 'PROPN', 1, 'compound', 0], ['@edvalleewx', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['our', 'ADJ', 4, 'poss', 3], ['models', 'NOUN', 10, 'nsubj', 4], ['specifically', 'ADV', 6, 'advmod', 5], ['used', 'VERB', 4, 'acl', 6], ['for', 'ADP', 6, 'prep', 7], ['forecasting', 'VERB', 7, 'pcomp', 8], ['hurricanes', 'NOUN', 8, 'dobj', 9], ['have', 'VERB', 10, 'ROOT', 10], ['great', 'ADJ', 12, 'amod', 11], ['agreement', 'NOUN', 10, 'dobj', 12], ['in', 'ADP', 12, 'prep', 13], ['#florence', 'NOUN', 15, 'nsubj', 14], ['making', 'VERB', 13, 'pcomp', 15], ['landfall', 'NOUN', 15, 'dobj', 16], ['near', 'ADP', 16, 'prep', 17], ['new', 'PROPN', 20, 'compound', 18], ['bern', 'PROPN', 20, 'compound', 19], ['nc', 'PROPN', 17, 'pobj', 20], ['…', 'PUNCT', 10, 'punct', 21]]]\n",
      "candidate 0=new bern\n",
      "anchor NE candidates = \n",
      "full parse [[['rt', 'PROPN', 1, 'compound', 0], ['@wmo', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['hurricane', 'PROPN', 4, 'compound', 3], ['#florence', 'PROPN', 5, 'nsubj', 4], ['is', 'VERB', 5, 'ROOT', 5], ['likely', 'ADJ', 5, 'acomp', 6], ['to', 'PART', 8, 'aux', 7], ['make', 'VERB', 6, 'xcomp', 8], ['landfall', 'NOUN', 8, 'dobj', 9], ['near', 'ADP', 9, 'prep', 10], ['wilmington', 'PROPN', 10, 'pobj', 11], ['(', 'PUNCT', 11, 'punct', 12], ['north', 'PROPN', 14, 'compound', 13], ['carolina', 'PROPN', 11, 'appos', 14], [')', 'PUNCT', 11, 'punct', 15], ['.', 'PUNCT', 5, 'punct', 16]], [['the', 'DET', 2, 'det', 0], ['tidal', 'ADJ', 2, 'amod', 1], ['data', 'NOUN', 3, 'nsubj', 2], ['shows', 'VERB', 3, 'ROOT', 3], ['a', 'DET', 7, 'det', 4], ['sea', 'NOUN', 6, 'compound', 5], ['level', 'NOUN', 7, 'compound', 6], ['rise', 'NOUN', 3, 'dobj', 7], ['of', 'ADP', 7, 'prep', 8], ['around', 'ADP', 8, 'pobj', 9], ['…', 'PUNCT', 3, 'punct', 10]]]\n",
      "candidate 0=wilmington\n",
      "anchor NE candidates = \n",
      "full parse [[['rt', 'PROPN', 1, 'compound', 0], ['@abc', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['latest', 'PROPN', 1, 'appos', 3], [':', 'PUNCT', 1, 'punct', 4], ['hurricane', 'PROPN', 6, 'compound', 5], ['#florence', 'PROPN', 6, 'ROOT', 6], ['a', 'DET', 10, 'det', 7], ['category', 'NOUN', 10, 'nmod', 8], ['4', 'NUM', 8, 'nummod', 9], ['storm', 'NOUN', 6, 'appos', 10], ['670', 'NUM', 12, 'nummod', 11], ['miles', 'NOUN', 10, 'appos', 12], ['ese', 'PROPN', 10, 'appos', 13], ['of', 'ADP', 13, 'prep', 14], ['cape', 'PROPN', 16, 'compound', 15], ['fear', 'PROPN', 18, 'compound', 16], ['north', 'PROPN', 18, 'compound', 17], ['carolina', 'PROPN', 14, 'pobj', 18], ['with', 'ADP', 10, 'prep', 19], ['maximum', 'ADJ', 22, 'amod', 20], ['sustained', 'ADJ', 22, 'amod', 21], ['winds', 'NOUN', 19, 'pobj', 22], ['of', 'ADP', 22, 'prep', 23], ['140', 'NUM', 25, 'nummod', 24], ['mph', 'NOUN', 23, 'pobj', 25], ['…', 'PUNCT', 6, 'punct', 26]]]\n",
      "candidate 0=cape fear\n",
      "anchor NE candidates = \n",
      "full parse [[['you', 'PRON', 1, 'nsubj', 0], ['put', 'VERB', 15, 'ccomp', 1], ['your', 'ADJ', 3, 'poss', 2], ['lips', 'NOUN', 1, 'dobj', 3], ['on', 'ADP', 1, 'prep', 4], ['them', 'PRON', 4, 'pobj', 5], ['cigars', 'NOUN', 1, 'dobj', 6], ['more', 'ADJ', 1, 'advmod', 7], ['than', 'ADP', 10, 'mark', 8], ['you', 'PRON', 10, 'nsubj', 9], ['do', 'VERB', 7, 'advcl', 10], ['on', 'ADP', 1, 'prep', 11], ['me', 'PRON', 11, 'pobj', 12], ['\"', 'PUNCT', 15, 'punct', 13], ['gf', 'PROPN', 15, 'nsubj', 14], ['says', 'VERB', 15, 'ROOT', 15], ['.', 'PUNCT', 15, 'punct', 16]], [['#cigar', 'PROPN', 1, 'compound', 0], ['#lastselfie', 'PROPN', 2, 'compound', 1], ['#sotl', 'PROPN', 2, 'ROOT', 2], ['#botl', 'PROPN', 4, 'compound', 3], ['#hurricaneflorence', 'PROPN', 2, 'appos', 4], ['@', 'ADP', 2, 'punct', 5], ['fayetteville', 'PROPN', 8, 'compound', 6], ['north', 'PROPN', 8, 'compound', 7], ['carolina', 'PROPN', 8, 'ROOT', 8]]]\n",
      "candidate 0=fayetteville\n",
      "anchor NE candidates = \n",
      "full parse [[['rt', 'PROPN', 0, 'ROOT', 0], ['@foxnewsresearch', 'PROPN', 0, 'punct', 1], [':', 'PUNCT', 0, 'punct', 2], ['#hurricaneflorence', 'PROPN', 6, 'nmod', 3], ['latest', 'ADJ', 6, 'amod', 4], ['•', 'PROPN', 6, 'nmod', 5], ['cat', 'PROPN', 6, 'ROOT', 6], ['2', 'NUM', 6, 'nummod', 7], ['•', 'NOUN', 6, 'appos', 8], ['170', 'NUM', 11, 'nummod', 9], ['mi', 'ADP', 11, 'compound', 10], ['ese', 'PROPN', 6, 'appos', 11], ['of', 'ADP', 11, 'prep', 12], ['wilmington', 'PROPN', 14, 'compound', 13], ['nc', 'PROPN', 12, 'pobj', 14], ['•', 'PROPN', 6, 'appos', 15], ['220', 'NUM', 18, 'nummod', 16], ['mi', 'ADP', 18, 'compound', 17], ['e', 'NOUN', 6, 'appos', 18], ['of', 'ADP', 18, 'prep', 19], ['myrtle', 'PROPN', 21, 'compound', 20], ['beach', 'PROPN', 22, 'compound', 21], ['sc', 'PROPN', 19, 'pobj', 22], ['•', 'NUM', 24, 'compound', 23], ['10m', 'NUM', 29, 'npadvmod', 24], ['+', 'CCONJ', 24, 'cc', 25], ['in', 'ADP', 29, 'prep', 26], ['its', 'ADJ', 28, 'poss', 27], ['path', 'NOUN', 26, 'pobj', 28], ['•', 'NOUN', 29, 'ROOT', 29], ['1.7', 'NUM', 31, 'nummod', 30], ['m', 'NOUN', 31, 'ROOT', 31], ['…', 'NOUN', 31, 'punct', 32]]]\n",
      "candidate 0=wilmington\n",
      "anchor NE candidates = \n",
      "candidate 1=myrtle beach\n",
      "anchor NE candidates = wilmington\n",
      "data NE tree=[['myrtle', 'PROPN', 21, 'compound', 20], ['beach', 'PROPN', 22, 'compound', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['beach', 'PROPN', 22, 'compound', 21]\n",
      "NE parent token:\n",
      "['sc', 'PROPN', 19, 'pobj', 22]\n",
      "parent node subtree [['myrtle', 'PROPN', 21, 'compound', 20], ['beach', 'PROPN', 22, 'compound', 21], ['sc', 'PROPN', 19, 'pobj', 22]]\n",
      "parent node subtree str \"myrtle beach sc\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "full parse [[['met', 'PROPN', 1, 'compound', 0], ['reyna', 'PROPN', 1, 'ROOT', 1], ['and', 'CCONJ', 1, 'cc', 2], ['her', 'ADJ', 5, 'poss', 3], ['whole', 'ADJ', 5, 'amod', 4], ['family', 'NOUN', 1, 'conj', 5], ['who', 'NOUN', 7, 'nsubj', 6], ['evacuated', 'VERB', 5, 'relcl', 7], ['from', 'ADP', 7, 'prep', 8], ['the', 'DET', 10, 'det', 9], ['coast', 'NOUN', 8, 'pobj', 10], ['to', 'ADP', 7, 'prep', 11], ['a', 'DET', 15, 'det', 12], ['red', 'PROPN', 14, 'compound', 13], ['cross', 'PROPN', 15, 'compound', 14], ['shelter', 'NOUN', 11, 'pobj', 15], ['in', 'ADP', 15, 'prep', 16], ['wilson', 'PROPN', 18, 'compound', 17], ['nc', 'PROPN', 16, 'pobj', 18], ['.', 'PUNCT', 1, 'punct', 19]], [['she', 'PRON', 1, 'nsubj', 0], ['says', 'VERB', 1, 'ROOT', 1], ['they', 'PRON', 3, 'nsubj', 2], ['left', 'VERB', 1, 'ccomp', 3], ['everything', 'NOUN', 3, 'dobj', 4], ['behind', 'ADV', 3, 'prt', 5], ['so', 'ADP', 9, 'mark', 6], ['they', 'PRON', 9, 'nsubj', 7], ['are', 'VERB', 9, 'aux', 8], ['hoping', 'VERB', 3, 'advcl', 9], ['to', 'PART', 11, 'aux', 10], ['have', 'VERB', 9, 'xcomp', 11], ['something', 'NOUN', 11, 'dobj', 12], ['to', 'PART', 14, 'aux', 13], ['go', 'VERB', 12, 'relcl', 14], ['back', 'ADV', 14, 'advmod', 15], ['to', 'ADP', 15, 'prep', 16], ['.', 'PUNCT', 1, 'punct', 17]], [['#hurricaneflorence', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=red cross\n",
      "anchor NE candidates = \n",
      "full parse [[['update', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['the', 'DET', 3, 'det', 2], ['@wafflehouse', 'NOUN', 8, 'nsubj', 3], ['in', 'ADP', 3, 'prep', 4], ['north', 'PROPN', 6, 'compound', 5], ['myrtle', 'PROPN', 7, 'compound', 6], ['beach', 'PROPN', 4, 'pobj', 7], ['remains', 'VERB', 8, 'ROOT', 8], ['open', 'ADJ', 8, 'acomp', 9], ['this', 'DET', 11, 'det', 10], ['morning', 'NOUN', 8, 'npadvmod', 11], ['even', 'ADV', 15, 'advmod', 12], ['as', 'ADP', 15, 'mark', 13], ['#hurricaneflorence', 'PROPN', 15, 'nsubj', 14], ['bears', 'VERB', 8, 'advcl', 15], ['down', 'PART', 15, 'prt', 16], ['.', 'PUNCT', 8, 'punct', 17]], [['and', 'CCONJ', 4, 'cc', 0], ['who', 'NOUN', 4, 'dobj', 1], ['do', 'VERB', 4, 'aux', 2], ['i', 'PRON', 4, 'nsubj', 3], ['meet', 'VERB', 4, 'ROOT', 4], ['?', 'PUNCT', 4, 'punct', 5]], [['barrett', 'PROPN', 0, 'ROOT', 0], ['the', 'DET', 3, 'det', 1], ['tenacious', 'ADJ', 3, 'amod', 2], ['employee', 'NOUN', 0, 'appos', 3], ['from', 'ADP', 3, 'prep', 4], ['shallotte', 'PROPN', 4, 'pobj', 5], ['who', 'NOUN', 7, 'nsubj', 6], ['refused', 'VERB', 3, 'relcl', 7], ['to', 'PART', 9, 'aux', 8], ['shut', 'VERB', 7, 'xcomp', 9], ['down', 'PART', 9, 'prt', 10], ['as', 'ADV', 12, 'advmod', 11], ['long', 'ADV', 9, 'advmod', 12], ['as', 'ADP', 15, 'mark', 13], ['@bojangles1977', 'NOUN', 15, 'nsubj', 14], ['was', 'VERB', 12, 'advcl', 15], ['still', 'ADV', 15, 'advmod', 16], ['slingin', 'NOUN', 19, 'compound', 17], ['’', 'NUM', 19, 'compound', 18], ['hash', 'NOUN', 15, 'attr', 19], ['.', 'PUNCT', 0, 'punct', 20]]]\n",
      "candidate 0=shallotte\n",
      "anchor NE candidates = myrtle beach\n",
      "data NE tree=[['shallotte', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=2, token=6:\n",
      "['shallotte', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['from', 'ADP', 3, 'prep', 4]\n",
      "candidate 1=myrtle beach\n",
      "anchor NE candidates = \n",
      "full parse [[['fast', 'ADJ', 1, 'amod', 0], ['move', 'NOUN', 1, 'ROOT', 1], ['ng', 'NOUN', 4, 'nmod', 2], ['low', 'ADJ', 4, 'amod', 3], ['clouds', 'NOUN', 1, 'dobj', 4], ['and', 'CCONJ', 4, 'cc', 5], ['trees', 'NOUN', 4, 'conj', 6], ['starting', 'VERB', 1, 'advcl', 7], ['to', 'PART', 9, 'aux', 8], ['dance', 'VERB', 7, 'xcomp', 9], ['!', 'PUNCT', 1, 'punct', 10]], [['#florence', 'PROPN', 0, 'ROOT', 0], ['@', 'ADP', 0, 'prep', 1], ['kensington', 'PROPN', 2, 'ROOT', 2], ['at', 'ADP', 2, 'prep', 3], ['regency', 'PROPN', 5, 'compound', 4], ['cary', 'PROPN', 3, 'pobj', 5]]]\n",
      "candidate 0=kensington\n",
      "anchor NE candidates = cary\n",
      "data NE tree=[['kensington', 'PROPN', 2, 'ROOT', 2]]\n",
      "NE=kensington subtree=[['at', 'ADP', 2, 'prep', 3], ['regency', 'PROPN', 5, 'compound', 4], ['cary', 'PROPN', 3, 'pobj', 5]]\n",
      "min node deps ['prep']\n",
      "subtree = at regency cary\n",
      "candidate 1=cary\n",
      "anchor NE candidates = \n",
      "full parse [[['#hurricaneflorence', 'PROPN', 6, 'meta', 0], ['#sunsetbeachnc', 'PROPN', 3, 'compound', 1], ['#oceanislebeach', 'PROPN', 3, 'compound', 2], ['#northcarolina', 'PROPN', 6, 'nmod', 3], ['#sup', 'PUNCT', 3, 'appos', 4], ['#veterinary', 'ADJ', 6, 'amod', 5], ['@wildearthpets', 'NOUN', 7, 'nsubj', 6], ['lauraw', 'NOUN', 7, 'ROOT', 7], ['1717', 'NUM', 10, 'nummod', 8], ['madisonwardd', 'NOUN', 10, 'compound', 9], ['_taylor_51', 'PROPN', 7, 'appos', 10], ['@', 'PUNCT', 7, 'punct', 11], ['sunset', 'PROPN', 13, 'compound', 12], ['beach', 'PROPN', 15, 'compound', 13], ['north', 'PROPN', 15, 'compound', 14], ['carolina', 'PROPN', 15, 'ROOT', 15]]]\n",
      "candidate 0=sunset beach\n",
      "anchor NE candidates = \n",
      "full parse [[['morehead', 'PROPN', 1, 'compound', 0], ['city', 'PROPN', 2, 'compound', 1], ['nc', 'PROPN', 3, 'nsubj', 2], ['decimated', 'VERB', 3, 'ROOT', 3], ['by', 'ADP', 3, 'agent', 4], ['#hurricaneflorence', 'PROPN', 4, 'pobj', 5], ['with', 'ADP', 3, 'prep', 6], ['@dukeenergy', 'PUNCT', 8, 'nmod', 7], ['experts', 'NOUN', 9, 'nsubj', 8], ['doing', 'VERB', 6, 'pcomp', 9], ['damage', 'NOUN', 11, 'compound', 10], ['assessments', 'NOUN', 9, 'dobj', 11], ['—', 'NUM', 3, 'punct', 12], ['saying', 'VERB', 3, 'advcl', 13], ['it', 'PRON', 16, 'nsubj', 14], ['’', 'NOUN', 16, 'nsubj', 15], ['s', 'VERB', 13, 'ccomp', 16], ['the', 'DET', 18, 'det', 17], ['worst', 'ADJ', 16, 'attr', 18], ['they', 'PRON', 20, 'nmod', 19], ['’', 'NOUN', 22, 'nsubj', 20], ['ve', 'VERB', 22, 'aux', 21], ['seen', 'VERB', 18, 'relcl', 22], ['.', 'PUNCT', 3, 'punct', 23]], [['flooded', 'ADJ', 1, 'amod', 0], ['areas', 'NOUN', 3, 'nsubj', 1], ['will', 'VERB', 3, 'aux', 2], ['make', 'VERB', 3, 'ROOT', 3], ['accessing', 'VERB', 8, 'csubj', 4], ['our', 'ADJ', 6, 'poss', 5], ['equipment', 'NOUN', 4, 'dobj', 6], ['extremely', 'ADV', 8, 'advmod', 7], ['difficult', 'ADJ', 3, 'ccomp', 8], ['.', 'PUNCT', 3, 'punct', 9]], [['stay', 'VERB', 0, 'ROOT', 0], ['safe', 'ADJ', 2, 'amod', 1], ['stay', 'NOUN', 0, 'npadvmod', 2], ['informed', 'ADJ', 2, 'acomp', 3], ['.', 'PUNCT', 0, 'punct', 4]]]\n",
      "candidate 0=morehead city\n",
      "anchor NE candidates = \n",
      "full parse [[['walking', 'VERB', 0, 'ROOT', 0], ['around', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['development', 'NOUN', 1, 'pobj', 3], ['so', 'ADV', 5, 'advmod', 4], ['far', 'ADV', 7, 'advmod', 5], ['so', 'ADV', 7, 'advmod', 6], ['good', 'ADJ', 0, 'acomp', 7], ['regarding', 'VERB', 7, 'prep', 8], ['#florence', 'NOUN', 8, 'pobj', 9], ['.', 'PUNCT', 0, 'punct', 10]], [['just', 'ADV', 2, 'advmod', 0], ['some', 'DET', 2, 'det', 1], ['branches', 'NOUN', 2, 'ROOT', 2], ['&', 'CCONJ', 2, 'cc', 3], ['pine', 'NOUN', 5, 'compound', 4], ['needles', 'NOUN', 2, 'conj', 5], ['down', 'PART', 2, 'prt', 6], ['.', 'PUNCT', 2, 'punct', 7]], [['#southcarolina', 'PROPN', 1, 'compound', 0], ['#murrellsinlet', 'PROPN', 2, 'nmod', 1], ['#nofilter', 'PROPN', 2, 'ROOT', 2], ['#scwx', 'PROPN', 4, 'compound', 3], ['#wx', 'PROPN', 2, 'appos', 4], ['@', 'PUNCT', 4, 'prep', 5], ['murrells', 'PROPN', 9, 'compound', 6], ['inlet', 'PROPN', 9, 'compound', 7], ['south', 'PROPN', 9, 'compound', 8], ['carolina', 'PROPN', 9, 'ROOT', 9]]]\n",
      "candidate 0=murrells inlet\n",
      "anchor NE candidates = \n",
      "full parse [[['the', 'DET', 1, 'det', 0], ['edge', 'NOUN', 1, 'ROOT', 1], ['of', 'ADP', 1, 'prep', 2], ['hurricane', 'PROPN', 4, 'compound', 3], ['florence', 'PROPN', 2, 'pobj', 4], ['#hurricaneflorence', 'NOUN', 6, 'nsubj', 5], ['moving', 'VERB', 6, 'ROOT', 6], ['into', 'ADP', 6, 'prep', 7], ['georgia', 'PROPN', 7, 'pobj', 8], ['.', 'PUNCT', 6, 'punct', 9]], [['@', 'ADP', 0, 'ROOT', 0], ['suwanee', 'PROPN', 2, 'compound', 1], ['georgia', 'PROPN', 0, 'pobj', 2]]]\n",
      "candidate 0=suwanee\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['late', 'ADJ', 1, 'amod', 0], ['dinner', 'NOUN', 1, 'ROOT', 1], ['for', 'ADP', 1, 'prep', 2], ['linemen', 'NOUN', 2, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['maxton', 'PROPN', 6, 'compound', 5], ['nc', 'PROPN', 4, 'pobj', 6], ['tonight', 'NOUN', 1, 'npadvmod', 7], ['.', 'PUNCT', 1, 'punct', 8]], [['it', 'PRON', 1, 'nsubj', 0], ['’', 'VERB', 1, 'ROOT', 1], ['s', 'VERB', 1, 'case', 2], ['windy', 'ADJ', 1, 'amod', 3], ['and', 'CCONJ', 3, 'cc', 4], ['rainy', 'ADJ', 3, 'conj', 5], ['but', 'CCONJ', 1, 'cc', 6], ['the', 'DET', 8, 'det', 7], ['base', 'NOUN', 9, 'nsubj', 8], ['camp', 'NOUN', 1, 'conj', 9], ['up', 'PART', 9, 'prt', 10], ['and', 'CCONJ', 10, 'cc', 11], ['operational', 'ADJ', 10, 'conj', 12], ['and', 'CCONJ', 9, 'cc', 13], ['is', 'VERB', 9, 'conj', 14], ['able', 'ADJ', 14, 'acomp', 15], ['to', 'PART', 17, 'aux', 16], ['get', 'VERB', 15, 'xcomp', 17], ['crews', 'NOUN', 21, 'nsubj', 18], ['a', 'DET', 21, 'det', 19], ['hot', 'ADJ', 21, 'amod', 20], ['meal', 'NOUN', 17, 'dobj', 21], ['.', 'PUNCT', 9, 'punct', 22]], [['#hurricaneflorence2018', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=maxton\n",
      "anchor NE candidates = \n",
      "full parse [[['downtown', 'NOUN', 2, 'compound', 0], ['new', 'PROPN', 2, 'compound', 1], ['bern', 'PROPN', 5, 'compound', 2], ['north', 'PROPN', 4, 'compound', 3], ['carolina', 'PROPN', 5, 'compound', 4], ['#florence', 'ADP', 5, 'ROOT', 5], ['#1010wins', 'PROPN', 7, 'compound', 6], ['#newbernstrong', 'X', 5, 'appos', 7]]]\n",
      "candidate 0=new bern\n",
      "anchor NE candidates = \n",
      "full parse [[['#hurricaneflorence', 'PROPN', 1, 'nsubj', 0], ['update', 'NOUN', 1, 'ROOT', 1], ['!', 'PUNCT', 1, 'punct', 2]], [['@', 'ADP', 0, 'ROOT', 0], ['charlotte', 'PROPN', 3, 'compound', 1], ['north', 'PROPN', 3, 'compound', 2], ['carolina', 'PROPN', 3, 'ROOT', 3]]]\n",
      "candidate 0=charlotte\n",
      "anchor NE candidates = \n",
      "full parse [[['@bentonblount', 'PROPN', 2, 'compound', 0], ['lincolnton', 'PROPN', 2, 'compound', 1], ['nc', 'PROPN', 2, 'ROOT', 2], ['still', 'ADV', 4, 'advmod', 3], ['okay', 'INTJ', 4, 'ROOT', 4], ['!', 'PUNCT', 4, 'punct', 5]], [['also', 'ADV', 6, 'advmod', 0], ['our', 'ADJ', 5, 'poss', 1], ['little', 'ADJ', 5, 'amod', 2], ['holden', 'PROPN', 5, 'compound', 3], ['beach', 'NOUN', 5, 'compound', 4], ['home', 'NOUN', 6, 'nsubj', 5], ['survived', 'VERB', 6, 'ROOT', 6], ['.', 'PUNCT', 6, 'punct', 7]], [['bought', 'VERB', 0, 'ROOT', 0], ['with', 'ADP', 0, 'prep', 1], ['the', 'DET', 4, 'det', 2], ['retirement', 'NOUN', 4, 'compound', 3], ['money', 'NOUN', 1, 'pobj', 4], ['from', 'ADP', 0, 'prep', 5], ['a', 'DET', 9, 'det', 6], ['36', 'NUM', 8, 'nummod', 7], ['year', 'NOUN', 9, 'compound', 8], ['cop', 'PROPN', 5, 'pobj', 9], ['.', 'PUNCT', 0, 'punct', 10]], [['..', 'PUNCT', 2, 'punct', 0], ['my', 'ADJ', 2, 'poss', 1], ['hubby', 'NOUN', 2, 'ROOT', 2], ['!', 'PUNCT', 2, 'punct', 3]], [['#hurricaneflorence2018', 'PROPN', 1, 'compound', 0], ['#policewife', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=holden beach\n",
      "anchor NE candidates = \n",
      "full parse [[['hermight', 'PROPN', 0, 'ROOT', 0], ['&', 'CCONJ', 0, 'cc', 1], ['mercy', 'PROPN', 0, 'conj', 2], ['...', 'PUNCT', 4, 'punct', 3], ['captured', 'VERB', 0, 'acl', 4], ['in', 'ADP', 4, 'prep', 5], ['jacksonville', 'PROPN', 7, 'compound', 6], ['nc', 'PROPN', 5, 'pobj', 7], ['.', 'PUNCT', 4, 'punct', 8]], [['large', 'ADJ', 1, 'amod', 0], ['oak', 'NOUN', 2, 'nsubj', 1], ['uprooted', 'VERB', 2, 'ROOT', 2], ['but', 'CCONJ', 2, 'cc', 3], ['small', 'ADJ', 6, 'amod', 4], ['chicken', 'NOUN', 6, 'compound', 5], ['coop', 'NOUN', 7, 'nsubj', 6], ['left', 'VERB', 2, 'conj', 7], ['in', 'ADP', 7, 'prep', 8], ['exact', 'ADJ', 10, 'amod', 9], ['spot', 'NOUN', 8, 'pobj', 10], ['!', 'PUNCT', 7, 'punct', 11]], [['3', 'NUM', 1, 'nummod', 0], ['hens', 'NOUN', 3, 'nsubj', 1], ['left', 'VERB', 1, 'acl', 2], ['nestled', 'VERB', 3, 'ROOT', 3], ['together', 'ADV', 3, 'advmod', 4], ['w', 'ADP', 3, 'prep', 5], ['additional', 'ADJ', 7, 'amod', 6], ['shelter', 'NOUN', 5, 'pobj', 7], ['.', 'PUNCT', 3, 'punct', 8]], [['amazing', 'ADJ', 0, 'ROOT', 0], ['!', 'PUNCT', 0, 'punct', 1]], [['#hurricaneflorencenc', 'PROPN', 1, 'compound', 0], ['#florence', 'PROPN', 1, 'ROOT', 1], ['#jacksonvillenc', 'PUNCT', 2, 'ROOT', 2]]]\n",
      "candidate 0=jacksonville\n",
      "anchor NE candidates = \n",
      "full parse [[['we', 'PRON', 1, 'nsubj', 0], ['didn', 'VERB', 1, 'ROOT', 1], ['’', 'NOUN', 3, 'compound', 2], ['t', 'NOUN', 4, 'nsubj', 3], ['think', 'VERB', 1, 'ccomp', 4], ['it', 'PRON', 7, 'nsubj', 5], ['would', 'VERB', 7, 'aux', 6], ['be', 'VERB', 4, 'ccomp', 7], ['this', 'DET', 9, 'advmod', 8], ['bad', 'ADJ', 10, 'amod', 9], ['#hurricaneflorence', 'NOUN', 7, 'attr', 10], ['@', 'ADP', 1, 'punct', 11], ['lumberton', 'PROPN', 14, 'compound', 12], ['north', 'PROPN', 14, 'compound', 13], ['carolina', 'PROPN', 14, 'ROOT', 14]]]\n",
      "candidate 0=lumberton\n",
      "anchor NE candidates = \n",
      "full parse [[['deputies', 'NOUN', 7, 'nsubj', 0], ['from', 'ADP', 0, 'prep', 1], ['the', 'DET', 6, 'det', 2], ['rockingham', 'PROPN', 4, 'compound', 3], ['county', 'PROPN', 6, 'compound', 4], [\"sheriff's\", 'PROPN', 6, 'compound', 5], ['office', 'PROPN', 1, 'pobj', 6], ['are', 'VERB', 7, 'ROOT', 7], ['here', 'ADV', 7, 'advmod', 8], ['in', 'ADP', 7, 'prep', 9], ['kinston', 'PROPN', 11, 'compound', 10], ['nc', 'PROPN', 9, 'pobj', 11], ['helping', 'VERB', 7, 'advcl', 12], ['out', 'PART', 12, 'prt', 13], ['with', 'ADP', 12, 'prep', 14], ['issues', 'NOUN', 14, 'pobj', 15], ['caused', 'VERB', 15, 'acl', 16], ['by', 'ADP', 16, 'agent', 17], ['#flooding', 'VERB', 17, 'pobj', 18], ['.', 'PUNCT', 7, 'punct', 19]], [['#hurricaneflorence', 'PROPN', 1, 'compound', 0], ['#kinstonnc', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=kinston\n",
      "anchor NE candidates = \n",
      "full parse [[['homes', 'NOUN', 8, 'nsubj', 0], ['in', 'ADP', 0, 'prep', 1], ['the', 'DET', 4, 'det', 2], ['mayfair', 'PROPN', 4, 'compound', 3], ['neighborhood', 'NOUN', 1, 'pobj', 4], ['of', 'ADP', 4, 'prep', 5], ['lumberton', 'PROPN', 7, 'compound', 6], ['nc', 'PROPN', 5, 'pobj', 7], ['are', 'VERB', 8, 'ROOT', 8], ['underwater', 'ADJ', 8, 'acomp', 9], ['again', 'ADV', 8, 'advmod', 10], ['after', 'ADP', 8, 'prep', 11], ['being', 'VERB', 13, 'auxpass', 12], ['flooded', 'VERB', 11, 'pcomp', 13], ['in', 'ADP', 13, 'prep', 14], ['2016', 'NUM', 14, 'pobj', 15], ['during', 'ADP', 13, 'prep', 16], ['hurricane', 'PROPN', 18, 'compound', 17], ['matthew', 'PROPN', 16, 'pobj', 18], ['..', 'PUNCT', 8, 'punct', 19], ['and', 'CCONJ', 8, 'cc', 20], ['water', 'NOUN', 22, 'compound', 21], ['levels', 'NOUN', 23, 'nsubj', 22], ['continue', 'VERB', 8, 'conj', 23], ['to', 'PART', 25, 'aux', 24], ['rise', 'VERB', 23, 'xcomp', 25], ['.', 'PUNCT', 23, 'punct', 26]], [['#hurricaneflorence', 'PROPN', 2, 'compound', 0], ['#lumbertonnc', 'PROPN', 2, 'compound', 1], ['#northcarolina', 'PROPN', 2, 'ROOT', 2], ['#lumberriver', 'PROPN', 2, 'appos', 3], ['@thenowtv', 'PROPN', 2, 'punct', 4]]]\n",
      "candidate 0=mayfair\n",
      "anchor NE candidates = lumberton\n",
      "data NE tree=[['mayfair', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=0, token=4:\n",
      "['mayfair', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['neighborhood', 'NOUN', 1, 'pobj', 4]\n",
      "parent node subtree [['the', 'DET', 4, 'det', 2], ['mayfair', 'PROPN', 4, 'compound', 3], ['neighborhood', 'NOUN', 1, 'pobj', 4], ['of', 'ADP', 4, 'prep', 5], ['lumberton', 'PROPN', 7, 'compound', 6], ['nc', 'PROPN', 5, 'pobj', 7]]\n",
      "parent node subtree str \"the mayfair neighborhood of lumberton nc\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=lumberton\n",
      "anchor NE candidates = \n",
      "full parse [[['the', 'DET', 2, 'det', 0], ['little', 'PROPN', 2, 'compound', 1], ['river', 'PROPN', 14, 'nsubj', 2], ['in', 'ADP', 2, 'prep', 3], ['manchester', 'PROPN', 5, 'compound', 4], ['nc', 'PROPN', 3, 'pobj', 5], ['near', 'ADP', 2, 'prep', 6], ['spring', 'PROPN', 8, 'compound', 7], ['lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#fayettevillenc', 'PROPN', 11, 'pobj', 12], ['has', 'VERB', 14, 'aux', 13], ['hit', 'VERB', 14, 'ROOT', 14], ['a', 'DET', 17, 'det', 15], ['record', 'NOUN', 17, 'compound', 16], ['level', 'NOUN', 14, 'dobj', 17], ['according', 'VERB', 14, 'prep', 18], ['to', 'ADP', 18, 'prep', 19], ['@nws', 'X', 19, 'pobj', 20], ['.', 'PUNCT', 14, 'punct', 21]], [['river', 'NOUN', 0, 'ROOT', 0], ['at', 'ADP', 0, 'prep', 1], ['34.96', 'NUM', 3, 'nummod', 2], ['ft', 'NOUN', 1, 'pobj', 3], ['as', 'ADP', 0, 'prep', 4], ['of', 'ADP', 4, 'prep', 5], ['3:30', 'NUM', 7, 'nummod', 6], ['pm', 'NOUN', 5, 'pobj', 7], ['monday', 'PROPN', 0, 'npadvmod', 8], ['.', 'PUNCT', 0, 'punct', 9]], [['during', 'ADP', 10, 'prep', 0], ['hurricane', 'PROPN', 2, 'compound', 1], ['matthew', 'PROPN', 0, 'pobj', 2], ['(', 'PUNCT', 7, 'punct', 3], ['previous', 'ADJ', 7, 'advmod', 4], ['all', 'DET', 6, 'det', 5], ['time', 'NOUN', 7, 'npadvmod', 6], ['high', 'ADJ', 2, 'appos', 7], [')', 'PUNCT', 7, 'punct', 8], ['it', 'PRON', 10, 'nsubj', 9], ['reached', 'VERB', 10, 'ROOT', 10], ['32.19', 'NUM', 12, 'nummod', 11], ['ft', 'NOUN', 10, 'dobj', 12], ['.', 'PUNCT', 10, 'punct', 13], ['#florence', 'X', 15, 'compound', 14], ['#ncwx', 'PROPN', 15, 'ROOT', 15], ['@newsobserver', 'X', 15, 'punct', 16]]]\n",
      "candidate 0=little river\n",
      "anchor NE candidates = manchester,spring lake\n",
      "data NE tree=[['little', 'PROPN', 2, 'compound', 1], ['river', 'PROPN', 14, 'nsubj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['river', 'PROPN', 14, 'nsubj', 2]\n",
      "NE parent token:\n",
      "['hit', 'VERB', 14, 'ROOT', 14]\n",
      "NE=little river subtree=[['the', 'DET', 2, 'det', 0], ['in', 'ADP', 2, 'prep', 3], ['manchester', 'PROPN', 5, 'compound', 4], ['nc', 'PROPN', 3, 'pobj', 5], ['near', 'ADP', 2, 'prep', 6], ['spring', 'PROPN', 8, 'compound', 7], ['lake', 'PROPN', 6, 'pobj', 8], ['and', 'CCONJ', 6, 'cc', 9], ['upstream', 'NOUN', 6, 'conj', 10], ['from', 'ADP', 10, 'prep', 11], ['#fayettevillenc', 'PROPN', 11, 'pobj', 12]]\n",
      "min node deps ['det', 'prep', 'prep']\n",
      "subtree = the in manchester nc near spring lake and upstream from #fayettevillenc\n",
      "candidate 1=manchester\n",
      "anchor NE candidates = \n",
      "candidate 2=spring lake\n",
      "anchor NE candidates = manchester\n",
      "data NE tree=[['spring', 'PROPN', 8, 'compound', 7], ['lake', 'PROPN', 6, 'pobj', 8]]\n",
      "NE parse token at tree=0, token=9:\n",
      "['lake', 'PROPN', 6, 'pobj', 8]\n",
      "NE parent token:\n",
      "['near', 'ADP', 2, 'prep', 6]\n",
      "full parse [[['road', 'PROPN', 1, 'compound', 0], ['closure', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['another', 'DET', 4, 'det', 3], ['closure', 'NOUN', 6, 'nsubj', 4], ['just', 'ADV', 6, 'advmod', 5], ['added', 'VERB', 6, 'ROOT', 6], ['to', 'ADP', 6, 'prep', 7], ['the', 'DET', 9, 'det', 8], ['list', 'NOUN', 7, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['union', 'PROPN', 12, 'compound', 11], ['county', 'PROPN', 10, 'pobj', 12], ['.', 'PUNCT', 6, 'punct', 13]], [['this', 'DET', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['on', 'ADP', 1, 'prep', 2], ['chesnut', 'PROPN', 4, 'compound', 3], ['lane', 'PROPN', 2, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['indian', 'PROPN', 7, 'compound', 6], ['trail', 'PROPN', 5, 'pobj', 7], ['.', 'PUNCT', 1, 'punct', 8]], [['the', 'DET', 1, 'det', 0], ['area', 'NOUN', 3, 'nsubjpass', 1], ['was', 'VERB', 3, 'auxpass', 2], ['flooded', 'VERB', 3, 'ROOT', 3], ['yesterday', 'NOUN', 3, 'npadvmod', 4], ['.', 'PUNCT', 3, 'punct', 5]], [['today', 'NOUN', 0, 'ROOT', 0], ['...', 'PUNCT', 0, 'punct', 1]], [['this', 'DET', 0, 'ROOT', 0], ['.', 'PUNCT', 0, 'punct', 1]], [['@wsoctv', 'ADV', 1, 'compound', 0], ['#florence', 'X', 1, 'ROOT', 1]]]\n",
      "candidate 0=indian trail\n",
      "anchor NE candidates = union county\n",
      "data NE tree=[['indian', 'PROPN', 7, 'compound', 6], ['trail', 'PROPN', 5, 'pobj', 7]]\n",
      "NE parse token at tree=1, token=8:\n",
      "['trail', 'PROPN', 5, 'pobj', 7]\n",
      "NE parent token:\n",
      "['in', 'ADP', 4, 'prep', 5]\n",
      "candidate 1=union county\n",
      "anchor NE candidates = \n",
      "full parse [[['the', 'DET', 1, 'det', 0], ['remains', 'NOUN', 4, 'nsubj', 1], ['of', 'ADP', 1, 'prep', 2], ['#florence', 'NOUN', 2, 'pobj', 3], ['spared', 'VERB', 4, 'ROOT', 4], ['rochester', 'PROPN', 4, 'dobj', 5], ['.', 'PUNCT', 4, 'punct', 6]], [['however', 'ADV', 4, 'advmod', 0], [\"it's\", 'ADJ', 4, 'poss', 1], ['a', 'DET', 4, 'det', 2], ['different', 'ADJ', 4, 'amod', 3], ['story', 'NOUN', 4, 'ROOT', 4], ['from', 'ADP', 4, 'prep', 5], ['ithaca', 'PROPN', 5, 'pobj', 6], ['to', 'ADP', 4, 'prep', 7], ['oneonta', 'PROPN', 7, 'pobj', 8], ['.', 'PUNCT', 4, 'punct', 9]], [['3', 'NUM', 2, 'quantmod', 0], ['to', 'ADP', 2, 'quantmod', 1], ['4', 'NUM', 8, 'nsubj', 2], ['\"', 'PUNCT', 2, 'punct', 3], ['\"', 'PUNCT', 2, 'punct', 4], ['of', 'ADP', 2, 'prep', 5], ['rain', 'NOUN', 5, 'pobj', 6], ['has', 'VERB', 8, 'aux', 7], ['fallen', 'VERB', 8, 'ROOT', 8], ['from', 'ADP', 8, 'prep', 9], ['chemung', 'PROPN', 9, 'pobj', 10], ['to', 'ADP', 8, 'prep', 11], ['southern', 'ADJ', 13, 'amod', 12], ['cortland', 'PROPN', 14, 'compound', 13], ['counties', 'NOUN', 11, 'pobj', 14], ['.', 'PUNCT', 8, 'punct', 15]], [['flood', 'PROPN', 1, 'compound', 0], ['warnings', 'PROPN', 2, 'nsubj', 1], ['are', 'VERB', 2, 'ROOT', 2], ['up', 'ADV', 2, 'advmod', 3], ['for', 'ADP', 2, 'prep', 4], ['some', 'DET', 4, 'pobj', 5], ['there', 'ADV', 2, 'advmod', 6], ['.', 'PUNCT', 2, 'punct', 7]]]\n",
      "candidate 0=ithaca\n",
      "anchor NE candidates = \n",
      "full parse [[['yesterday', 'NOUN', 3, 'npadvmod', 0], ['our', 'ADJ', 2, 'poss', 1], ['crews', 'NOUN', 3, 'nsubj', 2], ['teamed', 'VERB', 3, 'ROOT', 3], ['up', 'PART', 3, 'prt', 4], ['with', 'ADP', 3, 'prep', 5], ['@insidefpl', 'NOUN', 5, 'pobj', 6], ['to', 'PART', 8, 'aux', 7], ['assess', 'VERB', 3, 'advcl', 8], ['damage', 'NOUN', 8, 'dobj', 9], ['throughout', 'ADP', 9, 'prep', 10], ['columbus', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['bladen', 'PROPN', 11, 'conj', 13], ['counties', 'NOUN', 10, 'pobj', 14], ['in', 'ADP', 14, 'prep', 15], ['north', 'PROPN', 17, 'compound', 16], ['carolina', 'PROPN', 15, 'pobj', 17], ['.', 'PUNCT', 3, 'punct', 18]], [['crews', 'NOUN', 1, 'nsubj', 0], ['continue', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['work', 'VERB', 1, 'xcomp', 3], ['through', 'ADP', 3, 'prep', 4], ['challenging', 'ADJ', 6, 'amod', 5], ['conditions', 'NOUN', 4, 'pobj', 6], ['to', 'PART', 8, 'aux', 7], ['restore', 'VERB', 6, 'acl', 8], ['power', 'NOUN', 8, 'dobj', 9], ['to', 'ADP', 8, 'prep', 10], ['customers', 'NOUN', 10, 'pobj', 11], ['impacted', 'VERB', 11, 'acl', 12], ['by', 'ADP', 12, 'agent', 13], ['#florence', 'PROPN', 13, 'pobj', 14], ['.', 'PUNCT', 1, 'punct', 15]], [['track', 'NOUN', 1, 'compound', 0], ['progress', 'NOUN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2]]]\n",
      "candidate 0=columbus\n",
      "anchor NE candidates = \n",
      "candidate 1=bladen\n",
      "anchor NE candidates = columbus\n",
      "data NE tree=[['bladen', 'PROPN', 11, 'conj', 13]]\n",
      "NE parse token at tree=0, token=14:\n",
      "['bladen', 'PROPN', 11, 'conj', 13]\n",
      "NE parent token:\n",
      "['columbus', 'PROPN', 14, 'nmod', 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['@weatherchannel', 'PROPN', 2, 'punct', 0], ['this', 'DET', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['from', 'ADP', 2, 'prep', 3], ['williamstown', 'PROPN', 5, 'compound', 4], ['ma', 'PROPN', 3, 'pobj', 5], ['.', 'PUNCT', 2, 'punct', 6]], [['our', 'ADJ', 1, 'poss', 0], ['bridge', 'NOUN', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['about', 'ADJ', 2, 'acomp', 3], ['to', 'PART', 6, 'aux', 4], ['get', 'VERB', 6, 'auxpass', 5], ['wiped', 'VERB', 3, 'xcomp', 6], ['out', 'PART', 6, 'prt', 7], ['!', 'PUNCT', 2, 'punct', 8]], [['even', 'ADV', 1, 'advmod', 0], ['mass', 'PROPN', 4, 'nsubjpass', 1], ['is', 'VERB', 4, 'aux', 2], ['being', 'VERB', 4, 'auxpass', 3], ['affected', 'VERB', 4, 'ROOT', 4], ['by', 'ADP', 4, 'agent', 5], ['#florence', 'PROPN', 5, 'pobj', 6]]]\n",
      "candidate 0=williamstown\n",
      "anchor NE candidates = \n",
      "full parse [[['looks', 'VERB', 0, 'ROOT', 0], ['like', 'ADP', 3, 'mark', 1], ['i', 'PRON', 3, 'nsubj', 2], ['made', 'VERB', 0, 'advcl', 3], ['it', 'PRON', 3, 'dobj', 4], ['to', 'ADP', 3, 'prep', 5], ['brooklyn', 'PROPN', 5, 'pobj', 6], ['not', 'ADV', 9, 'neg', 7], ['a', 'DET', 9, 'det', 8], ['moment', 'NOUN', 11, 'npadvmod', 9], ['too', 'ADV', 11, 'advmod', 10], ['soon', 'ADV', 3, 'advmod', 11], ['.', 'PUNCT', 0, 'punct', 12]], [['the', 'DET', 1, 'det', 0], ['remnants', 'NOUN', 5, 'nsubj', 1], ['of', 'ADP', 1, 'prep', 2], ['#florence', 'NOUN', 2, 'pobj', 3], ['have', 'VERB', 5, 'aux', 4], ['arrived', 'VERB', 5, 'ROOT', 5], ['here', 'ADV', 5, 'advmod', 6], ['in', 'ADP', 5, 'prep', 7], ['nyc', 'PROPN', 7, 'pobj', 8], ['...', 'PUNCT', 5, 'punct', 9]]]\n",
      "candidate 0=brooklyn\n",
      "anchor NE candidates = \n",
      "full parse [[['after', 'ADP', 13, 'prep', 0], ['almost', 'ADV', 2, 'advmod', 1], ['30', 'NUM', 0, 'pobj', 2], ['\"', 'PUNCT', 2, 'punct', 3], ['\"', 'PUNCT', 0, 'punct', 4], ['of', 'ADP', 0, 'prep', 5], ['rain', 'NOUN', 5, 'pobj', 6], ['during', 'ADP', 6, 'prep', 7], ['#florence', 'PROPN', 9, 'compound', 8], ['jones', 'PROPN', 10, 'compound', 9], ['county', 'NOUN', 7, 'pobj', 10], ['is', 'VERB', 13, 'aux', 11], ['now', 'ADV', 13, 'advmod', 12], ['experiencing', 'VERB', 13, 'ROOT', 13], ['historic', 'ADJ', 15, 'amod', 14], ['flooding', 'NOUN', 13, 'dobj', 15], ['along', 'ADP', 15, 'prep', 16], ['the', 'DET', 19, 'det', 17], ['trent', 'PROPN', 19, 'compound', 18], ['river', 'PROPN', 16, 'pobj', 19], ['.', 'PUNCT', 13, 'punct', 20]], [['here', 'ADV', 3, 'advmod', 0], ['r', 'ADV', 3, 'det', 1], ['some', 'DET', 3, 'det', 2], ['pics', 'NOUN', 3, 'ROOT', 3], ['from', 'ADP', 3, 'prep', 4], ['pollocksville', 'PROPN', 4, 'pobj', 5], ['where', 'ADV', 10, 'advmod', 6], ['rescue', 'NOUN', 8, 'compound', 7], ['crews', 'NOUN', 10, 'nsubj', 8], ['have', 'VERB', 10, 'aux', 9], ['worked', 'VERB', 3, 'relcl', 10], ['tirelessly', 'ADV', 12, 'advmod', 11], ['assisting', 'VERB', 10, 'advcl', 12], ['residents', 'NOUN', 12, 'dobj', 13], ['.', 'PUNCT', 3, 'punct', 14]], [['special', 'NOUN', 1, 'amod', 0], ['thank', 'VERB', 1, 'ROOT', 1], ['you', 'PRON', 1, 'dobj', 2], ['to', 'ADP', 1, 'prep', 3], ['@nypdnews', 'PROPN', 3, 'pobj', 4], ['who', 'NOUN', 7, 'nsubj', 5], ['have', 'VERB', 7, 'aux', 6], ['come', 'VERB', 4, 'relcl', 7], ['a', 'DET', 10, 'det', 8], ['long', 'ADJ', 10, 'amod', 9], ['way', 'NOUN', 7, 'npadvmod', 10], ['2', 'NUM', 12, 'nummod', 11], ['help', 'NOUN', 7, 'npadvmod', 12], ['!', 'PUNCT', 1, 'punct', 13]]]\n",
      "candidate 0=pollocksville\n",
      "anchor NE candidates = jones county\n",
      "data NE tree=[['pollocksville', 'PROPN', 4, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['pollocksville', 'PROPN', 4, 'pobj', 5]\n",
      "NE parent token:\n",
      "['from', 'ADP', 3, 'prep', 4]\n",
      "candidate 1=jones county\n",
      "anchor NE candidates = \n",
      "full parse [[['aviators', 'NOUN', 9, 'nsubj', 0], ['of', 'ADP', 0, 'prep', 1], ['the', 'DET', 8, 'det', 2], ['82nd', 'ADJ', 2, 'preconj', 3], ['airborne', 'PROPN', 5, 'compound', 4], ['division', 'PROPN', 8, 'compound', 5], ['combat', 'PROPN', 8, 'compound', 6], ['aviation', 'PROPN', 8, 'compound', 7], ['brigade', 'PROPN', 1, 'pobj', 8], ['began', 'VERB', 9, 'ROOT', 9], ['returning', 'VERB', 9, 'xcomp', 10], ['aircraft', 'NOUN', 10, 'dobj', 11], ['to', 'ADP', 10, 'prep', 12], ['fort', 'PROPN', 14, 'compound', 13], ['bragg', 'PROPN', 12, 'pobj', 14], ['today', 'NOUN', 9, 'npadvmod', 15], ['.', 'PUNCT', 9, 'punct', 16]], [['they', 'PRON', 2, 'nsubjpass', 0], ['were', 'VERB', 2, 'auxpass', 1], ['placed', 'VERB', 2, 'ROOT', 2], ['out', 'ADP', 2, 'prep', 3], ['of', 'ADP', 3, 'prep', 4], ['harms', 'NOUN', 4, 'pobj', 5], ['way', 'NOUN', 2, 'npadvmod', 6], ['at', 'ADP', 2, 'prep', 7], ['robins', 'PROPN', 11, 'compound', 8], ['air', 'PROPN', 10, 'compound', 9], ['force', 'PROPN', 11, 'compound', 10], ['base', 'PROPN', 7, 'pobj', 11], ['in', 'ADP', 11, 'prep', 12], ['georgia', 'PROPN', 12, 'pobj', 13], ['.', 'PUNCT', 2, 'punct', 14]], [['#hurricaneflorence', 'PROPN', 7, 'dep', 0], [';', 'PUNCT', 0, 'punct', 1], ['#armyhurricaneresponse', 'PROPN', 3, 'compound', 2], ['#armyhurricaneflorence', 'X', 0, 'appos', 3], ['#hurevac2018', 'PROPN', 5, 'compound', 4], ['#armyresponse', 'NOUN', 3, 'appos', 5], [';', 'PUNCT', 7, 'punct', 6], ['#18abc', 'X', 7, 'ROOT', 7]]]\n",
      "candidate 0=fort bragg\n",
      "anchor NE candidates = \n",
      "full parse [[['houses', 'NOUN', 1, 'nsubj', 0], ['sit', 'VERB', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['floodwater', 'NOUN', 2, 'pobj', 3], ['caused', 'VERB', 3, 'acl', 4], ['by', 'ADP', 4, 'agent', 5], ['#hurricaneflorence', 'NOUN', 5, 'pobj', 6], ['in', 'ADP', 4, 'prep', 7], ['this', 'DET', 10, 'det', 8], ['aerial', 'ADJ', 10, 'amod', 9], ['picture', 'NOUN', 7, 'pobj', 10], ['on', 'ADP', 10, 'prep', 11], ['the', 'DET', 13, 'det', 12], ['outskirts', 'NOUN', 11, 'pobj', 13], ['of', 'ADP', 13, 'prep', 14], ['lumberton', 'PROPN', 17, 'compound', 15], ['north', 'PROPN', 17, 'compound', 16], ['carolina', 'PROPN', 14, 'pobj', 17], ['via', 'ADP', 1, 'prep', 18], ['@reuters', 'PROPN', 20, 'compound', 19], ['photographer', 'NOUN', 18, 'pobj', 20], ['jason', 'PROPN', 22, 'compound', 21], ['miczek', 'PROPN', 23, 'nsubj', 22], ['see', 'VERB', 23, 'ROOT', 23], ['reuters', 'PROPN', 23, 'dobj', 24], ['top', 'VERB', 26, 'amod', 25], ['photos', 'NOUN', 23, 'dobj', 26], ['from', 'ADP', 26, 'prep', 27], ['the', 'DET', 31, 'det', 28], ['last', 'ADJ', 31, 'amod', 29], ['24', 'NUM', 31, 'nummod', 30], ['hours', 'NOUN', 27, 'pobj', 31], [':', 'PUNCT', 23, 'punct', 32]]]\n",
      "candidate 0=lumberton\n",
      "anchor NE candidates = \n",
      "full parse [[['new', 'ADJ', 1, 'compound', 0], ['wck', 'PROPN', 3, 'compound', 1], ['kitchen', 'NOUN', 3, 'compound', 2], ['opening', 'NOUN', 3, 'ROOT', 3], ['in', 'ADP', 3, 'prep', 4], ['new', 'PROPN', 6, 'compound', 5], ['bern', 'PROPN', 4, 'pobj', 6], ['!', 'PUNCT', 3, 'punct', 7]], [['this', 'DET', 1, 'nsubj', 0], ['is', 'VERB', 1, 'ROOT', 1], ['one', 'NUM', 1, 'attr', 2], ['of', 'ADP', 2, 'prep', 3], ['the', 'DET', 7, 'det', 4], ['worst', 'ADJ', 7, 'amod', 5], ['hit', 'VERB', 7, 'amod', 6], ['areas', 'NOUN', 3, 'pobj', 7], ['in', 'ADP', 7, 'prep', 8], ['north', 'PROPN', 10, 'compound', 9], ['carolina', 'PROPN', 8, 'pobj', 10], ['...', 'PUNCT', 1, 'punct', 11], ['tonight', 'NOUN', 14, 'npadvmod', 12], ['we', 'PRON', 14, 'nsubj', 13], ['served', 'VERB', 14, 'ROOT', 14], ['hundreds', 'NOUN', 14, 'dobj', 15], ['of', 'ADP', 15, 'prep', 16], ['residents', 'NOUN', 16, 'pobj', 17], ['&', 'CCONJ', 14, 'cc', 18], ['we', 'PRON', 20, 'nsubj', 19], ['activate', 'VERB', 14, 'conj', 20], ['a', 'DET', 24, 'det', 21], ['local', 'ADJ', 24, 'amod', 22], ['food', 'NOUN', 24, 'compound', 23], ['truck', 'NOUN', 20, 'dobj', 24], ['tomorrow', 'NOUN', 20, 'npadvmod', 25], ['!', 'PUNCT', 20, 'punct', 26]], [['my', 'ADJ', 1, 'poss', 0], ['brother', 'NOUN', 1, 'ROOT', 1], ['@cheftkilcoyne', 'PROPN', 1, 'appos', 2], ['showing', 'VERB', 1, 'acl', 3], ['how', 'ADV', 9, 'advmod', 4], ['food', 'NOUN', 6, 'compound', 5], ['relief', 'NOUN', 9, 'nsubjpass', 6], ['should', 'VERB', 9, 'aux', 7], ['be', 'VERB', 9, 'auxpass', 8], ['done', 'VERB', 3, 'ccomp', 9], ['!', 'PUNCT', 1, 'punct', 10]], [['#florence', 'ADV', 1, 'compound', 0], ['@wckitchen', 'PROPN', 1, 'ROOT', 1], ['@nc_governor', 'PUNCT', 1, 'punct', 2]]]\n",
      "candidate 0=new bern\n",
      "anchor NE candidates = \n",
      "full parse [[['our', 'ADJ', 1, 'poss', 0], ['teams', 'NOUN', 2, 'nsubj', 1], ['returned', 'VERB', 2, 'ROOT', 2], ['to', 'ADP', 2, 'prep', 3], ['the', 'DET', 6, 'det', 4], ['command', 'NOUN', 6, 'compound', 5], ['base', 'NOUN', 3, 'pobj', 6], ['in', 'ADP', 6, 'prep', 7], ['darlington', 'PROPN', 7, 'pobj', 8], ['this', 'DET', 10, 'det', 9], ['evening', 'NOUN', 2, 'npadvmod', 10], ['with', 'ADP', 2, 'prep', 11], ['eyes', 'NOUN', 11, 'pobj', 12], ['still', 'ADV', 14, 'advmod', 13], ['on', 'ADP', 2, 'prep', 14], ['a', 'DET', 20, 'det', 15], ['concerning', 'VERB', 20, 'amod', 16], ['river', 'NOUN', 20, 'nmod', 17], ['and', 'CCONJ', 17, 'cc', 18], ['dam', 'NOUN', 17, 'conj', 19], ['situation', 'NOUN', 14, 'pobj', 20], ['in', 'ADP', 20, 'prep', 21], ['hartsville', 'PROPN', 21, 'pobj', 22], ['.', 'PUNCT', 2, 'punct', 23]], [['here', 'ADV', 1, 'advmod', 0], ['is', 'VERB', 1, 'ROOT', 1], ['a', 'DET', 3, 'det', 2], ['look', 'NOUN', 1, 'nsubj', 3], ['at', 'ADP', 3, 'prep', 4], ['the', 'DET', 6, 'det', 5], ['area', 'NOUN', 4, 'pobj', 6], ['they', 'PRON', 8, 'nsubj', 7], ['staged', 'VERB', 6, 'relcl', 8], ['at', 'ADP', 8, 'prep', 9], ['today', 'NOUN', 9, 'pobj', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['#florence', 'PROPN', 1, 'compound', 0], ['#louisianaproud', 'PUNCT', 1, 'ROOT', 1]]]\n",
      "candidate 0=hartsville\n",
      "anchor NE candidates = darlington\n",
      "data NE tree=[['hartsville', 'PROPN', 21, 'pobj', 22]]\n",
      "NE parse token at tree=0, token=23:\n",
      "['hartsville', 'PROPN', 21, 'pobj', 22]\n",
      "NE parent token:\n",
      "['in', 'ADP', 20, 'prep', 21]\n",
      "candidate 1=darlington\n",
      "anchor NE candidates = \n",
      "full parse [[['thanks', 'NOUN', 0, 'ROOT', 0], ['.', 'PUNCT', 0, 'punct', 1]], [['my', 'ADJ', 1, 'poss', 0], ['wife', 'NOUN', 5, 'nsubj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['i', 'PRON', 1, 'conj', 3], ['were', 'VERB', 5, 'aux', 4], ['driving', 'VERB', 5, 'ROOT', 5], ['that', 'DET', 7, 'det', 6], ['road', 'NOUN', 5, 'dobj', 7], ['16', 'NUM', 9, 'nummod', 8], ['days', 'NOUN', 10, 'npadvmod', 9], ['ago', 'ADV', 5, 'advmod', 10], ['heading', 'VERB', 5, 'advcl', 11], ['from', 'ADP', 11, 'prep', 12], ['myrtle', 'PROPN', 14, 'compound', 13], ['beach', 'PROPN', 12, 'pobj', 14], ['to', 'ADP', 11, 'prep', 15], ['the', 'DET', 18, 'det', 16], ['nascar', 'PROPN', 18, 'compound', 17], ['race', 'NOUN', 15, 'pobj', 18], ['in', 'ADP', 18, 'prep', 19], ['darlington', 'PROPN', 19, 'pobj', 20], ['.', 'PUNCT', 5, 'punct', 21]], [['the', 'DET', 2, 'det', 0], ['peedee', 'PROPN', 2, 'compound', 1], ['river', 'PROPN', 3, 'nsubj', 2], ['is', 'VERB', 3, 'ROOT', 3], ['halfway', 'ADV', 3, 'advmod', 4], ['between', 'ADP', 4, 'prep', 5], ['marion', 'PROPN', 5, 'pobj', 6], ['and', 'CCONJ', 6, 'cc', 7], ['darlington', 'PROPN', 6, 'conj', 8], ['.', 'PUNCT', 3, 'punct', 9]], [['very', 'ADV', 1, 'advmod', 0], ['sad', 'ADJ', 1, 'ROOT', 1], ['what', 'NOUN', 4, 'nsubj', 2], ['is', 'VERB', 4, 'aux', 3], ['happening', 'VERB', 1, 'ccomp', 4], ['.', 'PUNCT', 1, 'punct', 5]], [[\"we're\", 'PROPN', 1, 'nsubj', 0], ['thinking', 'VERB', 1, 'ROOT', 1], ['about', 'ADP', 1, 'prep', 2], ['everyone', 'NOUN', 2, 'pobj', 3], ['in', 'ADP', 3, 'prep', 4], ['the', 'DET', 6, 'det', 5], ['carolinas', 'PROPN', 4, 'pobj', 6], ['affected', 'VERB', 3, 'acl', 7], ['by', 'ADP', 7, 'agent', 8], ['#hurricaneflorence', 'PROPN', 8, 'pobj', 9], ['.', 'PUNCT', 1, 'punct', 10]]]\n",
      "candidate 0=myrtle beach\n",
      "anchor NE candidates = darlington,marion,darlington\n",
      "data NE tree=[['myrtle', 'PROPN', 14, 'compound', 13], ['beach', 'PROPN', 12, 'pobj', 14]]\n",
      "NE parse token at tree=1, token=15:\n",
      "['beach', 'PROPN', 12, 'pobj', 14]\n",
      "NE parent token:\n",
      "['from', 'ADP', 11, 'prep', 12]\n",
      "candidate 1=darlington\n",
      "anchor NE candidates = \n",
      "candidate 2=marion\n",
      "anchor NE candidates = darlington,darlington\n",
      "data NE tree=[['marion', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=2, token=7:\n",
      "['marion', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['between', 'ADP', 4, 'prep', 5]\n",
      "NE=marion subtree=[['and', 'CCONJ', 6, 'cc', 7], ['darlington', 'PROPN', 6, 'conj', 8]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 3=darlington\n",
      "anchor NE candidates = \n",
      "full parse [[['my', 'ADJ', 1, 'poss', 0], ['aunt', 'NOUN', 5, 'nsubj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['uncle', 'NOUN', 1, 'conj', 3], ['have', 'VERB', 5, 'aux', 4], ['lived', 'VERB', 5, 'ROOT', 5], ['in', 'ADP', 5, 'prep', 6], ['southport', 'PROPN', 9, 'compound', 7], ['north', 'PROPN', 9, 'compound', 8], ['carolina', 'PROPN', 6, 'pobj', 9], ['for', 'ADP', 5, 'prep', 10], ['about', 'ADV', 12, 'advmod', 11], ['35', 'NUM', 13, 'nummod', 12], ['years', 'NOUN', 10, 'pobj', 13], ['.', 'PUNCT', 5, 'punct', 14]], [['they', 'PRON', 1, 'nsubj', 0], ['evacuated', 'VERB', 1, 'ROOT', 1], ['from', 'ADP', 1, 'prep', 2], ['#hurricaneflorence', 'PROPN', 2, 'pobj', 3], ['and', 'CCONJ', 1, 'cc', 4], ['stayed', 'VERB', 1, 'conj', 5], ['with', 'ADP', 5, 'prep', 6], ['family', 'NOUN', 6, 'pobj', 7], ['a', 'DET', 9, 'quantmod', 8], ['couple', 'NOUN', 10, 'nummod', 9], ['hours', 'NOUN', 11, 'npadvmod', 10], ['away', 'ADV', 5, 'advmod', 11], ['.', 'PUNCT', 1, 'punct', 12]], [['they', 'PRON', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['still', 'ADV', 1, 'advmod', 2], ['away', 'ADV', 1, 'advmod', 3], ['but', 'CCONJ', 6, 'cc', 4], ['i', 'PRON', 6, 'nsubj', 5], ['heard', 'VERB', 6, 'ROOT', 6], ['from', 'ADP', 6, 'prep', 7], ['my', 'ADJ', 9, 'poss', 8], ['mother', 'NOUN', 7, 'pobj', 9], ['today', 'NOUN', 6, 'npadvmod', 10], ['that', 'ADP', 14, 'mark', 11], ['their', 'ADJ', 13, 'poss', 12], ['house', 'NOUN', 14, 'nsubj', 13], ['is', 'VERB', 6, 'ccomp', 14], ['structurally', 'ADV', 16, 'advmod', 15], ['safe', 'ADJ', 14, 'acomp', 16], ['.', 'PUNCT', 6, 'punct', 17]], [['so', 'ADV', 1, 'advmod', 0], ['much', 'ADJ', 2, 'amod', 1], ['flooding', 'NOUN', 2, 'ROOT', 2], ['though', 'ADV', 2, 'advmod', 3], ['.', 'PUNCT', 2, 'punct', 4]], [[':(', 'PUNCT', 0, 'ROOT', 0]]]\n",
      "candidate 0=southport\n",
      "anchor NE candidates = \n",
      "full parse [[['check', 'VERB', 1, 'compound', 0], ['this', 'VERB', 1, 'ROOT', 1], ['out', 'ADV', 1, 'advmod', 2], ['!', 'PUNCT', 1, 'punct', 3]], [['viewer', 'PROPN', 1, 'compound', 0], ['video', 'NOUN', 1, 'ROOT', 1], ['of', 'ADP', 1, 'prep', 2], ['mayesville', 'PROPN', 4, 'compound', 3], ['rd', 'PROPN', 2, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['anson', 'PROPN', 7, 'compound', 6], ['county', 'PROPN', 5, 'pobj', 7], ['during', 'ADP', 1, 'prep', 8], ['#florence', 'PROPN', 8, 'pobj', 9], ['.', 'PUNCT', 1, 'punct', 10]], [['@ncdot', 'PUNCT', 1, 'nummod', 0], ['crews', 'NOUN', 2, 'nsubj', 1], ['say', 'VERB', 2, 'ROOT', 2], ['it', 'PRON', 5, 'nsubj', 3], ['will', 'VERB', 5, 'aux', 4], ['take', 'VERB', 2, 'ccomp', 5], ['several', 'ADJ', 7, 'amod', 6], ['months', 'NOUN', 5, 'dobj', 7], ['until', 'ADP', 13, 'mark', 8], ['all', 'DET', 11, 'det', 9], ['impacted', 'VERB', 11, 'amod', 10], ['roads', 'NOUN', 13, 'nsubjpass', 11], ['are', 'VERB', 13, 'auxpass', 12], ['reopened', 'VERB', 5, 'advcl', 13], ['.', 'PUNCT', 2, 'punct', 14]], [['there', 'ADV', 1, 'expl', 0], ['are', 'VERB', 1, 'ROOT', 1], ['44', 'NUM', 4, 'nummod', 2], ['closed', 'ADJ', 4, 'amod', 3], ['roads', 'NOUN', 1, 'attr', 4], ['in', 'ADP', 4, 'prep', 5], ['anson', 'PROPN', 7, 'compound', 6], ['county', 'PROPN', 5, 'pobj', 7], ['alone', 'ADV', 1, 'advmod', 8], ['.', 'PUNCT', 1, 'punct', 9]], [['ncdot', 'PROPN', 1, 'nsubj', 0], ['has', 'VERB', 1, 'ROOT', 1], ['12', 'NUM', 4, 'nummod', 2], ['assessment', 'NOUN', 4, 'compound', 3], ['teams', 'NOUN', 1, 'dobj', 4], ['checking', 'VERB', 4, 'acl', 5], ['damage', 'NOUN', 5, 'dobj', 6], ['in', 'ADP', 6, 'prep', 7], ['anson', 'PROPN', 7, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['union', 'PROPN', 8, 'conj', 10], ['.', 'PUNCT', 1, 'punct', 11]]]\n",
      "candidate 0=anson\n",
      "anchor NE candidates = anson county,anson county,union\n",
      "data NE tree=[['anson', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=1, token=7:\n",
      "['anson', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['county', 'PROPN', 5, 'pobj', 7]\n",
      "parent node subtree [['anson', 'PROPN', 7, 'compound', 6], ['county', 'PROPN', 5, 'pobj', 7]]\n",
      "parent node subtree str \"anson county\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=anson county\n",
      "anchor NE candidates = \n",
      "candidate 2=anson county\n",
      "anchor NE candidates = \n",
      "candidate 3=union\n",
      "anchor NE candidates = anson county,anson county\n",
      "data NE tree=[['union', 'PROPN', 8, 'conj', 10]]\n",
      "NE parse token at tree=4, token=11:\n",
      "['union', 'PROPN', 8, 'conj', 10]\n",
      "NE parent token:\n",
      "['anson', 'PROPN', 7, 'pobj', 8]\n",
      "full parse [[['more', 'ADJ', 1, 'amod', 0], ['evacuations', 'NOUN', 1, 'ROOT', 1], ['coming', 'VERB', 1, 'acl', 2], ['in', 'ADP', 2, 'prep', 3], ['horry', 'PROPN', 5, 'compound', 4], ['county', 'PROPN', 6, 'compound', 5], ['sc', 'PROPN', 3, 'pobj', 6], ['.', 'PUNCT', 1, 'punct', 7]], [['#florence', 'X', 1, 'compound', 0], ['#flooding', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=horry county\n",
      "anchor NE candidates = \n",
      "full parse [[['new', 'PROPN', 2, 'compound', 0], ['bern', 'PROPN', 2, 'compound', 1], ['nc', 'PROPN', 6, 'nsubj', 2], ['&', 'CCONJ', 2, 'cc', 3], ['conway', 'PROPN', 5, 'compound', 4], ['sc', 'PROPN', 2, 'conj', 5], ['got', 'VERB', 6, 'ROOT', 6], ['visits', 'NOUN', 6, 'dobj', 7], ['from', 'ADP', 7, 'prep', 8], ['@potus', 'X', 10, 'compound', 9], ['trump', 'PROPN', 8, 'pobj', 10], ['yesterday', 'NOUN', 6, 'npadvmod', 11], ['as', 'ADP', 14, 'mark', 12], ['they', 'PRON', 14, 'nsubj', 13], ['recover', 'VERB', 6, 'advcl', 14], ['from', 'ADP', 14, 'prep', 15], ['the', 'DET', 17, 'det', 16], ['devastation', 'NOUN', 15, 'pobj', 17], ['brought', 'VERB', 17, 'acl', 18], ['by', 'ADP', 18, 'agent', 19], ['#florence', 'NOUN', 19, 'pobj', 20], ['.', 'PUNCT', 6, 'punct', 21]], [['coming', 'VERB', 2, 'advcl', 0], ['up', 'PART', 0, 'prt', 1], ['hear', 'VERB', 2, 'ROOT', 2], ['what', 'NOUN', 7, 'dobj', 3], ['ppl', 'NOUN', 7, 'nsubj', 4], ['in', 'ADP', 4, 'prep', 5], ['area', 'NOUN', 5, 'pobj', 6], ['had', 'VERB', 2, 'ccomp', 7], ['to', 'PART', 9, 'aux', 8], ['say', 'VERB', 7, 'xcomp', 9], ['about', 'ADP', 9, 'prep', 10], ['his', 'ADJ', 13, 'poss', 11], ['visit', 'NOUN', 13, 'compound', 12], ['@wbtv_news', 'X', 10, 'pobj', 13]]]\n",
      "candidate 0=new bern\n",
      "anchor NE candidates = conway\n",
      "data NE tree=[['new', 'PROPN', 2, 'compound', 0], ['bern', 'PROPN', 2, 'compound', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['bern', 'PROPN', 2, 'compound', 1]\n",
      "NE parent token:\n",
      "['nc', 'PROPN', 6, 'nsubj', 2]\n",
      "parent node subtree [['new', 'PROPN', 2, 'compound', 0], ['bern', 'PROPN', 2, 'compound', 1], ['nc', 'PROPN', 6, 'nsubj', 2], ['&', 'CCONJ', 2, 'cc', 3], ['conway', 'PROPN', 5, 'compound', 4], ['sc', 'PROPN', 2, 'conj', 5]]\n",
      "parent node subtree str \"new bern nc & conway sc\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=conway\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['thanks', 'NOUN', 13, 'npadvmod', 0], ['to', 'ADP', 0, 'prep', 1], ['the', 'DET', 4, 'det', 2], ['amazing', 'ADJ', 4, 'amod', 3], ['generosity', 'NOUN', 1, 'pobj', 4], ['of', 'ADP', 4, 'prep', 5], ['people', 'NOUN', 5, 'pobj', 6], ['in', 'ADP', 4, 'prep', 7], ['and', 'CCONJ', 7, 'cc', 8], ['around', 'ADP', 7, 'conj', 9], ['the', 'DET', 12, 'det', 10], ['triangle', 'PROPN', 12, 'compound', 11], ['@wral', 'PROPN', 9, 'pobj', 12], ['helped', 'VERB', 13, 'ROOT', 13], ['fill', 'VERB', 13, 'xcomp', 14], ['5', 'NUM', 16, 'nummod', 15], ['buses', 'NOUN', 14, 'dative', 16], ['5', 'NUM', 18, 'nummod', 17], ['trailers', 'NOUN', 14, 'dobj', 18], ['3', 'NUM', 20, 'nummod', 19], ['vans', 'NOUN', 18, 'appos', 20], ['and', 'CCONJ', 20, 'cc', 21], ['a', 'DET', 24, 'det', 22], ['small', 'ADJ', 24, 'amod', 23], ['truck', 'NOUN', 20, 'conj', 24], ['with', 'ADP', 24, 'prep', 25], ['supplies', 'NOUN', 25, 'pobj', 26], ['for', 'ADP', 26, 'prep', 27], ['#florence', 'NOUN', 29, 'compound', 28], ['victims', 'NOUN', 27, 'pobj', 29], ['.', 'PUNCT', 13, 'punct', 30]], [['130', 'NUM', 2, 'nummod', 0], ['500', 'NUM', 2, 'nummod', 1], ['lbs', 'NOUN', 7, 'nsubjpass', 2], ['in', 'ADP', 2, 'prep', 3], ['supplies', 'NOUN', 3, 'pobj', 4], ['will', 'VERB', 7, 'aux', 5], ['be', 'VERB', 7, 'auxpass', 6], ['delivered', 'VERB', 7, 'ROOT', 7], ['next', 'ADJ', 9, 'amod', 8], ['week', 'NOUN', 7, 'npadvmod', 9], ['to', 'ADP', 7, 'prep', 10], ['wilmington', 'PROPN', 12, 'compound', 11], ['lumberton', 'PROPN', 10, 'pobj', 12], ['and', 'CCONJ', 12, 'cc', 13], ['new', 'PROPN', 15, 'compound', 14], ['bern', 'PROPN', 12, 'conj', 15], ['.', 'PUNCT', 7, 'punct', 16]], [['#wral', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=lumberton\n",
      "anchor NE candidates = wilmington,new bern\n",
      "data NE tree=[['lumberton', 'PROPN', 10, 'pobj', 12]]\n",
      "NE parse token at tree=1, token=13:\n",
      "['lumberton', 'PROPN', 10, 'pobj', 12]\n",
      "NE parent token:\n",
      "['to', 'ADP', 7, 'prep', 10]\n",
      "NE=lumberton subtree=[['wilmington', 'PROPN', 12, 'compound', 11], ['and', 'CCONJ', 12, 'cc', 13], ['new', 'PROPN', 15, 'compound', 14], ['bern', 'PROPN', 12, 'conj', 15]]\n",
      "min node deps ['compound', 'cc', 'conj']\n",
      "candidate 1=wilmington\n",
      "anchor NE candidates = \n",
      "candidate 2=new bern\n",
      "anchor NE candidates = wilmington\n",
      "data NE tree=[['new', 'PROPN', 15, 'compound', 14], ['bern', 'PROPN', 12, 'conj', 15]]\n",
      "NE parse token at tree=1, token=16:\n",
      "['bern', 'PROPN', 12, 'conj', 15]\n",
      "NE parent token:\n",
      "['lumberton', 'PROPN', 10, 'pobj', 12]\n",
      "full parse [[['update', 'NOUN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['#hurricaneflorence', 'PROPN', 4, 'compound', 2], ['brunswick', 'PROPN', 4, 'compound', 3], ['county', 'PROPN', 6, 'nsubj', 4], ['will', 'VERB', 6, 'aux', 5], ['have', 'VERB', 0, 'acl', 6], ['food', 'NOUN', 6, 'dobj', 7], ['and', 'CCONJ', 7, 'cc', 8], ['water', 'NOUN', 7, 'conj', 9], ['available', 'ADJ', 7, 'amod', 10], ['for', 'ADP', 10, 'prep', 11], ['distribution', 'NOUN', 11, 'pobj', 12], ['friday', 'PROPN', 14, 'compound', 13], ['sept', 'PROPN', 6, 'npadvmod', 14], ['.', 'PUNCT', 0, 'punct', 15], ['21', 'NUM', 16, 'ROOT', 16], ['from', 'ADP', 16, 'prep', 17], ['11', 'NUM', 17, 'pobj', 18], ['a', 'DET', 19, 'ROOT', 19], ['.', 'PUNCT', 19, 'punct', 20], ['m', 'NOUN', 21, 'ROOT', 21], ['.', 'PUNCT', 21, 'punct', 22], ['to', 'ADP', 23, 'ROOT', 23], ['5', 'NUM', 25, 'nummod', 24], ['p', 'NOUN', 23, 'pobj', 25], ['.', 'PUNCT', 23, 'punct', 26], ['m', 'NOUN', 27, 'ROOT', 27], ['.', 'PUNCT', 27, 'punct', 28], ['at', 'ADP', 29, 'ROOT', 29], [':', 'PUNCT', 29, 'punct', 30], ['spring', 'PROPN', 33, 'compound', 31], ['lake', 'PROPN', 33, 'compound', 32], ['park', 'PROPN', 29, 'pobj', 33], ['(', 'PUNCT', 33, 'punct', 34], ['210', 'NUM', 37, 'nummod', 35], ['pine', 'PROPN', 37, 'compound', 36], ['road', 'PROPN', 33, 'appos', 37], ['in', 'ADP', 37, 'prep', 38], ['boiling', 'VERB', 41, 'compound', 39], ['spring', 'PROPN', 41, 'compound', 40], ['lakes', 'PROPN', 38, 'pobj', 41], [')', 'PUNCT', 33, 'punct', 42], ['northwest', 'PROPN', 43, 'ROOT', 43], ['...', 'PUNCT', 43, 'punct', 44]]]\n",
      "candidate 0=boiling spring lakes\n",
      "anchor NE candidates = brunswick county\n",
      "data NE tree=[['boiling', 'VERB', 41, 'compound', 39], ['spring', 'PROPN', 41, 'compound', 40], ['lakes', 'PROPN', 38, 'pobj', 41]]\n",
      "NE parse token at tree=0, token=42:\n",
      "['lakes', 'PROPN', 38, 'pobj', 41]\n",
      "NE parent token:\n",
      "['in', 'ADP', 37, 'prep', 38]\n",
      "candidate 1=brunswick county\n",
      "anchor NE candidates = \n",
      "candidate 2=northwest\n",
      "anchor NE candidates = boiling spring lakes,brunswick county\n",
      "data NE tree=[['northwest', 'PROPN', 43, 'ROOT', 43]]\n",
      "NE=northwest subtree=[['...', 'PUNCT', 43, 'punct', 44]]\n",
      "min node deps ['punct']\n",
      "full parse [[['.', 'PUNCT', 0, 'ROOT', 0]], [['@cojacksonville', 'PROPN', 0, 'ROOT', 0], ['nc', 'PROPN', 3, 'nmod', 1], ['\\u200b', 'PROPN', 3, 'amod', 2], ['officials', 'NOUN', 4, 'nsubj', 3], ['recommend', 'VERB', 4, 'ROOT', 4], ['avoiding', 'VERB', 4, 'xcomp', 5], ['a', 'DET', 8, 'det', 6], ['major', 'ADJ', 8, 'amod', 7], ['intersection', 'NOUN', 5, 'dobj', 8], ['at', 'ADP', 5, 'prep', 9], ['the', 'DET', 11, 'det', 10], ['end', 'NOUN', 9, 'pobj', 11], ['of', 'ADP', 11, 'prep', 12], ['the', 'DET', 15, 'det', 13], ['jacksonville', 'PROPN', 15, 'compound', 14], ['bypass', 'NOUN', 12, 'pobj', 15], ['because', 'ADP', 4, 'prep', 16], ['of', 'ADP', 16, 'pcomp', 17], ['heavy', 'ADJ', 20, 'amod', 18], ['traffic', 'NOUN', 20, 'compound', 19], ['use', 'NOUN', 16, 'pobj', 20], ['by', 'ADP', 20, 'prep', 21], ['those', 'DET', 21, 'pobj', 22], ['heading', 'VERB', 22, 'acl', 23], ['to', 'ADP', 23, 'prep', 24], ['the', 'DET', 27, 'det', 25], ['southern', 'ADJ', 27, 'amod', 26], ['coast', 'NOUN', 24, 'pobj', 27], ['.', 'PUNCT', 4, 'punct', 28]], [['#hurricaneflorence', 'PROPN', 1, 'compound', 0], ['#florencenc', 'X', 1, 'ROOT', 1]]]\n",
      "candidate 0=jacksonville\n",
      "anchor NE candidates = \n",
      "full parse [[['please', 'INTJ', 1, 'intj', 0], ['pay', 'VERB', 1, 'ROOT', 1], ['attention', 'NOUN', 1, 'dobj', 2], ['to', 'ADP', 1, 'prep', 3], ['#wilmingtonnc', 'PROPN', 3, 'pobj', 4], ['and', 'CCONJ', 4, 'cc', 5], ['surrounding', 'VERB', 7, 'amod', 6], ['areas', 'NOUN', 4, 'conj', 7], ['near', 'ADP', 7, 'prep', 8], ['the', 'DET', 14, 'det', 9], ['cape', 'PROPN', 12, 'compound', 10], ['fear', 'NOUN', 12, 'compound', 11], ['ne', 'PROPN', 14, 'compound', 12], ['cape', 'PROPN', 14, 'compound', 13], ['fear', 'PROPN', 8, 'pobj', 14], ['&', 'CCONJ', 14, 'cc', 15], ['black', 'PROPN', 17, 'compound', 16], ['rivers', 'PROPN', 14, 'conj', 17], ['today', 'NOUN', 1, 'npadvmod', 18], ['and', 'CCONJ', 18, 'cc', 19], ['through', 'ADP', 18, 'conj', 20], ['the', 'DET', 22, 'det', 21], ['weekend', 'NOUN', 20, 'pobj', 22], ['.', 'PUNCT', 1, 'punct', 23]], [['many', 'ADJ', 5, 'nsubjpass', 0], ['in', 'ADP', 0, 'prep', 1], ['pender', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 1, 'pobj', 3], ['were', 'VERB', 5, 'auxpass', 4], ['evacuated', 'VERB', 5, 'ROOT', 5], ['last', 'ADJ', 7, 'amod', 6], ['night', 'NOUN', 5, 'npadvmod', 7], ['by', 'ADP', 5, 'agent', 8], ['national', 'PROPN', 10, 'compound', 9], ['guard', 'PROPN', 8, 'pobj', 10], ['now', 'ADV', 13, 'advmod', 11], ['this', 'DET', 13, 'det', 12], ['today', 'NOUN', 5, 'npadvmod', 13], ['.', 'PUNCT', 5, 'punct', 14]], [['#hurricaneflorence', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=cape fear\n",
      "anchor NE candidates = pender county\n",
      "data NE tree=[['cape', 'PROPN', 12, 'compound', 10], ['fear', 'NOUN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['fear', 'NOUN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['ne', 'PROPN', 14, 'compound', 12]\n",
      "parent node subtree [['cape', 'PROPN', 12, 'compound', 10], ['fear', 'NOUN', 12, 'compound', 11], ['ne', 'PROPN', 14, 'compound', 12]]\n",
      "parent node subtree str \"cape fear ne\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=pender county\n",
      "anchor NE candidates = \n",
      "full parse [[['boiling', 'VERB', 3, 'amod', 0], ['spring', 'PROPN', 2, 'compound', 1], ['lakes', 'PROPN', 3, 'compound', 2], ['nc', 'PROPN', 5, 'compound', 3], ['#carolinastrong', 'ADP', 5, 'compound', 4], ['#hurricaneflorence', 'PROPN', 8, 'compound', 5], ['#giveback', 'PROPN', 8, 'compound', 6], ['@edpiotrowski', 'PROPN', 8, 'compound', 7], ['@wpdeabc15', 'NOUN', 8, 'ROOT', 8], ['@jamiearnoldwmbf', 'X', 10, 'punct', 9], ['@wmbfweather', 'PUNCT', 8, 'punct', 10]]]\n",
      "candidate 0=spring lakes\n",
      "anchor NE candidates = \n",
      "full parse [[['georgetown', 'PROPN', 1, 'compound', 0], ['county', 'PROPN', 3, 'nsubj', 1], ['will', 'VERB', 3, 'aux', 2], ['open', 'VERB', 3, 'ROOT', 3], ['emergency', 'NOUN', 5, 'compound', 4], ['shelters', 'NOUN', 3, 'dobj', 5], ['at', 'ADP', 3, 'prep', 6], ['7', 'NUM', 6, 'pobj', 7], ['a', 'DET', 7, 'det', 8], ['.', 'PUNCT', 3, 'punct', 9], ['m', 'NOUN', 10, 'ROOT', 10], ['.', 'PUNCT', 10, 'punct', 11], ['monday', 'PROPN', 12, 'ROOT', 12], ['at', 'ADP', 12, 'prep', 13], ['the', 'DET', 16, 'det', 14], ['following', 'VERB', 16, 'amod', 15], ['locations', 'NOUN', 13, 'pobj', 16], [':', 'PUNCT', 12, 'punct', 17], ['•', 'PROPN', 18, 'ROOT', 18], ['georgetown', 'PROPN', 21, 'compound', 19], ['high', 'PROPN', 21, 'compound', 20], ['school', 'PROPN', 21, 'ROOT', 21], ['2500', 'NUM', 21, 'nummod', 22], ['anthuan', 'PROPN', 26, 'compound', 23], ['maybank', 'PROPN', 26, 'compound', 24], ['drive', 'PROPN', 26, 'compound', 25], ['georgetown', 'PROPN', 21, 'appos', 26], ['•', 'PROPN', 27, 'ROOT', 27], ['waccamaw', 'PROPN', 30, 'compound', 28], ['middle', 'PROPN', 30, 'compound', 29], ['school', 'PROPN', 35, 'compound', 30], ['247', 'NUM', 33, 'nummod', 31], ['wildcat', 'PROPN', 33, 'compound', 32], ['way', 'PROPN', 35, 'compound', 33], ['pawleys', 'PROPN', 35, 'compound', 34], ['island', 'PROPN', 35, 'ROOT', 35], ['@scpublicradio', 'PROPN', 35, 'punct', 36], ['#hurricaneflorence', 'PROPN', 38, 'compound', 37], ['@gcemd', 'X', 38, 'ROOT', 38]]]\n",
      "candidate 0=georgetown county\n",
      "anchor NE candidates = georgetown\n",
      "data NE tree=[['georgetown', 'PROPN', 1, 'compound', 0], ['county', 'PROPN', 3, 'nsubj', 1]]\n",
      "NE parse token at tree=0, token=2:\n",
      "['county', 'PROPN', 3, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['open', 'VERB', 3, 'ROOT', 3]\n",
      "candidate 1=georgetown\n",
      "anchor NE candidates = \n",
      "candidate 2=pawleys island\n",
      "anchor NE candidates = georgetown county,georgetown\n",
      "data NE tree=[['pawleys', 'PROPN', 35, 'compound', 34], ['island', 'PROPN', 35, 'ROOT', 35]]\n",
      "NE=pawleys island subtree=[['waccamaw', 'PROPN', 30, 'compound', 28], ['middle', 'PROPN', 30, 'compound', 29], ['school', 'PROPN', 35, 'compound', 30], ['247', 'NUM', 33, 'nummod', 31], ['wildcat', 'PROPN', 33, 'compound', 32], ['way', 'PROPN', 35, 'compound', 33], ['@scpublicradio', 'PROPN', 35, 'punct', 36]]\n",
      "min node deps ['compound', 'compound']\n",
      "full parse [[['eat', 'VERB', 0, 'ROOT', 0], ['at', 'ADP', 0, 'prep', 1], ['#beachsidebistro', 'PROPN', 1, 'pobj', 2], ['and', 'CCONJ', 0, 'cc', 3], ['10', 'NUM', 5, 'nummod', 4], ['%', 'NOUN', 11, 'nsubjpass', 5], ['of', 'ADP', 5, 'prep', 6], ['your', 'ADJ', 8, 'poss', 7], ['purchase', 'NOUN', 6, 'pobj', 8], ['will', 'VERB', 11, 'aux', 9], ['be', 'VERB', 11, 'auxpass', 10], ['donated', 'VERB', 0, 'conj', 11], ['to', 'ADP', 11, 'prep', 12], ['the', 'DET', 15, 'det', 13], ['red', 'PROPN', 15, 'compound', 14], ['cross', 'PROPN', 12, 'pobj', 15], ['of', 'ADP', 15, 'prep', 16], ['north', 'PROPN', 18, 'compound', 17], ['carolina', 'PROPN', 16, 'pobj', 18], ['to', 'PART', 20, 'aux', 19], ['help', 'VERB', 11, 'advcl', 20], ['our', 'ADJ', 23, 'poss', 21], ['fellow', 'ADJ', 23, 'amod', 22], ['#northcarolinians', 'NOUN', 24, 'nsubj', 23], ['affected', 'VERB', 20, 'ccomp', 24], ['by', 'ADP', 24, 'agent', 25], ['#hurricaneflorence', 'NOUN', 27, 'compound', 26], ['#foodforflo', 'PROPN', 25, 'pobj', 27], ['…', 'PUNCT', 11, 'punct', 28]]]\n",
      "candidate 0=red cross\n",
      "anchor NE candidates = \n",
      "full parse [[['coal', 'NOUN', 1, 'compound', 0], ['ash', 'NOUN', 2, 'nsubj', 1], ['flowing', 'VERB', 2, 'ROOT', 2], ['like', 'ADP', 2, 'prep', 3], ['pudding', 'NOUN', 3, 'pobj', 4], ['in', 'ADP', 4, 'prep', 5], ['neuse', 'PROPN', 7, 'compound', 6], ['river', 'PROPN', 5, 'pobj', 7], ['near', 'ADP', 4, 'prep', 8], [\"duke's\", 'PROPN', 12, 'compound', 9], ['goldsboro', 'PROPN', 12, 'compound', 10], ['power', 'NOUN', 12, 'compound', 11], ['plant', 'NOUN', 8, 'pobj', 12]]]\n",
      "candidate 0=duke\n",
      "anchor NE candidates = goldsboro\n",
      "candidate 1=goldsboro\n",
      "anchor NE candidates = \n",
      "full parse [[['the', 'DET', 3, 'det', 0], ['latest', 'ADJ', 3, 'amod', 1], ['reliable', 'ADJ', 3, 'amod', 2], ['models', 'NOUN', 3, 'ROOT', 3], ['available', 'ADJ', 3, 'amod', 4], ['(', 'PUNCT', 3, 'punct', 5], ['from', 'ADP', 3, 'prep', 6], ['this', 'DET', 8, 'det', 7], ['morning', 'NOUN', 6, 'pobj', 8], [')', 'PUNCT', 3, 'punct', 9], ['all', 'DET', 11, 'nsubj', 10], ['keep', 'VERB', 11, 'ROOT', 11], ['hurricane', 'PROPN', 13, 'compound', 12], ['force', 'NOUN', 11, 'dobj', 13], ['*', 'PUNCT', 15, 'punct', 14], ['sustained', 'VERB', 17, 'amod', 15], ['*', 'PUNCT', 17, 'punct', 16], ['winds', 'NOUN', 17, 'ROOT', 17], ['out', 'ADP', 17, 'prep', 18], ['of', 'ADP', 18, 'prep', 19], ['#tallahassee', 'PROPN', 19, 'pobj', 20], ['from', 'ADP', 17, 'prep', 21], ['#hurricanemichael', 'PROPN', 21, 'pobj', 22], ['.', 'PUNCT', 17, 'punct', 23]], [['however', 'ADV', 9, 'advmod', 0], ['gadsden', 'PROPN', 6, 'nsubj', 1], ['&', 'CCONJ', 1, 'cc', 2], ['liberty', 'PROPN', 1, 'conj', 3], ['will', 'VERB', 6, 'aux', 4], ['still', 'ADV', 6, 'advmod', 5], ['per', 'ADP', 9, 'prep', 6], ['these', 'DET', 8, 'det', 7], ['models', 'NOUN', 6, 'pobj', 8], ['get', 'VERB', 9, 'ROOT', 9], ['hurricane', 'PROPN', 11, 'compound', 10], ['force', 'NOUN', 12, 'compound', 11], ['winds', 'NOUN', 9, 'ccomp', 12], ['so', 'ADP', 16, 'advmod', 13], ['it', 'PRON', 15, 'nsubj', 14], ['’', 'VERB', 16, 'nsubj', 15], ['s', 'VERB', 9, 'advcl', 16], ['close', 'ADV', 16, 'acomp', 17], ['enough', 'ADV', 17, 'advmod', 18], ['to', 'ADP', 17, 'prep', 19], ['tallahassee', 'PROPN', 19, 'pobj', 20], ['to', 'PART', 22, 'aux', 21], ['worry', 'VERB', 17, 'advcl', 22], ['.', 'PUNCT', 9, 'punct', 23]]]\n",
      "candidate 0=gadsden\n",
      "anchor NE candidates = liberty,tallahassee\n",
      "data NE tree=[['gadsden', 'PROPN', 6, 'nsubj', 1]]\n",
      "NE parse token at tree=1, token=2:\n",
      "['gadsden', 'PROPN', 6, 'nsubj', 1]\n",
      "NE parent token:\n",
      "['per', 'ADP', 9, 'prep', 6]\n",
      "NE=gadsden subtree=[['&', 'CCONJ', 1, 'cc', 2], ['liberty', 'PROPN', 1, 'conj', 3]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=liberty\n",
      "anchor NE candidates = tallahassee\n",
      "data NE tree=[['liberty', 'PROPN', 1, 'conj', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['liberty', 'PROPN', 1, 'conj', 3]\n",
      "NE parent token:\n",
      "['gadsden', 'PROPN', 6, 'nsubj', 1]\n",
      "candidate 2=tallahassee\n",
      "anchor NE candidates = \n",
      "full parse [[['hurrication', 'PROPN', 2, 'compound', 0], ['self', 'PROPN', 2, 'compound', 1], ['portrait', 'PROPN', 2, 'ROOT', 2], ['3', 'NUM', 2, 'nummod', 3], ['.', 'PUNCT', 2, 'punct', 4]], [['nice', 'ADJ', 1, 'amod', 0], ['work', 'NOUN', 1, 'ROOT', 1], ['on', 'ADP', 1, 'prep', 2], ['the', 'DET', 4, 'det', 3], ['backdrop', 'NOUN', 5, 'compound', 4], ['katebackdrops', 'NOUN', 2, 'pobj', 5], ['#hurricanemichaelmademedoit', 'X', 7, 'compound', 6], ['#longexposure', 'PROPN', 7, 'ROOT', 7], ['@', 'ADP', 7, 'punct', 8], ['tallahassee', 'PROPN', 10, 'compound', 9], ['florida', 'PROPN', 10, 'ROOT', 10]]]\n",
      "candidate 0=tallahassee\n",
      "anchor NE candidates = \n",
      "full parse [[['please', 'INTJ', 1, 'intj', 0], ['be', 'VERB', 1, 'ROOT', 1], ['safe', 'ADJ', 1, 'acomp', 2], ['my', 'ADJ', 8, 'poss', 3], ['florida', 'PROPN', 8, 'nmod', 4], ['and', 'CCONJ', 4, 'cc', 5], ['gulf', 'PROPN', 7, 'compound', 6], ['shores', 'PROPN', 4, 'conj', 7], ['friends', 'NOUN', 1, 'npadvmod', 8], ['!', 'PUNCT', 1, 'punct', 9], ['!', 'PUNCT', 1, 'punct', 10]], [['praying', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['you', 'PRON', 1, 'pobj', 2], ['!', 'PUNCT', 0, 'punct', 3]], [['#hurricanemichael', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=gulf shores\n",
      "anchor NE candidates = \n",
      "full parse [[['#hurricanemichael', 'PROPN', 9, 'intj', 0], ['siesta', 'PROPN', 2, 'compound', 1], ['key', 'PROPN', 3, 'compound', 2], ['beach', 'PROPN', 4, 'compound', 3], ['sarasota', 'PROPN', 6, 'compound', 4], ['florida.only', 'ADV', 6, 'compound', 5], ['brits', 'NOUN', 9, 'nsubj', 6], ['🇬', 'PROPN', 9, 'punct', 7], ['🇧', 'PROPN', 9, 'nsubj', 8], ['left', 'VERB', 9, 'ROOT', 9], ['on', 'ADP', 9, 'prep', 10], ['the', 'DET', 12, 'det', 11], ['beach', 'NOUN', 10, 'pobj', 12], ['.', 'PUNCT', 9, 'punct', 13]], [['sending', 'VERB', 0, 'ROOT', 0], ['love', 'NOUN', 0, 'dobj', 1], ['further', 'ADV', 3, 'advmod', 2], ['up', 'ADP', 0, 'prep', 3], ['the', 'DET', 5, 'det', 4], ['panhandle', 'NOUN', 3, 'pobj', 5], ['.', 'PUNCT', 0, 'punct', 6]]]\n",
      "candidate 0=sarasota\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['our', 'ADJ', 4, 'poss', 0], ['first', 'ADJ', 2, 'amod', 1], ['#hurricanemichael', 'PROPN', 4, 'compound', 2], ['response', 'NOUN', 4, 'compound', 3], ['teams', 'NOUN', 6, 'nsubj', 4], ['have', 'VERB', 6, 'aux', 5], ['arrived', 'VERB', 6, 'ROOT', 6], ['at', 'ADP', 6, 'prep', 7], ['a', 'DET', 10, 'det', 8], ['staging', 'NOUN', 10, 'compound', 9], ['area', 'NOUN', 7, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['okaloosa', 'PROPN', 13, 'compound', 12], ['county', 'PROPN', 14, 'compound', 13], ['fl', 'PROPN', 11, 'pobj', 14], ['just', 'ADV', 16, 'advmod', 15], ['across', 'ADP', 6, 'prep', 16], ['the', 'DET', 18, 'det', 17], ['b', 'NOUN', 16, 'pobj', 18], ['…', 'PUNCT', 6, 'punct', 19]]]\n",
      "candidate 0=okaloosa county\n",
      "anchor NE candidates = \n",
      "full parse [[['posting', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['a', 'DET', 3, 'det', 2], ['friend', 'NOUN', 1, 'pobj', 3], [':', 'PUNCT', 0, 'punct', 4], ['“', 'INTJ', 0, 'appos', 5], ['if', 'ADP', 8, 'mark', 6], ['anyone', 'NOUN', 8, 'nsubj', 7], ['knows', 'VERB', 0, 'advcl', 8], ['what', 'ADJ', 10, 'det', 9], ['conditions', 'NOUN', 11, 'nsubj', 10], ['are', 'VERB', 8, 'ccomp', 11], ['like', 'ADP', 11, 'acomp', 12], ['or', 'CCONJ', 11, 'cc', 13], ['has', 'VERB', 11, 'conj', 14], ['pics', 'NOUN', 14, 'dobj', 15], ['near', 'ADP', 15, 'prep', 16], ['delaware', 'PROPN', 18, 'compound', 17], ['ave', 'PROPN', 16, 'pobj', 18], ['(', 'PUNCT', 18, 'punct', 19], ['right', 'ADV', 21, 'advmod', 20], ['outside', 'ADP', 14, 'prep', 21], ['the', 'DET', 26, 'det', 22], ['lynn', 'PROPN', 26, 'compound', 23], ['haven', 'PROPN', 26, 'compound', 24], ['country', 'PROPN', 26, 'compound', 25], ['club', 'PROPN', 21, 'pobj', 26], [')', 'PUNCT', 14, 'punct', 27], ['or', 'CCONJ', 14, 'cc', 28], ['on', 'ADP', 14, 'conj', 29], ['lisenby', 'PROPN', 29, 'pobj', 30], ['near', 'ADP', 14, 'prep', 31], ['390', 'NUM', 36, 'nummod', 32], ['lynn', 'PROPN', 34, 'compound', 33], ['haven', 'PROPN', 36, 'compound', 34], ['fl', 'PROPN', 36, 'compound', 35], ['north', 'NOUN', 31, 'pobj', 36], ['of', 'ADP', 36, 'prep', 37], ['panama', 'PROPN', 41, 'compound', 38], ['city', 'PROPN', 41, 'compound', 39], ['beach', 'PROPN', 41, 'compound', 40], ['fl', 'PROPN', 37, 'pobj', 41], ['.', 'PUNCT', 0, 'punct', 42]], [['still', 'ADV', 2, 'advmod', 0], ['can', 'VERB', 2, 'aux', 1], ['get', 'VERB', 2, 'ROOT', 2], ['ahold', 'ADP', 2, 'acomp', 3], ['of', 'ADP', 3, 'prep', 4], ['my', 'ADJ', 6, 'poss', 5], ['mom', 'NOUN', 4, 'pobj', 6], ['or', 'CCONJ', 6, 'cc', 7], ['grandparents', 'NOUN', 6, 'conj', 8], ['.', 'PUNCT', 2, 'punct', 9], ['”', 'PUNCT', 10, 'ROOT', 10], ['#hurricanemichael', 'PROPN', 11, 'ROOT', 11]]]\n",
      "candidate 0=lynn haven\n",
      "anchor NE candidates = \n",
      "candidate 1=panama city beach\n",
      "anchor NE candidates = lynn haven\n",
      "data NE tree=[['panama', 'PROPN', 41, 'compound', 38], ['city', 'PROPN', 41, 'compound', 39], ['beach', 'PROPN', 41, 'compound', 40]]\n",
      "NE parse token at tree=0, token=41:\n",
      "['beach', 'PROPN', 41, 'compound', 40]\n",
      "NE parent token:\n",
      "['fl', 'PROPN', 37, 'pobj', 41]\n",
      "parent node subtree [['panama', 'PROPN', 41, 'compound', 38], ['city', 'PROPN', 41, 'compound', 39], ['beach', 'PROPN', 41, 'compound', 40], ['fl', 'PROPN', 37, 'pobj', 41]]\n",
      "parent node subtree str \"panama city beach fl\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "full parse [[['sadly', 'ADV', 3, 'advmod', 0], ['we', 'PRON', 3, 'nsubj', 1], ['now', 'ADV', 3, 'advmod', 2], ['have', 'VERB', 3, 'ROOT', 3], ['6', 'NUM', 6, 'nummod', 4], ['confirmed', 'VERB', 6, 'amod', 5], ['fatalities', 'NOUN', 3, 'dobj', 6], ['due', 'ADJ', 6, 'amod', 7], ['to', 'ADP', 7, 'prep', 8], ['#michael', 'PROPN', 8, 'pobj', 9], ['all', 'DET', 11, 'det', 10], ['inland', 'ADV', 3, 'npadvmod', 11], ['.', 'PUNCT', 3, 'punct', 12]], [['4', 'PUNCT', 0, 'ROOT', 0], ['in', 'ADP', 0, 'prep', 1], ['gadsden', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 4, 'compound', 3], ['fl', 'PROPN', 1, 'pobj', 4], ['(', 'PUNCT', 4, 'punct', 5], ['nw', 'PROPN', 4, 'appos', 6], ['of', 'ADP', 6, 'prep', 7], ['tallahassee', 'PROPN', 7, 'pobj', 8], [')', 'PUNCT', 4, 'punct', 9], ['one', 'NUM', 4, 'appos', 10], ['in', 'ADP', 10, 'prep', 11], ['seminole', 'PROPN', 13, 'compound', 12], ['county', 'PROPN', 11, 'pobj', 13], ['in', 'ADP', 13, 'prep', 14], ['sw', 'PROPN', 16, 'compound', 15], ['georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['iredell', 'PROPN', 24, 'compound', 23], ['county', 'PROPN', 25, 'compound', 24], ['nc', 'PROPN', 22, 'pobj', 25], ['.', 'PUNCT', 0, 'punct', 26]], [['most', 'ADV', 1, 'advmod', 0], ['known', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['be', 'VERB', 1, 'xcomp', 3], ['due', 'ADJ', 3, 'acomp', 4], ['to', 'ADP', 4, 'pcomp', 5], ['wind', 'NOUN', 4, 'pobj', 6], ['knocking', 'VERB', 6, 'acl', 7], ['down', 'PART', 7, 'prt', 8], ['trees', 'NOUN', 7, 'dobj', 9], ['or', 'CCONJ', 9, 'cc', 10], ['structures', 'NOUN', 9, 'conj', 11], ['onto', 'ADP', 7, 'prep', 12], ['victims', 'NOUN', 12, 'pobj', 13], ['.', 'PUNCT', 1, 'punct', 14]]]\n",
      "candidate 0=gadsden county\n",
      "anchor NE candidates = tallahassee,seminole county\n",
      "data NE tree=[['gadsden', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 4, 'compound', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['county', 'PROPN', 4, 'compound', 3]\n",
      "NE parent token:\n",
      "['fl', 'PROPN', 1, 'pobj', 4]\n",
      "parent node subtree [['gadsden', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 4, 'compound', 3], ['fl', 'PROPN', 1, 'pobj', 4], ['(', 'PUNCT', 4, 'punct', 5], ['nw', 'PROPN', 4, 'appos', 6], ['of', 'ADP', 6, 'prep', 7], ['tallahassee', 'PROPN', 7, 'pobj', 8], [')', 'PUNCT', 4, 'punct', 9], ['one', 'NUM', 4, 'appos', 10], ['in', 'ADP', 10, 'prep', 11], ['seminole', 'PROPN', 13, 'compound', 12], ['county', 'PROPN', 11, 'pobj', 13], ['in', 'ADP', 13, 'prep', 14], ['sw', 'PROPN', 16, 'compound', 15], ['georgia', 'PROPN', 14, 'pobj', 16], ['and', 'CCONJ', 13, 'cc', 17], ['one', 'NUM', 19, 'nummod', 18], ['north', 'NOUN', 13, 'conj', 19], ['of', 'ADP', 19, 'prep', 20], ['charlotte', 'PROPN', 20, 'pobj', 21], ['in', 'ADP', 19, 'prep', 22], ['iredell', 'PROPN', 24, 'compound', 23], ['county', 'PROPN', 25, 'compound', 24], ['nc', 'PROPN', 22, 'pobj', 25]]\n",
      "parent node subtree str \"gadsden county fl ( nw of tallahassee ) one in seminole county in sw georgia and one north of charlotte in iredell county nc\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=tallahassee\n",
      "anchor NE candidates = seminole county\n",
      "data NE tree=[['tallahassee', 'PROPN', 7, 'pobj', 8]]\n",
      "NE parse token at tree=1, token=9:\n",
      "['tallahassee', 'PROPN', 7, 'pobj', 8]\n",
      "NE parent token:\n",
      "['of', 'ADP', 6, 'prep', 7]\n",
      "candidate 2=seminole county\n",
      "anchor NE candidates = \n",
      "full parse [[['but', 'CCONJ', 5, 'cc', 0], ['here', 'ADV', 5, 'advmod', 1], ['i', 'PRON', 5, 'nsubj', 2], ['am', 'VERB', 5, 'aux', 3], ['always', 'ADV', 5, 'advmod', 4], ['watching', 'VERB', 5, 'ROOT', 5], ['other', 'ADJ', 7, 'amod', 6], ['places', 'NOUN', 8, 'nsubj', 7], ['have', 'VERB', 5, 'ccomp', 8], ['outside', 'ADJ', 10, 'amod', 9], ['help', 'NOUN', 8, 'dobj', 10], ['in', 'ADP', 10, 'prep', 11], ['a', 'DET', 13, 'det', 12], ['disaster', 'NOUN', 11, 'pobj', 13], ['and', 'CCONJ', 8, 'cc', 14], ['here', 'ADV', 17, 'advmod', 15], ['we', 'PRON', 17, 'nsubj', 16], ['live', 'VERB', 8, 'conj', 17], ['with', 'ADP', 17, 'prep', 18], ['police', 'NOUN', 18, 'pobj', 19], ['and', 'CCONJ', 19, 'cc', 20], ['fire', 'NOUN', 19, 'conj', 21], ['from', 'ADP', 17, 'prep', 22], ['jacksonville', 'PROPN', 26, 'compound', 23], ['miami', 'PROPN', 26, 'compound', 24], ['hillsborough', 'PROPN', 26, 'compound', 25], ['tallahassee', 'PROPN', 22, 'pobj', 26], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29], ['roll', 'VERB', 17, 'conj', 30], ['up', 'PART', 30, 'prt', 31], ['and', 'CCONJ', 31, 'cc', 32], ['down', 'ADP', 31, 'conj', 33], ['the', 'DET', 35, 'det', 34], ['roads', 'NOUN', 33, 'pobj', 35], ['#panamacity', 'VERB', 37, 'compound', 36], ['#hurricanemichael', 'PROPN', 37, 'ROOT', 37]]]\n",
      "candidate 0=miami\n",
      "anchor NE candidates = jacksonville\n",
      "data NE tree=[['miami', 'PROPN', 26, 'compound', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['miami', 'PROPN', 26, 'compound', 24]\n",
      "NE parent token:\n",
      "['tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "parent node subtree [['jacksonville', 'PROPN', 26, 'compound', 23], ['miami', 'PROPN', 26, 'compound', 24], ['hillsborough', 'PROPN', 26, 'compound', 25], ['tallahassee', 'PROPN', 22, 'pobj', 26], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "parent node subtree str \"jacksonville miami hillsborough tallahassee and other places\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=jacksonville\n",
      "anchor NE candidates = \n",
      "candidate 2=hillsborough\n",
      "anchor NE candidates = miami,jacksonville,tallahassee\n",
      "data NE tree=[['hillsborough', 'PROPN', 26, 'compound', 25]]\n",
      "NE parse token at tree=0, token=26:\n",
      "['hillsborough', 'PROPN', 26, 'compound', 25]\n",
      "NE parent token:\n",
      "['tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "parent node subtree [['jacksonville', 'PROPN', 26, 'compound', 23], ['miami', 'PROPN', 26, 'compound', 24], ['hillsborough', 'PROPN', 26, 'compound', 25], ['tallahassee', 'PROPN', 22, 'pobj', 26], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "parent node subtree str \"jacksonville miami hillsborough tallahassee and other places\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 3=tallahassee\n",
      "anchor NE candidates = miami,jacksonville\n",
      "data NE tree=[['tallahassee', 'PROPN', 22, 'pobj', 26]]\n",
      "NE parse token at tree=0, token=27:\n",
      "['tallahassee', 'PROPN', 22, 'pobj', 26]\n",
      "NE parent token:\n",
      "['from', 'ADP', 17, 'prep', 22]\n",
      "NE=tallahassee subtree=[['jacksonville', 'PROPN', 26, 'compound', 23], ['miami', 'PROPN', 26, 'compound', 24], ['hillsborough', 'PROPN', 26, 'compound', 25], ['and', 'CCONJ', 26, 'cc', 27], ['other', 'ADJ', 29, 'amod', 28], ['places', 'NOUN', 26, 'conj', 29]]\n",
      "min node deps ['compound', 'compound', 'compound', 'cc', 'conj']\n",
      "full parse [[['ides', 'PROPN', 2, 'nsubj', 0], ['is', 'VERB', 2, 'aux', 1], ['responding', 'VERB', 2, 'ROOT', 2], ['to', 'ADP', 2, 'prep', 3], ['#hurricanemichael', 'PROPN', 6, 'compound', 4], ['ides', 'PROPN', 6, 'compound', 5], ['staff', 'NOUN', 3, 'pobj', 6], ['is', 'VERB', 2, 'conj', 7], ['en', 'ADP', 7, 'advmod', 8], ['route', 'NOUN', 8, 'npadvmod', 9], ['to', 'ADP', 9, 'prep', 10], ['florida', 'PROPN', 10, 'pobj', 11], ['where', 'ADV', 16, 'advmod', 12], ['we', 'PRON', 16, 'nsubj', 13], ['will', 'VERB', 16, 'aux', 14], ['be', 'VERB', 16, 'aux', 15], ['#partnering', 'VERB', 11, 'relcl', 16], ['with', 'ADP', 16, 'prep', 17], ['our', 'ADJ', 22, 'poss', 18], ['anchor', 'PROPN', 20, 'compound', 19], ['church', 'PROPN', 22, 'compound', 20], [\"christ's\", 'PROPN', 22, 'compound', 21], ['church', 'PROPN', 17, 'pobj', 22], ['of', 'ADP', 22, 'prep', 23], ['jacksonville', 'PROPN', 25, 'compound', 24], ['@ccontheweb', 'PUNCT', 2, 'dobj', 25], ['to', 'PART', 27, 'aux', 26], ['connect', 'VERB', 2, 'advcl', 27], ['with', 'ADP', 27, 'prep', 28], ['churches', 'NOUN', 28, 'pobj', 29], ['in', 'ADP', 29, 'prep', 30], ['communities', 'NOUN', 30, 'pobj', 31], ['affected', 'VERB', 31, 'acl', 32], ['by', 'ADP', 32, 'agent', 33], ['#hurricane', 'PROPN', 35, 'compound', 34], ['michael', 'PROPN', 33, 'pobj', 35], ['.', 'PUNCT', 2, 'punct', 36]]]\n",
      "candidate 0=jacksonville\n",
      "anchor NE candidates = \n",
      "full parse [[['ts', 'PROPN', 1, 'compound', 0], ['#michael', 'PROPN', 2, 'nsubj', 1], ['knocked', 'VERB', 2, 'ROOT', 2], ['down', 'PART', 2, 'prt', 3], ['some', 'DET', 5, 'det', 4], ['trees', 'NOUN', 2, 'dobj', 5], ['left', 'VERB', 2, 'conj', 6], ['thousands', 'NOUN', 6, 'dobj', 7], ['without', 'ADP', 6, 'prep', 8], ['power', 'NOUN', 8, 'pobj', 9], ['and', 'CCONJ', 6, 'cc', 10], ['blocked', 'VERB', 6, 'conj', 11], ['several', 'ADJ', 13, 'amod', 12], ['roadways', 'NOUN', 11, 'dobj', 13], ['in', 'ADP', 11, 'prep', 14], ['darlington', 'PROPN', 16, 'compound', 15], ['sc', 'PROPN', 14, 'pobj', 16], ['.', 'PUNCT', 2, 'punct', 17]]]\n",
      "candidate 0=darlington\n",
      "anchor NE candidates = \n",
      "full parse [[['keep', 'VERB', 0, 'ROOT', 0], ['all', 'ADJ', 3, 'predet', 1], ['the', 'DET', 3, 'det', 2], ['cities', 'NOUN', 0, 'dobj', 3], ['affected', 'VERB', 3, 'acl', 4], ['by', 'ADP', 4, 'agent', 5], ['#hurricanemichael', 'PROPN', 5, 'pobj', 6], ['in', 'ADP', 4, 'prep', 7], ['your', 'ADJ', 9, 'poss', 8], ['prayers', 'NOUN', 7, 'pobj', 9], ['.', 'PUNCT', 0, 'punct', 10]], [['jackson', 'PROPN', 1, 'compound', 0], ['county', 'PROPN', 3, 'compound', 1], ['bay', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 5, 'compound', 3], ['washington', 'PROPN', 5, 'compound', 4], ['county', 'PROPN', 7, 'compound', 5], ['houston', 'PROPN', 7, 'compound', 6], ['county', 'PROPN', 7, 'ROOT', 7], ['and', 'CCONJ', 7, 'cc', 8], ['others', 'NOUN', 7, 'conj', 9], ['.', 'PUNCT', 7, 'punct', 10]], [['we', 'PRON', 2, 'nsubj', 0], ['all', 'DET', 0, 'appos', 1], ['need', 'VERB', 2, 'ROOT', 2], ['help', 'NOUN', 2, 'dobj', 3], ['!', 'PUNCT', 2, 'punct', 4]]]\n",
      "candidate 0=houston county\n",
      "anchor NE candidates = jackson county\n",
      "data NE tree=[['houston', 'PROPN', 7, 'compound', 6], ['county', 'PROPN', 7, 'ROOT', 7]]\n",
      "NE=houston county subtree=[['jackson', 'PROPN', 1, 'compound', 0], ['county', 'PROPN', 3, 'compound', 1], ['bay', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 5, 'compound', 3], ['washington', 'PROPN', 5, 'compound', 4], ['county', 'PROPN', 7, 'compound', 5], ['and', 'CCONJ', 7, 'cc', 8], ['others', 'NOUN', 7, 'conj', 9], ['.', 'PUNCT', 7, 'punct', 10]]\n",
      "min node deps ['compound']\n",
      "candidate 1=jackson county\n",
      "anchor NE candidates = \n",
      "full parse [[['all', 'DET', 1, 'det', 0], ['orders', 'NOUN', 8, 'nsubjpass', 1], ['to', 'ADP', 1, 'prep', 2], ['mexico', 'PROPN', 5, 'compound', 3], ['beach', 'PROPN', 5, 'compound', 4], ['fl', 'PROPN', 2, 'pobj', 5], ['will', 'VERB', 8, 'aux', 6], ['be', 'VERB', 8, 'auxpass', 7], ['refunded', 'VERB', 8, 'ROOT', 8], ['foc', 'PROPN', 8, 'dobj', 9], ['and', 'CCONJ', 8, 'cc', 10], ['sent', 'VERB', 8, 'conj', 11], ['in', 'PART', 11, 'advmod', 12], ['due', 'ADJ', 14, 'amod', 13], ['course', 'NOUN', 11, 'dobj', 14], ['!', 'PUNCT', 8, 'punct', 15]], [['please', 'INTJ', 1, 'intj', 0], ['contact', 'VERB', 1, 'ROOT', 1], ['info@wave97.com', 'X', 1, 'dobj', 2], ['for', 'ADP', 1, 'prep', 3], ['more', 'ADJ', 5, 'amod', 4], ['information', 'NOUN', 3, 'pobj', 5], ['.', 'PUNCT', 1, 'punct', 6]], [['#hurricanemichael', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=mexico beach\n",
      "anchor NE candidates = \n",
      "full parse [[['icymi', 'PROPN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1], ['this', 'DET', 3, 'det', 2], ['reporter', 'NOUN', 4, 'nsubj', 3], ['hunkered', 'VERB', 4, 'ROOT', 4], ['down', 'PART', 4, 'prt', 5], ['in', 'ADP', 4, 'prep', 6], ['a', 'DET', 12, 'det', 7], ['panama', 'PROPN', 10, 'compound', 8], ['city', 'PROPN', 10, 'compound', 9], ['florida', 'PROPN', 12, 'compound', 10], ['parking', 'NOUN', 12, 'compound', 11], ['deck', 'NOUN', 6, 'pobj', 12], ['as', 'ADP', 16, 'mark', 13], ['hurricane', 'PROPN', 15, 'compound', 14], ['michael', 'PROPN', 16, 'nsubj', 15], ['roared', 'VERB', 4, 'advcl', 16], ['ashore', 'ADV', 16, 'advmod', 17], ['wednesday', 'PROPN', 16, 'npadvmod', 18], ['more', 'ADV', 20, 'amod', 19], ['#hurricanemichael', 'PROPN', 21, 'nummod', 20], ['video', 'NOUN', 21, 'ROOT', 21], [':', 'PUNCT', 21, 'punct', 22]]]\n",
      "candidate 0=panama city\n",
      "anchor NE candidates = \n",
      "full parse [[['#hurricanerelief', 'PROPN', 2, 'nmod', 0], ['#hurricanemichael', 'PROPN', 2, 'compound', 1], ['#maga', 'PROPN', 4, 'compound', 2], ['#americafirst', 'X', 4, 'compound', 3], ['#nationalguard', 'PROPN', 4, 'ROOT', 4], ['#fema', 'X', 5, 'ROOT', 5], ['@fema', 'X', 5, 'punct', 6], ['#kag', 'PUNCT', 7, 'ROOT', 7], ['from', 'ADP', 7, 'prep', 8], ['congressman', 'PROPN', 11, 'compound', 9], ['matt', 'PROPN', 11, 'compound', 10], ['gaetz', 'PROPN', 8, 'pobj', 11], ['for', 'ADP', 8, 'prep', 12], ['areas', 'NOUN', 12, 'pobj', 13], ['having', 'VERB', 13, 'acl', 14], ['trouble', 'NOUN', 14, 'dobj', 15], ['getting', 'VERB', 15, 'acl', 16], ['supplies', 'NOUN', 16, 'dobj', 17], ['food', 'NOUN', 19, 'compound', 18], ['water', 'NOUN', 17, 'dobj', 19], ['around', 'ADP', 17, 'prep', 20], ['bonifay', 'PROPN', 23, 'compound', 21], ['holmes', 'PROPN', 23, 'compound', 22], ['county', 'PROPN', 27, 'compound', 23], ['ponce', 'PROPN', 26, 'compound', 24], ['de', 'PROPN', 26, 'compound', 25], ['leon', 'PROPN', 27, 'compound', 26], ['areas', 'NOUN', 20, 'pobj', 27], ['.', 'PUNCT', 7, 'punct', 28]], [['disaster', 'NOUN', 1, 'compound', 0], ['relief', 'NOUN', 2, 'compound', 1], ['contact', 'NOUN', 3, 'compound', 2], ['info', 'NOUN', 3, 'ROOT', 3], ['below', 'ADV', 3, 'advmod', 4], ['.', 'PUNCT', 3, 'punct', 5]], [['@repmattgaetz', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=bonifay\n",
      "anchor NE candidates = holmes county\n",
      "data NE tree=[['bonifay', 'PROPN', 23, 'compound', 21]]\n",
      "NE parse token at tree=0, token=22:\n",
      "['bonifay', 'PROPN', 23, 'compound', 21]\n",
      "NE parent token:\n",
      "['county', 'PROPN', 27, 'compound', 23]\n",
      "parent node subtree [['bonifay', 'PROPN', 23, 'compound', 21], ['holmes', 'PROPN', 23, 'compound', 22], ['county', 'PROPN', 27, 'compound', 23]]\n",
      "parent node subtree str \"bonifay holmes county\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=holmes county\n",
      "anchor NE candidates = \n",
      "candidate 2=ponce de leon\n",
      "anchor NE candidates = bonifay,holmes county\n",
      "data NE tree=[['ponce', 'PROPN', 26, 'compound', 24], ['de', 'PROPN', 26, 'compound', 25], ['leon', 'PROPN', 27, 'compound', 26]]\n",
      "NE parse token at tree=0, token=27:\n",
      "['leon', 'PROPN', 27, 'compound', 26]\n",
      "NE parent token:\n",
      "['areas', 'NOUN', 20, 'pobj', 27]\n",
      "parent node subtree [['bonifay', 'PROPN', 23, 'compound', 21], ['holmes', 'PROPN', 23, 'compound', 22], ['county', 'PROPN', 27, 'compound', 23], ['ponce', 'PROPN', 26, 'compound', 24], ['de', 'PROPN', 26, 'compound', 25], ['leon', 'PROPN', 27, 'compound', 26], ['areas', 'NOUN', 20, 'pobj', 27]]\n",
      "parent node subtree str \"bonifay holmes county ponce de leon areas\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "full parse [[['new', 'ADJ', 2, 'amod', 0], ['aerial', 'ADJ', 2, 'amod', 1], ['video', 'NOUN', 2, 'ROOT', 2], ['of', 'ADP', 2, 'prep', 3], ['the', 'DET', 6, 'det', 4], ['massive', 'ADJ', 6, 'amod', 5], ['destruction', 'NOUN', 3, 'pobj', 6], ['at', 'ADP', 6, 'prep', 7], ['mexico', 'PROPN', 10, 'compound', 8], ['beach', 'PROPN', 10, 'compound', 9], ['florida', 'PROPN', 7, 'pobj', 10], ['.', 'PUNCT', 2, 'punct', 11]], [['thanks', 'NOUN', 0, 'ROOT', 0], ['once', 'ADV', 2, 'advmod', 1], ['again', 'ADV', 0, 'advmod', 2], ['to', 'ADP', 0, 'prep', 3], ['our', 'ADJ', 6, 'poss', 4], ['exclusive', 'ADJ', 6, 'amod', 5], ['partners', 'NOUN', 3, 'pobj', 6], ['at', 'ADP', 6, 'prep', 7], ['@livestormsmedia', 'PROPN', 7, 'pobj', 8], ['#arwx', 'X', 10, 'compound', 9], ['#michael', 'PROPN', 7, 'pobj', 10]]]\n",
      "candidate 0=mexico beach\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['devastating', 'ADJ', 1, 'amod', 0], ['damage', 'NOUN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['this', 'DET', 4, 'nsubj', 3], ['is', 'VERB', 4, 'ROOT', 4], ['my', 'ADJ', 7, 'poss', 5], ['2nd', 'ADJ', 7, 'amod', 6], ['year', 'NOUN', 4, 'attr', 7], ['living', 'VERB', 7, 'acl', 8], ['in', 'ADP', 8, 'prep', 9], ['florida', 'PROPN', 9, 'pobj', 10], ['during', 'ADP', 8, 'prep', 11], ['hurricane', 'PROPN', 13, 'compound', 12], ['season', 'PROPN', 11, 'pobj', 13], ['and', 'CCONJ', 7, 'cc', 14], ['the', 'DET', 16, 'det', 15], ['images', 'NOUN', 18, 'nsubj', 16], [\"don't\", 'VERB', 18, 'aux', 17], ['get', 'VERB', 4, 'conj', 18], ['easier', 'ADJ', 18, 'acomp', 19], ['to', 'PART', 21, 'aux', 20], ['watch', 'VERB', 19, 'xcomp', 21], ['.', 'PUNCT', 4, 'punct', 22]], [['this', 'DET', 1, 'det', 0], ['picture', 'NOUN', 2, 'nsubj', 1], ['shows', 'VERB', 2, 'ROOT', 2], ['the', 'DET', 4, 'det', 3], ['devastation', 'NOUN', 2, 'dobj', 4], ['left', 'VERB', 4, 'acl', 5], ['behind', 'ADV', 5, 'prt', 6], ['by', 'ADP', 5, 'agent', 7], ['#hurricanemichael', 'PROPN', 7, 'pobj', 8], ['in', 'ADP', 5, 'prep', 9], ['mexico', 'PROPN', 11, 'compound', 10], ['beach', 'PROPN', 9, 'pobj', 11], ['.', 'PUNCT', 2, 'punct', 12]], [['praying', 'VERB', 0, 'ROOT', 0], ['for', 'ADP', 0, 'prep', 1], ['the', 'DET', 3, 'det', 2], ['victims', 'NOUN', 1, 'pobj', 3], ['and', 'CCONJ', 3, 'cc', 4], ['their', 'ADJ', 6, 'poss', 5], ['families', 'NOUN', 3, 'conj', 6], ['.', 'PUNCT', 0, 'punct', 7]], [['#prayersforthepanhandle', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=mexico beach\n",
      "anchor NE candidates = \n",
      "full parse [[['thank', 'VERB', 0, 'ROOT', 0], ['you', 'PRON', 0, 'dative', 1], ['this', 'DET', 7, 'det', 2], ['panama', 'PROPN', 5, 'compound', 3], ['city', 'PROPN', 5, 'compound', 4], ['beach', 'PROPN', 7, 'nmod', 5], ['#hurricanemichael', 'PROPN', 7, 'compound', 6], ['survivor', 'NOUN', 8, 'nsubj', 7], ['appreciates', 'VERB', 0, 'ccomp', 8], ['what', 'NOUN', 12, 'dobj', 9], ['you', 'PRON', 12, 'nsubj', 10], ['are', 'VERB', 12, 'aux', 11], ['doing', 'VERB', 8, 'ccomp', 12], ['for', 'ADP', 12, 'dative', 13], ['us', 'PRON', 13, 'pobj', 14], ['!', 'PUNCT', 0, 'punct', 15], ['!', 'PUNCT', 0, 'punct', 16]], [['your', 'ADJ', 1, 'poss', 0], ['store', 'NOUN', 6, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['santa', 'PROPN', 4, 'compound', 3], ['rosa', 'PROPN', 5, 'compound', 4], ['beach', 'PROPN', 2, 'pobj', 5], ['helped', 'VERB', 6, 'ROOT', 6], ['us', 'PRON', 6, 'dobj', 7], ['today', 'NOUN', 6, 'npadvmod', 8], ['when', 'ADV', 11, 'advmod', 9], ['we', 'PRON', 11, 'nsubj', 10], ['drove', 'VERB', 6, 'advcl', 11], ['over', 'PART', 11, 'advmod', 12], ['from', 'ADP', 11, 'prep', 13], ['panama', 'PROPN', 15, 'compound', 14], ['city', 'PROPN', 13, 'pobj', 15], ['to', 'PART', 17, 'aux', 16], ['purchase', 'VERB', 11, 'advcl', 17], ['food', 'NOUN', 22, 'nmod', 18], ['/', 'SYM', 22, 'punct', 19], ['water', 'NOUN', 22, 'nmod', 20], ['/', 'SYM', 22, 'punct', 21], ['supplies', 'NOUN', 17, 'dobj', 22], ['for', 'ADP', 22, 'prep', 23], ['our', 'ADJ', 25, 'poss', 24], ['friends', 'NOUN', 23, 'pobj', 25], ['and', 'CCONJ', 25, 'cc', 26], ['coworkers', 'NOUN', 25, 'conj', 27], ['.', 'PUNCT', 6, 'punct', 28]], [['the', 'DET', 1, 'det', 0], ['employees', 'NOUN', 2, 'nsubj', 1], ['were', 'VERB', 2, 'ROOT', 2], ['so', 'ADV', 4, 'advmod', 3], ['kind', 'ADJ', 2, 'acomp', 4], ['!', 'PUNCT', 2, 'punct', 5]]]\n",
      "candidate 0=panama city beach\n",
      "anchor NE candidates = panama city\n",
      "data NE tree=[['panama', 'PROPN', 5, 'compound', 3], ['city', 'PROPN', 5, 'compound', 4], ['beach', 'PROPN', 7, 'nmod', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['beach', 'PROPN', 7, 'nmod', 5]\n",
      "NE parent token:\n",
      "['survivor', 'NOUN', 8, 'nsubj', 7]\n",
      "parent node subtree [['this', 'DET', 7, 'det', 2], ['panama', 'PROPN', 5, 'compound', 3], ['city', 'PROPN', 5, 'compound', 4], ['beach', 'PROPN', 7, 'nmod', 5], ['#hurricanemichael', 'PROPN', 7, 'compound', 6], ['survivor', 'NOUN', 8, 'nsubj', 7]]\n",
      "parent node subtree str \"this panama city beach #hurricanemichael survivor\"\n",
      "candidate 1=santa rosa beach\n",
      "anchor NE candidates = panama city beach,panama city\n",
      "data NE tree=[['santa', 'PROPN', 4, 'compound', 3], ['rosa', 'PROPN', 5, 'compound', 4], ['beach', 'PROPN', 2, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['beach', 'PROPN', 2, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "candidate 2=panama city\n",
      "anchor NE candidates = \n",
      "full parse [[['rob', 'PROPN', 1, 'compound', 0], ['golding', 'PROPN', 2, 'nsubj', 1], ['drove', 'VERB', 2, 'ROOT', 2], ['to', 'ADP', 2, 'prep', 3], ['springfield', 'PROPN', 5, 'compound', 4], ['florida', 'PROPN', 3, 'pobj', 5], ['to', 'PART', 7, 'aux', 6], ['be', 'VERB', 2, 'advcl', 7], ['with', 'ADP', 7, 'prep', 8], ['his', 'ADJ', 13, 'poss', 9], ['89', 'NUM', 11, 'nummod', 10], ['year', 'NOUN', 12, 'npadvmod', 11], ['old', 'ADJ', 13, 'amod', 12], ['dad', 'NOUN', 8, 'pobj', 13], ['during', 'ADP', 7, 'prep', 14], ['#hurricanemichael', 'PROPN', 14, 'pobj', 15], ['.', 'PUNCT', 2, 'punct', 16]], [['his', 'ADJ', 1, 'poss', 0], ['home', 'NOUN', 3, 'nsubjpass', 1], ['was', 'VERB', 3, 'auxpass', 2], ['spared', 'VERB', 3, 'ROOT', 3], ['but', 'CCONJ', 3, 'cc', 4], ['the', 'DET', 6, 'det', 5], ['area', 'NOUN', 7, 'nsubj', 6], ['suffered', 'VERB', 3, 'conj', 7], ['damage', 'NOUN', 7, 'dobj', 8], ['so', 'ADP', 11, 'mark', 9], ['they', 'PRON', 11, 'nsubj', 10], ['started', 'VERB', 7, 'advcl', 11], ['taking', 'VERB', 11, 'xcomp', 12], ['in', 'PART', 12, 'prt', 13], ['neighbors', 'NOUN', 12, 'dobj', 14], ['going', 'VERB', 14, 'acl', 15], ['out', 'PART', 15, 'prt', 16], ['to', 'PART', 18, 'aux', 17], ['rescue', 'VERB', 15, 'advcl', 18], ['friends', 'NOUN', 18, 'dobj', 19], ['and', 'CCONJ', 18, 'cc', 20], ['organizing', 'VERB', 18, 'conj', 21], ['food', 'NOUN', 21, 'dobj', 22], ['for', 'ADP', 21, 'prep', 23], ['the', 'DET', 25, 'det', 24], ['community', 'NOUN', 23, 'pobj', 25], ['.', 'PUNCT', 7, 'punct', 26]]]\n",
      "candidate 0=springfield\n",
      "anchor NE candidates = \n",
      "full parse [[['heard', 'ADP', 4, 'mark', 0], ['you', 'PRON', 2, 'nmod', 1], ['guys', 'NOUN', 4, 'nsubj', 2], ['are', 'VERB', 4, 'aux', 3], ['bringing', 'VERB', 4, 'ROOT', 4], ['prepaid', 'ADJ', 6, 'amod', 5], ['phones', 'NOUN', 4, 'dobj', 6], ['and', 'CCONJ', 4, 'cc', 7], ['charging', 'VERB', 4, 'conj', 8], ['stations', 'NOUN', 8, 'dobj', 9], ['.', 'PUNCT', 4, 'punct', 10]], [['please', 'INTJ', 1, 'intj', 0], ['don', 'VERB', 1, 'ROOT', 1], ['’', 'NOUN', 3, 'compound', 2], ['t', 'NOUN', 1, 'dobj', 3], ['do', 'VERB', 1, 'conj', 4], ['this', 'DET', 4, 'dobj', 5], ['on', 'ADP', 4, 'prep', 6], ['panama', 'PROPN', 9, 'compound', 7], ['city', 'PROPN', 9, 'compound', 8], ['beach', 'PROPN', 6, 'pobj', 9], ['.', 'PUNCT', 1, 'punct', 10]], [['they', 'PRON', 1, 'nsubj', 0], ['have', 'VERB', 1, 'ROOT', 1], ['electricity', 'NOUN', 1, 'dobj', 2], ['and', 'CCONJ', 2, 'cc', 3], ['access', 'NOUN', 2, 'conj', 4], ['to', 'ADP', 2, 'prep', 5], ['destin', 'PROPN', 5, 'pobj', 6], ['.', 'PUNCT', 1, 'punct', 7]], [['come', 'VERB', 0, 'ROOT', 0], ['into', 'ADP', 0, 'prep', 1], ['panama', 'PROPN', 3, 'compound', 2], ['city', 'PROPN', 6, 'compound', 3], ['callaway', 'PROPN', 6, 'compound', 4], ['lynn', 'PROPN', 6, 'compound', 5], ['haven', 'PROPN', 7, 'compound', 6], ['@tmobile', 'PROPN', 1, 'pobj', 7], ['@tmobilehelp', 'NOUN', 0, 'punct', 8], ['#hurricanemichael', 'PUNCT', 9, 'ROOT', 9]]]\n",
      "candidate 0=panama city beach\n",
      "anchor NE candidates = destin,panama city,callaway,lynn haven\n",
      "data NE tree=[['panama', 'PROPN', 9, 'compound', 7], ['city', 'PROPN', 9, 'compound', 8], ['beach', 'PROPN', 6, 'pobj', 9]]\n",
      "NE parse token at tree=1, token=10:\n",
      "['beach', 'PROPN', 6, 'pobj', 9]\n",
      "NE parent token:\n",
      "['on', 'ADP', 4, 'prep', 6]\n",
      "candidate 1=destin\n",
      "anchor NE candidates = panama city,callaway,lynn haven\n",
      "data NE tree=[['destin', 'PROPN', 5, 'pobj', 6]]\n",
      "NE parse token at tree=2, token=7:\n",
      "['destin', 'PROPN', 5, 'pobj', 6]\n",
      "NE parent token:\n",
      "['to', 'ADP', 2, 'prep', 5]\n",
      "candidate 2=panama city\n",
      "anchor NE candidates = \n",
      "candidate 3=callaway\n",
      "anchor NE candidates = panama city,lynn haven\n",
      "data NE tree=[['callaway', 'PROPN', 6, 'compound', 4]]\n",
      "NE parse token at tree=3, token=5:\n",
      "['callaway', 'PROPN', 6, 'compound', 4]\n",
      "NE parent token:\n",
      "['haven', 'PROPN', 7, 'compound', 6]\n",
      "parent node subtree [['panama', 'PROPN', 3, 'compound', 2], ['city', 'PROPN', 6, 'compound', 3], ['callaway', 'PROPN', 6, 'compound', 4], ['lynn', 'PROPN', 6, 'compound', 5], ['haven', 'PROPN', 7, 'compound', 6]]\n",
      "parent node subtree str \"panama city callaway lynn haven\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 4=lynn haven\n",
      "anchor NE candidates = panama city\n",
      "data NE tree=[['lynn', 'PROPN', 6, 'compound', 5], ['haven', 'PROPN', 7, 'compound', 6]]\n",
      "NE parse token at tree=3, token=7:\n",
      "['haven', 'PROPN', 7, 'compound', 6]\n",
      "NE parent token:\n",
      "['@tmobile', 'PROPN', 1, 'pobj', 7]\n",
      "parent node subtree [['panama', 'PROPN', 3, 'compound', 2], ['city', 'PROPN', 6, 'compound', 3], ['callaway', 'PROPN', 6, 'compound', 4], ['lynn', 'PROPN', 6, 'compound', 5], ['haven', 'PROPN', 7, 'compound', 6], ['@tmobile', 'PROPN', 1, 'pobj', 7]]\n",
      "parent node subtree str \"panama city callaway lynn haven @tmobile\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "NE=lynn haven subtree=[['panama', 'PROPN', 3, 'compound', 2], ['city', 'PROPN', 6, 'compound', 3], ['callaway', 'PROPN', 6, 'compound', 4]]\n",
      "min node deps ['compound']\n",
      "full parse [[['devastation', 'NOUN', 0, 'ROOT', 0], ['in', 'ADP', 0, 'prep', 1], ['mexico', 'PROPN', 4, 'compound', 2], ['beach', 'PROPN', 4, 'compound', 3], ['florida', 'PROPN', 1, 'pobj', 4], ['from', 'ADP', 0, 'prep', 5], ['hurricane', 'PROPN', 7, 'compound', 6], ['#michael', 'PROPN', 5, 'pobj', 7], ['.', 'PUNCT', 0, 'punct', 8]]]\n",
      "candidate 0=mexico beach\n",
      "anchor NE candidates = \n",
      "full parse [[['vacasa', 'PROPN', 1, 'compound', 0], ['office', 'NOUN', 1, 'ROOT', 1], ['in', 'ADP', 1, 'prep', 2], ['panama', 'PROPN', 5, 'compound', 3], ['city', 'PROPN', 5, 'compound', 4], ['beach', 'PROPN', 2, 'pobj', 5], ['.', 'PUNCT', 1, 'punct', 6]], [['not', 'ADV', 2, 'neg', 0], ['too', 'ADV', 2, 'advmod', 1], ['bad', 'ADJ', 2, 'ROOT', 2], ['...', 'PUNCT', 2, 'punct', 3], ['property', 'NOUN', 5, 'compound', 4], ['assessments', 'NOUN', 6, 'nsubj', 5], ['are', 'VERB', 9, 'ccomp', 6], ['under', 'ADP', 6, 'prep', 7], ['way', 'NOUN', 7, 'pobj', 8], ['looks', 'VERB', 9, 'ROOT', 9], ['promising', 'ADJ', 9, 'xcomp', 10], ['and', 'CCONJ', 10, 'cc', 11], ['positive', 'ADJ', 10, 'conj', 12], ['so', 'ADV', 14, 'advmod', 13], ['far', 'ADV', 12, 'advmod', 14], ['#hurricanemichael', 'PROPN', 17, 'meta', 15], ['@vacasarentals', 'NOUN', 17, 'punct', 16], ['@rickyhaskins', 'X', 17, 'ROOT', 17], ['@', 'ADP', 17, 'prep', 18], ['panama', 'PROPN', 20, 'compound', 19], ['city', 'PROPN', 20, 'ROOT', 20], ['…', 'PUNCT', 20, 'punct', 21]]]\n",
      "candidate 0=panama city beach\n",
      "anchor NE candidates = panama city\n",
      "data NE tree=[['panama', 'PROPN', 5, 'compound', 3], ['city', 'PROPN', 5, 'compound', 4], ['beach', 'PROPN', 2, 'pobj', 5]]\n",
      "NE parse token at tree=0, token=6:\n",
      "['beach', 'PROPN', 2, 'pobj', 5]\n",
      "NE parent token:\n",
      "['in', 'ADP', 1, 'prep', 2]\n",
      "candidate 1=panama city\n",
      "anchor NE candidates = \n",
      "full parse [[['at', 'ADV', 1, 'advmod', 0], ['least', 'ADJ', 2, 'advmod', 1], ['46', 'NUM', 3, 'nummod', 2], ['people', 'NOUN', 4, 'nsubj', 3], ['remained', 'VERB', 4, 'ROOT', 4], ['unaccounted', 'ADJ', 4, 'acomp', 5], ['for', 'ADP', 5, 'prep', 6], ['on', 'ADP', 6, 'prep', 7], ['sunday', 'PROPN', 7, 'pobj', 8], ['in', 'ADP', 4, 'prep', 9], ['mexico', 'PROPN', 12, 'compound', 10], ['beach', 'PROPN', 12, 'compound', 11], ['florida', 'PROPN', 9, 'pobj', 12], ['an', 'DET', 14, 'det', 13], ['area', 'NOUN', 23, 'nsubj', 14], ['pulverized', 'VERB', 14, 'acl', 15], ['by', 'ADP', 15, 'agent', 16], ['#hurricanemichael', 'PROPN', 19, 'nmod', 17], ['289', 'NUM', 19, 'nummod', 18], ['people', 'NOUN', 16, 'pobj', 19], ['including', 'VERB', 19, 'prep', 20], ['10', 'NUM', 22, 'nummod', 21], ['children', 'NOUN', 20, 'pobj', 22], ['decided', 'VERB', 4, 'conj', 23], ['to', 'PART', 25, 'aux', 24], ['stay', 'VERB', 23, 'xcomp', 25], ['put', 'VERB', 25, 'acomp', 26], ['despite', 'ADP', 25, 'prep', 27], ['evacuation', 'NOUN', 29, 'compound', 28], ['orders', 'NOUN', 27, 'pobj', 29], ['and', 'CCONJ', 25, 'cc', 30], ['ride', 'VERB', 25, 'conj', 31], ['out', 'PART', 31, 'prt', 32], ['the', 'DET', 36, 'det', 33], ['category', 'NOUN', 36, 'nmod', 34], ['4', 'NUM', 34, 'nummod', 35], ['storm', 'NOUN', 31, 'dobj', 36]]]\n",
      "candidate 0=mexico beach\n",
      "anchor NE candidates = \n",
      "full parse [[['jackie', 'PROPN', 9, 'nsubj', 0], ['a', 'DET', 3, 'det', 1], ['#hurricanemichael', 'PROPN', 3, 'compound', 2], ['survivor', 'NOUN', 0, 'appos', 3], ['in', 'ADP', 3, 'prep', 4], ['panama', 'PROPN', 8, 'compound', 5], ['city', 'PROPN', 8, 'compound', 6], ['beach', 'PROPN', 8, 'compound', 7], ['fl', 'PROPN', 4, 'pobj', 8], ['is', 'VERB', 28, 'ccomp', 9], ['desperate', 'ADJ', 9, 'acomp', 10], ['to', 'PART', 12, 'aux', 11], ['contact', 'VERB', 10, 'xcomp', 12], ['family', 'NOUN', 12, 'dobj', 13], ['and', 'CCONJ', 13, 'cc', 14], ['friends', 'NOUN', 13, 'conj', 15], ['as', 'ADP', 19, 'mark', 16], ['cell', 'NOUN', 18, 'compound', 17], ['service', 'NOUN', 19, 'nsubj', 18], ['remains', 'VERB', 9, 'advcl', 19], ['down', 'ADV', 19, 'prt', 20], ['following', 'VERB', 19, 'prep', 21], ['the', 'DET', 23, 'det', 22], ['storm', 'NOUN', 21, 'dobj', 23], [':', 'PUNCT', 28, 'punct', 24], ['\"', 'PUNCT', 28, 'punct', 25], ['\"', 'PUNCT', 28, 'punct', 26], ['i', 'PRON', 28, 'nsubj', 27], ['hope', 'VERB', 28, 'ROOT', 28], ['you', 'PRON', 31, 'nsubj', 29], ['all', 'DET', 29, 'appos', 30], ['are', 'VERB', 28, 'ccomp', 31], ['all', 'DET', 31, 'advmod', 32], ['okay', 'ADJ', 31, 'acomp', 33], ['...', 'PUNCT', 28, 'punct', 34], [\"we're\", 'INTJ', 35, 'ROOT', 35], ['all', 'ADV', 35, 'appos', 36], ['okay', 'INTJ', 37, 'ROOT', 37], ['.', 'PUNCT', 37, 'punct', 38], ['\"', 'PUNCT', 37, 'punct', 39], ['\"', 'PUNCT', 37, 'punct', 40]]]\n",
      "candidate 0=panama city beach\n",
      "anchor NE candidates = \n",
      "full parse [[['i', 'PRON', 2, 'nsubj', 0], ['would', 'VERB', 2, 'aux', 1], ['like', 'VERB', 2, 'ROOT', 2], ['to', 'PART', 4, 'aux', 3], ['give', 'VERB', 2, 'xcomp', 4], ['a', 'DET', 8, 'det', 5], ['great', 'ADJ', 8, 'amod', 6], ['big', 'ADJ', 8, 'amod', 7], ['thank', 'VERB', 4, 'dative', 8], ['you', 'PRON', 8, 'dobj', 9], ['to', 'PART', 11, 'aux', 10], ['@tmobile', 'VERB', 4, 'advcl', 11], ['for', 'ADP', 11, 'prep', 12], ['having', 'VERB', 12, 'pcomp', 13], ['your', 'ADJ', 17, 'poss', 14], ['emergency', 'NOUN', 16, 'compound', 15], ['management', 'NOUN', 17, 'compound', 16], ['truck', 'NOUN', 13, 'dobj', 17], ['here', 'ADV', 17, 'advmod', 18], ['in', 'ADP', 18, 'prep', 19], ['blountstown', 'PROPN', 21, 'compound', 20], ['fl', 'PROPN', 19, 'pobj', 21], ['and', 'CCONJ', 13, 'cc', 22], ['making', 'VERB', 13, 'conj', 23], ['it', 'PRON', 25, 'nsubj', 24], ['possible', 'ADJ', 23, 'ccomp', 25], ['for', 'ADP', 29, 'mark', 26], ['us', 'PRON', 29, 'nsubj', 27], ['to', 'PART', 29, 'aux', 28], ['have', 'VERB', 25, 'advcl', 29], ['wifi', 'PROPN', 29, 'dobj', 30], ['during', 'ADP', 29, 'prep', 31], ['the', 'DET', 33, 'det', 32], ['aftermath', 'NOUN', 31, 'pobj', 33], ['of', 'ADP', 33, 'prep', 34], ['#hurricanemichael', 'PROPN', 34, 'pobj', 35]]]\n",
      "candidate 0=blountstown\n",
      "anchor NE candidates = \n",
      "full parse [[['#happymonday', 'PROPN', 9, 'npadvmod', 0], ['if', 'ADP', 3, 'mark', 1], ['you', 'PRON', 3, 'nsubj', 2], ['think', 'VERB', 9, 'advcl', 3], ['your', 'ADJ', 5, 'poss', 4], [\"monday's\", 'PROPN', 6, 'nsubj', 5], ['bad', 'ADJ', 3, 'ccomp', 6], ['...', 'PUNCT', 9, 'punct', 7], ['be', 'VERB', 9, 'auxpass', 8], ['reminded', 'VERB', 9, 'ROOT', 9], ['by', 'ADP', 9, 'agent', 10], ['the', 'DET', 12, 'det', 11], ['pics', 'NOUN', 10, 'pobj', 12], ['from', 'ADP', 9, 'prep', 13], ['#hurricanemichael', 'PROPN', 13, 'pobj', 14], ['that', 'ADP', 19, 'mark', 15], ['it', 'PRON', 19, 'nsubj', 16], ['can', 'VERB', 19, 'aux', 17], ['always', 'ADV', 19, 'advmod', 18], ['get', 'VERB', 9, 'ccomp', 19], ['worse', 'ADJ', 19, 'acomp', 20], ['.', 'PUNCT', 9, 'punct', 21]], [['listen', 'VERB', 0, 'ROOT', 0], ['we', 'PRON', 2, 'nsubj', 1], ['are', 'VERB', 0, 'ccomp', 2], ['here', 'ADV', 2, 'advmod', 3], ['in', 'ADP', 3, 'prep', 4], ['panama', 'PROPN', 7, 'compound', 5], ['city', 'PROPN', 7, 'compound', 6], ['fl', 'PROPN', 4, 'pobj', 7], ['at', 'ADP', 2, 'prep', 8], ['groundzero', 'NOUN', 8, 'pobj', 9], ['delivering', 'VERB', 2, 'advcl', 10], ['supplies', 'NOUN', 10, 'dobj', 11], ['to', 'ADP', 10, 'dative', 12], ['those', 'DET', 12, 'pobj', 13], ['impacted', 'VERB', 13, 'acl', 14], ['...', 'PUNCT', 0, 'punct', 15]]]\n",
      "candidate 0=panama city\n",
      "anchor NE candidates = \n",
      "full parse [[['the', 'DET', 1, 'det', 0], ['people', 'NOUN', 13, 'nsubj', 1], ['ravaged', 'VERB', 1, 'acl', 2], ['by', 'ADP', 2, 'agent', 3], ['#hurricanemichael', 'PROPN', 3, 'pobj', 4], ['in', 'ADP', 2, 'prep', 5], ['panama', 'PROPN', 7, 'compound', 6], ['city', 'PROPN', 8, 'compound', 7], ['florida', 'PROPN', 5, 'pobj', 8], ['and', 'CCONJ', 8, 'cc', 9], ['mexico', 'PROPN', 11, 'compound', 10], ['beach', 'PROPN', 12, 'compound', 11], ['florida', 'PROPN', 8, 'conj', 12], ['need', 'VERB', 13, 'ROOT', 13], ['our', 'ADJ', 15, 'poss', 14], ['help', 'NOUN', 13, 'dobj', 15], ['.', 'PUNCT', 13, 'punct', 16]], [['let', 'VERB', 0, 'ROOT', 0], ['’', 'NOUN', 3, 'nsubj', 1], ['s', 'PRON', 3, 'aux', 2], ['do', 'VERB', 0, 'ccomp', 3], ['this', 'DET', 3, 'dobj', 4], ['by', 'ADP', 3, 'prep', 5], ['donating', 'VERB', 5, 'pcomp', 6], ['to', 'ADP', 6, 'prep', 7], ['the', 'DET', 11, 'det', 8], ['american', 'PROPN', 11, 'compound', 9], ['red', 'PROPN', 11, 'compound', 10], ['cross', 'PROPN', 7, 'pobj', 11], ['.', 'PUNCT', 0, 'punct', 12]]]\n",
      "candidate 0=panama city\n",
      "anchor NE candidates = \n",
      "candidate 1=mexico beach\n",
      "anchor NE candidates = panama city\n",
      "data NE tree=[['mexico', 'PROPN', 11, 'compound', 10], ['beach', 'PROPN', 12, 'compound', 11]]\n",
      "NE parse token at tree=0, token=12:\n",
      "['beach', 'PROPN', 12, 'compound', 11]\n",
      "NE parent token:\n",
      "['florida', 'PROPN', 8, 'conj', 12]\n",
      "parent node subtree [['mexico', 'PROPN', 11, 'compound', 10], ['beach', 'PROPN', 12, 'compound', 11], ['florida', 'PROPN', 8, 'conj', 12]]\n",
      "parent node subtree str \"mexico beach florida\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "full parse [[['#hurricanemichael', 'PROPN', 7, 'meta', 0], ['|', 'PUNCT', 7, 'punct', 1], ['tide', 'NOUN', 3, 'compound', 2], ['loads', 'NOUN', 7, 'nsubj', 3], ['of', 'ADP', 3, 'prep', 4], ['hope', 'PROPN', 4, 'pobj', 5], ['is', 'VERB', 7, 'aux', 6], ['washing', 'VERB', 7, 'ROOT', 7], ['clothes', 'NOUN', 7, 'dobj', 8], ['for', 'ADP', 7, 'prep', 9], ['free', 'ADJ', 9, 'amod', 10], ['from', 'ADP', 7, 'prep', 11], ['9am', 'ADJ', 13, 'compound', 12], ['5pm', 'NOUN', 11, 'pobj', 13], ['at', 'ADP', 7, 'prep', 14], ['walmart', 'PROPN', 16, 'compound', 15], ['supercenter', 'PROPN', 14, 'pobj', 16], ['(', 'PUNCT', 16, 'punct', 17], ['25', 'NUM', 23, 'nummod', 18], ['n', 'NOUN', 23, 'compound', 19], ['tyndall', 'PROPN', 23, 'compound', 20], ['pkwy', 'PROPN', 23, 'compound', 21], ['callaway', 'PROPN', 23, 'compound', 22], ['fl', 'PROPN', 16, 'appos', 23], ['32404', 'NUM', 23, 'nummod', 24], [')', 'PUNCT', 16, 'punct', 25], ['#panhandlestrong', 'PROPN', 26, 'ROOT', 26], ['#panamacity', 'PROPN', 26, 'appos', 27]]]\n",
      "candidate 0=callaway\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full parse [[['check', 'VERB', 0, 'ROOT', 0], ['out', 'PART', 0, 'prt', 1], ['calhoun', 'PROPN', 0, 'dobj', 2], ['(', 'PUNCT', 2, 'punct', 3], ['98', 'NUM', 5, 'nummod', 4], ['%', 'NOUN', 2, 'appos', 5], ['out', 'PART', 5, 'prt', 6], [')', 'PUNCT', 2, 'punct', 7], ['gulf', 'PROPN', 8, 'ROOT', 8], ['(8', 'PROPN', 8, 'punct', 9], ['6', 'NUM', 11, 'nummod', 10], ['%', 'NOUN', 8, 'appos', 11], [')', 'PUNCT', 8, 'punct', 12], ['jackson', 'PROPN', 16, 'nmod', 13], ['(8', 'PROPN', 16, 'punct', 14], ['3', 'NUM', 16, 'nummod', 15], ['%', 'NOUN', 16, 'ROOT', 16], [')', 'PUNCT', 16, 'punct', 17], ['liberty', 'PROPN', 18, 'ROOT', 18], ['(', 'PUNCT', 18, 'punct', 19], ['71', 'NUM', 21, 'nummod', 20], ['%', 'NOUN', 18, 'appos', 21], [')', 'PUNCT', 18, 'punct', 22], ['and', 'CCONJ', 18, 'cc', 23], ['bay', 'PROPN', 18, 'conj', 24], ['(', 'PUNCT', 24, 'punct', 25], ['56', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], [')', 'PUNCT', 24, 'punct', 28], ['.', 'PUNCT', 18, 'punct', 29]], [['then', 'ADV', 1, 'advmod', 0], ['donate', 'VERB', 1, 'ROOT', 1], ['some', 'DET', 3, 'det', 2], ['money', 'NOUN', 1, 'dobj', 3], ['or', 'CCONJ', 3, 'cc', 4], ['critical', 'ADJ', 6, 'amod', 5], ['supplies', 'NOUN', 3, 'conj', 6], ['&', 'CCONJ', 1, 'cc', 7], ['lend', 'VERB', 1, 'conj', 8], ['a', 'DET', 10, 'det', 9], ['hand', 'NOUN', 8, 'dobj', 10], ['.', 'PUNCT', 1, 'punct', 11]], [['#floridastrong', 'PROPN', 1, 'compound', 0], ['#hurricanemichael', 'PROPN', 2, 'nummod', 1], ['#beagoodneighbor', 'PROPN', 2, 'ROOT', 2]]]\n",
      "candidate 0=calhoun\n",
      "anchor NE candidates = liberty\n",
      "data NE tree=[['calhoun', 'PROPN', 0, 'dobj', 2]]\n",
      "NE parse token at tree=0, token=3:\n",
      "['calhoun', 'PROPN', 0, 'dobj', 2]\n",
      "NE parent token:\n",
      "['check', 'VERB', 0, 'ROOT', 0]\n",
      "NE=calhoun subtree=[['(', 'PUNCT', 2, 'punct', 3], ['98', 'NUM', 5, 'nummod', 4], ['%', 'NOUN', 2, 'appos', 5], ['out', 'PART', 5, 'prt', 6], [')', 'PUNCT', 2, 'punct', 7]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( 98 % out )\n",
      "candidate 1=gulf\n",
      "anchor NE candidates = calhoun,liberty\n",
      "data NE tree=[['gulf', 'PROPN', 8, 'ROOT', 8]]\n",
      "NE=gulf subtree=[['(8', 'PROPN', 8, 'punct', 9], ['6', 'NUM', 11, 'nummod', 10], ['%', 'NOUN', 8, 'appos', 11], [')', 'PUNCT', 8, 'punct', 12]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = (8 6 % )\n",
      "candidate 2=liberty\n",
      "anchor NE candidates = \n",
      "candidate 3=bay\n",
      "anchor NE candidates = calhoun,gulf,liberty\n",
      "data NE tree=[['bay', 'PROPN', 18, 'conj', 24]]\n",
      "NE parse token at tree=0, token=25:\n",
      "['bay', 'PROPN', 18, 'conj', 24]\n",
      "NE parent token:\n",
      "['liberty', 'PROPN', 18, 'ROOT', 18]\n",
      "NE=bay subtree=[['(', 'PUNCT', 24, 'punct', 25], ['56', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], [')', 'PUNCT', 24, 'punct', 28]]\n",
      "min node deps ['punct', 'appos', 'punct']\n",
      "subtree = ( 56 % )\n",
      "full parse [[['amr', 'PROPN', 1, 'compound', 0], ['leaders', 'NOUN', 2, 'nsubj', 1], ['were', 'VERB', 2, 'ROOT', 2], ['able', 'ADJ', 2, 'acomp', 3], ['to', 'PART', 5, 'aux', 4], ['visit', 'VERB', 3, 'xcomp', 5], ['crews', 'NOUN', 5, 'dobj', 6], ['today', 'NOUN', 5, 'npadvmod', 7], ['in', 'ADP', 5, 'prep', 8], ['panama', 'PROPN', 10, 'compound', 9], ['city', 'PROPN', 11, 'compound', 10], ['florida', 'PROPN', 8, 'pobj', 11], ['as', 'ADP', 16, 'mark', 12], ['the', 'DET', 14, 'det', 13], ['crews', 'NOUN', 16, 'nsubj', 14], ['were', 'VERB', 16, 'aux', 15], ['coming', 'VERB', 5, 'advcl', 16], ['and', 'CCONJ', 16, 'cc', 17], ['going', 'VERB', 16, 'conj', 18], ['from', 'ADP', 18, 'prep', 19], ['missions', 'NOUN', 19, 'pobj', 20], ['.', 'PUNCT', 2, 'punct', 21]], [['crews', 'NOUN', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['all', 'DET', 1, 'dep', 2], ['pretty', 'ADV', 4, 'advmod', 3], ['upbeat', 'ADJ', 1, 'acomp', 4], ['and', 'CCONJ', 4, 'cc', 5], ['so', 'ADV', 7, 'advmod', 6], ['glad', 'ADJ', 4, 'conj', 7], ['to', 'PART', 9, 'aux', 8], ['be', 'VERB', 7, 'xcomp', 9], ['able', 'ADJ', 9, 'acomp', 10], ['to', 'PART', 12, 'aux', 11], ['be', 'VERB', 10, 'xcomp', 12], ['in', 'ADP', 12, 'prep', 13], ['the', 'DET', 15, 'det', 14], ['area', 'NOUN', 13, 'pobj', 15], ['to', 'PART', 17, 'aux', 16], ['help', 'VERB', 12, 'advcl', 17], ['people', 'NOUN', 17, 'dobj', 18], ['!', 'PUNCT', 1, 'punct', 19]], [['#hurricanemichael', 'PROPN', 0, 'ROOT', 0]]]\n",
      "candidate 0=panama city\n",
      "anchor NE candidates = \n",
      "full parse [[['clean', 'PROPN', 1, 'compound', 0], ['water', 'PROPN', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['on', 'ADP', 2, 'prep', 3], ['the', 'DET', 5, 'det', 4], ['way', 'NOUN', 3, 'pobj', 5], ['to', 'ADP', 5, 'prep', 6], ['sneads', 'PROPN', 8, 'compound', 7], ['florida', 'PROPN', 6, 'pobj', 8], ['!', 'PUNCT', 2, 'punct', 9]], [['want', 'VERB', 0, 'ROOT', 0], ['to', 'PART', 2, 'aux', 1], ['help', 'VERB', 0, 'xcomp', 2], ['us', 'PRON', 4, 'nsubj', 3], ['deliver', 'VERB', 2, 'ccomp', 4], ['more', 'ADJ', 6, 'amod', 5], ['water', 'NOUN', 4, 'dobj', 6], ['to', 'ADP', 4, 'prep', 7], ['victims', 'NOUN', 7, 'pobj', 8], ['of', 'ADP', 8, 'prep', 9], ['#hurricanemichael', 'PROPN', 9, 'pobj', 10], ['?', 'PUNCT', 0, 'punct', 11]], [['visit', 'VERB', 0, 'ROOT', 0], ['our', 'ADJ', 2, 'poss', 1], ['website', 'NOUN', 0, 'dobj', 2], ['to', 'PART', 4, 'aux', 3], ['make', 'VERB', 0, 'xcomp', 4], ['a', 'DET', 6, 'det', 5], ['donation', 'NOUN', 4, 'dobj', 6], ['!', 'PUNCT', 0, 'punct', 7]], [['usa', 'PROPN', 0, 'ROOT', 0], [':', 'PUNCT', 0, 'punct', 1]]]\n",
      "candidate 0=sneads\n",
      "anchor NE candidates = \n",
      "full parse [[['one', 'NUM', 1, 'nummod', 0], ['week', 'NOUN', 10, 'npadvmod', 1], ['after', 'ADP', 1, 'prep', 2], ['#michael', 'PROPN', 4, 'compound', 3], ['county', 'PROPN', 2, 'pobj', 4], ['by', 'ADP', 9, 'prep', 5], ['county', 'PROPN', 5, 'pobj', 6], ['#flwx', 'PROPN', 8, 'compound', 7], ['power', 'PROPN', 9, 'compound', 8], ['outage', 'PROPN', 10, 'nsubj', 9], ['update', 'PROPN', 10, 'ROOT', 10], [':', 'PUNCT', 10, 'punct', 11], ['calhoun', 'PROPN', 10, 'appos', 12], [':', 'PUNCT', 12, 'punct', 13], ['97', 'NUM', 15, 'nummod', 14], ['%', 'NOUN', 16, 'compound', 15], ['jackson', 'PROPN', 12, 'appos', 16], [':', 'PUNCT', 16, 'punct', 17], ['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['liberty', 'PROPN', 19, 'appos', 20], [':', 'PUNCT', 16, 'punct', 21], ['67', 'NUM', 23, 'nummod', 22], ['%', 'NOUN', 24, 'compound', 23], ['gulf', 'PROPN', 24, 'ROOT', 24], [':', 'PUNCT', 24, 'punct', 25], ['58', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], ['bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29], ['gadsden', 'PROPN', 27, 'appos', 30], [':', 'PUNCT', 27, 'punct', 31], ['52', 'NUM', 33, 'nummod', 32], ['%', 'NOUN', 27, 'appos', 33], ['washington', 'PROPN', 33, 'appos', 34], [':', 'PUNCT', 27, 'punct', 35], ['18', 'NUM', 37, 'nummod', 36], ['%', 'NOUN', 27, 'appos', 37], ['holmes', 'PROPN', 37, 'appos', 38], [':', 'PUNCT', 37, 'punct', 39], ['17', 'NUM', 41, 'nummod', 40], ['%', 'NOUN', 37, 'appos', 41]]]\n",
      "candidate 0=calhoun\n",
      "anchor NE candidates = jackson,liberty,gadsden\n",
      "data NE tree=[['calhoun', 'PROPN', 10, 'appos', 12]]\n",
      "NE parse token at tree=0, token=13:\n",
      "['calhoun', 'PROPN', 10, 'appos', 12]\n",
      "NE parent token:\n",
      "['update', 'PROPN', 10, 'ROOT', 10]\n",
      "parent node subtree [['one', 'NUM', 1, 'nummod', 0], ['week', 'NOUN', 10, 'npadvmod', 1], ['after', 'ADP', 1, 'prep', 2], ['#michael', 'PROPN', 4, 'compound', 3], ['county', 'PROPN', 2, 'pobj', 4], ['by', 'ADP', 9, 'prep', 5], ['county', 'PROPN', 5, 'pobj', 6], ['#flwx', 'PROPN', 8, 'compound', 7], ['power', 'PROPN', 9, 'compound', 8], ['outage', 'PROPN', 10, 'nsubj', 9], ['update', 'PROPN', 10, 'ROOT', 10], [':', 'PUNCT', 10, 'punct', 11], ['calhoun', 'PROPN', 10, 'appos', 12], [':', 'PUNCT', 12, 'punct', 13], ['97', 'NUM', 15, 'nummod', 14], ['%', 'NOUN', 16, 'compound', 15], ['jackson', 'PROPN', 12, 'appos', 16], [':', 'PUNCT', 16, 'punct', 17], ['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['liberty', 'PROPN', 19, 'appos', 20], [':', 'PUNCT', 16, 'punct', 21]]\n",
      "parent node subtree str \"one week after #michael county by county #flwx power outage update : calhoun : 97 % jackson : 81 % liberty :\"\n",
      "NE=calhoun subtree=[[':', 'PUNCT', 12, 'punct', 13], ['97', 'NUM', 15, 'nummod', 14], ['%', 'NOUN', 16, 'compound', 15], ['jackson', 'PROPN', 12, 'appos', 16], [':', 'PUNCT', 16, 'punct', 17], ['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['liberty', 'PROPN', 19, 'appos', 20], [':', 'PUNCT', 16, 'punct', 21]]\n",
      "min node deps ['punct', 'appos']\n",
      "subtree = : 97 % jackson : 81 % liberty :\n",
      "candidate 1=jackson\n",
      "anchor NE candidates = \n",
      "candidate 2=liberty\n",
      "anchor NE candidates = jackson\n",
      "data NE tree=[['liberty', 'PROPN', 19, 'appos', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['liberty', 'PROPN', 19, 'appos', 20]\n",
      "NE parent token:\n",
      "['%', 'NOUN', 16, 'appos', 19]\n",
      "parent node subtree [['81', 'NUM', 19, 'nummod', 18], ['%', 'NOUN', 16, 'appos', 19], ['liberty', 'PROPN', 19, 'appos', 20]]\n",
      "parent node subtree str \"81 % liberty\"\n",
      "candidate 3=bay\n",
      "anchor NE candidates = calhoun,jackson,liberty,gadsden\n",
      "data NE tree=[['bay', 'PROPN', 30, 'nmod', 28]]\n",
      "NE parse token at tree=0, token=29:\n",
      "['bay', 'PROPN', 30, 'nmod', 28]\n",
      "NE parent token:\n",
      "['gadsden', 'PROPN', 27, 'appos', 30]\n",
      "parent node subtree [['bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29], ['gadsden', 'PROPN', 27, 'appos', 30]]\n",
      "parent node subtree str \"bay / gadsden\"\n",
      "candidate 4=gadsden\n",
      "anchor NE candidates = jackson,liberty\n",
      "data NE tree=[['gadsden', 'PROPN', 27, 'appos', 30]]\n",
      "NE parse token at tree=0, token=31:\n",
      "['gadsden', 'PROPN', 27, 'appos', 30]\n",
      "NE parent token:\n",
      "['%', 'NOUN', 24, 'appos', 27]\n",
      "parent node subtree [['58', 'NUM', 27, 'nummod', 26], ['%', 'NOUN', 24, 'appos', 27], ['bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29], ['gadsden', 'PROPN', 27, 'appos', 30], [':', 'PUNCT', 27, 'punct', 31], ['52', 'NUM', 33, 'nummod', 32], ['%', 'NOUN', 27, 'appos', 33], ['washington', 'PROPN', 33, 'appos', 34], [':', 'PUNCT', 27, 'punct', 35], ['18', 'NUM', 37, 'nummod', 36], ['%', 'NOUN', 27, 'appos', 37], ['holmes', 'PROPN', 37, 'appos', 38], [':', 'PUNCT', 37, 'punct', 39], ['17', 'NUM', 41, 'nummod', 40], ['%', 'NOUN', 37, 'appos', 41]]\n",
      "parent node subtree str \"58 % bay / gadsden : 52 % washington : 18 % holmes : 17 %\"\n",
      "NE=gadsden subtree=[['bay', 'PROPN', 30, 'nmod', 28], ['/', 'SYM', 30, 'punct', 29]]\n",
      "min node deps ['nmod', 'punct']\n",
      "full parse [[['orange', 'PROPN', 3, 'compound', 0], ['county', 'PROPN', 3, 'compound', 1], ['utilities', 'PROPN', 3, 'compound', 2], ['’', 'PROPN', 10, 'nmod', 3], ['water', 'PROPN', 5, 'nmod', 4], ['reclamation', 'PROPN', 10, 'nmod', 5], ['and', 'CCONJ', 5, 'cc', 6], ['field', 'PROPN', 8, 'compound', 7], ['services', 'PROPN', 5, 'conj', 8], ['team', 'NOUN', 10, 'compound', 9], ['members', 'NOUN', 12, 'nsubj', 10], ['are', 'VERB', 12, 'aux', 11], ['helping', 'VERB', 12, 'ROOT', 12], ['restore', 'VERB', 12, 'xcomp', 13], ['sewer', 'NOUN', 15, 'compound', 14], ['systems', 'NOUN', 13, 'dobj', 15], ['impacted', 'VERB', 15, 'acl', 16], ['by', 'ADP', 16, 'agent', 17], ['#hurricanemichael', 'PROPN', 17, 'pobj', 18], ['in', 'ADP', 16, 'prep', 19], ['tallahassee', 'PROPN', 19, 'pobj', 20], ['and', 'CCONJ', 20, 'cc', 21], ['panama', 'PROPN', 23, 'compound', 22], ['city', 'PROPN', 20, 'conj', 23], ['.', 'PUNCT', 12, 'punct', 24]], [['we', 'PRON', 1, 'nsubj', 0], ['are', 'VERB', 1, 'ROOT', 1], ['proud', 'ADJ', 1, 'acomp', 2], ['to', 'PART', 4, 'aux', 3], ['support', 'VERB', 2, 'xcomp', 4], ['our', 'ADJ', 6, 'poss', 5], ['neighbors', 'NOUN', 4, 'dobj', 6], ['just', 'ADV', 11, 'advmod', 7], ['as', 'ADP', 11, 'mark', 8], ['they', 'PRON', 11, 'nsubj', 9], ['did', 'VERB', 11, 'aux', 10], ['following', 'VERB', 1, 'advcl', 11], ['past', 'ADJ', 13, 'amod', 12], ['storms', 'NOUN', 11, 'dobj', 13], ['that', 'ADJ', 15, 'nsubj', 14], ['affected', 'VERB', 13, 'relcl', 15], ['central', 'PROPN', 17, 'compound', 16], ['florida', 'PROPN', 15, 'dobj', 17], ['.', 'PUNCT', 1, 'punct', 18]]]\n",
      "candidate 0=tallahassee\n",
      "anchor NE candidates = orange county\n",
      "data NE tree=[['tallahassee', 'PROPN', 19, 'pobj', 20]]\n",
      "NE parse token at tree=0, token=21:\n",
      "['tallahassee', 'PROPN', 19, 'pobj', 20]\n",
      "NE parent token:\n",
      "['in', 'ADP', 16, 'prep', 19]\n",
      "NE=tallahassee subtree=[['and', 'CCONJ', 20, 'cc', 21], ['panama', 'PROPN', 23, 'compound', 22], ['city', 'PROPN', 20, 'conj', 23]]\n",
      "min node deps ['cc', 'conj']\n",
      "candidate 1=orange county\n",
      "anchor NE candidates = \n",
      "candidate 2=panama city\n",
      "anchor NE candidates = tallahassee,orange county\n",
      "data NE tree=[['panama', 'PROPN', 23, 'compound', 22], ['city', 'PROPN', 20, 'conj', 23]]\n",
      "NE parse token at tree=0, token=24:\n",
      "['city', 'PROPN', 20, 'conj', 23]\n",
      "NE parent token:\n",
      "['tallahassee', 'PROPN', 19, 'pobj', 20]\n",
      "full parse [[['reminders', 'NOUN', 0, 'ROOT', 0], ['from', 'ADP', 0, 'prep', 1], ['#hurricanemichael', 'PROPN', 1, 'pobj', 2], ['.', 'PUNCT', 0, 'punct', 3]], [['posted', 'VERB', 0, 'ROOT', 0], ['orignally', 'ADV', 0, 'advmod', 1], ['by', 'ADP', 0, 'agent', 2], ['\"', 'PUNCT', 8, 'punct', 3], ['\"', 'PUNCT', 8, 'punct', 4], ['the', 'DET', 8, 'det', 5], ['most', 'ADV', 8, 'compound', 6], ['excellent', 'ADJ', 8, 'compound', 7], ['way', 'NOUN', 2, 'pobj', 8], ['\"', 'PUNCT', 8, 'punct', 9], ['\"', 'PUNCT', 8, 'punct', 10], ['of', 'ADP', 8, 'prep', 11], ['panama', 'PROPN', 14, 'compound', 12], ['city', 'PROPN', 14, 'compound', 13], ['fl', 'PROPN', 11, 'pobj', 14], ['.', 'PUNCT', 0, 'punct', 15]], [['\"', 'PUNCT', 4, 'punct', 0], ['\"', 'PUNCT', 4, 'punct', 1], ['and', 'CCONJ', 4, 'cc', 2], ['we', 'PRON', 4, 'nsubj', 3], ['know', 'VERB', 4, 'ROOT', 4], ['that', 'ADP', 13, 'mark', 5], ['for', 'ADP', 13, 'prep', 6], ['those', 'DET', 6, 'pobj', 7], ['who', 'NOUN', 9, 'nsubj', 8], ['love', 'VERB', 7, 'relcl', 9], ['god', 'PROPN', 9, 'dobj', 10], ['all', 'DET', 12, 'det', 11], ['things', 'NOUN', 9, 'dobj', 12], ['work', 'VERB', 4, 'ccomp', 13], ['together', 'ADV', 13, 'advmod', 14], ['for', 'ADP', 13, 'prep', 15], ['good', 'ADJ', 15, 'amod', 16], ['for', 'ADP', 13, 'prep', 17], ['those', 'DET', 17, 'pobj', 18], ['…', 'PUNCT', 4, 'punct', 19]]]\n",
      "candidate 0=panama city\n",
      "anchor NE candidates = \n",
      "full parse [[['one', 'NUM', 1, 'nummod', 0], ['home', 'NOUN', 6, 'nsubj', 1], ['in', 'ADP', 1, 'prep', 2], ['mexico', 'PROPN', 4, 'compound', 3], ['beach', 'PROPN', 5, 'compound', 4], ['florida', 'PROPN', 2, 'pobj', 5], ['appeared', 'VERB', 6, 'ROOT', 6], ['largely', 'ADV', 8, 'advmod', 7], ['untouched', 'ADJ', 6, 'oprd', 8], ['amid', 'ADP', 8, 'prep', 9], ['the', 'DET', 12, 'det', 10], ['incredible', 'ADJ', 12, 'amod', 11], ['destruction', 'NOUN', 9, 'pobj', 12], ['of', 'ADP', 12, 'prep', 13], ['#hurricanemichael', 'PROPN', 13, 'pobj', 14], ['.', 'PUNCT', 6, 'punct', 15]], [['and', 'CCONJ', 10, 'cc', 0], ['its', 'ADJ', 2, 'poss', 1], ['owners', 'NOUN', 10, 'nsubj', 2], ['lebron', 'PROPN', 4, 'compound', 3], ['lackey', 'PROPN', 2, 'appos', 4], ['and', 'CCONJ', 4, 'cc', 5], ['his', 'ADJ', 7, 'poss', 6], ['uncle', 'NOUN', 4, 'conj', 7], ['russell', 'PROPN', 9, 'compound', 8], ['king', 'PROPN', 7, 'appos', 9], ['say', 'VERB', 10, 'ROOT', 10], [\"it's\", 'PRON', 12, 'nsubj', 11], ['no', 'DET', 10, 'ccomp', 12], ['…', 'PUNCT', 10, 'punct', 13]]]\n",
      "candidate 0=mexico beach\n",
      "anchor NE candidates = \n",
      "full parse [[['hey', 'INTJ', 1, 'intj', 0], ['guys', 'NOUN', 1, 'ROOT', 1], ['...', 'PUNCT', 1, 'punct', 2]], [['please', 'PRON', 0, 'ROOT', 0], ['come', 'VERB', 0, 'xcomp', 1], ['to', 'ADP', 1, 'prep', 2], ['panama', 'PROPN', 5, 'compound', 3], ['city', 'PROPN', 5, 'compound', 4], ['fl', 'PROPN', 2, 'pobj', 5], ['.', 'PUNCT', 0, 'punct', 6]], [['we', 'PRON', 1, 'nsubj', 0], ['need', 'VERB', 1, 'ROOT', 1], ['some', 'DET', 3, 'det', 2], ['laughs', 'NOUN', 1, 'dobj', 3], ['after', 'ADP', 1, 'prep', 4], ['#hurricanemichael', 'PROPN', 4, 'pobj', 5], ['the', 'DET', 7, 'det', 6], ['beach', 'NOUN', 10, 'nsubjpass', 7], [\"didn't\", 'VERB', 10, 'aux', 8], ['get', 'VERB', 10, 'auxpass', 9], ['hit', 'VERB', 10, 'ROOT', 10], ['bad', 'ADJ', 10, 'advmod', 11], ['at', 'ADV', 13, 'advmod', 12], ['all', 'ADV', 10, 'advmod', 13], ['.', 'PUNCT', 10, 'punct', 14]], [['there', 'ADV', 1, 'expl', 0], ['are', 'VERB', 1, 'ROOT', 1], ['many', 'ADJ', 3, 'amod', 2], ['venues', 'NOUN', 1, 'attr', 3], ['.', 'PUNCT', 1, 'punct', 4]], [['club', 'PROPN', 2, 'compound', 0], ['la', 'PROPN', 2, 'compound', 1], ['vila', 'PROPN', 3, 'nsubj', 2], ['is', 'VERB', 3, 'ROOT', 3], ['a', 'DET', 6, 'det', 4], ['huge', 'ADJ', 6, 'amod', 5], ['one', 'NOUN', 3, 'attr', 6], ['.', 'PUNCT', 3, 'punct', 7]], [[\"we'd\", 'ADJ', 1, 'compound', 0], ['love', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['see', 'VERB', 1, 'xcomp', 3], [\"ya'll\", 'PROPN', 3, 'dobj', 4], ['.', 'PUNCT', 1, 'punct', 5]], [['please', 'INTJ', 1, 'intj', 0], ['consider', 'VERB', 1, 'ROOT', 1], ['it', 'PRON', 1, 'dobj', 2], ['.', 'PUNCT', 1, 'punct', 3]]]\n",
      "candidate 0=panama city\n",
      "anchor NE candidates = \n",
      "full parse [[['this', 'DET', 5, 'det', 0], ['afternoon', 'NOUN', 5, 'nmod', 1], ['state', 'NOUN', 5, 'nmod', 2], ['and', 'CCONJ', 2, 'cc', 3], ['federal', 'ADJ', 2, 'conj', 4], ['partners', 'NOUN', 6, 'nsubj', 5], ['held', 'VERB', 6, 'ROOT', 6], ['a', 'DET', 8, 'det', 7], ['call', 'NOUN', 6, 'dobj', 8], ['to', 'PART', 10, 'aux', 9], ['coordinate', 'VERB', 8, 'acl', 10], ['housing', 'NOUN', 12, 'compound', 11], ['solutions', 'NOUN', 10, 'dobj', 12], ['in', 'ADP', 12, 'prep', 13], ['areas', 'NOUN', 13, 'pobj', 14], ['impacted', 'VERB', 14, 'acl', 15], ['by', 'ADP', 15, 'agent', 16], ['#hurricanemichael', 'PROPN', 16, 'pobj', 17], ['.', 'PUNCT', 6, 'punct', 18]], [['thanks', 'NOUN', 0, 'ROOT', 0], ['to', 'ADP', 0, 'prep', 1], ['franklin', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 5, 'compound', 3], ['liberty', 'PROPN', 5, 'compound', 4], ['county', 'PROPN', 1, 'pobj', 5], ['and', 'CCONJ', 5, 'cc', 6], ['washington', 'PROPN', 8, 'compound', 7], ['county', 'PROPN', 5, 'conj', 8], ['for', 'ADP', 0, 'prep', 9], ['joining', 'VERB', 9, 'pcomp', 10], ['us', 'PRON', 10, 'dobj', 11], ['on', 'ADP', 10, 'prep', 12], ['the', 'DET', 14, 'det', 13], ['call', 'NOUN', 12, 'pobj', 14], ['.', 'PUNCT', 0, 'punct', 15]], [['em2franklin', 'PROPN', 1, 'compound', 0], ['libertycoflem', 'PROPN', 1, 'ROOT', 1]]]\n",
      "candidate 0=franklin county\n",
      "anchor NE candidates = washington county\n",
      "data NE tree=[['franklin', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 5, 'compound', 3]]\n",
      "NE parse token at tree=1, token=4:\n",
      "['county', 'PROPN', 5, 'compound', 3]\n",
      "NE parent token:\n",
      "['county', 'PROPN', 1, 'pobj', 5]\n",
      "parent node subtree [['franklin', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 5, 'compound', 3], ['liberty', 'PROPN', 5, 'compound', 4], ['county', 'PROPN', 1, 'pobj', 5], ['and', 'CCONJ', 5, 'cc', 6], ['washington', 'PROPN', 8, 'compound', 7], ['county', 'PROPN', 5, 'conj', 8]]\n",
      "parent node subtree str \"franklin county liberty county and washington county\"\n",
      "testing to find anchor in parent subtree => compound\n",
      "candidate 1=liberty county\n",
      "anchor NE candidates = franklin county,washington county\n",
      "data NE tree=[['liberty', 'PROPN', 5, 'compound', 4], ['county', 'PROPN', 1, 'pobj', 5]]\n",
      "NE parse token at tree=1, token=6:\n",
      "['county', 'PROPN', 1, 'pobj', 5]\n",
      "NE parent token:\n",
      "['to', 'ADP', 0, 'prep', 1]\n",
      "NE=liberty county subtree=[['franklin', 'PROPN', 3, 'compound', 2], ['county', 'PROPN', 5, 'compound', 3], ['and', 'CCONJ', 5, 'cc', 6], ['washington', 'PROPN', 8, 'compound', 7], ['county', 'PROPN', 5, 'conj', 8]]\n",
      "min node deps ['compound']\n",
      "candidate 2=washington county\n",
      "anchor NE candidates = \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/199 FN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['harris county',\n",
       "        'Sending prayers - More than 1,700 square miles of Harris County in Texas in underwater - more than New York City & Chicago combined. #Harvey <URL>',\n",
       "        list([[['Sending', 'VERB', 0, 'ROOT', 0], ['prayers', 'NOUN', 0, 'dobj', 1], ['More', 'ADJ', 5, 'amod', 2], ['than', 'ADP', 5, 'quantmod', 3], ['1', 'NUM', 5, 'compound', 4], ['700', 'NUM', 7, 'nummod', 5], ['square', 'ADJ', 7, 'amod', 6], ['miles', 'NOUN', 0, 'dobj', 7], ['of', 'ADP', 7, 'prep', 8], ['Harris', 'PROPN', 10, 'compound', 9], ['County', 'PROPN', 8, 'pobj', 10], ['in', 'ADP', 10, 'prep', 11], ['Texas', 'PROPN', 11, 'pobj', 12], ['in', 'ADP', 0, 'prep', 13], ['underwater', 'NOUN', 13, 'pobj', 14], ['more', 'ADJ', 14, 'amod', 15], ['than', 'ADP', 15, 'prep', 16], ['New', 'PROPN', 18, 'compound', 17], ['York', 'PROPN', 19, 'compound', 18], ['City', 'PROPN', 22, 'nsubj', 19], ['&', 'CCONJ', 19, 'cc', 20], ['Chicago', 'PROPN', 19, 'conj', 21], ['combined', 'VERB', 1, 'relcl', 22], ['.', 'PUNCT', 0, 'punct', 23]], [['#Harvey', 'PROPN', 0, 'ROOT', 0]]])],\n",
       "       ['sandy',\n",
       "        \"Sweet! There's no age limit on kindness. We're taking donations today @KATUNews - ocated at NE 21st & Sandy in PDX. #Harvey #TexasStrong <URL>\",\n",
       "        list([[['Sweet', 'ADJ', 0, 'ROOT', 0], ['!', 'PUNCT', 0, 'punct', 1]], [[\"There's\", 'NOUN', 3, 'nsubj', 0], ['no', 'DET', 3, 'det', 1], ['age', 'NOUN', 3, 'compound', 2], ['limit', 'NOUN', 3, 'ROOT', 3], ['on', 'ADP', 3, 'prep', 4], ['kindness', 'NOUN', 4, 'pobj', 5], ['.', 'PUNCT', 3, 'punct', 6]], [[\"We're\", 'PROPN', 1, 'nsubj', 0], ['taking', 'VERB', 1, 'ROOT', 1], ['donations', 'NOUN', 1, 'dobj', 2], ['today', 'NOUN', 1, 'npadvmod', 3], ['@KATUNews', 'NOUN', 1, 'punct', 4], ['ocated', 'VERB', 1, 'advcl', 5], ['at', 'ADP', 5, 'prep', 6], ['NE', 'PROPN', 8, 'compound', 7], ['21st', 'PROPN', 6, 'pobj', 8], ['&', 'CCONJ', 8, 'cc', 9], ['Sandy', 'PROPN', 8, 'conj', 10], ['in', 'ADP', 8, 'prep', 11], ['PDX', 'PROPN', 11, 'pobj', 12], ['.', 'PUNCT', 1, 'punct', 13]], [['#Harvey', 'PROPN', 1, 'compound', 0], ['#TexasStrong', 'X', 1, 'ROOT', 1]]])],\n",
       "       ['morgantown',\n",
       "        \"@kellycass Good morning from Morgantown,WV. Watching today's rain & that impact on Cheat River watershed before #Irma arrives.\",\n",
       "        list([[['@kellycass', 'PUNCT', 2, 'nmod', 0], ['Good', 'ADJ', 2, 'amod', 1], ['morning', 'NOUN', 2, 'ROOT', 2], ['from', 'ADP', 2, 'prep', 3], ['Morgantown', 'PROPN', 5, 'compound', 4], ['WV', 'PROPN', 3, 'pobj', 5], ['.', 'PUNCT', 2, 'punct', 6]], [['Watching', 'VERB', 12, 'csubj', 0], [\"today's\", 'NUM', 2, 'compound', 1], ['rain', 'VERB', 0, 'dobj', 2], ['&', 'CCONJ', 2, 'cc', 3], ['that', 'DET', 5, 'det', 4], ['impact', 'NOUN', 2, 'conj', 5], ['on', 'ADP', 5, 'prep', 6], ['Cheat', 'PROPN', 8, 'compound', 7], ['River', 'PROPN', 6, 'pobj', 8], ['watershed', 'NOUN', 0, 'ccomp', 9], ['before', 'ADP', 9, 'prep', 10], ['#Irma', 'PROPN', 10, 'pobj', 11], ['arrives', 'VERB', 12, 'ROOT', 12], ['.', 'PUNCT', 12, 'punct', 13]]])],\n",
       "       ['miami',\n",
       "        'Heavy flooding right now on the streets of Downtown Miami in Florida #Irma',\n",
       "        list([[['Heavy', 'ADJ', 1, 'amod', 0], ['flooding', 'NOUN', 1, 'ROOT', 1], ['right', 'ADV', 3, 'advmod', 2], ['now', 'ADV', 1, 'advmod', 3], ['on', 'ADP', 1, 'prep', 4], ['the', 'DET', 6, 'det', 5], ['streets', 'NOUN', 4, 'pobj', 6], ['of', 'ADP', 6, 'prep', 7], ['Downtown', 'PROPN', 9, 'compound', 8], ['Miami', 'PROPN', 7, 'pobj', 9], ['in', 'ADP', 6, 'prep', 10], ['Florida', 'PROPN', 12, 'compound', 11], ['#Irma', 'PUNCT', 10, 'pobj', 12]]])],\n",
       "       ['guaynabo',\n",
       "        'Our potus is in Guaynabo -one of the wealthiest towns in Puerto Rico - does anyone know if he plans to go out of San Juan?? #hurricanemaria',\n",
       "        list([[['Our', 'ADJ', 1, 'poss', 0], ['potus', 'NOUN', 2, 'nsubj', 1], ['is', 'VERB', 15, 'ccomp', 2], ['in', 'ADP', 2, 'prep', 3], ['Guaynabo', 'PROPN', 3, 'pobj', 4], ['one', 'NUM', 4, 'nummod', 5], ['of', 'ADP', 5, 'prep', 6], ['the', 'DET', 9, 'det', 7], ['wealthiest', 'ADJ', 9, 'amod', 8], ['towns', 'NOUN', 6, 'pobj', 9], ['in', 'ADP', 9, 'prep', 10], ['Puerto', 'PROPN', 12, 'compound', 11], ['Rico', 'PROPN', 10, 'pobj', 12], ['does', 'VERB', 15, 'aux', 13], ['anyone', 'NOUN', 15, 'nsubj', 14], ['know', 'VERB', 15, 'ROOT', 15], ['if', 'ADP', 18, 'mark', 16], ['he', 'PRON', 18, 'nsubj', 17], ['plans', 'VERB', 15, 'advcl', 18], ['to', 'PART', 20, 'aux', 19], ['go', 'VERB', 18, 'xcomp', 20], ['out', 'ADP', 20, 'prep', 21], ['of', 'ADP', 21, 'prep', 22], ['San', 'PROPN', 24, 'compound', 23], ['Juan', 'PROPN', 22, 'pobj', 24], ['?', 'PUNCT', 15, 'punct', 25], ['?', 'PUNCT', 15, 'punct', 26]], [['#hurricanemaria', 'PROPN', 0, 'ROOT', 0]]])],\n",
       "       ['wilmington',\n",
       "        'RT @WMO: Hurricane #Florence is likely to make landfall near Wilmington (North Carolina) . The tidal data shows a sea level rise of around…',\n",
       "        list([[['RT', 'PROPN', 1, 'compound', 0], ['@WMO', 'PROPN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2], ['Hurricane', 'PROPN', 4, 'compound', 3], ['#Florence', 'PROPN', 5, 'nsubj', 4], ['is', 'VERB', 5, 'ROOT', 5], ['likely', 'ADJ', 5, 'acomp', 6], ['to', 'PART', 8, 'aux', 7], ['make', 'VERB', 6, 'xcomp', 8], ['landfall', 'NOUN', 8, 'dobj', 9], ['near', 'ADP', 9, 'prep', 10], ['Wilmington', 'PROPN', 10, 'pobj', 11], ['(', 'PUNCT', 11, 'punct', 12], ['North', 'PROPN', 14, 'compound', 13], ['Carolina', 'PROPN', 11, 'appos', 14], [')', 'PUNCT', 11, 'punct', 15], ['.', 'PUNCT', 5, 'punct', 16]], [['The', 'DET', 2, 'det', 0], ['tidal', 'ADJ', 2, 'amod', 1], ['data', 'NOUN', 3, 'nsubj', 2], ['shows', 'VERB', 3, 'ROOT', 3], ['a', 'DET', 7, 'det', 4], ['sea', 'NOUN', 6, 'compound', 5], ['level', 'NOUN', 7, 'compound', 6], ['rise', 'NOUN', 3, 'dobj', 7], ['of', 'ADP', 7, 'prep', 8], ['around', 'ADP', 8, 'pobj', 9], ['…', 'PUNCT', 3, 'punct', 10]]])],\n",
       "       ['red cross',\n",
       "        'Met Reyna and her whole family who evacuated from the coast to a Red Cross shelter in Wilson, NC. She says they left everything behind, so they are hoping to have something to go back to. #hurricaneflorence <URL>',\n",
       "        list([[['Met', 'PROPN', 1, 'compound', 0], ['Reyna', 'PROPN', 1, 'ROOT', 1], ['and', 'CCONJ', 1, 'cc', 2], ['her', 'ADJ', 5, 'poss', 3], ['whole', 'ADJ', 5, 'amod', 4], ['family', 'NOUN', 1, 'conj', 5], ['who', 'NOUN', 7, 'nsubj', 6], ['evacuated', 'VERB', 5, 'relcl', 7], ['from', 'ADP', 7, 'prep', 8], ['the', 'DET', 10, 'det', 9], ['coast', 'NOUN', 8, 'pobj', 10], ['to', 'ADP', 7, 'prep', 11], ['a', 'DET', 15, 'det', 12], ['Red', 'PROPN', 14, 'compound', 13], ['Cross', 'PROPN', 15, 'compound', 14], ['shelter', 'NOUN', 11, 'pobj', 15], ['in', 'ADP', 15, 'prep', 16], ['Wilson', 'PROPN', 18, 'compound', 17], ['NC', 'PROPN', 16, 'pobj', 18], ['.', 'PUNCT', 1, 'punct', 19]], [['She', 'PRON', 1, 'nsubj', 0], ['says', 'VERB', 1, 'ROOT', 1], ['they', 'PRON', 3, 'nsubj', 2], ['left', 'VERB', 1, 'ccomp', 3], ['everything', 'NOUN', 3, 'dobj', 4], ['behind', 'ADV', 3, 'prt', 5], ['so', 'ADP', 9, 'mark', 6], ['they', 'PRON', 9, 'nsubj', 7], ['are', 'VERB', 9, 'aux', 8], ['hoping', 'VERB', 3, 'advcl', 9], ['to', 'PART', 11, 'aux', 10], ['have', 'VERB', 9, 'xcomp', 11], ['something', 'NOUN', 11, 'dobj', 12], ['to', 'PART', 14, 'aux', 13], ['go', 'VERB', 12, 'relcl', 14], ['back', 'ADV', 14, 'advmod', 15], ['to', 'ADP', 15, 'prep', 16], ['.', 'PUNCT', 1, 'punct', 17]], [['#hurricaneflorence', 'PROPN', 0, 'ROOT', 0]]])],\n",
       "       ['columbus',\n",
       "        'Yesterday, our crews teamed up with @insideFPL to assess damage throughout Columbus and Bladen counties in North Carolina. Crews continue to work through challenging conditions to restore power to customers impacted by #Florence . Track progress: <URL>',\n",
       "        list([[['Yesterday', 'NOUN', 3, 'npadvmod', 0], ['our', 'ADJ', 2, 'poss', 1], ['crews', 'NOUN', 3, 'nsubj', 2], ['teamed', 'VERB', 3, 'ROOT', 3], ['up', 'PART', 3, 'prt', 4], ['with', 'ADP', 3, 'prep', 5], ['@insideFPL', 'NOUN', 5, 'pobj', 6], ['to', 'PART', 8, 'aux', 7], ['assess', 'VERB', 3, 'advcl', 8], ['damage', 'NOUN', 8, 'dobj', 9], ['throughout', 'ADP', 9, 'prep', 10], ['Columbus', 'PROPN', 14, 'nmod', 11], ['and', 'CCONJ', 11, 'cc', 12], ['Bladen', 'PROPN', 11, 'conj', 13], ['counties', 'NOUN', 10, 'pobj', 14], ['in', 'ADP', 14, 'prep', 15], ['North', 'PROPN', 17, 'compound', 16], ['Carolina', 'PROPN', 15, 'pobj', 17], ['.', 'PUNCT', 3, 'punct', 18]], [['Crews', 'NOUN', 1, 'nsubj', 0], ['continue', 'VERB', 1, 'ROOT', 1], ['to', 'PART', 3, 'aux', 2], ['work', 'VERB', 1, 'xcomp', 3], ['through', 'ADP', 3, 'prep', 4], ['challenging', 'ADJ', 6, 'amod', 5], ['conditions', 'NOUN', 4, 'pobj', 6], ['to', 'PART', 8, 'aux', 7], ['restore', 'VERB', 6, 'acl', 8], ['power', 'NOUN', 8, 'dobj', 9], ['to', 'ADP', 8, 'prep', 10], ['customers', 'NOUN', 10, 'pobj', 11], ['impacted', 'VERB', 11, 'acl', 12], ['by', 'ADP', 12, 'agent', 13], ['#Florence', 'PROPN', 13, 'pobj', 14], ['.', 'PUNCT', 1, 'punct', 15]], [['Track', 'NOUN', 1, 'compound', 0], ['progress', 'NOUN', 1, 'ROOT', 1], [':', 'PUNCT', 1, 'punct', 2]]])],\n",
       "       ['williamstown',\n",
       "        '@weatherchannel this is from Williamstown, MA. Our bridge is about to get wiped out! Even Mass is being affected by #Florence <URL>',\n",
       "        list([[['@weatherchannel', 'PROPN', 2, 'punct', 0], ['this', 'DET', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['from', 'ADP', 2, 'prep', 3], ['Williamstown', 'PROPN', 5, 'compound', 4], ['MA', 'PROPN', 3, 'pobj', 5], ['.', 'PUNCT', 2, 'punct', 6]], [['Our', 'ADJ', 1, 'poss', 0], ['bridge', 'NOUN', 2, 'nsubj', 1], ['is', 'VERB', 2, 'ROOT', 2], ['about', 'ADJ', 2, 'acomp', 3], ['to', 'PART', 6, 'aux', 4], ['get', 'VERB', 6, 'auxpass', 5], ['wiped', 'VERB', 3, 'xcomp', 6], ['out', 'PART', 6, 'prt', 7], ['!', 'PUNCT', 2, 'punct', 8]], [['Even', 'ADV', 1, 'advmod', 0], ['Mass', 'PROPN', 4, 'nsubjpass', 1], ['is', 'VERB', 4, 'aux', 2], ['being', 'VERB', 4, 'auxpass', 3], ['affected', 'VERB', 4, 'ROOT', 4], ['by', 'ADP', 4, 'agent', 5], ['#Florence', 'PROPN', 5, 'pobj', 6]]])],\n",
       "       ['red cross',\n",
       "        'Eat at #beachsidebistro and 10% of your purchase will be donated to the Red Cross of North Carolina to help our fellow #northcarolinians affected by #hurricaneflorence #foodforflo … <URL>',\n",
       "        list([[['Eat', 'VERB', 0, 'ROOT', 0], ['at', 'ADP', 0, 'prep', 1], ['#beachsidebistro', 'PROPN', 1, 'pobj', 2], ['and', 'CCONJ', 0, 'cc', 3], ['10', 'NUM', 5, 'nummod', 4], ['%', 'NOUN', 11, 'nsubjpass', 5], ['of', 'ADP', 5, 'prep', 6], ['your', 'ADJ', 8, 'poss', 7], ['purchase', 'NOUN', 6, 'pobj', 8], ['will', 'VERB', 11, 'aux', 9], ['be', 'VERB', 11, 'auxpass', 10], ['donated', 'VERB', 0, 'conj', 11], ['to', 'ADP', 11, 'prep', 12], ['the', 'DET', 15, 'det', 13], ['Red', 'PROPN', 15, 'compound', 14], ['Cross', 'PROPN', 12, 'pobj', 15], ['of', 'ADP', 15, 'prep', 16], ['North', 'PROPN', 18, 'compound', 17], ['Carolina', 'PROPN', 16, 'pobj', 18], ['to', 'PART', 20, 'aux', 19], ['help', 'VERB', 11, 'advcl', 20], ['our', 'ADJ', 23, 'poss', 21], ['fellow', 'ADJ', 23, 'amod', 22], ['#northcarolinians', 'NOUN', 24, 'nsubj', 23], ['affected', 'VERB', 20, 'ccomp', 24], ['by', 'ADP', 24, 'agent', 25], ['#hurricaneflorence', 'NOUN', 27, 'compound', 26], ['#foodforflo', 'PROPN', 25, 'pobj', 27], ['…', 'PUNCT', 11, 'punct', 28]]])]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor_types = state,descriptor,compound,list, P=0.843, R=0.896\n"
     ]
    }
   ],
   "source": [
    "# anchor_types_to_use = [['state'], ['descriptor', 'state'], ['descriptor', 'state', 'compound'], ['descriptor', 'state', 'list'], ['descriptor', 'state', 'compound', 'list']]\n",
    "anchor_types_to_use = [['state', 'descriptor', 'compound', 'list']]\n",
    "for anchor_types_to_use_i in anchor_types_to_use:\n",
    "    prec, rec, pred_data = detect_anchor_prec_recall(annotated_data_parsed, anchor_types_to_use=anchor_types_to_use_i)\n",
    "    print('anchor_types = %s, P=%.3f, R=%.3f'%(','.join(anchor_types_to_use_i), prec, rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model|P|R\n",
    "---|---|---\n",
    "state+descriptor|0.988|0.833\n",
    "state+descriptor+compound|0.966|0.875\n",
    "state+descriptor+conjunction|0.976|0.865\n",
    "state+descriptor+compound+conjunction|0.966|0.875\n",
    "state+descriptor+compound_lax+conjunction|0.843|0.896\n",
    "\n",
    "For \"compound_lax\" we try to find any anchor (\"[Beaufort]_1 [Colleton County]_2\") in the NE parent subtree; for \"compound\" we only try to find a state anchor. Unsurprisingly the \"compound_lax\" strategy improves recall at the cost of precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
